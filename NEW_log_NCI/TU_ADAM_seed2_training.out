2021-12-12 22:59:37,451 load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 256, 768])
load_pretrained: grid-size from 14 to 16
2021-12-12 22:59:41,746 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:59:41,747 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:59:41,747 ============================================================
2021-12-12 22:59:41,747 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-12 22:59:41,747 ============================================================
2021-12-12 22:59:41,747 Loading data...
2021-12-12 22:59:41,747 Reading NCI - RUNMC images...
2021-12-12 22:59:41,747 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-12 22:59:41,875 Already preprocessed this configuration. Loading now!
2021-12-12 22:59:41,894 Training Images: (256, 256, 286)
2021-12-12 22:59:41,894 Training Labels: (256, 256, 286)
2021-12-12 22:59:41,894 Validation Images: (256, 256, 98)
2021-12-12 22:59:41,894 Validation Labels: (256, 256, 98)
2021-12-12 22:59:41,894 ============================================================
2021-12-12 22:59:41,943 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-12 22:59:44,778 iteration 1 : loss : 1.072302, loss_ce: 1.372232
2021-12-12 22:59:46,107 iteration 2 : loss : 0.949348, loss_ce: 1.192785
2021-12-12 22:59:47,509 iteration 3 : loss : 0.925266, loss_ce: 1.144689
2021-12-12 22:59:48,859 iteration 4 : loss : 0.876411, loss_ce: 1.059615
2021-12-12 22:59:50,141 iteration 5 : loss : 0.849813, loss_ce: 0.999345
2021-12-12 22:59:51,476 iteration 6 : loss : 0.748407, loss_ce: 0.860250
2021-12-12 22:59:52,846 iteration 7 : loss : 0.697888, loss_ce: 0.782946
2021-12-12 22:59:54,281 iteration 8 : loss : 0.664384, loss_ce: 0.723985
2021-12-12 22:59:55,582 iteration 9 : loss : 0.660183, loss_ce: 0.689436
2021-12-12 22:59:56,885 iteration 10 : loss : 0.629596, loss_ce: 0.644354
2021-12-12 22:59:58,174 iteration 11 : loss : 0.588907, loss_ce: 0.591443
2021-12-12 22:59:59,513 iteration 12 : loss : 0.537545, loss_ce: 0.540350
2021-12-12 23:00:00,906 iteration 13 : loss : 0.506722, loss_ce: 0.507630
2021-12-12 23:00:02,203 iteration 14 : loss : 0.492227, loss_ce: 0.472944
2021-12-12 23:00:03,591 iteration 15 : loss : 0.464452, loss_ce: 0.434724
2021-12-12 23:00:04,923 iteration 16 : loss : 0.449581, loss_ce: 0.404381
2021-12-12 23:00:06,248 iteration 17 : loss : 0.422487, loss_ce: 0.384667
  0%|                               | 1/400 [00:24<2:42:06, 24.38s/it]2021-12-12 23:00:07,633 iteration 18 : loss : 0.422226, loss_ce: 0.353990
2021-12-12 23:00:08,990 iteration 19 : loss : 0.379312, loss_ce: 0.315708
2021-12-12 23:00:10,329 iteration 20 : loss : 0.362059, loss_ce: 0.297727
2021-12-12 23:00:11,737 iteration 21 : loss : 0.366625, loss_ce: 0.282936
2021-12-12 23:00:13,067 iteration 22 : loss : 0.339129, loss_ce: 0.255428
2021-12-12 23:00:14,426 iteration 23 : loss : 0.325005, loss_ce: 0.236001
2021-12-12 23:00:15,721 iteration 24 : loss : 0.295467, loss_ce: 0.222462
2021-12-12 23:00:16,976 iteration 25 : loss : 0.280867, loss_ce: 0.197046
2021-12-12 23:00:18,269 iteration 26 : loss : 0.273585, loss_ce: 0.180074
2021-12-12 23:00:19,618 iteration 27 : loss : 0.274369, loss_ce: 0.179917
2021-12-12 23:00:20,944 iteration 28 : loss : 0.281023, loss_ce: 0.170892
2021-12-12 23:00:22,411 iteration 29 : loss : 0.251843, loss_ce: 0.159570
2021-12-12 23:00:23,799 iteration 30 : loss : 0.276858, loss_ce: 0.164461
2021-12-12 23:00:25,101 iteration 31 : loss : 0.232458, loss_ce: 0.141712
2021-12-12 23:00:26,430 iteration 32 : loss : 0.242746, loss_ce: 0.142128
2021-12-12 23:00:27,846 iteration 33 : loss : 0.247261, loss_ce: 0.140656
2021-12-12 23:00:29,166 iteration 34 : loss : 0.228692, loss_ce: 0.113813
  0%|▏                              | 2/400 [00:47<2:35:52, 23.50s/it]2021-12-12 23:00:30,596 iteration 35 : loss : 0.219393, loss_ce: 0.129394
2021-12-12 23:00:31,954 iteration 36 : loss : 0.211235, loss_ce: 0.112768
2021-12-12 23:00:33,344 iteration 37 : loss : 0.198232, loss_ce: 0.108553
2021-12-12 23:00:34,800 iteration 38 : loss : 0.241656, loss_ce: 0.117514
2021-12-12 23:00:36,161 iteration 39 : loss : 0.205958, loss_ce: 0.095228
2021-12-12 23:00:37,560 iteration 40 : loss : 0.244501, loss_ce: 0.131841
2021-12-12 23:00:38,863 iteration 41 : loss : 0.187107, loss_ce: 0.079926
2021-12-12 23:00:40,339 iteration 42 : loss : 0.220863, loss_ce: 0.108755
2021-12-12 23:00:41,641 iteration 43 : loss : 0.206963, loss_ce: 0.082986
2021-12-12 23:00:43,019 iteration 44 : loss : 0.191765, loss_ce: 0.087612
2021-12-12 23:00:44,413 iteration 45 : loss : 0.224088, loss_ce: 0.098159
2021-12-12 23:00:45,685 iteration 46 : loss : 0.209450, loss_ce: 0.088655
2021-12-12 23:00:47,026 iteration 47 : loss : 0.211640, loss_ce: 0.074411
2021-12-12 23:00:48,407 iteration 48 : loss : 0.212099, loss_ce: 0.102101
2021-12-12 23:00:49,772 iteration 49 : loss : 0.221135, loss_ce: 0.097753
2021-12-12 23:00:51,193 iteration 50 : loss : 0.193379, loss_ce: 0.075625
2021-12-12 23:00:52,634 iteration 51 : loss : 0.168822, loss_ce: 0.081471
  1%|▏                              | 3/400 [01:10<2:35:23, 23.48s/it]2021-12-12 23:00:54,049 iteration 52 : loss : 0.205248, loss_ce: 0.097115
2021-12-12 23:00:55,433 iteration 53 : loss : 0.175175, loss_ce: 0.081084
2021-12-12 23:00:56,923 iteration 54 : loss : 0.175028, loss_ce: 0.080411
2021-12-12 23:00:58,378 iteration 55 : loss : 0.199382, loss_ce: 0.085300
2021-12-12 23:00:59,845 iteration 56 : loss : 0.196519, loss_ce: 0.077713
2021-12-12 23:01:01,299 iteration 57 : loss : 0.180885, loss_ce: 0.075240
2021-12-12 23:01:02,741 iteration 58 : loss : 0.183937, loss_ce: 0.083934
2021-12-12 23:01:04,167 iteration 59 : loss : 0.206122, loss_ce: 0.075074
2021-12-12 23:01:05,658 iteration 60 : loss : 0.177596, loss_ce: 0.065570
2021-12-12 23:01:07,149 iteration 61 : loss : 0.164797, loss_ce: 0.068261
2021-12-12 23:01:08,574 iteration 62 : loss : 0.191431, loss_ce: 0.064141
2021-12-12 23:01:09,942 iteration 63 : loss : 0.187031, loss_ce: 0.082512
2021-12-12 23:01:11,371 iteration 64 : loss : 0.191627, loss_ce: 0.083600
2021-12-12 23:01:12,793 iteration 65 : loss : 0.206466, loss_ce: 0.084312
2021-12-12 23:01:14,275 iteration 66 : loss : 0.162011, loss_ce: 0.063950
2021-12-12 23:01:15,659 iteration 67 : loss : 0.196153, loss_ce: 0.084161
2021-12-12 23:01:17,082 iteration 68 : loss : 0.210025, loss_ce: 0.073140
  1%|▎                              | 4/400 [01:35<2:37:30, 23.87s/it]2021-12-12 23:01:18,553 iteration 69 : loss : 0.188211, loss_ce: 0.071821
2021-12-12 23:01:20,008 iteration 70 : loss : 0.185185, loss_ce: 0.076240
2021-12-12 23:01:21,401 iteration 71 : loss : 0.184707, loss_ce: 0.072026
2021-12-12 23:01:22,888 iteration 72 : loss : 0.175615, loss_ce: 0.059171
2021-12-12 23:01:24,312 iteration 73 : loss : 0.182063, loss_ce: 0.077145
2021-12-12 23:01:25,810 iteration 74 : loss : 0.171186, loss_ce: 0.070086
2021-12-12 23:01:27,240 iteration 75 : loss : 0.186008, loss_ce: 0.085246
2021-12-12 23:01:28,718 iteration 76 : loss : 0.179051, loss_ce: 0.075497
2021-12-12 23:01:30,231 iteration 77 : loss : 0.185053, loss_ce: 0.074254
2021-12-12 23:01:31,718 iteration 78 : loss : 0.149770, loss_ce: 0.067827
2021-12-12 23:01:33,122 iteration 79 : loss : 0.158406, loss_ce: 0.059725
2021-12-12 23:01:34,603 iteration 80 : loss : 0.195659, loss_ce: 0.078635
2021-12-12 23:01:36,023 iteration 81 : loss : 0.142795, loss_ce: 0.054682
2021-12-12 23:01:37,460 iteration 82 : loss : 0.192804, loss_ce: 0.088138
2021-12-12 23:01:38,954 iteration 83 : loss : 0.136092, loss_ce: 0.049194
2021-12-12 23:01:40,354 iteration 84 : loss : 0.141019, loss_ce: 0.058101
2021-12-12 23:01:40,354 Training Data Eval:
2021-12-12 23:01:47,790   Average segmentation loss on training set: 0.1511
2021-12-12 23:01:47,791 Validation Data Eval:
2021-12-12 23:01:50,491   Average segmentation loss on validation set: 0.2211
2021-12-12 23:01:57,183 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:01:58,602 iteration 85 : loss : 0.143437, loss_ce: 0.061685
  1%|▍                              | 5/400 [02:16<3:19:01, 30.23s/it]2021-12-12 23:01:59,979 iteration 86 : loss : 0.179828, loss_ce: 0.063377
2021-12-12 23:02:01,255 iteration 87 : loss : 0.148959, loss_ce: 0.057764
2021-12-12 23:02:02,580 iteration 88 : loss : 0.152693, loss_ce: 0.052844
2021-12-12 23:02:03,994 iteration 89 : loss : 0.144571, loss_ce: 0.055742
2021-12-12 23:02:05,321 iteration 90 : loss : 0.130909, loss_ce: 0.050597
2021-12-12 23:02:06,702 iteration 91 : loss : 0.152896, loss_ce: 0.058532
2021-12-12 23:02:08,052 iteration 92 : loss : 0.140161, loss_ce: 0.060011
2021-12-12 23:02:09,485 iteration 93 : loss : 0.111995, loss_ce: 0.046458
2021-12-12 23:02:10,925 iteration 94 : loss : 0.131964, loss_ce: 0.059525
2021-12-12 23:02:12,275 iteration 95 : loss : 0.197586, loss_ce: 0.079369
2021-12-12 23:02:13,605 iteration 96 : loss : 0.103692, loss_ce: 0.039003
2021-12-12 23:02:14,998 iteration 97 : loss : 0.103758, loss_ce: 0.043387
2021-12-12 23:02:16,460 iteration 98 : loss : 0.155249, loss_ce: 0.064079
2021-12-12 23:02:18,049 iteration 99 : loss : 0.131259, loss_ce: 0.052084
2021-12-12 23:02:19,638 iteration 100 : loss : 0.169400, loss_ce: 0.075208
2021-12-12 23:02:21,059 iteration 101 : loss : 0.125691, loss_ce: 0.051861
2021-12-12 23:02:22,514 iteration 102 : loss : 0.130688, loss_ce: 0.045819
  2%|▍                              | 6/400 [02:40<3:04:25, 28.09s/it]2021-12-12 23:02:24,028 iteration 103 : loss : 0.112817, loss_ce: 0.040827
2021-12-12 23:02:25,544 iteration 104 : loss : 0.137269, loss_ce: 0.058202
2021-12-12 23:02:27,020 iteration 105 : loss : 0.128985, loss_ce: 0.052371
2021-12-12 23:02:28,497 iteration 106 : loss : 0.128757, loss_ce: 0.047284
2021-12-12 23:02:30,034 iteration 107 : loss : 0.143440, loss_ce: 0.053552
2021-12-12 23:02:31,484 iteration 108 : loss : 0.123723, loss_ce: 0.053528
2021-12-12 23:02:32,963 iteration 109 : loss : 0.108314, loss_ce: 0.043342
2021-12-12 23:02:34,463 iteration 110 : loss : 0.135594, loss_ce: 0.059779
2021-12-12 23:02:36,089 iteration 111 : loss : 0.159704, loss_ce: 0.078085
2021-12-12 23:02:37,508 iteration 112 : loss : 0.134232, loss_ce: 0.050090
2021-12-12 23:02:39,068 iteration 113 : loss : 0.110858, loss_ce: 0.044578
2021-12-12 23:02:40,548 iteration 114 : loss : 0.152657, loss_ce: 0.049030
2021-12-12 23:02:41,948 iteration 115 : loss : 0.122800, loss_ce: 0.047668
2021-12-12 23:02:43,423 iteration 116 : loss : 0.130430, loss_ce: 0.043872
2021-12-12 23:02:44,852 iteration 117 : loss : 0.138248, loss_ce: 0.059635
2021-12-12 23:02:46,370 iteration 118 : loss : 0.174601, loss_ce: 0.075904
2021-12-12 23:02:47,813 iteration 119 : loss : 0.145718, loss_ce: 0.066589
  2%|▌                              | 7/400 [03:05<2:57:59, 27.17s/it]2021-12-12 23:02:49,379 iteration 120 : loss : 0.122706, loss_ce: 0.058176
2021-12-12 23:02:50,871 iteration 121 : loss : 0.142267, loss_ce: 0.064403
2021-12-12 23:02:52,240 iteration 122 : loss : 0.114238, loss_ce: 0.047829
2021-12-12 23:02:53,705 iteration 123 : loss : 0.147819, loss_ce: 0.059963
2021-12-12 23:02:55,133 iteration 124 : loss : 0.143513, loss_ce: 0.050355
2021-12-12 23:02:56,588 iteration 125 : loss : 0.162585, loss_ce: 0.058926
2021-12-12 23:02:58,037 iteration 126 : loss : 0.126162, loss_ce: 0.061931
2021-12-12 23:02:59,504 iteration 127 : loss : 0.121177, loss_ce: 0.049609
2021-12-12 23:03:00,944 iteration 128 : loss : 0.130027, loss_ce: 0.054231
2021-12-12 23:03:02,461 iteration 129 : loss : 0.137278, loss_ce: 0.049398
2021-12-12 23:03:03,818 iteration 130 : loss : 0.120438, loss_ce: 0.046716
2021-12-12 23:03:05,268 iteration 131 : loss : 0.130292, loss_ce: 0.053906
2021-12-12 23:03:06,751 iteration 132 : loss : 0.090162, loss_ce: 0.037457
2021-12-12 23:03:08,220 iteration 133 : loss : 0.131000, loss_ce: 0.070285
2021-12-12 23:03:09,665 iteration 134 : loss : 0.142382, loss_ce: 0.056861
2021-12-12 23:03:11,100 iteration 135 : loss : 0.117412, loss_ce: 0.040342
2021-12-12 23:03:12,632 iteration 136 : loss : 0.104047, loss_ce: 0.047159
  2%|▌                              | 8/400 [03:30<2:52:37, 26.42s/it]2021-12-12 23:03:14,203 iteration 137 : loss : 0.092080, loss_ce: 0.033116
2021-12-12 23:03:15,598 iteration 138 : loss : 0.111496, loss_ce: 0.045205
2021-12-12 23:03:17,145 iteration 139 : loss : 0.113645, loss_ce: 0.034502
2021-12-12 23:03:18,607 iteration 140 : loss : 0.141312, loss_ce: 0.054398
2021-12-12 23:03:20,022 iteration 141 : loss : 0.129773, loss_ce: 0.047716
2021-12-12 23:03:21,477 iteration 142 : loss : 0.134151, loss_ce: 0.063282
2021-12-12 23:03:22,950 iteration 143 : loss : 0.097654, loss_ce: 0.041196
2021-12-12 23:03:24,395 iteration 144 : loss : 0.138748, loss_ce: 0.050349
2021-12-12 23:03:25,861 iteration 145 : loss : 0.112647, loss_ce: 0.052625
2021-12-12 23:03:27,362 iteration 146 : loss : 0.111613, loss_ce: 0.048403
2021-12-12 23:03:28,850 iteration 147 : loss : 0.126191, loss_ce: 0.051095
2021-12-12 23:03:30,411 iteration 148 : loss : 0.129282, loss_ce: 0.050255
2021-12-12 23:03:31,950 iteration 149 : loss : 0.101552, loss_ce: 0.037070
2021-12-12 23:03:33,480 iteration 150 : loss : 0.139529, loss_ce: 0.050594
2021-12-12 23:03:34,894 iteration 151 : loss : 0.099698, loss_ce: 0.050546
2021-12-12 23:03:36,278 iteration 152 : loss : 0.084333, loss_ce: 0.041267
2021-12-12 23:03:37,729 iteration 153 : loss : 0.120370, loss_ce: 0.042655
  2%|▋                              | 9/400 [03:55<2:49:28, 26.01s/it]2021-12-12 23:03:39,266 iteration 154 : loss : 0.105255, loss_ce: 0.046476
2021-12-12 23:03:40,719 iteration 155 : loss : 0.087089, loss_ce: 0.038893
2021-12-12 23:03:42,152 iteration 156 : loss : 0.089994, loss_ce: 0.037354
2021-12-12 23:03:43,584 iteration 157 : loss : 0.080032, loss_ce: 0.034015
2021-12-12 23:03:45,099 iteration 158 : loss : 0.099356, loss_ce: 0.040000
2021-12-12 23:03:46,595 iteration 159 : loss : 0.080495, loss_ce: 0.032408
2021-12-12 23:03:48,038 iteration 160 : loss : 0.104272, loss_ce: 0.042900
2021-12-12 23:03:49,592 iteration 161 : loss : 0.089071, loss_ce: 0.040762
2021-12-12 23:03:51,055 iteration 162 : loss : 0.137512, loss_ce: 0.045252
2021-12-12 23:03:52,525 iteration 163 : loss : 0.177410, loss_ce: 0.065906
2021-12-12 23:03:53,983 iteration 164 : loss : 0.093088, loss_ce: 0.034425
2021-12-12 23:03:55,399 iteration 165 : loss : 0.081092, loss_ce: 0.035562
2021-12-12 23:03:56,898 iteration 166 : loss : 0.130859, loss_ce: 0.075683
2021-12-12 23:03:58,463 iteration 167 : loss : 0.099280, loss_ce: 0.039997
2021-12-12 23:03:59,917 iteration 168 : loss : 0.098352, loss_ce: 0.033072
2021-12-12 23:04:01,411 iteration 169 : loss : 0.129900, loss_ce: 0.048316
2021-12-12 23:04:01,412 Training Data Eval:
2021-12-12 23:04:08,906   Average segmentation loss on training set: 0.3604
2021-12-12 23:04:08,906 Validation Data Eval:
2021-12-12 23:04:11,497   Average segmentation loss on validation set: 0.3469
2021-12-12 23:04:13,048 iteration 170 : loss : 0.110969, loss_ce: 0.043938
  2%|▊                             | 10/400 [04:31<3:07:43, 28.88s/it]2021-12-12 23:04:14,616 iteration 171 : loss : 0.082169, loss_ce: 0.037190
2021-12-12 23:04:16,029 iteration 172 : loss : 0.111545, loss_ce: 0.048564
2021-12-12 23:04:17,554 iteration 173 : loss : 0.140266, loss_ce: 0.065812
2021-12-12 23:04:18,956 iteration 174 : loss : 0.079389, loss_ce: 0.035676
2021-12-12 23:04:20,411 iteration 175 : loss : 0.127825, loss_ce: 0.054129
2021-12-12 23:04:21,853 iteration 176 : loss : 0.079391, loss_ce: 0.034938
2021-12-12 23:04:23,347 iteration 177 : loss : 0.077774, loss_ce: 0.033684
2021-12-12 23:04:24,808 iteration 178 : loss : 0.092643, loss_ce: 0.031722
2021-12-12 23:04:26,202 iteration 179 : loss : 0.078840, loss_ce: 0.028878
2021-12-12 23:04:27,757 iteration 180 : loss : 0.106329, loss_ce: 0.047041
2021-12-12 23:04:29,253 iteration 181 : loss : 0.090615, loss_ce: 0.043573
2021-12-12 23:04:30,707 iteration 182 : loss : 0.093799, loss_ce: 0.041242
2021-12-12 23:04:32,187 iteration 183 : loss : 0.105119, loss_ce: 0.036535
2021-12-12 23:04:33,778 iteration 184 : loss : 0.162146, loss_ce: 0.055212
2021-12-12 23:04:35,351 iteration 185 : loss : 0.102706, loss_ce: 0.043991
2021-12-12 23:04:36,798 iteration 186 : loss : 0.100093, loss_ce: 0.029129
2021-12-12 23:04:38,286 iteration 187 : loss : 0.070833, loss_ce: 0.030075
  3%|▊                             | 11/400 [04:56<3:00:01, 27.77s/it]2021-12-12 23:04:39,740 iteration 188 : loss : 0.107256, loss_ce: 0.037913
2021-12-12 23:04:41,278 iteration 189 : loss : 0.113004, loss_ce: 0.044136
2021-12-12 23:04:42,772 iteration 190 : loss : 0.130119, loss_ce: 0.060305
2021-12-12 23:04:44,244 iteration 191 : loss : 0.096316, loss_ce: 0.040941
2021-12-12 23:04:45,695 iteration 192 : loss : 0.118376, loss_ce: 0.039357
2021-12-12 23:04:47,098 iteration 193 : loss : 0.086241, loss_ce: 0.038243
2021-12-12 23:04:48,595 iteration 194 : loss : 0.096504, loss_ce: 0.040042
2021-12-12 23:04:50,098 iteration 195 : loss : 0.096896, loss_ce: 0.040216
2021-12-12 23:04:51,558 iteration 196 : loss : 0.114700, loss_ce: 0.050688
2021-12-12 23:04:53,062 iteration 197 : loss : 0.110154, loss_ce: 0.040747
2021-12-12 23:04:54,530 iteration 198 : loss : 0.105323, loss_ce: 0.036607
2021-12-12 23:04:55,912 iteration 199 : loss : 0.110814, loss_ce: 0.034571
2021-12-12 23:04:57,375 iteration 200 : loss : 0.073617, loss_ce: 0.035588
2021-12-12 23:04:58,951 iteration 201 : loss : 0.114124, loss_ce: 0.050587
2021-12-12 23:05:00,385 iteration 202 : loss : 0.085172, loss_ce: 0.034741
2021-12-12 23:05:01,810 iteration 203 : loss : 0.115514, loss_ce: 0.060573
2021-12-12 23:05:03,201 iteration 204 : loss : 0.076874, loss_ce: 0.035641
  3%|▉                             | 12/400 [05:21<2:53:57, 26.90s/it]2021-12-12 23:05:04,653 iteration 205 : loss : 0.086148, loss_ce: 0.035017
2021-12-12 23:05:06,139 iteration 206 : loss : 0.109709, loss_ce: 0.045985
2021-12-12 23:05:07,695 iteration 207 : loss : 0.097395, loss_ce: 0.041964
2021-12-12 23:05:09,234 iteration 208 : loss : 0.088326, loss_ce: 0.034209
2021-12-12 23:05:10,640 iteration 209 : loss : 0.077855, loss_ce: 0.032019
2021-12-12 23:05:12,042 iteration 210 : loss : 0.095273, loss_ce: 0.033788
2021-12-12 23:05:13,512 iteration 211 : loss : 0.112144, loss_ce: 0.039939
2021-12-12 23:05:14,894 iteration 212 : loss : 0.120642, loss_ce: 0.033479
2021-12-12 23:05:16,398 iteration 213 : loss : 0.090236, loss_ce: 0.036763
2021-12-12 23:05:17,872 iteration 214 : loss : 0.126423, loss_ce: 0.044066
2021-12-12 23:05:19,278 iteration 215 : loss : 0.123464, loss_ce: 0.042647
2021-12-12 23:05:20,802 iteration 216 : loss : 0.096018, loss_ce: 0.034575
2021-12-12 23:05:22,232 iteration 217 : loss : 0.068661, loss_ce: 0.032930
2021-12-12 23:05:23,675 iteration 218 : loss : 0.088326, loss_ce: 0.032581
2021-12-12 23:05:25,126 iteration 219 : loss : 0.071444, loss_ce: 0.023614
2021-12-12 23:05:26,543 iteration 220 : loss : 0.112044, loss_ce: 0.056805
2021-12-12 23:05:27,994 iteration 221 : loss : 0.111712, loss_ce: 0.057621
  3%|▉                             | 13/400 [05:46<2:49:23, 26.26s/it]2021-12-12 23:05:29,601 iteration 222 : loss : 0.090752, loss_ce: 0.032532
2021-12-12 23:05:31,087 iteration 223 : loss : 0.078302, loss_ce: 0.029689
2021-12-12 23:05:32,457 iteration 224 : loss : 0.122759, loss_ce: 0.061538
2021-12-12 23:05:33,970 iteration 225 : loss : 0.088457, loss_ce: 0.031869
2021-12-12 23:05:35,475 iteration 226 : loss : 0.111387, loss_ce: 0.034044
2021-12-12 23:05:36,973 iteration 227 : loss : 0.085146, loss_ce: 0.036629
2021-12-12 23:05:38,447 iteration 228 : loss : 0.089889, loss_ce: 0.034741
2021-12-12 23:05:39,920 iteration 229 : loss : 0.114470, loss_ce: 0.049652
2021-12-12 23:05:41,374 iteration 230 : loss : 0.115943, loss_ce: 0.046226
2021-12-12 23:05:42,809 iteration 231 : loss : 0.132609, loss_ce: 0.038432
2021-12-12 23:05:44,346 iteration 232 : loss : 0.093399, loss_ce: 0.049791
2021-12-12 23:05:45,864 iteration 233 : loss : 0.099927, loss_ce: 0.045720
2021-12-12 23:05:47,353 iteration 234 : loss : 0.098782, loss_ce: 0.033000
2021-12-12 23:05:48,800 iteration 235 : loss : 0.071782, loss_ce: 0.027556
2021-12-12 23:05:50,227 iteration 236 : loss : 0.078329, loss_ce: 0.035563
2021-12-12 23:05:51,649 iteration 237 : loss : 0.074519, loss_ce: 0.031634
2021-12-12 23:05:53,022 iteration 238 : loss : 0.081037, loss_ce: 0.035309
  4%|█                             | 14/400 [06:11<2:46:32, 25.89s/it]2021-12-12 23:05:54,490 iteration 239 : loss : 0.077811, loss_ce: 0.030111
2021-12-12 23:05:56,015 iteration 240 : loss : 0.153409, loss_ce: 0.091536
2021-12-12 23:05:57,434 iteration 241 : loss : 0.110156, loss_ce: 0.035552
2021-12-12 23:05:58,958 iteration 242 : loss : 0.084131, loss_ce: 0.037831
2021-12-12 23:06:00,477 iteration 243 : loss : 0.093254, loss_ce: 0.041555
2021-12-12 23:06:01,991 iteration 244 : loss : 0.089174, loss_ce: 0.041200
2021-12-12 23:06:03,390 iteration 245 : loss : 0.083230, loss_ce: 0.030839
2021-12-12 23:06:04,870 iteration 246 : loss : 0.093050, loss_ce: 0.036670
2021-12-12 23:06:06,292 iteration 247 : loss : 0.073304, loss_ce: 0.030291
2021-12-12 23:06:07,681 iteration 248 : loss : 0.089352, loss_ce: 0.037339
2021-12-12 23:06:09,235 iteration 249 : loss : 0.082035, loss_ce: 0.031836
2021-12-12 23:06:10,736 iteration 250 : loss : 0.089364, loss_ce: 0.037367
2021-12-12 23:06:12,176 iteration 251 : loss : 0.070523, loss_ce: 0.028728
2021-12-12 23:06:13,633 iteration 252 : loss : 0.099392, loss_ce: 0.048499
2021-12-12 23:06:15,039 iteration 253 : loss : 0.094657, loss_ce: 0.030938
2021-12-12 23:06:16,444 iteration 254 : loss : 0.071882, loss_ce: 0.026493
2021-12-12 23:06:16,444 Training Data Eval:
2021-12-12 23:06:23,945   Average segmentation loss on training set: 0.0831
2021-12-12 23:06:23,945 Validation Data Eval:
2021-12-12 23:06:26,536   Average segmentation loss on validation set: 0.1309
2021-12-12 23:06:33,033 Found new lowest validation loss at iteration 254! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:06:34,413 iteration 255 : loss : 0.071856, loss_ce: 0.025756
  4%|█▏                            | 15/400 [06:52<3:16:05, 30.56s/it]2021-12-12 23:06:35,810 iteration 256 : loss : 0.085328, loss_ce: 0.031715
2021-12-12 23:06:37,151 iteration 257 : loss : 0.098829, loss_ce: 0.056019
2021-12-12 23:06:38,633 iteration 258 : loss : 0.097729, loss_ce: 0.031786
2021-12-12 23:06:39,943 iteration 259 : loss : 0.064631, loss_ce: 0.021732
2021-12-12 23:06:41,329 iteration 260 : loss : 0.091880, loss_ce: 0.038768
2021-12-12 23:06:42,738 iteration 261 : loss : 0.075353, loss_ce: 0.031946
2021-12-12 23:06:44,132 iteration 262 : loss : 0.068363, loss_ce: 0.034489
2021-12-12 23:06:45,464 iteration 263 : loss : 0.084860, loss_ce: 0.038484
2021-12-12 23:06:46,792 iteration 264 : loss : 0.084075, loss_ce: 0.028620
2021-12-12 23:06:48,244 iteration 265 : loss : 0.086897, loss_ce: 0.042222
2021-12-12 23:06:49,729 iteration 266 : loss : 0.125281, loss_ce: 0.041294
2021-12-12 23:06:51,202 iteration 267 : loss : 0.085015, loss_ce: 0.036444
2021-12-12 23:06:52,682 iteration 268 : loss : 0.068777, loss_ce: 0.031220
2021-12-12 23:06:54,130 iteration 269 : loss : 0.075461, loss_ce: 0.030206
2021-12-12 23:06:55,528 iteration 270 : loss : 0.090085, loss_ce: 0.034487
2021-12-12 23:06:57,021 iteration 271 : loss : 0.133507, loss_ce: 0.047019
2021-12-12 23:06:58,567 iteration 272 : loss : 0.070313, loss_ce: 0.027111
  4%|█▏                            | 16/400 [07:16<3:03:15, 28.63s/it]2021-12-12 23:07:00,065 iteration 273 : loss : 0.076783, loss_ce: 0.031993
2021-12-12 23:07:01,565 iteration 274 : loss : 0.068084, loss_ce: 0.025566
2021-12-12 23:07:03,050 iteration 275 : loss : 0.087390, loss_ce: 0.039541
2021-12-12 23:07:04,468 iteration 276 : loss : 0.066993, loss_ce: 0.030122
2021-12-12 23:07:06,014 iteration 277 : loss : 0.096829, loss_ce: 0.035037
2021-12-12 23:07:07,413 iteration 278 : loss : 0.151110, loss_ce: 0.037747
2021-12-12 23:07:08,897 iteration 279 : loss : 0.075263, loss_ce: 0.033691
2021-12-12 23:07:10,292 iteration 280 : loss : 0.062242, loss_ce: 0.025158
2021-12-12 23:07:11,781 iteration 281 : loss : 0.073987, loss_ce: 0.026510
2021-12-12 23:07:13,289 iteration 282 : loss : 0.076799, loss_ce: 0.033172
2021-12-12 23:07:14,774 iteration 283 : loss : 0.069829, loss_ce: 0.027830
2021-12-12 23:07:16,187 iteration 284 : loss : 0.058252, loss_ce: 0.022727
2021-12-12 23:07:17,660 iteration 285 : loss : 0.095511, loss_ce: 0.034949
2021-12-12 23:07:19,151 iteration 286 : loss : 0.111081, loss_ce: 0.045080
2021-12-12 23:07:20,575 iteration 287 : loss : 0.106366, loss_ce: 0.038451
2021-12-12 23:07:22,033 iteration 288 : loss : 0.056649, loss_ce: 0.024732
2021-12-12 23:07:23,499 iteration 289 : loss : 0.074141, loss_ce: 0.032480
  4%|█▎                            | 17/400 [07:41<2:55:40, 27.52s/it]2021-12-12 23:07:25,007 iteration 290 : loss : 0.065215, loss_ce: 0.022119
2021-12-12 23:07:26,474 iteration 291 : loss : 0.080206, loss_ce: 0.028076
2021-12-12 23:07:27,929 iteration 292 : loss : 0.077522, loss_ce: 0.032346
2021-12-12 23:07:29,519 iteration 293 : loss : 0.082472, loss_ce: 0.040998
2021-12-12 23:07:30,940 iteration 294 : loss : 0.085666, loss_ce: 0.037986
2021-12-12 23:07:32,375 iteration 295 : loss : 0.119461, loss_ce: 0.044308
2021-12-12 23:07:33,830 iteration 296 : loss : 0.105241, loss_ce: 0.039187
2021-12-12 23:07:35,354 iteration 297 : loss : 0.095028, loss_ce: 0.043109
2021-12-12 23:07:36,796 iteration 298 : loss : 0.088766, loss_ce: 0.027626
2021-12-12 23:07:38,299 iteration 299 : loss : 0.079742, loss_ce: 0.024615
2021-12-12 23:07:39,731 iteration 300 : loss : 0.075596, loss_ce: 0.022474
2021-12-12 23:07:41,193 iteration 301 : loss : 0.094916, loss_ce: 0.028203
2021-12-12 23:07:42,743 iteration 302 : loss : 0.134244, loss_ce: 0.067330
2021-12-12 23:07:44,236 iteration 303 : loss : 0.125494, loss_ce: 0.053362
2021-12-12 23:07:45,692 iteration 304 : loss : 0.089605, loss_ce: 0.034045
2021-12-12 23:07:47,168 iteration 305 : loss : 0.081905, loss_ce: 0.032901
2021-12-12 23:07:48,630 iteration 306 : loss : 0.110228, loss_ce: 0.040373
  4%|█▎                            | 18/400 [08:06<2:50:37, 26.80s/it]2021-12-12 23:07:50,102 iteration 307 : loss : 0.067235, loss_ce: 0.027432
2021-12-12 23:07:51,625 iteration 308 : loss : 0.102213, loss_ce: 0.032597
2021-12-12 23:07:53,096 iteration 309 : loss : 0.085796, loss_ce: 0.038238
2021-12-12 23:07:54,546 iteration 310 : loss : 0.098430, loss_ce: 0.039693
2021-12-12 23:07:55,963 iteration 311 : loss : 0.103720, loss_ce: 0.037092
2021-12-12 23:07:57,429 iteration 312 : loss : 0.155301, loss_ce: 0.038118
2021-12-12 23:07:58,951 iteration 313 : loss : 0.091664, loss_ce: 0.033373
2021-12-12 23:08:00,340 iteration 314 : loss : 0.096660, loss_ce: 0.036792
2021-12-12 23:08:01,795 iteration 315 : loss : 0.093885, loss_ce: 0.041648
2021-12-12 23:08:03,341 iteration 316 : loss : 0.102797, loss_ce: 0.040141
2021-12-12 23:08:04,895 iteration 317 : loss : 0.099518, loss_ce: 0.048775
2021-12-12 23:08:06,364 iteration 318 : loss : 0.089082, loss_ce: 0.041872
2021-12-12 23:08:07,844 iteration 319 : loss : 0.066210, loss_ce: 0.032278
2021-12-12 23:08:09,309 iteration 320 : loss : 0.107650, loss_ce: 0.040679
2021-12-12 23:08:10,742 iteration 321 : loss : 0.122790, loss_ce: 0.048220
2021-12-12 23:08:12,166 iteration 322 : loss : 0.065959, loss_ce: 0.030059
2021-12-12 23:08:13,626 iteration 323 : loss : 0.063832, loss_ce: 0.028852
  5%|█▍                            | 19/400 [08:31<2:46:45, 26.26s/it]2021-12-12 23:08:15,148 iteration 324 : loss : 0.068411, loss_ce: 0.033307
2021-12-12 23:08:16,596 iteration 325 : loss : 0.096589, loss_ce: 0.035361
2021-12-12 23:08:18,028 iteration 326 : loss : 0.079474, loss_ce: 0.027990
2021-12-12 23:08:19,444 iteration 327 : loss : 0.067307, loss_ce: 0.029244
2021-12-12 23:08:20,930 iteration 328 : loss : 0.060526, loss_ce: 0.021946
2021-12-12 23:08:22,460 iteration 329 : loss : 0.118754, loss_ce: 0.040265
2021-12-12 23:08:23,913 iteration 330 : loss : 0.079171, loss_ce: 0.037517
2021-12-12 23:08:25,378 iteration 331 : loss : 0.107189, loss_ce: 0.039808
2021-12-12 23:08:26,760 iteration 332 : loss : 0.067176, loss_ce: 0.028750
2021-12-12 23:08:28,277 iteration 333 : loss : 0.094381, loss_ce: 0.042870
2021-12-12 23:08:29,737 iteration 334 : loss : 0.071652, loss_ce: 0.028775
2021-12-12 23:08:31,257 iteration 335 : loss : 0.072314, loss_ce: 0.035161
2021-12-12 23:08:32,708 iteration 336 : loss : 0.082353, loss_ce: 0.037094
2021-12-12 23:08:34,157 iteration 337 : loss : 0.122229, loss_ce: 0.047764
2021-12-12 23:08:35,627 iteration 338 : loss : 0.076176, loss_ce: 0.032766
2021-12-12 23:08:37,066 iteration 339 : loss : 0.083031, loss_ce: 0.035272
2021-12-12 23:08:37,066 Training Data Eval:
2021-12-12 23:08:44,560   Average segmentation loss on training set: 0.0886
2021-12-12 23:08:44,561 Validation Data Eval:
2021-12-12 23:08:47,149   Average segmentation loss on validation set: 0.1507
2021-12-12 23:08:48,669 iteration 340 : loss : 0.101272, loss_ce: 0.038530
  5%|█▌                            | 20/400 [09:06<3:03:00, 28.90s/it]2021-12-12 23:08:50,166 iteration 341 : loss : 0.062771, loss_ce: 0.027315
2021-12-12 23:08:51,689 iteration 342 : loss : 0.086278, loss_ce: 0.039766
2021-12-12 23:08:53,195 iteration 343 : loss : 0.076231, loss_ce: 0.029789
2021-12-12 23:08:54,655 iteration 344 : loss : 0.078647, loss_ce: 0.039850
2021-12-12 23:08:56,112 iteration 345 : loss : 0.075886, loss_ce: 0.028085
2021-12-12 23:08:57,634 iteration 346 : loss : 0.068723, loss_ce: 0.024711
2021-12-12 23:08:59,139 iteration 347 : loss : 0.086237, loss_ce: 0.031110
2021-12-12 23:09:00,584 iteration 348 : loss : 0.061156, loss_ce: 0.022243
2021-12-12 23:09:02,055 iteration 349 : loss : 0.082391, loss_ce: 0.028759
2021-12-12 23:09:03,544 iteration 350 : loss : 0.084668, loss_ce: 0.036791
2021-12-12 23:09:04,993 iteration 351 : loss : 0.062545, loss_ce: 0.022835
2021-12-12 23:09:06,536 iteration 352 : loss : 0.068155, loss_ce: 0.038670
2021-12-12 23:09:08,063 iteration 353 : loss : 0.081753, loss_ce: 0.032304
2021-12-12 23:09:09,492 iteration 354 : loss : 0.073924, loss_ce: 0.024651
2021-12-12 23:09:10,980 iteration 355 : loss : 0.064499, loss_ce: 0.020326
2021-12-12 23:09:12,440 iteration 356 : loss : 0.060291, loss_ce: 0.019295
2021-12-12 23:09:13,925 iteration 357 : loss : 0.070874, loss_ce: 0.023984
  5%|█▌                            | 21/400 [09:32<2:55:37, 27.80s/it]2021-12-12 23:09:15,527 iteration 358 : loss : 0.101820, loss_ce: 0.050550
2021-12-12 23:09:17,059 iteration 359 : loss : 0.071378, loss_ce: 0.030701
2021-12-12 23:09:18,488 iteration 360 : loss : 0.070004, loss_ce: 0.023992
2021-12-12 23:09:19,984 iteration 361 : loss : 0.086711, loss_ce: 0.034061
2021-12-12 23:09:21,483 iteration 362 : loss : 0.071706, loss_ce: 0.036998
2021-12-12 23:09:22,892 iteration 363 : loss : 0.056186, loss_ce: 0.023997
2021-12-12 23:09:24,377 iteration 364 : loss : 0.097017, loss_ce: 0.026366
2021-12-12 23:09:25,801 iteration 365 : loss : 0.060792, loss_ce: 0.024526
2021-12-12 23:09:27,255 iteration 366 : loss : 0.089789, loss_ce: 0.028224
2021-12-12 23:09:28,732 iteration 367 : loss : 0.077664, loss_ce: 0.026463
2021-12-12 23:09:30,169 iteration 368 : loss : 0.083155, loss_ce: 0.031485
2021-12-12 23:09:31,600 iteration 369 : loss : 0.102641, loss_ce: 0.047305
2021-12-12 23:09:33,067 iteration 370 : loss : 0.101571, loss_ce: 0.039525
2021-12-12 23:09:34,523 iteration 371 : loss : 0.090490, loss_ce: 0.031558
2021-12-12 23:09:35,935 iteration 372 : loss : 0.074233, loss_ce: 0.030395
2021-12-12 23:09:37,383 iteration 373 : loss : 0.070817, loss_ce: 0.026932
2021-12-12 23:09:38,886 iteration 374 : loss : 0.070985, loss_ce: 0.031533
  6%|█▋                            | 22/400 [09:56<2:49:47, 26.95s/it]2021-12-12 23:09:40,398 iteration 375 : loss : 0.061657, loss_ce: 0.025206
2021-12-12 23:09:41,844 iteration 376 : loss : 0.155577, loss_ce: 0.052305
2021-12-12 23:09:43,307 iteration 377 : loss : 0.098047, loss_ce: 0.036547
2021-12-12 23:09:44,832 iteration 378 : loss : 0.066542, loss_ce: 0.021332
2021-12-12 23:09:46,305 iteration 379 : loss : 0.095385, loss_ce: 0.044169
2021-12-12 23:09:47,735 iteration 380 : loss : 0.081296, loss_ce: 0.030100
2021-12-12 23:09:49,216 iteration 381 : loss : 0.093765, loss_ce: 0.040204
2021-12-12 23:09:50,609 iteration 382 : loss : 0.076908, loss_ce: 0.035601
2021-12-12 23:09:52,086 iteration 383 : loss : 0.104639, loss_ce: 0.025137
2021-12-12 23:09:53,544 iteration 384 : loss : 0.096032, loss_ce: 0.033480
2021-12-12 23:09:54,977 iteration 385 : loss : 0.073890, loss_ce: 0.028863
2021-12-12 23:09:56,454 iteration 386 : loss : 0.073576, loss_ce: 0.029780
2021-12-12 23:09:57,870 iteration 387 : loss : 0.077191, loss_ce: 0.030371
2021-12-12 23:09:59,357 iteration 388 : loss : 0.068561, loss_ce: 0.032411
2021-12-12 23:10:00,817 iteration 389 : loss : 0.074567, loss_ce: 0.025700
2021-12-12 23:10:02,297 iteration 390 : loss : 0.091974, loss_ce: 0.042224
2021-12-12 23:10:03,783 iteration 391 : loss : 0.052673, loss_ce: 0.021748
  6%|█▋                            | 23/400 [10:21<2:45:28, 26.34s/it]2021-12-12 23:10:05,330 iteration 392 : loss : 0.073363, loss_ce: 0.032994
2021-12-12 23:10:06,746 iteration 393 : loss : 0.062639, loss_ce: 0.028613
2021-12-12 23:10:08,227 iteration 394 : loss : 0.079466, loss_ce: 0.028063
2021-12-12 23:10:09,646 iteration 395 : loss : 0.054769, loss_ce: 0.020461
2021-12-12 23:10:11,104 iteration 396 : loss : 0.074844, loss_ce: 0.028784
2021-12-12 23:10:12,639 iteration 397 : loss : 0.077119, loss_ce: 0.035304
2021-12-12 23:10:14,092 iteration 398 : loss : 0.082918, loss_ce: 0.027907
2021-12-12 23:10:15,562 iteration 399 : loss : 0.082762, loss_ce: 0.037144
2021-12-12 23:10:17,000 iteration 400 : loss : 0.050233, loss_ce: 0.017870
2021-12-12 23:10:18,485 iteration 401 : loss : 0.075770, loss_ce: 0.041112
2021-12-12 23:10:20,041 iteration 402 : loss : 0.062024, loss_ce: 0.023396
2021-12-12 23:10:21,541 iteration 403 : loss : 0.075133, loss_ce: 0.027810
2021-12-12 23:10:22,975 iteration 404 : loss : 0.052665, loss_ce: 0.018426
2021-12-12 23:10:24,419 iteration 405 : loss : 0.094982, loss_ce: 0.043214
2021-12-12 23:10:25,913 iteration 406 : loss : 0.055951, loss_ce: 0.025920
2021-12-12 23:10:27,400 iteration 407 : loss : 0.064577, loss_ce: 0.026003
2021-12-12 23:10:28,785 iteration 408 : loss : 0.058028, loss_ce: 0.025754
  6%|█▊                            | 24/400 [10:46<2:42:31, 25.94s/it]2021-12-12 23:10:30,348 iteration 409 : loss : 0.080375, loss_ce: 0.027209
2021-12-12 23:10:31,825 iteration 410 : loss : 0.075133, loss_ce: 0.030052
2021-12-12 23:10:33,308 iteration 411 : loss : 0.073609, loss_ce: 0.021818
2021-12-12 23:10:34,744 iteration 412 : loss : 0.061950, loss_ce: 0.028725
2021-12-12 23:10:36,198 iteration 413 : loss : 0.061560, loss_ce: 0.020302
2021-12-12 23:10:37,618 iteration 414 : loss : 0.059941, loss_ce: 0.022011
2021-12-12 23:10:39,153 iteration 415 : loss : 0.063482, loss_ce: 0.020817
2021-12-12 23:10:40,579 iteration 416 : loss : 0.059499, loss_ce: 0.025634
2021-12-12 23:10:42,064 iteration 417 : loss : 0.075524, loss_ce: 0.025834
2021-12-12 23:10:43,462 iteration 418 : loss : 0.071382, loss_ce: 0.040379
2021-12-12 23:10:44,909 iteration 419 : loss : 0.088697, loss_ce: 0.028740
2021-12-12 23:10:46,365 iteration 420 : loss : 0.060153, loss_ce: 0.027055
2021-12-12 23:10:47,888 iteration 421 : loss : 0.061294, loss_ce: 0.026062
2021-12-12 23:10:49,331 iteration 422 : loss : 0.077039, loss_ce: 0.029481
2021-12-12 23:10:50,799 iteration 423 : loss : 0.052787, loss_ce: 0.021674
2021-12-12 23:10:52,308 iteration 424 : loss : 0.075358, loss_ce: 0.032651
2021-12-12 23:10:52,308 Training Data Eval:
2021-12-12 23:10:59,795   Average segmentation loss on training set: 0.0459
2021-12-12 23:10:59,796 Validation Data Eval:
2021-12-12 23:11:02,396   Average segmentation loss on validation set: 0.0913
2021-12-12 23:11:08,776 Found new lowest validation loss at iteration 424! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:11:10,207 iteration 425 : loss : 0.083328, loss_ce: 0.036523
  6%|█▉                            | 25/400 [11:28<3:11:07, 30.58s/it]2021-12-12 23:11:11,664 iteration 426 : loss : 0.048233, loss_ce: 0.022590
2021-12-12 23:11:13,039 iteration 427 : loss : 0.075093, loss_ce: 0.033006
2021-12-12 23:11:14,457 iteration 428 : loss : 0.069811, loss_ce: 0.027242
2021-12-12 23:11:15,793 iteration 429 : loss : 0.062916, loss_ce: 0.022362
2021-12-12 23:11:17,180 iteration 430 : loss : 0.063358, loss_ce: 0.023546
2021-12-12 23:11:18,491 iteration 431 : loss : 0.065747, loss_ce: 0.025903
2021-12-12 23:11:19,836 iteration 432 : loss : 0.039167, loss_ce: 0.014858
2021-12-12 23:11:21,217 iteration 433 : loss : 0.073160, loss_ce: 0.022109
2021-12-12 23:11:22,569 iteration 434 : loss : 0.048953, loss_ce: 0.017180
2021-12-12 23:11:23,976 iteration 435 : loss : 0.083538, loss_ce: 0.044869
2021-12-12 23:11:25,487 iteration 436 : loss : 0.076541, loss_ce: 0.026014
2021-12-12 23:11:26,974 iteration 437 : loss : 0.069716, loss_ce: 0.025837
2021-12-12 23:11:28,453 iteration 438 : loss : 0.098101, loss_ce: 0.052426
2021-12-12 23:11:29,925 iteration 439 : loss : 0.062994, loss_ce: 0.027356
2021-12-12 23:11:31,359 iteration 440 : loss : 0.060981, loss_ce: 0.025592
2021-12-12 23:11:32,820 iteration 441 : loss : 0.073022, loss_ce: 0.033583
2021-12-12 23:11:34,266 iteration 442 : loss : 0.145784, loss_ce: 0.049455
  6%|█▉                            | 26/400 [11:52<2:58:25, 28.62s/it]2021-12-12 23:11:35,786 iteration 443 : loss : 0.066246, loss_ce: 0.032443
2021-12-12 23:11:37,246 iteration 444 : loss : 0.057050, loss_ce: 0.021649
2021-12-12 23:11:38,895 iteration 445 : loss : 0.068679, loss_ce: 0.027955
2021-12-12 23:11:40,316 iteration 446 : loss : 0.098033, loss_ce: 0.033909
2021-12-12 23:11:41,864 iteration 447 : loss : 0.099055, loss_ce: 0.042676
2021-12-12 23:11:43,365 iteration 448 : loss : 0.051201, loss_ce: 0.022875
2021-12-12 23:11:44,822 iteration 449 : loss : 0.082520, loss_ce: 0.029525
2021-12-12 23:11:46,224 iteration 450 : loss : 0.062767, loss_ce: 0.029172
2021-12-12 23:11:47,684 iteration 451 : loss : 0.090879, loss_ce: 0.029469
2021-12-12 23:11:49,178 iteration 452 : loss : 0.051056, loss_ce: 0.019928
2021-12-12 23:11:50,652 iteration 453 : loss : 0.048956, loss_ce: 0.016588
2021-12-12 23:11:52,155 iteration 454 : loss : 0.091855, loss_ce: 0.028825
2021-12-12 23:11:53,699 iteration 455 : loss : 0.067416, loss_ce: 0.020863
2021-12-12 23:11:55,170 iteration 456 : loss : 0.065985, loss_ce: 0.020492
2021-12-12 23:11:56,602 iteration 457 : loss : 0.060573, loss_ce: 0.022650
2021-12-12 23:11:58,057 iteration 458 : loss : 0.070710, loss_ce: 0.029349
2021-12-12 23:11:59,529 iteration 459 : loss : 0.064284, loss_ce: 0.024659
  7%|██                            | 27/400 [12:17<2:51:41, 27.62s/it]2021-12-12 23:12:00,964 iteration 460 : loss : 0.065288, loss_ce: 0.020521
2021-12-12 23:12:02,464 iteration 461 : loss : 0.045641, loss_ce: 0.019664
2021-12-12 23:12:03,942 iteration 462 : loss : 0.063802, loss_ce: 0.016846
2021-12-12 23:12:05,331 iteration 463 : loss : 0.064878, loss_ce: 0.030602
2021-12-12 23:12:06,867 iteration 464 : loss : 0.060805, loss_ce: 0.022772
2021-12-12 23:12:08,309 iteration 465 : loss : 0.067715, loss_ce: 0.034708
2021-12-12 23:12:09,810 iteration 466 : loss : 0.056067, loss_ce: 0.025138
2021-12-12 23:12:11,257 iteration 467 : loss : 0.058246, loss_ce: 0.020311
2021-12-12 23:12:12,724 iteration 468 : loss : 0.056745, loss_ce: 0.022568
2021-12-12 23:12:14,155 iteration 469 : loss : 0.068590, loss_ce: 0.025571
2021-12-12 23:12:15,678 iteration 470 : loss : 0.086050, loss_ce: 0.040704
2021-12-12 23:12:17,085 iteration 471 : loss : 0.045375, loss_ce: 0.018265
2021-12-12 23:12:18,601 iteration 472 : loss : 0.068215, loss_ce: 0.026131
2021-12-12 23:12:20,116 iteration 473 : loss : 0.059734, loss_ce: 0.022552
2021-12-12 23:12:21,643 iteration 474 : loss : 0.061968, loss_ce: 0.022816
2021-12-12 23:12:23,118 iteration 475 : loss : 0.067821, loss_ce: 0.019577
2021-12-12 23:12:24,623 iteration 476 : loss : 0.081886, loss_ce: 0.041983
  7%|██                            | 28/400 [12:42<2:46:31, 26.86s/it]2021-12-12 23:12:26,106 iteration 477 : loss : 0.072456, loss_ce: 0.027336
2021-12-12 23:12:27,614 iteration 478 : loss : 0.067229, loss_ce: 0.020443
2021-12-12 23:12:29,035 iteration 479 : loss : 0.053319, loss_ce: 0.020231
2021-12-12 23:12:30,425 iteration 480 : loss : 0.046955, loss_ce: 0.020202
2021-12-12 23:12:31,880 iteration 481 : loss : 0.062504, loss_ce: 0.026267
2021-12-12 23:12:33,391 iteration 482 : loss : 0.079444, loss_ce: 0.032920
2021-12-12 23:12:34,872 iteration 483 : loss : 0.066279, loss_ce: 0.022696
2021-12-12 23:12:36,329 iteration 484 : loss : 0.047569, loss_ce: 0.020348
2021-12-12 23:12:37,733 iteration 485 : loss : 0.040954, loss_ce: 0.015896
2021-12-12 23:12:39,202 iteration 486 : loss : 0.084630, loss_ce: 0.021941
2021-12-12 23:12:40,704 iteration 487 : loss : 0.079255, loss_ce: 0.038712
2021-12-12 23:12:42,253 iteration 488 : loss : 0.082249, loss_ce: 0.038590
2021-12-12 23:12:43,736 iteration 489 : loss : 0.055044, loss_ce: 0.022995
2021-12-12 23:12:45,156 iteration 490 : loss : 0.056787, loss_ce: 0.022199
2021-12-12 23:12:46,676 iteration 491 : loss : 0.088819, loss_ce: 0.034011
2021-12-12 23:12:48,107 iteration 492 : loss : 0.055818, loss_ce: 0.023107
2021-12-12 23:12:49,568 iteration 493 : loss : 0.061541, loss_ce: 0.024134
  7%|██▏                           | 29/400 [13:07<2:42:31, 26.28s/it]2021-12-12 23:12:51,047 iteration 494 : loss : 0.066575, loss_ce: 0.027145
2021-12-12 23:12:52,512 iteration 495 : loss : 0.064490, loss_ce: 0.030614
2021-12-12 23:12:53,906 iteration 496 : loss : 0.056672, loss_ce: 0.024871
2021-12-12 23:12:55,415 iteration 497 : loss : 0.051745, loss_ce: 0.019352
2021-12-12 23:12:56,862 iteration 498 : loss : 0.065097, loss_ce: 0.023966
2021-12-12 23:12:58,390 iteration 499 : loss : 0.059566, loss_ce: 0.026956
2021-12-12 23:12:59,779 iteration 500 : loss : 0.051600, loss_ce: 0.020491
2021-12-12 23:13:01,258 iteration 501 : loss : 0.051159, loss_ce: 0.019851
2021-12-12 23:13:02,699 iteration 502 : loss : 0.067536, loss_ce: 0.024279
2021-12-12 23:13:04,173 iteration 503 : loss : 0.078946, loss_ce: 0.036945
2021-12-12 23:13:05,710 iteration 504 : loss : 0.051561, loss_ce: 0.017574
2021-12-12 23:13:07,259 iteration 505 : loss : 0.069117, loss_ce: 0.027980
2021-12-12 23:13:08,738 iteration 506 : loss : 0.079002, loss_ce: 0.040401
2021-12-12 23:13:10,194 iteration 507 : loss : 0.065485, loss_ce: 0.021649
2021-12-12 23:13:11,702 iteration 508 : loss : 0.064100, loss_ce: 0.018886
2021-12-12 23:13:13,213 iteration 509 : loss : 0.061468, loss_ce: 0.027154
2021-12-12 23:13:13,213 Training Data Eval:
2021-12-12 23:13:20,704   Average segmentation loss on training set: 0.0440
2021-12-12 23:13:20,705 Validation Data Eval:
2021-12-12 23:13:23,303   Average segmentation loss on validation set: 0.0900
2021-12-12 23:13:29,548 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:13:30,896 iteration 510 : loss : 0.070116, loss_ce: 0.034565
  8%|██▎                           | 30/400 [13:48<3:09:56, 30.80s/it]2021-12-12 23:13:32,272 iteration 511 : loss : 0.061046, loss_ce: 0.021998
2021-12-12 23:13:33,627 iteration 512 : loss : 0.049689, loss_ce: 0.020729
2021-12-12 23:13:34,995 iteration 513 : loss : 0.057689, loss_ce: 0.024601
2021-12-12 23:13:36,393 iteration 514 : loss : 0.067774, loss_ce: 0.027005
2021-12-12 23:13:37,692 iteration 515 : loss : 0.045121, loss_ce: 0.019446
2021-12-12 23:13:38,962 iteration 516 : loss : 0.045329, loss_ce: 0.014542
2021-12-12 23:13:40,398 iteration 517 : loss : 0.058178, loss_ce: 0.027307
2021-12-12 23:13:41,860 iteration 518 : loss : 0.081183, loss_ce: 0.031478
2021-12-12 23:13:43,312 iteration 519 : loss : 0.057579, loss_ce: 0.025922
2021-12-12 23:13:44,742 iteration 520 : loss : 0.061702, loss_ce: 0.026270
2021-12-12 23:13:46,158 iteration 521 : loss : 0.054806, loss_ce: 0.017970
2021-12-12 23:13:47,677 iteration 522 : loss : 0.051698, loss_ce: 0.017249
2021-12-12 23:13:49,147 iteration 523 : loss : 0.059342, loss_ce: 0.019132
2021-12-12 23:13:50,605 iteration 524 : loss : 0.061778, loss_ce: 0.029074
2021-12-12 23:13:52,067 iteration 525 : loss : 0.053742, loss_ce: 0.020310
2021-12-12 23:13:53,581 iteration 526 : loss : 0.063418, loss_ce: 0.021496
2021-12-12 23:13:55,086 iteration 527 : loss : 0.061440, loss_ce: 0.025614
  8%|██▎                           | 31/400 [14:13<2:57:13, 28.82s/it]2021-12-12 23:13:56,583 iteration 528 : loss : 0.049608, loss_ce: 0.019251
2021-12-12 23:13:58,172 iteration 529 : loss : 0.077825, loss_ce: 0.027243
2021-12-12 23:13:59,616 iteration 530 : loss : 0.047730, loss_ce: 0.014763
2021-12-12 23:14:01,048 iteration 531 : loss : 0.058369, loss_ce: 0.019342
2021-12-12 23:14:02,539 iteration 532 : loss : 0.063176, loss_ce: 0.028512
2021-12-12 23:14:04,001 iteration 533 : loss : 0.054392, loss_ce: 0.021874
2021-12-12 23:14:05,449 iteration 534 : loss : 0.051448, loss_ce: 0.018961
2021-12-12 23:14:06,953 iteration 535 : loss : 0.068252, loss_ce: 0.021696
2021-12-12 23:14:08,444 iteration 536 : loss : 0.051569, loss_ce: 0.024832
2021-12-12 23:14:09,907 iteration 537 : loss : 0.051440, loss_ce: 0.019745
2021-12-12 23:14:11,390 iteration 538 : loss : 0.058997, loss_ce: 0.028395
2021-12-12 23:14:12,801 iteration 539 : loss : 0.070665, loss_ce: 0.031984
2021-12-12 23:14:14,389 iteration 540 : loss : 0.061473, loss_ce: 0.029328
2021-12-12 23:14:15,963 iteration 541 : loss : 0.068805, loss_ce: 0.032696
2021-12-12 23:14:17,396 iteration 542 : loss : 0.082679, loss_ce: 0.033643
2021-12-12 23:14:18,885 iteration 543 : loss : 0.062175, loss_ce: 0.027263
2021-12-12 23:14:20,346 iteration 544 : loss : 0.125149, loss_ce: 0.043466
  8%|██▍                           | 32/400 [14:38<2:50:11, 27.75s/it]2021-12-12 23:14:21,916 iteration 545 : loss : 0.072818, loss_ce: 0.036865
2021-12-12 23:14:23,451 iteration 546 : loss : 0.075733, loss_ce: 0.032012
2021-12-12 23:14:24,970 iteration 547 : loss : 0.055372, loss_ce: 0.019701
2021-12-12 23:14:26,392 iteration 548 : loss : 0.073893, loss_ce: 0.024409
2021-12-12 23:14:27,823 iteration 549 : loss : 0.084703, loss_ce: 0.027040
2021-12-12 23:14:29,261 iteration 550 : loss : 0.057855, loss_ce: 0.022046
2021-12-12 23:14:30,704 iteration 551 : loss : 0.051495, loss_ce: 0.017387
2021-12-12 23:14:32,216 iteration 552 : loss : 0.100592, loss_ce: 0.042152
2021-12-12 23:14:33,707 iteration 553 : loss : 0.060637, loss_ce: 0.022320
2021-12-12 23:14:35,187 iteration 554 : loss : 0.093659, loss_ce: 0.026799
2021-12-12 23:14:36,690 iteration 555 : loss : 0.068563, loss_ce: 0.019036
2021-12-12 23:14:38,218 iteration 556 : loss : 0.056743, loss_ce: 0.024066
2021-12-12 23:14:39,648 iteration 557 : loss : 0.074628, loss_ce: 0.034755
2021-12-12 23:14:41,068 iteration 558 : loss : 0.053032, loss_ce: 0.020662
2021-12-12 23:14:42,524 iteration 559 : loss : 0.076852, loss_ce: 0.028716
2021-12-12 23:14:44,055 iteration 560 : loss : 0.074463, loss_ce: 0.029461
2021-12-12 23:14:45,556 iteration 561 : loss : 0.061060, loss_ce: 0.026906
  8%|██▍                           | 33/400 [15:03<2:45:04, 26.99s/it]2021-12-12 23:14:47,095 iteration 562 : loss : 0.060476, loss_ce: 0.020151
2021-12-12 23:14:48,519 iteration 563 : loss : 0.043981, loss_ce: 0.021824
2021-12-12 23:14:49,947 iteration 564 : loss : 0.069597, loss_ce: 0.032968
2021-12-12 23:14:51,449 iteration 565 : loss : 0.047780, loss_ce: 0.020071
2021-12-12 23:14:52,921 iteration 566 : loss : 0.100983, loss_ce: 0.030757
2021-12-12 23:14:54,413 iteration 567 : loss : 0.081106, loss_ce: 0.030048
2021-12-12 23:14:55,906 iteration 568 : loss : 0.061321, loss_ce: 0.017251
2021-12-12 23:14:57,441 iteration 569 : loss : 0.156377, loss_ce: 0.054866
2021-12-12 23:14:58,908 iteration 570 : loss : 0.065656, loss_ce: 0.022972
2021-12-12 23:15:00,411 iteration 571 : loss : 0.072204, loss_ce: 0.030181
2021-12-12 23:15:01,940 iteration 572 : loss : 0.061494, loss_ce: 0.030754
2021-12-12 23:15:03,376 iteration 573 : loss : 0.079942, loss_ce: 0.033491
2021-12-12 23:15:04,922 iteration 574 : loss : 0.073413, loss_ce: 0.025905
2021-12-12 23:15:06,382 iteration 575 : loss : 0.075440, loss_ce: 0.025188
2021-12-12 23:15:07,794 iteration 576 : loss : 0.071681, loss_ce: 0.033189
2021-12-12 23:15:09,381 iteration 577 : loss : 0.125861, loss_ce: 0.062410
2021-12-12 23:15:10,874 iteration 578 : loss : 0.062875, loss_ce: 0.023740
  8%|██▌                           | 34/400 [15:28<2:41:33, 26.48s/it]2021-12-12 23:15:12,306 iteration 579 : loss : 0.050947, loss_ce: 0.023280
2021-12-12 23:15:13,818 iteration 580 : loss : 0.074328, loss_ce: 0.032332
2021-12-12 23:15:15,408 iteration 581 : loss : 0.054881, loss_ce: 0.022476
2021-12-12 23:15:16,822 iteration 582 : loss : 0.059967, loss_ce: 0.026301
2021-12-12 23:15:18,321 iteration 583 : loss : 0.064232, loss_ce: 0.026916
2021-12-12 23:15:19,824 iteration 584 : loss : 0.066066, loss_ce: 0.026003
2021-12-12 23:15:21,259 iteration 585 : loss : 0.066227, loss_ce: 0.023081
2021-12-12 23:15:22,769 iteration 586 : loss : 0.064234, loss_ce: 0.022365
2021-12-12 23:15:24,243 iteration 587 : loss : 0.047760, loss_ce: 0.020446
2021-12-12 23:15:25,666 iteration 588 : loss : 0.071065, loss_ce: 0.026733
2021-12-12 23:15:27,199 iteration 589 : loss : 0.061559, loss_ce: 0.032034
2021-12-12 23:15:28,657 iteration 590 : loss : 0.078047, loss_ce: 0.030026
2021-12-12 23:15:30,107 iteration 591 : loss : 0.073544, loss_ce: 0.026362
2021-12-12 23:15:31,606 iteration 592 : loss : 0.051416, loss_ce: 0.022725
2021-12-12 23:15:33,030 iteration 593 : loss : 0.072796, loss_ce: 0.026147
2021-12-12 23:15:34,546 iteration 594 : loss : 0.060713, loss_ce: 0.021811
2021-12-12 23:15:34,546 Training Data Eval:
2021-12-12 23:15:42,047   Average segmentation loss on training set: 0.0759
2021-12-12 23:15:42,047 Validation Data Eval:
2021-12-12 23:15:44,644   Average segmentation loss on validation set: 0.1157
2021-12-12 23:15:46,140 iteration 595 : loss : 0.062121, loss_ce: 0.020395
  9%|██▋                           | 35/400 [16:04<2:57:08, 29.12s/it]2021-12-12 23:15:47,742 iteration 596 : loss : 0.067580, loss_ce: 0.030224
2021-12-12 23:15:49,228 iteration 597 : loss : 0.042858, loss_ce: 0.015950
2021-12-12 23:15:50,691 iteration 598 : loss : 0.058377, loss_ce: 0.018919
2021-12-12 23:15:52,184 iteration 599 : loss : 0.062492, loss_ce: 0.019863
2021-12-12 23:15:53,695 iteration 600 : loss : 0.059256, loss_ce: 0.018845
2021-12-12 23:15:55,192 iteration 601 : loss : 0.073378, loss_ce: 0.028392
2021-12-12 23:15:56,580 iteration 602 : loss : 0.072257, loss_ce: 0.033505
2021-12-12 23:15:58,062 iteration 603 : loss : 0.055952, loss_ce: 0.023405
2021-12-12 23:15:59,503 iteration 604 : loss : 0.097052, loss_ce: 0.027290
2021-12-12 23:16:01,122 iteration 605 : loss : 0.064254, loss_ce: 0.023635
2021-12-12 23:16:02,548 iteration 606 : loss : 0.047598, loss_ce: 0.017990
2021-12-12 23:16:03,985 iteration 607 : loss : 0.060809, loss_ce: 0.021343
2021-12-12 23:16:05,414 iteration 608 : loss : 0.046770, loss_ce: 0.025379
2021-12-12 23:16:06,843 iteration 609 : loss : 0.062361, loss_ce: 0.023184
2021-12-12 23:16:08,400 iteration 610 : loss : 0.097126, loss_ce: 0.048957
2021-12-12 23:16:09,863 iteration 611 : loss : 0.055919, loss_ce: 0.029174
2021-12-12 23:16:11,281 iteration 612 : loss : 0.065556, loss_ce: 0.031052
  9%|██▋                           | 36/400 [16:29<2:49:24, 27.93s/it]2021-12-12 23:16:12,781 iteration 613 : loss : 0.081692, loss_ce: 0.031314
2021-12-12 23:16:14,286 iteration 614 : loss : 0.064737, loss_ce: 0.028531
2021-12-12 23:16:15,734 iteration 615 : loss : 0.056625, loss_ce: 0.026498
2021-12-12 23:16:17,159 iteration 616 : loss : 0.091971, loss_ce: 0.030910
2021-12-12 23:16:18,659 iteration 617 : loss : 0.071757, loss_ce: 0.024005
2021-12-12 23:16:20,194 iteration 618 : loss : 0.047398, loss_ce: 0.021095
2021-12-12 23:16:21,671 iteration 619 : loss : 0.051899, loss_ce: 0.021060
2021-12-12 23:16:23,178 iteration 620 : loss : 0.055148, loss_ce: 0.023241
2021-12-12 23:16:24,556 iteration 621 : loss : 0.048757, loss_ce: 0.016694
2021-12-12 23:16:26,090 iteration 622 : loss : 0.062797, loss_ce: 0.025958
2021-12-12 23:16:27,614 iteration 623 : loss : 0.056871, loss_ce: 0.022136
2021-12-12 23:16:29,013 iteration 624 : loss : 0.060466, loss_ce: 0.024161
2021-12-12 23:16:30,595 iteration 625 : loss : 0.069415, loss_ce: 0.026498
2021-12-12 23:16:32,038 iteration 626 : loss : 0.044743, loss_ce: 0.017105
2021-12-12 23:16:33,442 iteration 627 : loss : 0.062375, loss_ce: 0.018861
2021-12-12 23:16:34,836 iteration 628 : loss : 0.067534, loss_ce: 0.028282
2021-12-12 23:16:36,330 iteration 629 : loss : 0.046087, loss_ce: 0.019903
  9%|██▊                           | 37/400 [16:54<2:43:43, 27.06s/it]2021-12-12 23:16:37,744 iteration 630 : loss : 0.058656, loss_ce: 0.025105
2021-12-12 23:16:39,213 iteration 631 : loss : 0.068186, loss_ce: 0.022242
2021-12-12 23:16:40,616 iteration 632 : loss : 0.047236, loss_ce: 0.015724
2021-12-12 23:16:42,100 iteration 633 : loss : 0.051889, loss_ce: 0.022137
2021-12-12 23:16:43,564 iteration 634 : loss : 0.048141, loss_ce: 0.021240
2021-12-12 23:16:45,050 iteration 635 : loss : 0.043695, loss_ce: 0.017340
2021-12-12 23:16:46,498 iteration 636 : loss : 0.085499, loss_ce: 0.026718
2021-12-12 23:16:47,937 iteration 637 : loss : 0.059404, loss_ce: 0.024884
2021-12-12 23:16:49,379 iteration 638 : loss : 0.047183, loss_ce: 0.021968
2021-12-12 23:16:50,888 iteration 639 : loss : 0.054781, loss_ce: 0.025615
2021-12-12 23:16:52,386 iteration 640 : loss : 0.064780, loss_ce: 0.022008
2021-12-12 23:16:53,794 iteration 641 : loss : 0.058844, loss_ce: 0.021747
2021-12-12 23:16:55,271 iteration 642 : loss : 0.043756, loss_ce: 0.014164
2021-12-12 23:16:56,722 iteration 643 : loss : 0.062766, loss_ce: 0.020562
2021-12-12 23:16:58,198 iteration 644 : loss : 0.065851, loss_ce: 0.018896
2021-12-12 23:16:59,649 iteration 645 : loss : 0.049994, loss_ce: 0.018008
2021-12-12 23:17:01,150 iteration 646 : loss : 0.053415, loss_ce: 0.020415
 10%|██▊                           | 38/400 [17:19<2:39:14, 26.39s/it]2021-12-12 23:17:02,605 iteration 647 : loss : 0.052475, loss_ce: 0.019524
2021-12-12 23:17:04,108 iteration 648 : loss : 0.067683, loss_ce: 0.027299
2021-12-12 23:17:05,600 iteration 649 : loss : 0.052980, loss_ce: 0.021132
2021-12-12 23:17:07,008 iteration 650 : loss : 0.055059, loss_ce: 0.028199
2021-12-12 23:17:08,489 iteration 651 : loss : 0.056719, loss_ce: 0.022773
2021-12-12 23:17:09,905 iteration 652 : loss : 0.079633, loss_ce: 0.025219
2021-12-12 23:17:11,379 iteration 653 : loss : 0.080886, loss_ce: 0.022543
2021-12-12 23:17:12,902 iteration 654 : loss : 0.053848, loss_ce: 0.017711
2021-12-12 23:17:14,411 iteration 655 : loss : 0.042114, loss_ce: 0.015816
2021-12-12 23:17:15,818 iteration 656 : loss : 0.039787, loss_ce: 0.015443
2021-12-12 23:17:17,306 iteration 657 : loss : 0.050562, loss_ce: 0.021386
2021-12-12 23:17:18,820 iteration 658 : loss : 0.122635, loss_ce: 0.037746
2021-12-12 23:17:20,329 iteration 659 : loss : 0.050259, loss_ce: 0.022568
2021-12-12 23:17:21,810 iteration 660 : loss : 0.048396, loss_ce: 0.016960
2021-12-12 23:17:23,277 iteration 661 : loss : 0.053448, loss_ce: 0.023912
2021-12-12 23:17:24,694 iteration 662 : loss : 0.046088, loss_ce: 0.022049
2021-12-12 23:17:26,145 iteration 663 : loss : 0.051218, loss_ce: 0.016774
 10%|██▉                           | 39/400 [17:44<2:36:16, 25.97s/it]2021-12-12 23:17:27,599 iteration 664 : loss : 0.082008, loss_ce: 0.046419
2021-12-12 23:17:29,045 iteration 665 : loss : 0.059062, loss_ce: 0.030766
2021-12-12 23:17:30,514 iteration 666 : loss : 0.053079, loss_ce: 0.021611
2021-12-12 23:17:31,945 iteration 667 : loss : 0.033165, loss_ce: 0.013841
2021-12-12 23:17:33,471 iteration 668 : loss : 0.052839, loss_ce: 0.022987
2021-12-12 23:17:34,893 iteration 669 : loss : 0.049033, loss_ce: 0.019546
2021-12-12 23:17:36,327 iteration 670 : loss : 0.047782, loss_ce: 0.020346
2021-12-12 23:17:37,838 iteration 671 : loss : 0.051093, loss_ce: 0.015105
2021-12-12 23:17:39,344 iteration 672 : loss : 0.046576, loss_ce: 0.014456
2021-12-12 23:17:40,757 iteration 673 : loss : 0.055854, loss_ce: 0.024879
2021-12-12 23:17:42,250 iteration 674 : loss : 0.070767, loss_ce: 0.025360
2021-12-12 23:17:43,735 iteration 675 : loss : 0.079205, loss_ce: 0.029844
2021-12-12 23:17:45,162 iteration 676 : loss : 0.065009, loss_ce: 0.018779
2021-12-12 23:17:46,629 iteration 677 : loss : 0.078337, loss_ce: 0.035682
2021-12-12 23:17:48,068 iteration 678 : loss : 0.050347, loss_ce: 0.017788
2021-12-12 23:17:49,478 iteration 679 : loss : 0.094639, loss_ce: 0.041258
2021-12-12 23:17:49,478 Training Data Eval:
2021-12-12 23:17:56,989   Average segmentation loss on training set: 0.0520
2021-12-12 23:17:56,989 Validation Data Eval:
2021-12-12 23:17:59,583   Average segmentation loss on validation set: 0.0906
2021-12-12 23:18:01,080 iteration 680 : loss : 0.125896, loss_ce: 0.030231
 10%|███                           | 40/400 [18:19<2:51:57, 28.66s/it]2021-12-12 23:18:02,647 iteration 681 : loss : 0.053604, loss_ce: 0.022248
2021-12-12 23:18:04,067 iteration 682 : loss : 0.043270, loss_ce: 0.014692
2021-12-12 23:18:05,547 iteration 683 : loss : 0.071193, loss_ce: 0.027444
2021-12-12 23:18:07,041 iteration 684 : loss : 0.047744, loss_ce: 0.018366
2021-12-12 23:18:08,557 iteration 685 : loss : 0.047817, loss_ce: 0.020617
2021-12-12 23:18:09,935 iteration 686 : loss : 0.063028, loss_ce: 0.018884
2021-12-12 23:18:11,349 iteration 687 : loss : 0.045811, loss_ce: 0.015680
2021-12-12 23:18:12,877 iteration 688 : loss : 0.065672, loss_ce: 0.026265
2021-12-12 23:18:14,338 iteration 689 : loss : 0.048544, loss_ce: 0.022333
2021-12-12 23:18:15,750 iteration 690 : loss : 0.073911, loss_ce: 0.036980
2021-12-12 23:18:17,287 iteration 691 : loss : 0.054760, loss_ce: 0.021568
2021-12-12 23:18:18,795 iteration 692 : loss : 0.066427, loss_ce: 0.025685
2021-12-12 23:18:20,296 iteration 693 : loss : 0.090976, loss_ce: 0.036920
2021-12-12 23:18:21,773 iteration 694 : loss : 0.051079, loss_ce: 0.017840
2021-12-12 23:18:23,235 iteration 695 : loss : 0.074110, loss_ce: 0.024090
2021-12-12 23:18:24,693 iteration 696 : loss : 0.051475, loss_ce: 0.018745
2021-12-12 23:18:26,156 iteration 697 : loss : 0.067359, loss_ce: 0.021863
 10%|███                           | 41/400 [18:44<2:45:03, 27.59s/it]2021-12-12 23:18:27,622 iteration 698 : loss : 0.040003, loss_ce: 0.015790
2021-12-12 23:18:29,069 iteration 699 : loss : 0.049141, loss_ce: 0.014095
2021-12-12 23:18:30,527 iteration 700 : loss : 0.077274, loss_ce: 0.029325
2021-12-12 23:18:31,981 iteration 701 : loss : 0.059051, loss_ce: 0.023092
2021-12-12 23:18:33,482 iteration 702 : loss : 0.048597, loss_ce: 0.012840
2021-12-12 23:18:34,927 iteration 703 : loss : 0.085527, loss_ce: 0.039283
2021-12-12 23:18:36,373 iteration 704 : loss : 0.041744, loss_ce: 0.012037
2021-12-12 23:18:37,799 iteration 705 : loss : 0.075680, loss_ce: 0.036851
2021-12-12 23:18:39,304 iteration 706 : loss : 0.040024, loss_ce: 0.018509
2021-12-12 23:18:40,795 iteration 707 : loss : 0.064784, loss_ce: 0.029920
2021-12-12 23:18:42,284 iteration 708 : loss : 0.055218, loss_ce: 0.022107
2021-12-12 23:18:43,764 iteration 709 : loss : 0.048528, loss_ce: 0.019863
2021-12-12 23:18:45,218 iteration 710 : loss : 0.048897, loss_ce: 0.017298
2021-12-12 23:18:46,718 iteration 711 : loss : 0.104195, loss_ce: 0.031149
2021-12-12 23:18:48,237 iteration 712 : loss : 0.053409, loss_ce: 0.024929
2021-12-12 23:18:49,656 iteration 713 : loss : 0.053118, loss_ce: 0.028224
2021-12-12 23:18:51,104 iteration 714 : loss : 0.034561, loss_ce: 0.014220
 10%|███▏                          | 42/400 [19:09<2:39:52, 26.80s/it]2021-12-12 23:18:52,585 iteration 715 : loss : 0.041587, loss_ce: 0.019434
2021-12-12 23:18:54,032 iteration 716 : loss : 0.112119, loss_ce: 0.030802
2021-12-12 23:18:55,459 iteration 717 : loss : 0.050818, loss_ce: 0.017377
2021-12-12 23:18:56,821 iteration 718 : loss : 0.036717, loss_ce: 0.012940
2021-12-12 23:18:58,279 iteration 719 : loss : 0.055377, loss_ce: 0.026325
2021-12-12 23:18:59,664 iteration 720 : loss : 0.045550, loss_ce: 0.017427
2021-12-12 23:19:01,238 iteration 721 : loss : 0.072172, loss_ce: 0.024437
2021-12-12 23:19:02,698 iteration 722 : loss : 0.048670, loss_ce: 0.021788
2021-12-12 23:19:04,170 iteration 723 : loss : 0.073729, loss_ce: 0.027503
2021-12-12 23:19:05,702 iteration 724 : loss : 0.053371, loss_ce: 0.022656
2021-12-12 23:19:07,108 iteration 725 : loss : 0.050704, loss_ce: 0.020728
2021-12-12 23:19:08,576 iteration 726 : loss : 0.053046, loss_ce: 0.023696
2021-12-12 23:19:09,989 iteration 727 : loss : 0.040918, loss_ce: 0.014699
2021-12-12 23:19:11,424 iteration 728 : loss : 0.062673, loss_ce: 0.021840
2021-12-12 23:19:12,862 iteration 729 : loss : 0.057169, loss_ce: 0.024607
2021-12-12 23:19:14,337 iteration 730 : loss : 0.048112, loss_ce: 0.015318
2021-12-12 23:19:15,761 iteration 731 : loss : 0.065317, loss_ce: 0.023317
 11%|███▏                          | 43/400 [19:33<2:35:36, 26.15s/it]2021-12-12 23:19:17,295 iteration 732 : loss : 0.052729, loss_ce: 0.019850
2021-12-12 23:19:18,771 iteration 733 : loss : 0.040536, loss_ce: 0.017101
2021-12-12 23:19:20,239 iteration 734 : loss : 0.065025, loss_ce: 0.030247
2021-12-12 23:19:21,720 iteration 735 : loss : 0.048279, loss_ce: 0.020340
2021-12-12 23:19:23,206 iteration 736 : loss : 0.047428, loss_ce: 0.018049
2021-12-12 23:19:24,618 iteration 737 : loss : 0.039317, loss_ce: 0.013045
2021-12-12 23:19:26,147 iteration 738 : loss : 0.055999, loss_ce: 0.021853
2021-12-12 23:19:27,629 iteration 739 : loss : 0.054191, loss_ce: 0.023963
2021-12-12 23:19:29,078 iteration 740 : loss : 0.039410, loss_ce: 0.012534
2021-12-12 23:19:30,564 iteration 741 : loss : 0.045478, loss_ce: 0.016319
2021-12-12 23:19:32,050 iteration 742 : loss : 0.045751, loss_ce: 0.014930
2021-12-12 23:19:33,495 iteration 743 : loss : 0.039757, loss_ce: 0.012816
2021-12-12 23:19:34,966 iteration 744 : loss : 0.040322, loss_ce: 0.016887
2021-12-12 23:19:36,411 iteration 745 : loss : 0.053896, loss_ce: 0.016669
2021-12-12 23:19:37,844 iteration 746 : loss : 0.095325, loss_ce: 0.029112
2021-12-12 23:19:39,284 iteration 747 : loss : 0.054458, loss_ce: 0.023999
2021-12-12 23:19:40,754 iteration 748 : loss : 0.058716, loss_ce: 0.020257
 11%|███▎                          | 44/400 [19:58<2:33:05, 25.80s/it]2021-12-12 23:19:42,221 iteration 749 : loss : 0.063731, loss_ce: 0.026976
2021-12-12 23:19:43,663 iteration 750 : loss : 0.037346, loss_ce: 0.011443
2021-12-12 23:19:45,159 iteration 751 : loss : 0.079445, loss_ce: 0.033325
2021-12-12 23:19:46,588 iteration 752 : loss : 0.053708, loss_ce: 0.021132
2021-12-12 23:19:48,077 iteration 753 : loss : 0.045136, loss_ce: 0.018503
2021-12-12 23:19:49,519 iteration 754 : loss : 0.040679, loss_ce: 0.013744
2021-12-12 23:19:50,984 iteration 755 : loss : 0.036506, loss_ce: 0.014385
2021-12-12 23:19:52,361 iteration 756 : loss : 0.049838, loss_ce: 0.022190
2021-12-12 23:19:53,766 iteration 757 : loss : 0.050854, loss_ce: 0.021069
2021-12-12 23:19:55,236 iteration 758 : loss : 0.066170, loss_ce: 0.023062
2021-12-12 23:19:56,729 iteration 759 : loss : 0.065431, loss_ce: 0.021582
2021-12-12 23:19:58,203 iteration 760 : loss : 0.053935, loss_ce: 0.018548
2021-12-12 23:19:59,702 iteration 761 : loss : 0.050559, loss_ce: 0.017195
2021-12-12 23:20:01,085 iteration 762 : loss : 0.048628, loss_ce: 0.020182
2021-12-12 23:20:02,546 iteration 763 : loss : 0.055908, loss_ce: 0.026918
2021-12-12 23:20:03,935 iteration 764 : loss : 0.054286, loss_ce: 0.018746
2021-12-12 23:20:03,936 Training Data Eval:
2021-12-12 23:20:11,442   Average segmentation loss on training set: 0.0630
2021-12-12 23:20:11,443 Validation Data Eval:
2021-12-12 23:20:14,030   Average segmentation loss on validation set: 0.1579
2021-12-12 23:20:15,420 iteration 765 : loss : 0.047882, loss_ce: 0.022293
 11%|███▍                          | 45/400 [20:33<2:48:24, 28.46s/it]2021-12-12 23:20:16,994 iteration 766 : loss : 0.062209, loss_ce: 0.020879
2021-12-12 23:20:18,579 iteration 767 : loss : 0.062007, loss_ce: 0.026550
2021-12-12 23:20:20,060 iteration 768 : loss : 0.056591, loss_ce: 0.020265
2021-12-12 23:20:21,549 iteration 769 : loss : 0.050114, loss_ce: 0.020370
2021-12-12 23:20:23,070 iteration 770 : loss : 0.050873, loss_ce: 0.025502
2021-12-12 23:20:24,546 iteration 771 : loss : 0.037807, loss_ce: 0.018167
2021-12-12 23:20:25,956 iteration 772 : loss : 0.041877, loss_ce: 0.017270
2021-12-12 23:20:27,413 iteration 773 : loss : 0.087371, loss_ce: 0.026502
2021-12-12 23:20:28,925 iteration 774 : loss : 0.042841, loss_ce: 0.017234
2021-12-12 23:20:30,318 iteration 775 : loss : 0.043954, loss_ce: 0.017270
2021-12-12 23:20:31,761 iteration 776 : loss : 0.060803, loss_ce: 0.018365
2021-12-12 23:20:33,332 iteration 777 : loss : 0.054970, loss_ce: 0.024329
2021-12-12 23:20:34,791 iteration 778 : loss : 0.068969, loss_ce: 0.021346
2021-12-12 23:20:36,236 iteration 779 : loss : 0.042676, loss_ce: 0.016170
2021-12-12 23:20:37,785 iteration 780 : loss : 0.069906, loss_ce: 0.025153
2021-12-12 23:20:39,268 iteration 781 : loss : 0.035511, loss_ce: 0.012364
2021-12-12 23:20:40,700 iteration 782 : loss : 0.058902, loss_ce: 0.022285
 12%|███▍                          | 46/400 [20:58<2:42:17, 27.51s/it]2021-12-12 23:20:42,182 iteration 783 : loss : 0.046986, loss_ce: 0.019815
2021-12-12 23:20:43,593 iteration 784 : loss : 0.047915, loss_ce: 0.017880
2021-12-12 23:20:45,114 iteration 785 : loss : 0.053024, loss_ce: 0.016157
2021-12-12 23:20:46,571 iteration 786 : loss : 0.066113, loss_ce: 0.026391
2021-12-12 23:20:48,074 iteration 787 : loss : 0.063294, loss_ce: 0.024921
2021-12-12 23:20:49,482 iteration 788 : loss : 0.056699, loss_ce: 0.025383
2021-12-12 23:20:50,976 iteration 789 : loss : 0.063616, loss_ce: 0.022960
2021-12-12 23:20:52,490 iteration 790 : loss : 0.046345, loss_ce: 0.018903
2021-12-12 23:20:53,895 iteration 791 : loss : 0.053330, loss_ce: 0.024207
2021-12-12 23:20:55,417 iteration 792 : loss : 0.052114, loss_ce: 0.019895
2021-12-12 23:20:56,899 iteration 793 : loss : 0.061705, loss_ce: 0.023434
2021-12-12 23:20:58,400 iteration 794 : loss : 0.052232, loss_ce: 0.023222
2021-12-12 23:20:59,895 iteration 795 : loss : 0.056897, loss_ce: 0.020339
2021-12-12 23:21:01,434 iteration 796 : loss : 0.047878, loss_ce: 0.019083
2021-12-12 23:21:02,871 iteration 797 : loss : 0.041293, loss_ce: 0.020407
2021-12-12 23:21:04,301 iteration 798 : loss : 0.058545, loss_ce: 0.021601
2021-12-12 23:21:05,852 iteration 799 : loss : 0.070553, loss_ce: 0.025300
 12%|███▌                          | 47/400 [21:23<2:37:40, 26.80s/it]2021-12-12 23:21:07,361 iteration 800 : loss : 0.049128, loss_ce: 0.023764
2021-12-12 23:21:08,798 iteration 801 : loss : 0.076013, loss_ce: 0.024187
2021-12-12 23:21:10,291 iteration 802 : loss : 0.071907, loss_ce: 0.038571
2021-12-12 23:21:11,681 iteration 803 : loss : 0.039005, loss_ce: 0.014946
2021-12-12 23:21:13,224 iteration 804 : loss : 0.073460, loss_ce: 0.026161
2021-12-12 23:21:14,665 iteration 805 : loss : 0.046323, loss_ce: 0.019238
2021-12-12 23:21:16,066 iteration 806 : loss : 0.053191, loss_ce: 0.018831
2021-12-12 23:21:17,529 iteration 807 : loss : 0.043474, loss_ce: 0.020770
2021-12-12 23:21:18,996 iteration 808 : loss : 0.082818, loss_ce: 0.023414
2021-12-12 23:21:20,501 iteration 809 : loss : 0.057910, loss_ce: 0.023542
2021-12-12 23:21:21,897 iteration 810 : loss : 0.047277, loss_ce: 0.016393
2021-12-12 23:21:23,390 iteration 811 : loss : 0.054830, loss_ce: 0.023319
2021-12-12 23:21:24,822 iteration 812 : loss : 0.056706, loss_ce: 0.024613
2021-12-12 23:21:26,352 iteration 813 : loss : 0.047925, loss_ce: 0.020014
2021-12-12 23:21:27,893 iteration 814 : loss : 0.127196, loss_ce: 0.028667
2021-12-12 23:21:29,223 iteration 815 : loss : 0.043131, loss_ce: 0.021344
2021-12-12 23:21:30,745 iteration 816 : loss : 0.054472, loss_ce: 0.023480
 12%|███▌                          | 48/400 [21:48<2:33:52, 26.23s/it]2021-12-12 23:21:32,211 iteration 817 : loss : 0.054579, loss_ce: 0.024213
2021-12-12 23:21:33,648 iteration 818 : loss : 0.057432, loss_ce: 0.028816
2021-12-12 23:21:35,232 iteration 819 : loss : 0.070258, loss_ce: 0.031423
2021-12-12 23:21:36,735 iteration 820 : loss : 0.058132, loss_ce: 0.022086
2021-12-12 23:21:38,217 iteration 821 : loss : 0.051364, loss_ce: 0.019826
2021-12-12 23:21:39,671 iteration 822 : loss : 0.066999, loss_ce: 0.027693
2021-12-12 23:21:41,154 iteration 823 : loss : 0.041991, loss_ce: 0.014477
2021-12-12 23:21:42,564 iteration 824 : loss : 0.052980, loss_ce: 0.015884
2021-12-12 23:21:44,037 iteration 825 : loss : 0.080587, loss_ce: 0.025449
2021-12-12 23:21:45,440 iteration 826 : loss : 0.058206, loss_ce: 0.022622
2021-12-12 23:21:46,900 iteration 827 : loss : 0.072337, loss_ce: 0.026492
2021-12-12 23:21:48,283 iteration 828 : loss : 0.048039, loss_ce: 0.017514
2021-12-12 23:21:49,818 iteration 829 : loss : 0.075014, loss_ce: 0.032002
2021-12-12 23:21:51,286 iteration 830 : loss : 0.052264, loss_ce: 0.020932
2021-12-12 23:21:52,792 iteration 831 : loss : 0.098021, loss_ce: 0.053188
2021-12-12 23:21:54,268 iteration 832 : loss : 0.060869, loss_ce: 0.018572
2021-12-12 23:21:55,747 iteration 833 : loss : 0.052486, loss_ce: 0.022301
 12%|███▋                          | 49/400 [22:13<2:31:17, 25.86s/it]2021-12-12 23:21:57,183 iteration 834 : loss : 0.057948, loss_ce: 0.024054
2021-12-12 23:21:58,574 iteration 835 : loss : 0.041215, loss_ce: 0.013987
2021-12-12 23:22:00,099 iteration 836 : loss : 0.056870, loss_ce: 0.019693
2021-12-12 23:22:01,533 iteration 837 : loss : 0.039732, loss_ce: 0.014047
2021-12-12 23:22:03,008 iteration 838 : loss : 0.054791, loss_ce: 0.025504
2021-12-12 23:22:04,389 iteration 839 : loss : 0.047771, loss_ce: 0.018446
2021-12-12 23:22:05,796 iteration 840 : loss : 0.040285, loss_ce: 0.017220
2021-12-12 23:22:07,226 iteration 841 : loss : 0.071659, loss_ce: 0.024194
2021-12-12 23:22:08,771 iteration 842 : loss : 0.057298, loss_ce: 0.018347
2021-12-12 23:22:10,187 iteration 843 : loss : 0.044870, loss_ce: 0.014525
2021-12-12 23:22:11,679 iteration 844 : loss : 0.049412, loss_ce: 0.017843
2021-12-12 23:22:13,136 iteration 845 : loss : 0.054406, loss_ce: 0.028350
2021-12-12 23:22:14,595 iteration 846 : loss : 0.050532, loss_ce: 0.029174
2021-12-12 23:22:16,146 iteration 847 : loss : 0.053237, loss_ce: 0.019966
2021-12-12 23:22:17,581 iteration 848 : loss : 0.042469, loss_ce: 0.018395
2021-12-12 23:22:18,995 iteration 849 : loss : 0.043196, loss_ce: 0.016745
2021-12-12 23:22:18,996 Training Data Eval:
2021-12-12 23:22:26,498   Average segmentation loss on training set: 0.0479
2021-12-12 23:22:26,498 Validation Data Eval:
2021-12-12 23:22:29,093   Average segmentation loss on validation set: 0.0996
2021-12-12 23:22:30,525 iteration 850 : loss : 0.069072, loss_ce: 0.030258
 12%|███▊                          | 50/400 [22:48<2:46:27, 28.54s/it]2021-12-12 23:22:32,027 iteration 851 : loss : 0.054455, loss_ce: 0.022785
2021-12-12 23:22:33,477 iteration 852 : loss : 0.065097, loss_ce: 0.024024
2021-12-12 23:22:34,939 iteration 853 : loss : 0.051605, loss_ce: 0.017371
2021-12-12 23:22:36,413 iteration 854 : loss : 0.049068, loss_ce: 0.024045
2021-12-12 23:22:37,838 iteration 855 : loss : 0.044799, loss_ce: 0.019145
2021-12-12 23:22:39,331 iteration 856 : loss : 0.048138, loss_ce: 0.020183
2021-12-12 23:22:40,752 iteration 857 : loss : 0.072814, loss_ce: 0.033050
2021-12-12 23:22:42,282 iteration 858 : loss : 0.043822, loss_ce: 0.015331
2021-12-12 23:22:43,624 iteration 859 : loss : 0.041896, loss_ce: 0.012825
2021-12-12 23:22:45,074 iteration 860 : loss : 0.041815, loss_ce: 0.015664
2021-12-12 23:22:46,523 iteration 861 : loss : 0.063611, loss_ce: 0.020652
2021-12-12 23:22:48,007 iteration 862 : loss : 0.044936, loss_ce: 0.021287
2021-12-12 23:22:49,461 iteration 863 : loss : 0.055097, loss_ce: 0.019878
2021-12-12 23:22:50,899 iteration 864 : loss : 0.038518, loss_ce: 0.017347
2021-12-12 23:22:52,366 iteration 865 : loss : 0.038763, loss_ce: 0.014458
2021-12-12 23:22:53,789 iteration 866 : loss : 0.045354, loss_ce: 0.021211
2021-12-12 23:22:55,293 iteration 867 : loss : 0.047729, loss_ce: 0.019175
 13%|███▊                          | 51/400 [23:13<2:39:24, 27.41s/it]2021-12-12 23:22:56,786 iteration 868 : loss : 0.037698, loss_ce: 0.017238
2021-12-12 23:22:58,301 iteration 869 : loss : 0.048708, loss_ce: 0.020546
2021-12-12 23:22:59,682 iteration 870 : loss : 0.044617, loss_ce: 0.019262
2021-12-12 23:23:01,128 iteration 871 : loss : 0.038868, loss_ce: 0.016460
2021-12-12 23:23:02,565 iteration 872 : loss : 0.057597, loss_ce: 0.024470
2021-12-12 23:23:04,048 iteration 873 : loss : 0.048055, loss_ce: 0.020851
2021-12-12 23:23:05,519 iteration 874 : loss : 0.040444, loss_ce: 0.015896
2021-12-12 23:23:06,981 iteration 875 : loss : 0.046379, loss_ce: 0.017220
2021-12-12 23:23:08,441 iteration 876 : loss : 0.052371, loss_ce: 0.017035
2021-12-12 23:23:09,977 iteration 877 : loss : 0.045638, loss_ce: 0.017225
2021-12-12 23:23:11,403 iteration 878 : loss : 0.076560, loss_ce: 0.016228
2021-12-12 23:23:12,854 iteration 879 : loss : 0.069136, loss_ce: 0.018595
2021-12-12 23:23:14,271 iteration 880 : loss : 0.040705, loss_ce: 0.017605
2021-12-12 23:23:15,809 iteration 881 : loss : 0.039858, loss_ce: 0.012177
2021-12-12 23:23:17,303 iteration 882 : loss : 0.062528, loss_ce: 0.022359
2021-12-12 23:23:18,724 iteration 883 : loss : 0.051244, loss_ce: 0.015986
2021-12-12 23:23:20,231 iteration 884 : loss : 0.048128, loss_ce: 0.020988
 13%|███▉                          | 52/400 [23:38<2:34:39, 26.66s/it]2021-12-12 23:23:21,748 iteration 885 : loss : 0.046941, loss_ce: 0.019822
2021-12-12 23:23:23,213 iteration 886 : loss : 0.055611, loss_ce: 0.026467
2021-12-12 23:23:24,677 iteration 887 : loss : 0.063619, loss_ce: 0.022776
2021-12-12 23:23:26,153 iteration 888 : loss : 0.061149, loss_ce: 0.026089
2021-12-12 23:23:27,620 iteration 889 : loss : 0.086724, loss_ce: 0.016438
2021-12-12 23:23:29,054 iteration 890 : loss : 0.051035, loss_ce: 0.018671
2021-12-12 23:23:30,520 iteration 891 : loss : 0.068240, loss_ce: 0.043767
2021-12-12 23:23:31,985 iteration 892 : loss : 0.053929, loss_ce: 0.021252
2021-12-12 23:23:33,450 iteration 893 : loss : 0.078747, loss_ce: 0.038912
2021-12-12 23:23:34,906 iteration 894 : loss : 0.042529, loss_ce: 0.012819
2021-12-12 23:23:36,358 iteration 895 : loss : 0.050693, loss_ce: 0.016204
2021-12-12 23:23:37,800 iteration 896 : loss : 0.043006, loss_ce: 0.016506
2021-12-12 23:23:39,408 iteration 897 : loss : 0.063167, loss_ce: 0.022508
2021-12-12 23:23:40,842 iteration 898 : loss : 0.058369, loss_ce: 0.023446
2021-12-12 23:23:42,347 iteration 899 : loss : 0.065693, loss_ce: 0.022278
2021-12-12 23:23:43,831 iteration 900 : loss : 0.047669, loss_ce: 0.016170
2021-12-12 23:23:45,257 iteration 901 : loss : 0.057680, loss_ce: 0.021343
 13%|███▉                          | 53/400 [24:03<2:31:22, 26.18s/it]2021-12-12 23:23:46,806 iteration 902 : loss : 0.053521, loss_ce: 0.024498
2021-12-12 23:23:48,281 iteration 903 : loss : 0.068172, loss_ce: 0.019655
2021-12-12 23:23:49,722 iteration 904 : loss : 0.050811, loss_ce: 0.024602
2021-12-12 23:23:51,161 iteration 905 : loss : 0.046746, loss_ce: 0.017668
2021-12-12 23:23:52,709 iteration 906 : loss : 0.037742, loss_ce: 0.016616
2021-12-12 23:23:54,130 iteration 907 : loss : 0.043756, loss_ce: 0.017617
2021-12-12 23:23:55,574 iteration 908 : loss : 0.060187, loss_ce: 0.028641
2021-12-12 23:23:57,083 iteration 909 : loss : 0.053928, loss_ce: 0.022692
2021-12-12 23:23:58,625 iteration 910 : loss : 0.042839, loss_ce: 0.014120
2021-12-12 23:24:00,083 iteration 911 : loss : 0.045166, loss_ce: 0.017353
2021-12-12 23:24:01,569 iteration 912 : loss : 0.055912, loss_ce: 0.022505
2021-12-12 23:24:03,014 iteration 913 : loss : 0.055335, loss_ce: 0.016248
2021-12-12 23:24:04,407 iteration 914 : loss : 0.043151, loss_ce: 0.017768
2021-12-12 23:24:05,885 iteration 915 : loss : 0.059872, loss_ce: 0.021000
2021-12-12 23:24:07,413 iteration 916 : loss : 0.077378, loss_ce: 0.021831
2021-12-12 23:24:08,897 iteration 917 : loss : 0.039369, loss_ce: 0.014270
2021-12-12 23:24:10,416 iteration 918 : loss : 0.064195, loss_ce: 0.020256
 14%|████                          | 54/400 [24:28<2:29:11, 25.87s/it]2021-12-12 23:24:11,860 iteration 919 : loss : 0.051013, loss_ce: 0.017571
2021-12-12 23:24:13,349 iteration 920 : loss : 0.046997, loss_ce: 0.020230
2021-12-12 23:24:14,741 iteration 921 : loss : 0.039694, loss_ce: 0.015321
2021-12-12 23:24:16,231 iteration 922 : loss : 0.035847, loss_ce: 0.010995
2021-12-12 23:24:17,641 iteration 923 : loss : 0.037644, loss_ce: 0.012239
2021-12-12 23:24:19,138 iteration 924 : loss : 0.051575, loss_ce: 0.018603
2021-12-12 23:24:20,623 iteration 925 : loss : 0.053837, loss_ce: 0.016027
2021-12-12 23:24:22,088 iteration 926 : loss : 0.052078, loss_ce: 0.019006
2021-12-12 23:24:23,482 iteration 927 : loss : 0.053027, loss_ce: 0.014292
2021-12-12 23:24:25,008 iteration 928 : loss : 0.062987, loss_ce: 0.025463
2021-12-12 23:24:26,444 iteration 929 : loss : 0.051198, loss_ce: 0.020021
2021-12-12 23:24:27,842 iteration 930 : loss : 0.048871, loss_ce: 0.019127
2021-12-12 23:24:29,259 iteration 931 : loss : 0.062284, loss_ce: 0.035019
2021-12-12 23:24:30,722 iteration 932 : loss : 0.043484, loss_ce: 0.021502
2021-12-12 23:24:32,215 iteration 933 : loss : 0.056296, loss_ce: 0.027316
2021-12-12 23:24:33,644 iteration 934 : loss : 0.051486, loss_ce: 0.016414
2021-12-12 23:24:33,644 Training Data Eval:
2021-12-12 23:24:41,141   Average segmentation loss on training set: 0.0846
2021-12-12 23:24:41,141 Validation Data Eval:
2021-12-12 23:24:43,744   Average segmentation loss on validation set: 0.1099
2021-12-12 23:24:45,244 iteration 935 : loss : 0.040263, loss_ce: 0.018423
 14%|████▏                         | 55/400 [25:03<2:44:12, 28.56s/it]2021-12-12 23:24:46,757 iteration 936 : loss : 0.043650, loss_ce: 0.019064
2021-12-12 23:24:48,224 iteration 937 : loss : 0.076430, loss_ce: 0.028032
2021-12-12 23:24:49,720 iteration 938 : loss : 0.036813, loss_ce: 0.015971
2021-12-12 23:24:51,278 iteration 939 : loss : 0.067352, loss_ce: 0.018192
2021-12-12 23:24:52,678 iteration 940 : loss : 0.051336, loss_ce: 0.016648
2021-12-12 23:24:54,117 iteration 941 : loss : 0.051599, loss_ce: 0.019619
2021-12-12 23:24:55,585 iteration 942 : loss : 0.050447, loss_ce: 0.020841
2021-12-12 23:24:57,061 iteration 943 : loss : 0.075166, loss_ce: 0.022736
2021-12-12 23:24:58,512 iteration 944 : loss : 0.070567, loss_ce: 0.020529
2021-12-12 23:24:59,990 iteration 945 : loss : 0.055995, loss_ce: 0.024857
2021-12-12 23:25:01,435 iteration 946 : loss : 0.042442, loss_ce: 0.016458
2021-12-12 23:25:02,889 iteration 947 : loss : 0.054392, loss_ce: 0.018822
2021-12-12 23:25:04,403 iteration 948 : loss : 0.053329, loss_ce: 0.022446
2021-12-12 23:25:05,922 iteration 949 : loss : 0.064896, loss_ce: 0.030183
2021-12-12 23:25:07,454 iteration 950 : loss : 0.076505, loss_ce: 0.028404
2021-12-12 23:25:08,904 iteration 951 : loss : 0.036729, loss_ce: 0.013185
2021-12-12 23:25:10,400 iteration 952 : loss : 0.061267, loss_ce: 0.025177
 14%|████▏                         | 56/400 [25:28<2:37:52, 27.54s/it]2021-12-12 23:25:11,857 iteration 953 : loss : 0.047860, loss_ce: 0.015955
2021-12-12 23:25:13,289 iteration 954 : loss : 0.041035, loss_ce: 0.014325
2021-12-12 23:25:14,779 iteration 955 : loss : 0.041655, loss_ce: 0.014077
2021-12-12 23:25:16,263 iteration 956 : loss : 0.042630, loss_ce: 0.013741
2021-12-12 23:25:17,729 iteration 957 : loss : 0.069954, loss_ce: 0.025032
2021-12-12 23:25:19,207 iteration 958 : loss : 0.071375, loss_ce: 0.024329
2021-12-12 23:25:20,718 iteration 959 : loss : 0.070171, loss_ce: 0.030198
2021-12-12 23:25:22,211 iteration 960 : loss : 0.064383, loss_ce: 0.030221
2021-12-12 23:25:23,683 iteration 961 : loss : 0.053762, loss_ce: 0.020894
2021-12-12 23:25:25,169 iteration 962 : loss : 0.053577, loss_ce: 0.015931
2021-12-12 23:25:26,569 iteration 963 : loss : 0.043211, loss_ce: 0.018811
2021-12-12 23:25:28,055 iteration 964 : loss : 0.053226, loss_ce: 0.016051
2021-12-12 23:25:29,482 iteration 965 : loss : 0.035819, loss_ce: 0.012029
2021-12-12 23:25:31,022 iteration 966 : loss : 0.052542, loss_ce: 0.015983
2021-12-12 23:25:32,488 iteration 967 : loss : 0.064379, loss_ce: 0.026685
2021-12-12 23:25:33,872 iteration 968 : loss : 0.052797, loss_ce: 0.019439
2021-12-12 23:25:35,347 iteration 969 : loss : 0.050661, loss_ce: 0.023167
 14%|████▎                         | 57/400 [25:53<2:32:57, 26.76s/it]2021-12-12 23:25:36,814 iteration 970 : loss : 0.062292, loss_ce: 0.032097
2021-12-12 23:25:38,303 iteration 971 : loss : 0.045094, loss_ce: 0.020010
2021-12-12 23:25:39,747 iteration 972 : loss : 0.057484, loss_ce: 0.019926
2021-12-12 23:25:41,225 iteration 973 : loss : 0.044099, loss_ce: 0.018133
2021-12-12 23:25:42,682 iteration 974 : loss : 0.051970, loss_ce: 0.022342
2021-12-12 23:25:44,105 iteration 975 : loss : 0.062633, loss_ce: 0.024707
2021-12-12 23:25:45,619 iteration 976 : loss : 0.064089, loss_ce: 0.030963
2021-12-12 23:25:47,062 iteration 977 : loss : 0.049248, loss_ce: 0.019690
2021-12-12 23:25:48,537 iteration 978 : loss : 0.034301, loss_ce: 0.013068
2021-12-12 23:25:49,968 iteration 979 : loss : 0.037070, loss_ce: 0.013758
2021-12-12 23:25:51,406 iteration 980 : loss : 0.040729, loss_ce: 0.013420
2021-12-12 23:25:52,832 iteration 981 : loss : 0.028764, loss_ce: 0.011205
2021-12-12 23:25:54,320 iteration 982 : loss : 0.049419, loss_ce: 0.016089
2021-12-12 23:25:55,840 iteration 983 : loss : 0.066143, loss_ce: 0.033170
2021-12-12 23:25:57,356 iteration 984 : loss : 0.052424, loss_ce: 0.027059
2021-12-12 23:25:58,843 iteration 985 : loss : 0.053236, loss_ce: 0.026131
2021-12-12 23:26:00,268 iteration 986 : loss : 0.041795, loss_ce: 0.013089
 14%|████▎                         | 58/400 [26:18<2:29:23, 26.21s/it]2021-12-12 23:26:01,696 iteration 987 : loss : 0.050013, loss_ce: 0.019843
2021-12-12 23:26:03,150 iteration 988 : loss : 0.040462, loss_ce: 0.012516
2021-12-12 23:26:04,613 iteration 989 : loss : 0.038295, loss_ce: 0.013181
2021-12-12 23:26:06,064 iteration 990 : loss : 0.043406, loss_ce: 0.014101
2021-12-12 23:26:07,513 iteration 991 : loss : 0.041253, loss_ce: 0.015275
2021-12-12 23:26:08,931 iteration 992 : loss : 0.034438, loss_ce: 0.013706
2021-12-12 23:26:10,312 iteration 993 : loss : 0.034511, loss_ce: 0.012995
2021-12-12 23:26:11,659 iteration 994 : loss : 0.047550, loss_ce: 0.015630
2021-12-12 23:26:13,192 iteration 995 : loss : 0.048535, loss_ce: 0.021643
2021-12-12 23:26:14,681 iteration 996 : loss : 0.042495, loss_ce: 0.018444
2021-12-12 23:26:16,185 iteration 997 : loss : 0.050561, loss_ce: 0.019993
2021-12-12 23:26:17,675 iteration 998 : loss : 0.045424, loss_ce: 0.015056
2021-12-12 23:26:19,092 iteration 999 : loss : 0.048227, loss_ce: 0.019444
2021-12-12 23:26:20,603 iteration 1000 : loss : 0.044822, loss_ce: 0.024143
2021-12-12 23:26:22,036 iteration 1001 : loss : 0.039129, loss_ce: 0.014677
2021-12-12 23:26:23,550 iteration 1002 : loss : 0.059354, loss_ce: 0.022000
2021-12-12 23:26:24,946 iteration 1003 : loss : 0.073737, loss_ce: 0.017725
 15%|████▍                         | 59/400 [26:43<2:26:19, 25.75s/it]2021-12-12 23:26:26,429 iteration 1004 : loss : 0.048387, loss_ce: 0.015222
2021-12-12 23:26:27,877 iteration 1005 : loss : 0.063357, loss_ce: 0.032161
2021-12-12 23:26:29,417 iteration 1006 : loss : 0.061954, loss_ce: 0.033083
2021-12-12 23:26:30,908 iteration 1007 : loss : 0.057086, loss_ce: 0.024320
2021-12-12 23:26:32,424 iteration 1008 : loss : 0.071936, loss_ce: 0.041439
2021-12-12 23:26:33,870 iteration 1009 : loss : 0.043556, loss_ce: 0.014189
2021-12-12 23:26:35,270 iteration 1010 : loss : 0.031118, loss_ce: 0.009170
2021-12-12 23:26:36,710 iteration 1011 : loss : 0.044712, loss_ce: 0.018299
2021-12-12 23:26:38,218 iteration 1012 : loss : 0.061946, loss_ce: 0.025365
2021-12-12 23:26:39,675 iteration 1013 : loss : 0.039104, loss_ce: 0.015908
2021-12-12 23:26:41,119 iteration 1014 : loss : 0.037132, loss_ce: 0.015435
2021-12-12 23:26:42,689 iteration 1015 : loss : 0.073315, loss_ce: 0.028808
2021-12-12 23:26:44,144 iteration 1016 : loss : 0.049628, loss_ce: 0.020046
2021-12-12 23:26:45,574 iteration 1017 : loss : 0.066159, loss_ce: 0.028181
2021-12-12 23:26:47,091 iteration 1018 : loss : 0.068481, loss_ce: 0.021387
2021-12-12 23:26:48,587 iteration 1019 : loss : 0.044550, loss_ce: 0.020373
2021-12-12 23:26:48,588 Training Data Eval:
2021-12-12 23:26:56,077   Average segmentation loss on training set: 0.0386
2021-12-12 23:26:56,078 Validation Data Eval:
2021-12-12 23:26:58,681   Average segmentation loss on validation set: 0.1382
2021-12-12 23:27:00,238 iteration 1020 : loss : 0.066302, loss_ce: 0.031524
 15%|████▌                         | 60/400 [27:18<2:42:08, 28.61s/it]2021-12-12 23:27:01,741 iteration 1021 : loss : 0.058776, loss_ce: 0.021209
2021-12-12 23:27:03,304 iteration 1022 : loss : 0.047836, loss_ce: 0.021918
2021-12-12 23:27:04,727 iteration 1023 : loss : 0.036314, loss_ce: 0.013257
2021-12-12 23:27:06,167 iteration 1024 : loss : 0.056783, loss_ce: 0.020235
2021-12-12 23:27:07,679 iteration 1025 : loss : 0.048378, loss_ce: 0.019801
2021-12-12 23:27:09,162 iteration 1026 : loss : 0.068831, loss_ce: 0.014860
2021-12-12 23:27:10,608 iteration 1027 : loss : 0.045451, loss_ce: 0.014811
2021-12-12 23:27:12,142 iteration 1028 : loss : 0.067819, loss_ce: 0.020562
2021-12-12 23:27:13,651 iteration 1029 : loss : 0.043231, loss_ce: 0.013985
2021-12-12 23:27:15,119 iteration 1030 : loss : 0.068979, loss_ce: 0.028128
2021-12-12 23:27:16,683 iteration 1031 : loss : 0.085523, loss_ce: 0.033894
2021-12-12 23:27:18,168 iteration 1032 : loss : 0.069130, loss_ce: 0.030717
2021-12-12 23:27:19,599 iteration 1033 : loss : 0.057457, loss_ce: 0.026897
2021-12-12 23:27:21,005 iteration 1034 : loss : 0.040515, loss_ce: 0.014304
2021-12-12 23:27:22,506 iteration 1035 : loss : 0.052639, loss_ce: 0.022871
2021-12-12 23:27:24,028 iteration 1036 : loss : 0.077932, loss_ce: 0.031162
2021-12-12 23:27:25,429 iteration 1037 : loss : 0.043358, loss_ce: 0.018185
 15%|████▌                         | 61/400 [27:43<2:35:51, 27.59s/it]2021-12-12 23:27:26,902 iteration 1038 : loss : 0.047207, loss_ce: 0.023673
2021-12-12 23:27:28,350 iteration 1039 : loss : 0.041167, loss_ce: 0.017241
2021-12-12 23:27:29,796 iteration 1040 : loss : 0.070210, loss_ce: 0.024538
2021-12-12 23:27:31,248 iteration 1041 : loss : 0.050329, loss_ce: 0.024049
2021-12-12 23:27:32,687 iteration 1042 : loss : 0.045695, loss_ce: 0.021432
2021-12-12 23:27:34,142 iteration 1043 : loss : 0.051065, loss_ce: 0.017827
2021-12-12 23:27:35,647 iteration 1044 : loss : 0.059224, loss_ce: 0.029919
2021-12-12 23:27:37,101 iteration 1045 : loss : 0.064738, loss_ce: 0.024667
2021-12-12 23:27:38,516 iteration 1046 : loss : 0.054225, loss_ce: 0.024551
2021-12-12 23:27:39,869 iteration 1047 : loss : 0.040362, loss_ce: 0.015952
2021-12-12 23:27:41,344 iteration 1048 : loss : 0.038385, loss_ce: 0.017509
2021-12-12 23:27:42,853 iteration 1049 : loss : 0.054310, loss_ce: 0.018763
2021-12-12 23:27:44,307 iteration 1050 : loss : 0.106114, loss_ce: 0.020672
2021-12-12 23:27:45,754 iteration 1051 : loss : 0.062424, loss_ce: 0.030179
2021-12-12 23:27:47,256 iteration 1052 : loss : 0.046660, loss_ce: 0.015139
2021-12-12 23:27:48,727 iteration 1053 : loss : 0.077174, loss_ce: 0.020095
2021-12-12 23:27:50,172 iteration 1054 : loss : 0.046081, loss_ce: 0.016489
 16%|████▋                         | 62/400 [28:08<2:30:35, 26.73s/it]2021-12-12 23:27:51,651 iteration 1055 : loss : 0.045112, loss_ce: 0.013595
2021-12-12 23:27:53,039 iteration 1056 : loss : 0.053971, loss_ce: 0.020682
2021-12-12 23:27:54,524 iteration 1057 : loss : 0.047744, loss_ce: 0.015712
2021-12-12 23:27:55,989 iteration 1058 : loss : 0.080341, loss_ce: 0.027334
2021-12-12 23:27:57,474 iteration 1059 : loss : 0.058531, loss_ce: 0.020433
2021-12-12 23:27:58,878 iteration 1060 : loss : 0.045797, loss_ce: 0.015796
2021-12-12 23:28:00,434 iteration 1061 : loss : 0.048766, loss_ce: 0.025279
2021-12-12 23:28:01,911 iteration 1062 : loss : 0.074800, loss_ce: 0.025228
2021-12-12 23:28:03,495 iteration 1063 : loss : 0.045859, loss_ce: 0.020769
2021-12-12 23:28:04,962 iteration 1064 : loss : 0.043509, loss_ce: 0.015417
2021-12-12 23:28:06,492 iteration 1065 : loss : 0.044313, loss_ce: 0.020512
2021-12-12 23:28:07,918 iteration 1066 : loss : 0.037550, loss_ce: 0.014788
2021-12-12 23:28:09,356 iteration 1067 : loss : 0.040769, loss_ce: 0.015710
2021-12-12 23:28:10,847 iteration 1068 : loss : 0.040293, loss_ce: 0.016976
2021-12-12 23:28:12,324 iteration 1069 : loss : 0.040891, loss_ce: 0.017824
2021-12-12 23:28:13,878 iteration 1070 : loss : 0.091219, loss_ce: 0.023323
2021-12-12 23:28:15,338 iteration 1071 : loss : 0.052260, loss_ce: 0.028247
 16%|████▋                         | 63/400 [28:33<2:27:30, 26.26s/it]2021-12-12 23:28:16,933 iteration 1072 : loss : 0.051225, loss_ce: 0.013355
2021-12-12 23:28:18,418 iteration 1073 : loss : 0.050336, loss_ce: 0.019683
2021-12-12 23:28:19,912 iteration 1074 : loss : 0.072992, loss_ce: 0.024240
2021-12-12 23:28:21,391 iteration 1075 : loss : 0.060092, loss_ce: 0.016146
2021-12-12 23:28:22,829 iteration 1076 : loss : 0.041942, loss_ce: 0.015704
2021-12-12 23:28:24,362 iteration 1077 : loss : 0.055132, loss_ce: 0.020020
2021-12-12 23:28:25,780 iteration 1078 : loss : 0.058526, loss_ce: 0.024832
2021-12-12 23:28:27,304 iteration 1079 : loss : 0.062035, loss_ce: 0.023492
2021-12-12 23:28:28,700 iteration 1080 : loss : 0.029542, loss_ce: 0.009132
2021-12-12 23:28:30,154 iteration 1081 : loss : 0.039777, loss_ce: 0.019965
2021-12-12 23:28:31,662 iteration 1082 : loss : 0.055300, loss_ce: 0.026114
2021-12-12 23:28:33,096 iteration 1083 : loss : 0.038573, loss_ce: 0.014687
2021-12-12 23:28:34,546 iteration 1084 : loss : 0.059136, loss_ce: 0.016362
2021-12-12 23:28:36,012 iteration 1085 : loss : 0.047793, loss_ce: 0.018270
2021-12-12 23:28:37,458 iteration 1086 : loss : 0.054691, loss_ce: 0.025389
2021-12-12 23:28:38,990 iteration 1087 : loss : 0.040882, loss_ce: 0.015929
2021-12-12 23:28:40,457 iteration 1088 : loss : 0.044072, loss_ce: 0.017755
 16%|████▊                         | 64/400 [28:58<2:25:08, 25.92s/it]2021-12-12 23:28:41,927 iteration 1089 : loss : 0.061893, loss_ce: 0.024519
2021-12-12 23:28:43,356 iteration 1090 : loss : 0.054369, loss_ce: 0.016966
2021-12-12 23:28:44,862 iteration 1091 : loss : 0.051301, loss_ce: 0.023218
2021-12-12 23:28:46,330 iteration 1092 : loss : 0.067804, loss_ce: 0.026861
2021-12-12 23:28:47,789 iteration 1093 : loss : 0.033228, loss_ce: 0.012316
2021-12-12 23:28:49,277 iteration 1094 : loss : 0.040265, loss_ce: 0.017959
2021-12-12 23:28:50,766 iteration 1095 : loss : 0.097261, loss_ce: 0.024430
2021-12-12 23:28:52,218 iteration 1096 : loss : 0.038069, loss_ce: 0.015474
2021-12-12 23:28:53,636 iteration 1097 : loss : 0.069844, loss_ce: 0.021386
2021-12-12 23:28:55,078 iteration 1098 : loss : 0.039518, loss_ce: 0.016922
2021-12-12 23:28:56,577 iteration 1099 : loss : 0.040338, loss_ce: 0.014897
2021-12-12 23:28:58,019 iteration 1100 : loss : 0.052667, loss_ce: 0.021175
2021-12-12 23:28:59,454 iteration 1101 : loss : 0.045528, loss_ce: 0.015790
2021-12-12 23:29:00,974 iteration 1102 : loss : 0.066670, loss_ce: 0.026158
2021-12-12 23:29:02,409 iteration 1103 : loss : 0.035894, loss_ce: 0.012389
2021-12-12 23:29:03,826 iteration 1104 : loss : 0.050465, loss_ce: 0.021377
2021-12-12 23:29:03,826 Training Data Eval:
2021-12-12 23:29:11,332   Average segmentation loss on training set: 0.0349
2021-12-12 23:29:11,332 Validation Data Eval:
2021-12-12 23:29:13,920   Average segmentation loss on validation set: 0.0789
2021-12-12 23:29:20,334 Found new lowest validation loss at iteration 1104! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:29:21,732 iteration 1105 : loss : 0.039421, loss_ce: 0.017191
 16%|████▉                         | 65/400 [29:39<2:50:26, 30.53s/it]2021-12-12 23:29:23,148 iteration 1106 : loss : 0.039732, loss_ce: 0.013866
2021-12-12 23:29:24,587 iteration 1107 : loss : 0.065230, loss_ce: 0.033906
2021-12-12 23:29:25,917 iteration 1108 : loss : 0.032011, loss_ce: 0.011845
2021-12-12 23:29:27,230 iteration 1109 : loss : 0.070878, loss_ce: 0.028417
2021-12-12 23:29:28,587 iteration 1110 : loss : 0.042712, loss_ce: 0.017408
2021-12-12 23:29:29,966 iteration 1111 : loss : 0.047794, loss_ce: 0.016971
2021-12-12 23:29:31,355 iteration 1112 : loss : 0.048770, loss_ce: 0.019302
2021-12-12 23:29:32,697 iteration 1113 : loss : 0.044990, loss_ce: 0.015439
2021-12-12 23:29:34,014 iteration 1114 : loss : 0.047054, loss_ce: 0.019885
2021-12-12 23:29:35,298 iteration 1115 : loss : 0.037357, loss_ce: 0.011481
2021-12-12 23:29:36,780 iteration 1116 : loss : 0.052308, loss_ce: 0.024435
2021-12-12 23:29:38,317 iteration 1117 : loss : 0.038324, loss_ce: 0.015830
2021-12-12 23:29:39,763 iteration 1118 : loss : 0.041643, loss_ce: 0.017884
2021-12-12 23:29:41,203 iteration 1119 : loss : 0.032549, loss_ce: 0.012159
2021-12-12 23:29:42,624 iteration 1120 : loss : 0.046702, loss_ce: 0.015596
2021-12-12 23:29:44,054 iteration 1121 : loss : 0.045631, loss_ce: 0.012336
2021-12-12 23:29:45,476 iteration 1122 : loss : 0.033269, loss_ce: 0.013775
 16%|████▉                         | 66/400 [30:03<2:38:36, 28.49s/it]2021-12-12 23:29:46,980 iteration 1123 : loss : 0.038140, loss_ce: 0.017589
2021-12-12 23:29:48,418 iteration 1124 : loss : 0.035803, loss_ce: 0.015897
2021-12-12 23:29:49,944 iteration 1125 : loss : 0.055638, loss_ce: 0.019762
2021-12-12 23:29:51,535 iteration 1126 : loss : 0.064386, loss_ce: 0.027540
2021-12-12 23:29:53,028 iteration 1127 : loss : 0.047689, loss_ce: 0.016525
2021-12-12 23:29:54,520 iteration 1128 : loss : 0.041308, loss_ce: 0.012577
2021-12-12 23:29:55,970 iteration 1129 : loss : 0.039623, loss_ce: 0.015657
2021-12-12 23:29:57,482 iteration 1130 : loss : 0.062397, loss_ce: 0.031112
2021-12-12 23:29:59,004 iteration 1131 : loss : 0.069748, loss_ce: 0.017551
2021-12-12 23:30:00,475 iteration 1132 : loss : 0.048851, loss_ce: 0.018367
2021-12-12 23:30:01,963 iteration 1133 : loss : 0.053240, loss_ce: 0.019585
2021-12-12 23:30:03,453 iteration 1134 : loss : 0.042194, loss_ce: 0.017530
2021-12-12 23:30:04,882 iteration 1135 : loss : 0.042567, loss_ce: 0.014520
2021-12-12 23:30:06,356 iteration 1136 : loss : 0.039823, loss_ce: 0.016877
2021-12-12 23:30:07,796 iteration 1137 : loss : 0.039231, loss_ce: 0.014815
2021-12-12 23:30:09,335 iteration 1138 : loss : 0.048529, loss_ce: 0.021250
2021-12-12 23:30:10,863 iteration 1139 : loss : 0.034561, loss_ce: 0.013955
 17%|█████                         | 67/400 [30:28<2:32:57, 27.56s/it]2021-12-12 23:30:12,340 iteration 1140 : loss : 0.044829, loss_ce: 0.018011
2021-12-12 23:30:13,801 iteration 1141 : loss : 0.038222, loss_ce: 0.014680
2021-12-12 23:30:15,219 iteration 1142 : loss : 0.034327, loss_ce: 0.013748
2021-12-12 23:30:16,702 iteration 1143 : loss : 0.071755, loss_ce: 0.024298
2021-12-12 23:30:18,226 iteration 1144 : loss : 0.059431, loss_ce: 0.023503
2021-12-12 23:30:19,681 iteration 1145 : loss : 0.038109, loss_ce: 0.011823
2021-12-12 23:30:21,164 iteration 1146 : loss : 0.038230, loss_ce: 0.016202
2021-12-12 23:30:22,577 iteration 1147 : loss : 0.031781, loss_ce: 0.010997
2021-12-12 23:30:24,044 iteration 1148 : loss : 0.034224, loss_ce: 0.011930
2021-12-12 23:30:25,554 iteration 1149 : loss : 0.036980, loss_ce: 0.015671
2021-12-12 23:30:27,035 iteration 1150 : loss : 0.034822, loss_ce: 0.015153
2021-12-12 23:30:28,507 iteration 1151 : loss : 0.043732, loss_ce: 0.013712
2021-12-12 23:30:30,001 iteration 1152 : loss : 0.088970, loss_ce: 0.016429
2021-12-12 23:30:31,484 iteration 1153 : loss : 0.034461, loss_ce: 0.011931
2021-12-12 23:30:32,904 iteration 1154 : loss : 0.041846, loss_ce: 0.018794
2021-12-12 23:30:34,483 iteration 1155 : loss : 0.062437, loss_ce: 0.020783
2021-12-12 23:30:35,999 iteration 1156 : loss : 0.057262, loss_ce: 0.017579
 17%|█████                         | 68/400 [30:54<2:28:27, 26.83s/it]2021-12-12 23:30:37,469 iteration 1157 : loss : 0.034725, loss_ce: 0.013333
2021-12-12 23:30:39,043 iteration 1158 : loss : 0.062989, loss_ce: 0.023672
2021-12-12 23:30:40,556 iteration 1159 : loss : 0.059293, loss_ce: 0.025347
2021-12-12 23:30:41,949 iteration 1160 : loss : 0.035523, loss_ce: 0.015251
2021-12-12 23:30:43,420 iteration 1161 : loss : 0.064040, loss_ce: 0.020778
2021-12-12 23:30:44,876 iteration 1162 : loss : 0.064430, loss_ce: 0.016588
2021-12-12 23:30:46,426 iteration 1163 : loss : 0.077084, loss_ce: 0.024561
2021-12-12 23:30:47,904 iteration 1164 : loss : 0.047613, loss_ce: 0.018307
2021-12-12 23:30:49,309 iteration 1165 : loss : 0.047651, loss_ce: 0.023814
2021-12-12 23:30:50,773 iteration 1166 : loss : 0.040868, loss_ce: 0.018639
2021-12-12 23:30:52,267 iteration 1167 : loss : 0.049692, loss_ce: 0.021142
2021-12-12 23:30:53,658 iteration 1168 : loss : 0.036538, loss_ce: 0.012616
2021-12-12 23:30:55,114 iteration 1169 : loss : 0.045699, loss_ce: 0.013969
2021-12-12 23:30:56,574 iteration 1170 : loss : 0.045884, loss_ce: 0.015713
2021-12-12 23:30:57,978 iteration 1171 : loss : 0.029245, loss_ce: 0.011672
2021-12-12 23:30:59,440 iteration 1172 : loss : 0.051642, loss_ce: 0.028602
2021-12-12 23:31:00,923 iteration 1173 : loss : 0.072825, loss_ce: 0.044754
 17%|█████▏                        | 69/400 [31:19<2:24:52, 26.26s/it]2021-12-12 23:31:02,463 iteration 1174 : loss : 0.046277, loss_ce: 0.013050
2021-12-12 23:31:03,907 iteration 1175 : loss : 0.037723, loss_ce: 0.014668
2021-12-12 23:31:05,415 iteration 1176 : loss : 0.059167, loss_ce: 0.027160
2021-12-12 23:31:06,966 iteration 1177 : loss : 0.042334, loss_ce: 0.017663
2021-12-12 23:31:08,440 iteration 1178 : loss : 0.047566, loss_ce: 0.020846
2021-12-12 23:31:09,829 iteration 1179 : loss : 0.033987, loss_ce: 0.015629
2021-12-12 23:31:11,346 iteration 1180 : loss : 0.044113, loss_ce: 0.019058
2021-12-12 23:31:12,739 iteration 1181 : loss : 0.039604, loss_ce: 0.017425
2021-12-12 23:31:14,281 iteration 1182 : loss : 0.045913, loss_ce: 0.016879
2021-12-12 23:31:15,740 iteration 1183 : loss : 0.041119, loss_ce: 0.015788
2021-12-12 23:31:17,151 iteration 1184 : loss : 0.030720, loss_ce: 0.013622
2021-12-12 23:31:18,645 iteration 1185 : loss : 0.047698, loss_ce: 0.016845
2021-12-12 23:31:20,077 iteration 1186 : loss : 0.040896, loss_ce: 0.014977
2021-12-12 23:31:21,559 iteration 1187 : loss : 0.042383, loss_ce: 0.017263
2021-12-12 23:31:22,975 iteration 1188 : loss : 0.034954, loss_ce: 0.012410
2021-12-12 23:31:24,429 iteration 1189 : loss : 0.040847, loss_ce: 0.014417
2021-12-12 23:31:24,430 Training Data Eval:
2021-12-12 23:31:31,936   Average segmentation loss on training set: 0.0377
2021-12-12 23:31:31,936 Validation Data Eval:
2021-12-12 23:31:34,532   Average segmentation loss on validation set: 0.1214
2021-12-12 23:31:36,028 iteration 1190 : loss : 0.048176, loss_ce: 0.017934
 18%|█████▎                        | 70/400 [31:54<2:39:01, 28.91s/it]2021-12-12 23:31:37,504 iteration 1191 : loss : 0.070328, loss_ce: 0.033674
2021-12-12 23:31:38,920 iteration 1192 : loss : 0.037903, loss_ce: 0.016571
2021-12-12 23:31:40,394 iteration 1193 : loss : 0.047524, loss_ce: 0.013823
2021-12-12 23:31:41,831 iteration 1194 : loss : 0.069251, loss_ce: 0.026010
2021-12-12 23:31:43,335 iteration 1195 : loss : 0.070743, loss_ce: 0.023787
2021-12-12 23:31:44,735 iteration 1196 : loss : 0.042634, loss_ce: 0.014111
2021-12-12 23:31:46,223 iteration 1197 : loss : 0.052835, loss_ce: 0.024185
2021-12-12 23:31:47,685 iteration 1198 : loss : 0.044838, loss_ce: 0.022007
2021-12-12 23:31:49,160 iteration 1199 : loss : 0.034220, loss_ce: 0.013411
2021-12-12 23:31:50,661 iteration 1200 : loss : 0.048497, loss_ce: 0.017809
2021-12-12 23:31:52,118 iteration 1201 : loss : 0.027986, loss_ce: 0.011689
2021-12-12 23:31:53,633 iteration 1202 : loss : 0.038735, loss_ce: 0.017552
2021-12-12 23:31:55,080 iteration 1203 : loss : 0.048244, loss_ce: 0.016976
2021-12-12 23:31:56,520 iteration 1204 : loss : 0.041856, loss_ce: 0.019119
2021-12-12 23:31:58,006 iteration 1205 : loss : 0.040378, loss_ce: 0.021731
2021-12-12 23:31:59,514 iteration 1206 : loss : 0.089538, loss_ce: 0.026977
2021-12-12 23:32:00,945 iteration 1207 : loss : 0.051571, loss_ce: 0.019646
 18%|█████▎                        | 71/400 [32:19<2:31:58, 27.72s/it]2021-12-12 23:32:02,408 iteration 1208 : loss : 0.037997, loss_ce: 0.017677
2021-12-12 23:32:03,875 iteration 1209 : loss : 0.056597, loss_ce: 0.017122
2021-12-12 23:32:05,268 iteration 1210 : loss : 0.035690, loss_ce: 0.011268
2021-12-12 23:32:06,757 iteration 1211 : loss : 0.051435, loss_ce: 0.016860
2021-12-12 23:32:08,172 iteration 1212 : loss : 0.032989, loss_ce: 0.013633
2021-12-12 23:32:09,632 iteration 1213 : loss : 0.088986, loss_ce: 0.021934
2021-12-12 23:32:11,108 iteration 1214 : loss : 0.036542, loss_ce: 0.015018
2021-12-12 23:32:12,553 iteration 1215 : loss : 0.038879, loss_ce: 0.016405
2021-12-12 23:32:13,989 iteration 1216 : loss : 0.036713, loss_ce: 0.014064
2021-12-12 23:32:15,484 iteration 1217 : loss : 0.043869, loss_ce: 0.021012
2021-12-12 23:32:16,863 iteration 1218 : loss : 0.034485, loss_ce: 0.015036
2021-12-12 23:32:18,357 iteration 1219 : loss : 0.044747, loss_ce: 0.016472
2021-12-12 23:32:19,806 iteration 1220 : loss : 0.040240, loss_ce: 0.014190
2021-12-12 23:32:21,374 iteration 1221 : loss : 0.049928, loss_ce: 0.019065
2021-12-12 23:32:22,864 iteration 1222 : loss : 0.040475, loss_ce: 0.013024
2021-12-12 23:32:24,312 iteration 1223 : loss : 0.037744, loss_ce: 0.015806
2021-12-12 23:32:25,812 iteration 1224 : loss : 0.037139, loss_ce: 0.016529
 18%|█████▍                        | 72/400 [32:43<2:26:49, 26.86s/it]2021-12-12 23:32:27,333 iteration 1225 : loss : 0.048011, loss_ce: 0.016888
2021-12-12 23:32:28,794 iteration 1226 : loss : 0.045403, loss_ce: 0.018260
2021-12-12 23:32:30,221 iteration 1227 : loss : 0.040284, loss_ce: 0.012295
2021-12-12 23:32:31,767 iteration 1228 : loss : 0.062018, loss_ce: 0.020252
2021-12-12 23:32:33,276 iteration 1229 : loss : 0.068308, loss_ce: 0.030952
2021-12-12 23:32:34,778 iteration 1230 : loss : 0.039034, loss_ce: 0.018980
2021-12-12 23:32:36,233 iteration 1231 : loss : 0.068093, loss_ce: 0.024860
2021-12-12 23:32:37,744 iteration 1232 : loss : 0.041611, loss_ce: 0.019378
2021-12-12 23:32:39,299 iteration 1233 : loss : 0.051350, loss_ce: 0.023808
2021-12-12 23:32:40,770 iteration 1234 : loss : 0.053233, loss_ce: 0.022764
2021-12-12 23:32:42,216 iteration 1235 : loss : 0.043126, loss_ce: 0.018404
2021-12-12 23:32:43,651 iteration 1236 : loss : 0.039083, loss_ce: 0.016157
2021-12-12 23:32:45,056 iteration 1237 : loss : 0.040367, loss_ce: 0.015952
2021-12-12 23:32:46,518 iteration 1238 : loss : 0.044710, loss_ce: 0.020431
2021-12-12 23:32:48,025 iteration 1239 : loss : 0.042921, loss_ce: 0.014295
2021-12-12 23:32:49,430 iteration 1240 : loss : 0.037562, loss_ce: 0.013876
2021-12-12 23:32:50,983 iteration 1241 : loss : 0.038840, loss_ce: 0.014359
 18%|█████▍                        | 73/400 [33:09<2:23:38, 26.36s/it]2021-12-12 23:32:52,405 iteration 1242 : loss : 0.045339, loss_ce: 0.017472
2021-12-12 23:32:53,802 iteration 1243 : loss : 0.033026, loss_ce: 0.017063
2021-12-12 23:32:55,218 iteration 1244 : loss : 0.045520, loss_ce: 0.017553
2021-12-12 23:32:56,667 iteration 1245 : loss : 0.044528, loss_ce: 0.019766
2021-12-12 23:32:58,132 iteration 1246 : loss : 0.053475, loss_ce: 0.022971
2021-12-12 23:32:59,617 iteration 1247 : loss : 0.050680, loss_ce: 0.016498
2021-12-12 23:33:01,036 iteration 1248 : loss : 0.028883, loss_ce: 0.010631
2021-12-12 23:33:02,508 iteration 1249 : loss : 0.045509, loss_ce: 0.015043
2021-12-12 23:33:03,929 iteration 1250 : loss : 0.049092, loss_ce: 0.018323
2021-12-12 23:33:05,402 iteration 1251 : loss : 0.036127, loss_ce: 0.013930
2021-12-12 23:33:06,885 iteration 1252 : loss : 0.085496, loss_ce: 0.022503
2021-12-12 23:33:08,375 iteration 1253 : loss : 0.042042, loss_ce: 0.019084
2021-12-12 23:33:09,833 iteration 1254 : loss : 0.055419, loss_ce: 0.024835
2021-12-12 23:33:11,341 iteration 1255 : loss : 0.036048, loss_ce: 0.013835
2021-12-12 23:33:12,860 iteration 1256 : loss : 0.049494, loss_ce: 0.017066
2021-12-12 23:33:14,320 iteration 1257 : loss : 0.037897, loss_ce: 0.016120
2021-12-12 23:33:15,850 iteration 1258 : loss : 0.062084, loss_ce: 0.031233
 18%|█████▌                        | 74/400 [33:33<2:20:45, 25.91s/it]2021-12-12 23:33:17,341 iteration 1259 : loss : 0.044012, loss_ce: 0.014529
2021-12-12 23:33:18,840 iteration 1260 : loss : 0.047224, loss_ce: 0.013286
2021-12-12 23:33:20,298 iteration 1261 : loss : 0.042921, loss_ce: 0.016969
2021-12-12 23:33:21,717 iteration 1262 : loss : 0.036260, loss_ce: 0.018874
2021-12-12 23:33:23,238 iteration 1263 : loss : 0.037631, loss_ce: 0.011847
2021-12-12 23:33:24,636 iteration 1264 : loss : 0.040347, loss_ce: 0.019066
2021-12-12 23:33:26,036 iteration 1265 : loss : 0.041964, loss_ce: 0.015295
2021-12-12 23:33:27,433 iteration 1266 : loss : 0.037676, loss_ce: 0.016007
2021-12-12 23:33:28,984 iteration 1267 : loss : 0.052784, loss_ce: 0.019047
2021-12-12 23:33:30,437 iteration 1268 : loss : 0.112863, loss_ce: 0.031389
2021-12-12 23:33:31,943 iteration 1269 : loss : 0.060872, loss_ce: 0.021230
2021-12-12 23:33:33,362 iteration 1270 : loss : 0.049110, loss_ce: 0.014473
2021-12-12 23:33:34,818 iteration 1271 : loss : 0.033692, loss_ce: 0.011682
2021-12-12 23:33:36,248 iteration 1272 : loss : 0.058753, loss_ce: 0.024175
2021-12-12 23:33:37,721 iteration 1273 : loss : 0.047284, loss_ce: 0.022058
2021-12-12 23:33:39,173 iteration 1274 : loss : 0.043732, loss_ce: 0.013941
2021-12-12 23:33:39,173 Training Data Eval:
2021-12-12 23:33:46,648   Average segmentation loss on training set: 0.2018
2021-12-12 23:33:46,649 Validation Data Eval:
2021-12-12 23:33:49,251   Average segmentation loss on validation set: 0.2086
2021-12-12 23:33:50,746 iteration 1275 : loss : 0.054423, loss_ce: 0.017642
 19%|█████▋                        | 75/400 [34:08<2:34:56, 28.60s/it]2021-12-12 23:33:52,334 iteration 1276 : loss : 0.111958, loss_ce: 0.035384
2021-12-12 23:33:53,740 iteration 1277 : loss : 0.030745, loss_ce: 0.012010
2021-12-12 23:33:55,216 iteration 1278 : loss : 0.042527, loss_ce: 0.018262
2021-12-12 23:33:56,591 iteration 1279 : loss : 0.042704, loss_ce: 0.020202
2021-12-12 23:33:57,977 iteration 1280 : loss : 0.042462, loss_ce: 0.021714
2021-12-12 23:33:59,495 iteration 1281 : loss : 0.053855, loss_ce: 0.024491
2021-12-12 23:34:00,917 iteration 1282 : loss : 0.053583, loss_ce: 0.026557
2021-12-12 23:34:02,350 iteration 1283 : loss : 0.047501, loss_ce: 0.017389
2021-12-12 23:34:03,812 iteration 1284 : loss : 0.044822, loss_ce: 0.018571
2021-12-12 23:34:05,409 iteration 1285 : loss : 0.067966, loss_ce: 0.023112
2021-12-12 23:34:06,893 iteration 1286 : loss : 0.047554, loss_ce: 0.016289
2021-12-12 23:34:08,332 iteration 1287 : loss : 0.044554, loss_ce: 0.016821
2021-12-12 23:34:09,823 iteration 1288 : loss : 0.038720, loss_ce: 0.016271
2021-12-12 23:34:11,361 iteration 1289 : loss : 0.066317, loss_ce: 0.030853
2021-12-12 23:34:12,775 iteration 1290 : loss : 0.044675, loss_ce: 0.012797
2021-12-12 23:34:14,234 iteration 1291 : loss : 0.044838, loss_ce: 0.014592
2021-12-12 23:34:15,641 iteration 1292 : loss : 0.038770, loss_ce: 0.015798
 19%|█████▋                        | 76/400 [34:33<2:28:26, 27.49s/it]2021-12-12 23:34:17,129 iteration 1293 : loss : 0.055245, loss_ce: 0.024921
2021-12-12 23:34:18,547 iteration 1294 : loss : 0.052900, loss_ce: 0.019155
2021-12-12 23:34:19,978 iteration 1295 : loss : 0.037088, loss_ce: 0.014586
2021-12-12 23:34:21,433 iteration 1296 : loss : 0.033525, loss_ce: 0.011607
2021-12-12 23:34:22,886 iteration 1297 : loss : 0.038916, loss_ce: 0.014562
2021-12-12 23:34:24,356 iteration 1298 : loss : 0.044926, loss_ce: 0.023021
2021-12-12 23:34:25,772 iteration 1299 : loss : 0.045718, loss_ce: 0.014779
2021-12-12 23:34:27,296 iteration 1300 : loss : 0.059355, loss_ce: 0.014690
2021-12-12 23:34:28,770 iteration 1301 : loss : 0.039641, loss_ce: 0.018432
2021-12-12 23:34:30,276 iteration 1302 : loss : 0.033698, loss_ce: 0.010121
2021-12-12 23:34:31,698 iteration 1303 : loss : 0.044584, loss_ce: 0.019648
2021-12-12 23:34:33,196 iteration 1304 : loss : 0.051661, loss_ce: 0.013463
2021-12-12 23:34:34,651 iteration 1305 : loss : 0.046870, loss_ce: 0.021827
2021-12-12 23:34:36,141 iteration 1306 : loss : 0.046547, loss_ce: 0.018685
2021-12-12 23:34:37,649 iteration 1307 : loss : 0.061336, loss_ce: 0.024194
2021-12-12 23:34:39,123 iteration 1308 : loss : 0.044806, loss_ce: 0.027401
2021-12-12 23:34:40,589 iteration 1309 : loss : 0.053577, loss_ce: 0.020810
 19%|█████▊                        | 77/400 [34:58<2:23:52, 26.73s/it]2021-12-12 23:34:42,096 iteration 1310 : loss : 0.052477, loss_ce: 0.019117
2021-12-12 23:34:43,630 iteration 1311 : loss : 0.044638, loss_ce: 0.014607
2021-12-12 23:34:45,079 iteration 1312 : loss : 0.048544, loss_ce: 0.025774
2021-12-12 23:34:46,475 iteration 1313 : loss : 0.034083, loss_ce: 0.013387
2021-12-12 23:34:47,950 iteration 1314 : loss : 0.037429, loss_ce: 0.015596
2021-12-12 23:34:49,421 iteration 1315 : loss : 0.051290, loss_ce: 0.019310
2021-12-12 23:34:50,847 iteration 1316 : loss : 0.050302, loss_ce: 0.019830
2021-12-12 23:34:52,342 iteration 1317 : loss : 0.038256, loss_ce: 0.017795
2021-12-12 23:34:53,849 iteration 1318 : loss : 0.043670, loss_ce: 0.016928
2021-12-12 23:34:55,286 iteration 1319 : loss : 0.043526, loss_ce: 0.015206
2021-12-12 23:34:56,737 iteration 1320 : loss : 0.038094, loss_ce: 0.013331
2021-12-12 23:34:58,200 iteration 1321 : loss : 0.049737, loss_ce: 0.019760
2021-12-12 23:34:59,754 iteration 1322 : loss : 0.032658, loss_ce: 0.012767
2021-12-12 23:35:01,243 iteration 1323 : loss : 0.030945, loss_ce: 0.011823
2021-12-12 23:35:02,724 iteration 1324 : loss : 0.038537, loss_ce: 0.012742
2021-12-12 23:35:04,235 iteration 1325 : loss : 0.040892, loss_ce: 0.013059
2021-12-12 23:35:05,654 iteration 1326 : loss : 0.037005, loss_ce: 0.012634
 20%|█████▊                        | 78/400 [35:23<2:20:46, 26.23s/it]2021-12-12 23:35:07,198 iteration 1327 : loss : 0.042982, loss_ce: 0.026419
2021-12-12 23:35:08,752 iteration 1328 : loss : 0.051994, loss_ce: 0.016495
2021-12-12 23:35:10,138 iteration 1329 : loss : 0.038269, loss_ce: 0.017585
2021-12-12 23:35:11,586 iteration 1330 : loss : 0.035378, loss_ce: 0.011541
2021-12-12 23:35:13,041 iteration 1331 : loss : 0.031726, loss_ce: 0.011972
2021-12-12 23:35:14,500 iteration 1332 : loss : 0.027629, loss_ce: 0.010460
2021-12-12 23:35:15,995 iteration 1333 : loss : 0.054872, loss_ce: 0.013918
2021-12-12 23:35:17,446 iteration 1334 : loss : 0.027277, loss_ce: 0.010899
2021-12-12 23:35:19,000 iteration 1335 : loss : 0.049308, loss_ce: 0.016723
2021-12-12 23:35:20,476 iteration 1336 : loss : 0.035177, loss_ce: 0.013763
2021-12-12 23:35:21,983 iteration 1337 : loss : 0.034162, loss_ce: 0.015331
2021-12-12 23:35:23,509 iteration 1338 : loss : 0.039557, loss_ce: 0.015720
2021-12-12 23:35:25,011 iteration 1339 : loss : 0.038187, loss_ce: 0.015416
2021-12-12 23:35:26,426 iteration 1340 : loss : 0.033862, loss_ce: 0.011877
2021-12-12 23:35:27,874 iteration 1341 : loss : 0.034923, loss_ce: 0.013874
2021-12-12 23:35:29,322 iteration 1342 : loss : 0.059050, loss_ce: 0.017499
2021-12-12 23:35:30,756 iteration 1343 : loss : 0.031532, loss_ce: 0.010583
 20%|█████▉                        | 79/400 [35:48<2:18:31, 25.89s/it]2021-12-12 23:35:32,220 iteration 1344 : loss : 0.036945, loss_ce: 0.014151
2021-12-12 23:35:33,644 iteration 1345 : loss : 0.035903, loss_ce: 0.014636
2021-12-12 23:35:35,059 iteration 1346 : loss : 0.034933, loss_ce: 0.012244
2021-12-12 23:35:36,589 iteration 1347 : loss : 0.079700, loss_ce: 0.014822
2021-12-12 23:35:38,110 iteration 1348 : loss : 0.035531, loss_ce: 0.013476
2021-12-12 23:35:39,567 iteration 1349 : loss : 0.083981, loss_ce: 0.047699
2021-12-12 23:35:41,055 iteration 1350 : loss : 0.060607, loss_ce: 0.027236
2021-12-12 23:35:42,460 iteration 1351 : loss : 0.040614, loss_ce: 0.012097
2021-12-12 23:35:43,990 iteration 1352 : loss : 0.037625, loss_ce: 0.013165
2021-12-12 23:35:45,390 iteration 1353 : loss : 0.040978, loss_ce: 0.015786
2021-12-12 23:35:46,895 iteration 1354 : loss : 0.031309, loss_ce: 0.012816
2021-12-12 23:35:48,318 iteration 1355 : loss : 0.079230, loss_ce: 0.022993
2021-12-12 23:35:49,811 iteration 1356 : loss : 0.051104, loss_ce: 0.017042
2021-12-12 23:35:51,210 iteration 1357 : loss : 0.052145, loss_ce: 0.028289
2021-12-12 23:35:52,667 iteration 1358 : loss : 0.050165, loss_ce: 0.016976
2021-12-12 23:35:54,081 iteration 1359 : loss : 0.041525, loss_ce: 0.022416
2021-12-12 23:35:54,081 Training Data Eval:
2021-12-12 23:36:01,590   Average segmentation loss on training set: 0.0666
2021-12-12 23:36:01,590 Validation Data Eval:
2021-12-12 23:36:04,176   Average segmentation loss on validation set: 0.1008
2021-12-12 23:36:05,631 iteration 1360 : loss : 0.048157, loss_ce: 0.017047
 20%|██████                        | 80/400 [36:23<2:32:27, 28.59s/it]2021-12-12 23:36:07,183 iteration 1361 : loss : 0.072125, loss_ce: 0.019672
2021-12-12 23:36:08,674 iteration 1362 : loss : 0.037038, loss_ce: 0.015739
2021-12-12 23:36:10,163 iteration 1363 : loss : 0.035197, loss_ce: 0.012207
2021-12-12 23:36:11,678 iteration 1364 : loss : 0.051502, loss_ce: 0.016910
2021-12-12 23:36:13,221 iteration 1365 : loss : 0.048252, loss_ce: 0.019738
2021-12-12 23:36:14,681 iteration 1366 : loss : 0.036242, loss_ce: 0.015827
2021-12-12 23:36:16,116 iteration 1367 : loss : 0.040798, loss_ce: 0.018471
2021-12-12 23:36:17,604 iteration 1368 : loss : 0.035435, loss_ce: 0.013793
2021-12-12 23:36:19,066 iteration 1369 : loss : 0.054712, loss_ce: 0.014652
2021-12-12 23:36:20,530 iteration 1370 : loss : 0.058746, loss_ce: 0.019719
2021-12-12 23:36:21,937 iteration 1371 : loss : 0.038771, loss_ce: 0.016599
2021-12-12 23:36:23,422 iteration 1372 : loss : 0.044077, loss_ce: 0.012335
2021-12-12 23:36:24,978 iteration 1373 : loss : 0.054026, loss_ce: 0.028578
2021-12-12 23:36:26,432 iteration 1374 : loss : 0.053844, loss_ce: 0.016633
2021-12-12 23:36:27,949 iteration 1375 : loss : 0.036167, loss_ce: 0.012394
2021-12-12 23:36:29,348 iteration 1376 : loss : 0.035998, loss_ce: 0.014285
2021-12-12 23:36:30,859 iteration 1377 : loss : 0.053616, loss_ce: 0.019218
 20%|██████                        | 81/400 [36:48<2:26:37, 27.58s/it]2021-12-12 23:36:32,421 iteration 1378 : loss : 0.045603, loss_ce: 0.023943
2021-12-12 23:36:33,927 iteration 1379 : loss : 0.047842, loss_ce: 0.013997
2021-12-12 23:36:35,396 iteration 1380 : loss : 0.043925, loss_ce: 0.017511
2021-12-12 23:36:36,892 iteration 1381 : loss : 0.035736, loss_ce: 0.013895
2021-12-12 23:36:38,343 iteration 1382 : loss : 0.035386, loss_ce: 0.012989
2021-12-12 23:36:39,805 iteration 1383 : loss : 0.083272, loss_ce: 0.021372
2021-12-12 23:36:41,350 iteration 1384 : loss : 0.044719, loss_ce: 0.019238
2021-12-12 23:36:42,736 iteration 1385 : loss : 0.030633, loss_ce: 0.011255
2021-12-12 23:36:44,284 iteration 1386 : loss : 0.040869, loss_ce: 0.017869
2021-12-12 23:36:45,715 iteration 1387 : loss : 0.054235, loss_ce: 0.015871
2021-12-12 23:36:47,217 iteration 1388 : loss : 0.037123, loss_ce: 0.013590
2021-12-12 23:36:48,705 iteration 1389 : loss : 0.055256, loss_ce: 0.028653
2021-12-12 23:36:50,110 iteration 1390 : loss : 0.032338, loss_ce: 0.013954
2021-12-12 23:36:51,608 iteration 1391 : loss : 0.047041, loss_ce: 0.014561
2021-12-12 23:36:53,067 iteration 1392 : loss : 0.044465, loss_ce: 0.023587
2021-12-12 23:36:54,527 iteration 1393 : loss : 0.056649, loss_ce: 0.018045
2021-12-12 23:36:55,968 iteration 1394 : loss : 0.048997, loss_ce: 0.012692
 20%|██████▏                       | 82/400 [37:14<2:22:14, 26.84s/it]2021-12-12 23:36:57,512 iteration 1395 : loss : 0.042070, loss_ce: 0.020313
2021-12-12 23:36:58,926 iteration 1396 : loss : 0.043261, loss_ce: 0.020964
2021-12-12 23:37:00,446 iteration 1397 : loss : 0.037576, loss_ce: 0.015167
2021-12-12 23:37:01,827 iteration 1398 : loss : 0.026913, loss_ce: 0.010731
2021-12-12 23:37:03,310 iteration 1399 : loss : 0.042177, loss_ce: 0.018280
2021-12-12 23:37:04,824 iteration 1400 : loss : 0.039950, loss_ce: 0.014638
2021-12-12 23:37:06,244 iteration 1401 : loss : 0.036057, loss_ce: 0.011471
2021-12-12 23:37:07,762 iteration 1402 : loss : 0.039261, loss_ce: 0.015343
2021-12-12 23:37:09,229 iteration 1403 : loss : 0.038808, loss_ce: 0.012021
2021-12-12 23:37:10,764 iteration 1404 : loss : 0.042805, loss_ce: 0.016096
2021-12-12 23:37:12,089 iteration 1405 : loss : 0.030882, loss_ce: 0.012031
2021-12-12 23:37:13,591 iteration 1406 : loss : 0.042606, loss_ce: 0.014980
2021-12-12 23:37:15,020 iteration 1407 : loss : 0.038436, loss_ce: 0.017064
2021-12-12 23:37:16,423 iteration 1408 : loss : 0.037577, loss_ce: 0.018594
2021-12-12 23:37:17,941 iteration 1409 : loss : 0.072121, loss_ce: 0.023244
2021-12-12 23:37:19,358 iteration 1410 : loss : 0.047036, loss_ce: 0.017861
2021-12-12 23:37:20,756 iteration 1411 : loss : 0.034922, loss_ce: 0.012989
 21%|██████▏                       | 83/400 [37:38<2:18:32, 26.22s/it]2021-12-12 23:37:22,280 iteration 1412 : loss : 0.034603, loss_ce: 0.018057
2021-12-12 23:37:23,674 iteration 1413 : loss : 0.031695, loss_ce: 0.009899
2021-12-12 23:37:25,169 iteration 1414 : loss : 0.026581, loss_ce: 0.010643
2021-12-12 23:37:26,589 iteration 1415 : loss : 0.040082, loss_ce: 0.015055
2021-12-12 23:37:28,053 iteration 1416 : loss : 0.030727, loss_ce: 0.012599
2021-12-12 23:37:29,528 iteration 1417 : loss : 0.044645, loss_ce: 0.018475
2021-12-12 23:37:30,987 iteration 1418 : loss : 0.029260, loss_ce: 0.009186
2021-12-12 23:37:32,373 iteration 1419 : loss : 0.044193, loss_ce: 0.018161
2021-12-12 23:37:33,822 iteration 1420 : loss : 0.034697, loss_ce: 0.008565
2021-12-12 23:37:35,275 iteration 1421 : loss : 0.043723, loss_ce: 0.024693
2021-12-12 23:37:36,735 iteration 1422 : loss : 0.047521, loss_ce: 0.022179
2021-12-12 23:37:38,156 iteration 1423 : loss : 0.049731, loss_ce: 0.016589
2021-12-12 23:37:39,540 iteration 1424 : loss : 0.025385, loss_ce: 0.010357
2021-12-12 23:37:41,020 iteration 1425 : loss : 0.059880, loss_ce: 0.017862
2021-12-12 23:37:42,498 iteration 1426 : loss : 0.043735, loss_ce: 0.023973
2021-12-12 23:37:43,955 iteration 1427 : loss : 0.092503, loss_ce: 0.017779
2021-12-12 23:37:45,509 iteration 1428 : loss : 0.039423, loss_ce: 0.015000
 21%|██████▎                       | 84/400 [38:03<2:15:47, 25.78s/it]2021-12-12 23:37:47,028 iteration 1429 : loss : 0.032324, loss_ce: 0.015031
2021-12-12 23:37:48,473 iteration 1430 : loss : 0.030732, loss_ce: 0.010699
2021-12-12 23:37:49,895 iteration 1431 : loss : 0.045721, loss_ce: 0.016386
2021-12-12 23:37:51,357 iteration 1432 : loss : 0.048293, loss_ce: 0.020792
2021-12-12 23:37:52,760 iteration 1433 : loss : 0.041796, loss_ce: 0.017602
2021-12-12 23:37:54,294 iteration 1434 : loss : 0.044104, loss_ce: 0.018503
2021-12-12 23:37:55,775 iteration 1435 : loss : 0.058201, loss_ce: 0.021697
2021-12-12 23:37:57,276 iteration 1436 : loss : 0.042759, loss_ce: 0.020198
2021-12-12 23:37:58,746 iteration 1437 : loss : 0.044470, loss_ce: 0.019423
2021-12-12 23:38:00,215 iteration 1438 : loss : 0.040468, loss_ce: 0.017210
2021-12-12 23:38:01,690 iteration 1439 : loss : 0.052750, loss_ce: 0.022476
2021-12-12 23:38:03,101 iteration 1440 : loss : 0.037676, loss_ce: 0.012043
2021-12-12 23:38:04,576 iteration 1441 : loss : 0.052193, loss_ce: 0.018980
2021-12-12 23:38:06,024 iteration 1442 : loss : 0.051500, loss_ce: 0.016430
2021-12-12 23:38:07,541 iteration 1443 : loss : 0.063943, loss_ce: 0.023590
2021-12-12 23:38:09,006 iteration 1444 : loss : 0.040302, loss_ce: 0.009388
2021-12-12 23:38:09,006 Training Data Eval:
2021-12-12 23:38:16,470   Average segmentation loss on training set: 0.0595
2021-12-12 23:38:16,470 Validation Data Eval:
2021-12-12 23:38:19,064   Average segmentation loss on validation set: 0.2418
2021-12-12 23:38:20,579 iteration 1445 : loss : 0.047507, loss_ce: 0.021657
 21%|██████▍                       | 85/400 [38:38<2:29:59, 28.57s/it]2021-12-12 23:38:22,022 iteration 1446 : loss : 0.044746, loss_ce: 0.014702
2021-12-12 23:38:23,418 iteration 1447 : loss : 0.035652, loss_ce: 0.015400
2021-12-12 23:38:24,924 iteration 1448 : loss : 0.051029, loss_ce: 0.014583
2021-12-12 23:38:26,433 iteration 1449 : loss : 0.044412, loss_ce: 0.015843
2021-12-12 23:38:27,871 iteration 1450 : loss : 0.040905, loss_ce: 0.015634
2021-12-12 23:38:29,350 iteration 1451 : loss : 0.035221, loss_ce: 0.010604
2021-12-12 23:38:30,793 iteration 1452 : loss : 0.055143, loss_ce: 0.035804
2021-12-12 23:38:32,274 iteration 1453 : loss : 0.035178, loss_ce: 0.015771
2021-12-12 23:38:33,743 iteration 1454 : loss : 0.043995, loss_ce: 0.014772
2021-12-12 23:38:35,241 iteration 1455 : loss : 0.047843, loss_ce: 0.016815
2021-12-12 23:38:36,680 iteration 1456 : loss : 0.037878, loss_ce: 0.011145
2021-12-12 23:38:38,194 iteration 1457 : loss : 0.058142, loss_ce: 0.028439
2021-12-12 23:38:39,673 iteration 1458 : loss : 0.031619, loss_ce: 0.012021
2021-12-12 23:38:41,113 iteration 1459 : loss : 0.046270, loss_ce: 0.020052
2021-12-12 23:38:42,567 iteration 1460 : loss : 0.036632, loss_ce: 0.014881
2021-12-12 23:38:43,974 iteration 1461 : loss : 0.036516, loss_ce: 0.012863
2021-12-12 23:38:45,488 iteration 1462 : loss : 0.039093, loss_ce: 0.017028
 22%|██████▍                       | 86/400 [39:03<2:23:45, 27.47s/it]2021-12-12 23:38:47,076 iteration 1463 : loss : 0.057898, loss_ce: 0.016565
2021-12-12 23:38:48,481 iteration 1464 : loss : 0.032405, loss_ce: 0.015247
2021-12-12 23:38:50,040 iteration 1465 : loss : 0.050095, loss_ce: 0.018803
2021-12-12 23:38:51,490 iteration 1466 : loss : 0.034611, loss_ce: 0.013351
2021-12-12 23:38:52,917 iteration 1467 : loss : 0.035078, loss_ce: 0.013310
2021-12-12 23:38:54,385 iteration 1468 : loss : 0.035658, loss_ce: 0.015596
2021-12-12 23:38:55,830 iteration 1469 : loss : 0.057116, loss_ce: 0.022622
2021-12-12 23:38:57,234 iteration 1470 : loss : 0.061407, loss_ce: 0.013347
2021-12-12 23:38:58,687 iteration 1471 : loss : 0.032530, loss_ce: 0.013991
2021-12-12 23:39:00,175 iteration 1472 : loss : 0.035550, loss_ce: 0.012994
2021-12-12 23:39:01,606 iteration 1473 : loss : 0.032692, loss_ce: 0.015772
2021-12-12 23:39:03,111 iteration 1474 : loss : 0.050812, loss_ce: 0.016230
2021-12-12 23:39:04,541 iteration 1475 : loss : 0.046052, loss_ce: 0.023834
2021-12-12 23:39:05,977 iteration 1476 : loss : 0.033589, loss_ce: 0.012656
2021-12-12 23:39:07,520 iteration 1477 : loss : 0.046920, loss_ce: 0.022002
2021-12-12 23:39:08,944 iteration 1478 : loss : 0.040870, loss_ce: 0.011050
2021-12-12 23:39:10,402 iteration 1479 : loss : 0.041829, loss_ce: 0.012341
 22%|██████▌                       | 87/400 [39:28<2:19:18, 26.70s/it]2021-12-12 23:39:11,786 iteration 1480 : loss : 0.025392, loss_ce: 0.009209
2021-12-12 23:39:13,328 iteration 1481 : loss : 0.046362, loss_ce: 0.021567
2021-12-12 23:39:14,781 iteration 1482 : loss : 0.034937, loss_ce: 0.016047
2021-12-12 23:39:16,295 iteration 1483 : loss : 0.052262, loss_ce: 0.021935
2021-12-12 23:39:17,779 iteration 1484 : loss : 0.035246, loss_ce: 0.011929
2021-12-12 23:39:19,283 iteration 1485 : loss : 0.032923, loss_ce: 0.018595
2021-12-12 23:39:20,739 iteration 1486 : loss : 0.039991, loss_ce: 0.014474
2021-12-12 23:39:22,196 iteration 1487 : loss : 0.027999, loss_ce: 0.010220
2021-12-12 23:39:23,596 iteration 1488 : loss : 0.040461, loss_ce: 0.021223
2021-12-12 23:39:25,030 iteration 1489 : loss : 0.043705, loss_ce: 0.018844
2021-12-12 23:39:26,515 iteration 1490 : loss : 0.038506, loss_ce: 0.012978
2021-12-12 23:39:27,886 iteration 1491 : loss : 0.044136, loss_ce: 0.013011
2021-12-12 23:39:29,310 iteration 1492 : loss : 0.031296, loss_ce: 0.011781
2021-12-12 23:39:30,807 iteration 1493 : loss : 0.037457, loss_ce: 0.016339
2021-12-12 23:39:32,240 iteration 1494 : loss : 0.039508, loss_ce: 0.012291
2021-12-12 23:39:33,638 iteration 1495 : loss : 0.035540, loss_ce: 0.008728
2021-12-12 23:39:35,138 iteration 1496 : loss : 0.033315, loss_ce: 0.014708
 22%|██████▌                       | 88/400 [39:53<2:15:47, 26.11s/it]2021-12-12 23:39:36,564 iteration 1497 : loss : 0.028543, loss_ce: 0.011027
2021-12-12 23:39:38,045 iteration 1498 : loss : 0.039289, loss_ce: 0.014976
2021-12-12 23:39:39,441 iteration 1499 : loss : 0.044878, loss_ce: 0.015465
2021-12-12 23:39:40,917 iteration 1500 : loss : 0.039531, loss_ce: 0.018668
2021-12-12 23:39:42,374 iteration 1501 : loss : 0.034758, loss_ce: 0.014998
2021-12-12 23:39:43,901 iteration 1502 : loss : 0.044512, loss_ce: 0.011095
2021-12-12 23:39:45,468 iteration 1503 : loss : 0.057173, loss_ce: 0.015684
2021-12-12 23:39:46,902 iteration 1504 : loss : 0.029098, loss_ce: 0.012378
2021-12-12 23:39:48,387 iteration 1505 : loss : 0.035758, loss_ce: 0.014815
2021-12-12 23:39:49,877 iteration 1506 : loss : 0.034623, loss_ce: 0.014597
2021-12-12 23:39:51,371 iteration 1507 : loss : 0.048938, loss_ce: 0.013564
2021-12-12 23:39:52,866 iteration 1508 : loss : 0.035997, loss_ce: 0.019531
2021-12-12 23:39:54,343 iteration 1509 : loss : 0.033197, loss_ce: 0.011832
2021-12-12 23:39:55,884 iteration 1510 : loss : 0.044030, loss_ce: 0.014507
2021-12-12 23:39:57,399 iteration 1511 : loss : 0.038305, loss_ce: 0.015413
2021-12-12 23:39:58,850 iteration 1512 : loss : 0.034228, loss_ce: 0.009663
2021-12-12 23:40:00,308 iteration 1513 : loss : 0.028967, loss_ce: 0.009615
 22%|██████▋                       | 89/400 [40:18<2:13:53, 25.83s/it]2021-12-12 23:40:01,844 iteration 1514 : loss : 0.034296, loss_ce: 0.011575
2021-12-12 23:40:03,266 iteration 1515 : loss : 0.035119, loss_ce: 0.013553
2021-12-12 23:40:04,753 iteration 1516 : loss : 0.037453, loss_ce: 0.015459
2021-12-12 23:40:06,144 iteration 1517 : loss : 0.030830, loss_ce: 0.010748
2021-12-12 23:40:07,641 iteration 1518 : loss : 0.035021, loss_ce: 0.011844
2021-12-12 23:40:09,162 iteration 1519 : loss : 0.040785, loss_ce: 0.016100
2021-12-12 23:40:10,654 iteration 1520 : loss : 0.047423, loss_ce: 0.021009
2021-12-12 23:40:12,123 iteration 1521 : loss : 0.064961, loss_ce: 0.017358
2021-12-12 23:40:13,549 iteration 1522 : loss : 0.034452, loss_ce: 0.012357
2021-12-12 23:40:14,991 iteration 1523 : loss : 0.044526, loss_ce: 0.013533
2021-12-12 23:40:16,452 iteration 1524 : loss : 0.029369, loss_ce: 0.011785
2021-12-12 23:40:17,839 iteration 1525 : loss : 0.036335, loss_ce: 0.013766
2021-12-12 23:40:19,319 iteration 1526 : loss : 0.051021, loss_ce: 0.024267
2021-12-12 23:40:20,809 iteration 1527 : loss : 0.041451, loss_ce: 0.018392
2021-12-12 23:40:22,217 iteration 1528 : loss : 0.027520, loss_ce: 0.010989
2021-12-12 23:40:23,646 iteration 1529 : loss : 0.031751, loss_ce: 0.011957
2021-12-12 23:40:23,646 Training Data Eval:
2021-12-12 23:40:31,124   Average segmentation loss on training set: 0.0259
2021-12-12 23:40:31,125 Validation Data Eval:
2021-12-12 23:40:33,723   Average segmentation loss on validation set: 0.0735
2021-12-12 23:40:38,774 Found new lowest validation loss at iteration 1529! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:40:40,184 iteration 1530 : loss : 0.034958, loss_ce: 0.015735
 22%|██████▊                       | 90/400 [40:58<2:35:13, 30.04s/it]2021-12-12 23:40:41,612 iteration 1531 : loss : 0.038603, loss_ce: 0.015149
2021-12-12 23:40:42,976 iteration 1532 : loss : 0.035550, loss_ce: 0.012767
2021-12-12 23:40:44,292 iteration 1533 : loss : 0.029358, loss_ce: 0.010338
2021-12-12 23:40:45,635 iteration 1534 : loss : 0.036384, loss_ce: 0.016997
2021-12-12 23:40:47,054 iteration 1535 : loss : 0.041209, loss_ce: 0.016693
2021-12-12 23:40:48,472 iteration 1536 : loss : 0.049399, loss_ce: 0.023866
2021-12-12 23:40:49,835 iteration 1537 : loss : 0.034240, loss_ce: 0.010406
2021-12-12 23:40:51,241 iteration 1538 : loss : 0.029462, loss_ce: 0.010891
2021-12-12 23:40:52,622 iteration 1539 : loss : 0.030286, loss_ce: 0.012550
2021-12-12 23:40:54,038 iteration 1540 : loss : 0.042446, loss_ce: 0.017853
2021-12-12 23:40:55,466 iteration 1541 : loss : 0.020697, loss_ce: 0.009078
2021-12-12 23:40:56,895 iteration 1542 : loss : 0.028817, loss_ce: 0.011900
2021-12-12 23:40:58,352 iteration 1543 : loss : 0.049351, loss_ce: 0.015040
2021-12-12 23:40:59,769 iteration 1544 : loss : 0.028565, loss_ce: 0.009793
2021-12-12 23:41:01,359 iteration 1545 : loss : 0.042491, loss_ce: 0.017456
2021-12-12 23:41:02,779 iteration 1546 : loss : 0.067946, loss_ce: 0.016096
2021-12-12 23:41:04,317 iteration 1547 : loss : 0.028145, loss_ce: 0.011417
 23%|██████▊                       | 91/400 [41:22<2:25:35, 28.27s/it]2021-12-12 23:41:05,838 iteration 1548 : loss : 0.040787, loss_ce: 0.015350
2021-12-12 23:41:07,228 iteration 1549 : loss : 0.030096, loss_ce: 0.012024
2021-12-12 23:41:08,665 iteration 1550 : loss : 0.034436, loss_ce: 0.012843
2021-12-12 23:41:10,036 iteration 1551 : loss : 0.028884, loss_ce: 0.010214
2021-12-12 23:41:11,520 iteration 1552 : loss : 0.026615, loss_ce: 0.009214
2021-12-12 23:41:13,020 iteration 1553 : loss : 0.063231, loss_ce: 0.027035
2021-12-12 23:41:14,506 iteration 1554 : loss : 0.029987, loss_ce: 0.012476
2021-12-12 23:41:15,963 iteration 1555 : loss : 0.028938, loss_ce: 0.012670
2021-12-12 23:41:17,450 iteration 1556 : loss : 0.033678, loss_ce: 0.013298
2021-12-12 23:41:18,882 iteration 1557 : loss : 0.034661, loss_ce: 0.013249
2021-12-12 23:41:20,354 iteration 1558 : loss : 0.033301, loss_ce: 0.015253
2021-12-12 23:41:21,826 iteration 1559 : loss : 0.038340, loss_ce: 0.015529
2021-12-12 23:41:23,239 iteration 1560 : loss : 0.027552, loss_ce: 0.012388
2021-12-12 23:41:24,723 iteration 1561 : loss : 0.032034, loss_ce: 0.010629
2021-12-12 23:41:26,135 iteration 1562 : loss : 0.039712, loss_ce: 0.009152
2021-12-12 23:41:27,630 iteration 1563 : loss : 0.034639, loss_ce: 0.014453
2021-12-12 23:41:29,132 iteration 1564 : loss : 0.039261, loss_ce: 0.018464
 23%|██████▉                       | 92/400 [41:47<2:19:47, 27.23s/it]2021-12-12 23:41:30,607 iteration 1565 : loss : 0.034658, loss_ce: 0.015102
2021-12-12 23:41:32,055 iteration 1566 : loss : 0.029762, loss_ce: 0.011354
2021-12-12 23:41:33,542 iteration 1567 : loss : 0.044326, loss_ce: 0.013813
2021-12-12 23:41:34,967 iteration 1568 : loss : 0.033341, loss_ce: 0.011491
2021-12-12 23:41:36,442 iteration 1569 : loss : 0.032706, loss_ce: 0.014046
2021-12-12 23:41:37,919 iteration 1570 : loss : 0.022655, loss_ce: 0.010247
2021-12-12 23:41:39,357 iteration 1571 : loss : 0.043076, loss_ce: 0.010141
2021-12-12 23:41:40,880 iteration 1572 : loss : 0.055423, loss_ce: 0.018382
2021-12-12 23:41:42,354 iteration 1573 : loss : 0.036067, loss_ce: 0.016321
2021-12-12 23:41:43,754 iteration 1574 : loss : 0.021288, loss_ce: 0.009192
2021-12-12 23:41:45,108 iteration 1575 : loss : 0.026596, loss_ce: 0.010917
2021-12-12 23:41:46,552 iteration 1576 : loss : 0.032829, loss_ce: 0.013803
2021-12-12 23:41:48,001 iteration 1577 : loss : 0.024931, loss_ce: 0.009597
2021-12-12 23:41:49,454 iteration 1578 : loss : 0.046352, loss_ce: 0.014963
2021-12-12 23:41:50,942 iteration 1579 : loss : 0.039076, loss_ce: 0.018877
2021-12-12 23:41:52,367 iteration 1580 : loss : 0.033886, loss_ce: 0.013190
2021-12-12 23:41:53,810 iteration 1581 : loss : 0.038289, loss_ce: 0.011888
 23%|██████▉                       | 93/400 [42:11<2:15:25, 26.47s/it]2021-12-12 23:41:55,353 iteration 1582 : loss : 0.038232, loss_ce: 0.011655
2021-12-12 23:41:56,798 iteration 1583 : loss : 0.040188, loss_ce: 0.011188
2021-12-12 23:41:58,272 iteration 1584 : loss : 0.032001, loss_ce: 0.016171
2021-12-12 23:41:59,721 iteration 1585 : loss : 0.035535, loss_ce: 0.011716
2021-12-12 23:42:01,157 iteration 1586 : loss : 0.033510, loss_ce: 0.012143
2021-12-12 23:42:02,523 iteration 1587 : loss : 0.028506, loss_ce: 0.011207
2021-12-12 23:42:04,005 iteration 1588 : loss : 0.046313, loss_ce: 0.020949
2021-12-12 23:42:05,459 iteration 1589 : loss : 0.031829, loss_ce: 0.011940
2021-12-12 23:42:07,024 iteration 1590 : loss : 0.037291, loss_ce: 0.016028
2021-12-12 23:42:08,446 iteration 1591 : loss : 0.028609, loss_ce: 0.009088
2021-12-12 23:42:09,914 iteration 1592 : loss : 0.055874, loss_ce: 0.017697
2021-12-12 23:42:11,468 iteration 1593 : loss : 0.043132, loss_ce: 0.018775
2021-12-12 23:42:12,990 iteration 1594 : loss : 0.043599, loss_ce: 0.013803
2021-12-12 23:42:14,409 iteration 1595 : loss : 0.026771, loss_ce: 0.009300
2021-12-12 23:42:15,862 iteration 1596 : loss : 0.035484, loss_ce: 0.015667
2021-12-12 23:42:17,304 iteration 1597 : loss : 0.038429, loss_ce: 0.015299
2021-12-12 23:42:18,779 iteration 1598 : loss : 0.033443, loss_ce: 0.012188
 24%|███████                       | 94/400 [42:36<2:12:41, 26.02s/it]2021-12-12 23:42:20,255 iteration 1599 : loss : 0.027579, loss_ce: 0.010721
2021-12-12 23:42:21,729 iteration 1600 : loss : 0.023615, loss_ce: 0.008007
2021-12-12 23:42:23,245 iteration 1601 : loss : 0.032397, loss_ce: 0.012036
2021-12-12 23:42:24,813 iteration 1602 : loss : 0.041088, loss_ce: 0.019472
2021-12-12 23:42:26,255 iteration 1603 : loss : 0.029826, loss_ce: 0.013137
2021-12-12 23:42:27,684 iteration 1604 : loss : 0.033967, loss_ce: 0.012636
2021-12-12 23:42:29,199 iteration 1605 : loss : 0.046176, loss_ce: 0.016046
2021-12-12 23:42:30,654 iteration 1606 : loss : 0.033645, loss_ce: 0.013520
2021-12-12 23:42:32,095 iteration 1607 : loss : 0.028104, loss_ce: 0.011103
2021-12-12 23:42:33,632 iteration 1608 : loss : 0.032708, loss_ce: 0.010491
2021-12-12 23:42:35,086 iteration 1609 : loss : 0.060318, loss_ce: 0.030419
2021-12-12 23:42:36,557 iteration 1610 : loss : 0.038585, loss_ce: 0.013843
2021-12-12 23:42:38,109 iteration 1611 : loss : 0.047587, loss_ce: 0.016942
2021-12-12 23:42:39,563 iteration 1612 : loss : 0.029284, loss_ce: 0.014186
2021-12-12 23:42:40,893 iteration 1613 : loss : 0.043692, loss_ce: 0.020663
2021-12-12 23:42:42,399 iteration 1614 : loss : 0.047066, loss_ce: 0.012418
2021-12-12 23:42:42,399 Training Data Eval:
2021-12-12 23:42:49,873   Average segmentation loss on training set: 0.0251
2021-12-12 23:42:49,874 Validation Data Eval:
2021-12-12 23:42:52,470   Average segmentation loss on validation set: 0.0673
2021-12-12 23:42:58,822 Found new lowest validation loss at iteration 1614! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:43:00,225 iteration 1615 : loss : 0.028286, loss_ce: 0.011413
 24%|███████▏                      | 95/400 [43:18<2:35:47, 30.65s/it]2021-12-12 23:43:01,668 iteration 1616 : loss : 0.030043, loss_ce: 0.010315
2021-12-12 23:43:03,057 iteration 1617 : loss : 0.045210, loss_ce: 0.013411
2021-12-12 23:43:04,353 iteration 1618 : loss : 0.024491, loss_ce: 0.010313
2021-12-12 23:43:05,656 iteration 1619 : loss : 0.024566, loss_ce: 0.008057
2021-12-12 23:43:06,935 iteration 1620 : loss : 0.027552, loss_ce: 0.008314
2021-12-12 23:43:08,311 iteration 1621 : loss : 0.038320, loss_ce: 0.023998
2021-12-12 23:43:09,816 iteration 1622 : loss : 0.053649, loss_ce: 0.015219
2021-12-12 23:43:11,187 iteration 1623 : loss : 0.040031, loss_ce: 0.015639
2021-12-12 23:43:12,523 iteration 1624 : loss : 0.032666, loss_ce: 0.011754
2021-12-12 23:43:13,884 iteration 1625 : loss : 0.030189, loss_ce: 0.011962
2021-12-12 23:43:15,259 iteration 1626 : loss : 0.025227, loss_ce: 0.011215
2021-12-12 23:43:16,697 iteration 1627 : loss : 0.047053, loss_ce: 0.016285
2021-12-12 23:43:18,250 iteration 1628 : loss : 0.035827, loss_ce: 0.015921
2021-12-12 23:43:19,723 iteration 1629 : loss : 0.028895, loss_ce: 0.010902
2021-12-12 23:43:21,149 iteration 1630 : loss : 0.032804, loss_ce: 0.012260
2021-12-12 23:43:22,756 iteration 1631 : loss : 0.036232, loss_ce: 0.014203
2021-12-12 23:43:24,314 iteration 1632 : loss : 0.037715, loss_ce: 0.012818
 24%|███████▏                      | 96/400 [43:42<2:25:17, 28.68s/it]2021-12-12 23:43:25,877 iteration 1633 : loss : 0.034219, loss_ce: 0.012353
2021-12-12 23:43:27,373 iteration 1634 : loss : 0.047418, loss_ce: 0.015269
2021-12-12 23:43:28,841 iteration 1635 : loss : 0.026464, loss_ce: 0.012080
2021-12-12 23:43:30,394 iteration 1636 : loss : 0.037025, loss_ce: 0.016824
2021-12-12 23:43:31,872 iteration 1637 : loss : 0.032501, loss_ce: 0.011678
2021-12-12 23:43:33,302 iteration 1638 : loss : 0.041751, loss_ce: 0.018474
2021-12-12 23:43:34,850 iteration 1639 : loss : 0.067079, loss_ce: 0.014433
2021-12-12 23:43:36,346 iteration 1640 : loss : 0.052282, loss_ce: 0.015443
2021-12-12 23:43:37,747 iteration 1641 : loss : 0.024213, loss_ce: 0.011311
2021-12-12 23:43:39,201 iteration 1642 : loss : 0.036729, loss_ce: 0.011968
2021-12-12 23:43:40,704 iteration 1643 : loss : 0.032882, loss_ce: 0.009355
2021-12-12 23:43:42,143 iteration 1644 : loss : 0.032969, loss_ce: 0.012339
2021-12-12 23:43:43,590 iteration 1645 : loss : 0.036661, loss_ce: 0.012012
2021-12-12 23:43:45,037 iteration 1646 : loss : 0.040863, loss_ce: 0.016732
2021-12-12 23:43:46,491 iteration 1647 : loss : 0.048897, loss_ce: 0.015480
2021-12-12 23:43:47,974 iteration 1648 : loss : 0.050500, loss_ce: 0.022367
2021-12-12 23:43:49,397 iteration 1649 : loss : 0.038692, loss_ce: 0.017490
 24%|███████▎                      | 97/400 [44:07<2:19:22, 27.60s/it]2021-12-12 23:43:50,920 iteration 1650 : loss : 0.042303, loss_ce: 0.020591
2021-12-12 23:43:52,479 iteration 1651 : loss : 0.052292, loss_ce: 0.014509
2021-12-12 23:43:53,888 iteration 1652 : loss : 0.044295, loss_ce: 0.014885
2021-12-12 23:43:55,516 iteration 1653 : loss : 0.038515, loss_ce: 0.013363
2021-12-12 23:43:57,016 iteration 1654 : loss : 0.083783, loss_ce: 0.021032
2021-12-12 23:43:58,520 iteration 1655 : loss : 0.038760, loss_ce: 0.015822
2021-12-12 23:43:59,966 iteration 1656 : loss : 0.040683, loss_ce: 0.013615
2021-12-12 23:44:01,522 iteration 1657 : loss : 0.053302, loss_ce: 0.019628
2021-12-12 23:44:03,019 iteration 1658 : loss : 0.054958, loss_ce: 0.026808
2021-12-12 23:44:04,432 iteration 1659 : loss : 0.039752, loss_ce: 0.012898
2021-12-12 23:44:05,999 iteration 1660 : loss : 0.038780, loss_ce: 0.014241
2021-12-12 23:44:07,534 iteration 1661 : loss : 0.046149, loss_ce: 0.014180
2021-12-12 23:44:08,990 iteration 1662 : loss : 0.043582, loss_ce: 0.016122
2021-12-12 23:44:10,362 iteration 1663 : loss : 0.033717, loss_ce: 0.017897
2021-12-12 23:44:11,911 iteration 1664 : loss : 0.048117, loss_ce: 0.017052
2021-12-12 23:44:13,411 iteration 1665 : loss : 0.044255, loss_ce: 0.017920
2021-12-12 23:44:14,924 iteration 1666 : loss : 0.045900, loss_ce: 0.021009
 24%|███████▎                      | 98/400 [44:33<2:15:47, 26.98s/it]2021-12-12 23:44:16,452 iteration 1667 : loss : 0.053095, loss_ce: 0.017112
2021-12-12 23:44:17,919 iteration 1668 : loss : 0.046394, loss_ce: 0.016432
2021-12-12 23:44:19,343 iteration 1669 : loss : 0.036931, loss_ce: 0.015321
2021-12-12 23:44:20,826 iteration 1670 : loss : 0.066866, loss_ce: 0.033443
2021-12-12 23:44:22,285 iteration 1671 : loss : 0.037551, loss_ce: 0.015081
2021-12-12 23:44:23,811 iteration 1672 : loss : 0.033952, loss_ce: 0.012393
2021-12-12 23:44:25,310 iteration 1673 : loss : 0.042129, loss_ce: 0.015611
2021-12-12 23:44:26,842 iteration 1674 : loss : 0.048050, loss_ce: 0.023217
2021-12-12 23:44:28,271 iteration 1675 : loss : 0.041574, loss_ce: 0.012930
2021-12-12 23:44:29,731 iteration 1676 : loss : 0.045382, loss_ce: 0.016421
2021-12-12 23:44:31,258 iteration 1677 : loss : 0.065648, loss_ce: 0.035362
2021-12-12 23:44:32,619 iteration 1678 : loss : 0.038056, loss_ce: 0.015861
2021-12-12 23:44:34,065 iteration 1679 : loss : 0.028771, loss_ce: 0.008018
2021-12-12 23:44:35,573 iteration 1680 : loss : 0.028472, loss_ce: 0.013397
2021-12-12 23:44:37,078 iteration 1681 : loss : 0.043323, loss_ce: 0.022379
2021-12-12 23:44:38,581 iteration 1682 : loss : 0.037197, loss_ce: 0.012847
2021-12-12 23:44:39,990 iteration 1683 : loss : 0.027020, loss_ce: 0.008193
 25%|███████▍                      | 99/400 [44:58<2:12:28, 26.41s/it]2021-12-12 23:44:41,518 iteration 1684 : loss : 0.044120, loss_ce: 0.014635
2021-12-12 23:44:42,971 iteration 1685 : loss : 0.039721, loss_ce: 0.012599
2021-12-12 23:44:44,417 iteration 1686 : loss : 0.025887, loss_ce: 0.009397
2021-12-12 23:44:45,824 iteration 1687 : loss : 0.037200, loss_ce: 0.018163
2021-12-12 23:44:47,395 iteration 1688 : loss : 0.038166, loss_ce: 0.016512
2021-12-12 23:44:48,870 iteration 1689 : loss : 0.038603, loss_ce: 0.014463
2021-12-12 23:44:50,384 iteration 1690 : loss : 0.040849, loss_ce: 0.018432
2021-12-12 23:44:51,789 iteration 1691 : loss : 0.058374, loss_ce: 0.014682
2021-12-12 23:44:53,304 iteration 1692 : loss : 0.051851, loss_ce: 0.018190
2021-12-12 23:44:54,644 iteration 1693 : loss : 0.030847, loss_ce: 0.011678
2021-12-12 23:44:56,135 iteration 1694 : loss : 0.023328, loss_ce: 0.009532
2021-12-12 23:44:57,662 iteration 1695 : loss : 0.035810, loss_ce: 0.012945
2021-12-12 23:44:59,184 iteration 1696 : loss : 0.052598, loss_ce: 0.017604
2021-12-12 23:45:00,640 iteration 1697 : loss : 0.034732, loss_ce: 0.012497
2021-12-12 23:45:02,152 iteration 1698 : loss : 0.046843, loss_ce: 0.016983
2021-12-12 23:45:03,618 iteration 1699 : loss : 0.045914, loss_ce: 0.023545
2021-12-12 23:45:03,618 Training Data Eval:
2021-12-12 23:45:11,091   Average segmentation loss on training set: 0.0258
2021-12-12 23:45:11,091 Validation Data Eval:
2021-12-12 23:45:13,687   Average segmentation loss on validation set: 0.0803
2021-12-12 23:45:15,142 iteration 1700 : loss : 0.031391, loss_ce: 0.008392
 25%|███████▎                     | 100/400 [45:33<2:25:08, 29.03s/it]2021-12-12 23:45:16,667 iteration 1701 : loss : 0.032791, loss_ce: 0.014506
2021-12-12 23:45:18,112 iteration 1702 : loss : 0.041223, loss_ce: 0.017407
2021-12-12 23:45:19,656 iteration 1703 : loss : 0.037424, loss_ce: 0.018141
2021-12-12 23:45:21,184 iteration 1704 : loss : 0.040191, loss_ce: 0.016728
2021-12-12 23:45:22,633 iteration 1705 : loss : 0.038806, loss_ce: 0.012776
2021-12-12 23:45:24,133 iteration 1706 : loss : 0.039027, loss_ce: 0.010186
2021-12-12 23:45:25,577 iteration 1707 : loss : 0.041677, loss_ce: 0.017326
2021-12-12 23:45:27,025 iteration 1708 : loss : 0.033256, loss_ce: 0.012222
2021-12-12 23:45:28,625 iteration 1709 : loss : 0.064738, loss_ce: 0.024658
2021-12-12 23:45:30,045 iteration 1710 : loss : 0.033470, loss_ce: 0.015464
2021-12-12 23:45:31,526 iteration 1711 : loss : 0.046941, loss_ce: 0.020603
2021-12-12 23:45:33,015 iteration 1712 : loss : 0.049411, loss_ce: 0.014777
2021-12-12 23:45:34,499 iteration 1713 : loss : 0.033283, loss_ce: 0.013210
2021-12-12 23:45:35,936 iteration 1714 : loss : 0.032558, loss_ce: 0.012358
2021-12-12 23:45:37,443 iteration 1715 : loss : 0.052556, loss_ce: 0.019470
2021-12-12 23:45:38,885 iteration 1716 : loss : 0.059909, loss_ce: 0.018484
2021-12-12 23:45:40,376 iteration 1717 : loss : 0.036487, loss_ce: 0.016619
 25%|███████▎                     | 101/400 [45:58<2:18:59, 27.89s/it]2021-12-12 23:45:41,925 iteration 1718 : loss : 0.035668, loss_ce: 0.013181
2021-12-12 23:45:43,463 iteration 1719 : loss : 0.034582, loss_ce: 0.009582
2021-12-12 23:45:44,965 iteration 1720 : loss : 0.041323, loss_ce: 0.013867
2021-12-12 23:45:46,441 iteration 1721 : loss : 0.041545, loss_ce: 0.016913
2021-12-12 23:45:47,875 iteration 1722 : loss : 0.034772, loss_ce: 0.012641
2021-12-12 23:45:49,331 iteration 1723 : loss : 0.032159, loss_ce: 0.012439
2021-12-12 23:45:50,731 iteration 1724 : loss : 0.030897, loss_ce: 0.014999
2021-12-12 23:45:52,153 iteration 1725 : loss : 0.028367, loss_ce: 0.012801
2021-12-12 23:45:53,726 iteration 1726 : loss : 0.032383, loss_ce: 0.012946
2021-12-12 23:45:55,239 iteration 1727 : loss : 0.044816, loss_ce: 0.014152
2021-12-12 23:45:56,787 iteration 1728 : loss : 0.048644, loss_ce: 0.021759
2021-12-12 23:45:58,213 iteration 1729 : loss : 0.039441, loss_ce: 0.013660
2021-12-12 23:45:59,700 iteration 1730 : loss : 0.036840, loss_ce: 0.012901
2021-12-12 23:46:01,133 iteration 1731 : loss : 0.035263, loss_ce: 0.015768
2021-12-12 23:46:02,605 iteration 1732 : loss : 0.042298, loss_ce: 0.017310
2021-12-12 23:46:04,065 iteration 1733 : loss : 0.039522, loss_ce: 0.014352
2021-12-12 23:46:05,511 iteration 1734 : loss : 0.038849, loss_ce: 0.010300
 26%|███████▍                     | 102/400 [46:23<2:14:24, 27.06s/it]2021-12-12 23:46:07,076 iteration 1735 : loss : 0.050969, loss_ce: 0.016468
2021-12-12 23:46:08,539 iteration 1736 : loss : 0.029869, loss_ce: 0.012289
2021-12-12 23:46:10,020 iteration 1737 : loss : 0.041816, loss_ce: 0.017724
2021-12-12 23:46:11,471 iteration 1738 : loss : 0.042453, loss_ce: 0.016933
2021-12-12 23:46:12,928 iteration 1739 : loss : 0.043989, loss_ce: 0.021869
2021-12-12 23:46:14,370 iteration 1740 : loss : 0.042130, loss_ce: 0.010724
2021-12-12 23:46:15,911 iteration 1741 : loss : 0.035353, loss_ce: 0.010266
2021-12-12 23:46:17,364 iteration 1742 : loss : 0.039571, loss_ce: 0.014593
2021-12-12 23:46:18,816 iteration 1743 : loss : 0.047077, loss_ce: 0.026439
2021-12-12 23:46:20,230 iteration 1744 : loss : 0.038329, loss_ce: 0.013104
2021-12-12 23:46:21,748 iteration 1745 : loss : 0.032261, loss_ce: 0.011382
2021-12-12 23:46:23,188 iteration 1746 : loss : 0.039386, loss_ce: 0.014166
2021-12-12 23:46:24,643 iteration 1747 : loss : 0.041373, loss_ce: 0.013380
2021-12-12 23:46:26,064 iteration 1748 : loss : 0.030455, loss_ce: 0.013703
2021-12-12 23:46:27,553 iteration 1749 : loss : 0.044255, loss_ce: 0.015563
2021-12-12 23:46:28,968 iteration 1750 : loss : 0.031505, loss_ce: 0.015241
2021-12-12 23:46:30,395 iteration 1751 : loss : 0.037048, loss_ce: 0.013731
 26%|███████▍                     | 103/400 [46:48<2:10:43, 26.41s/it]2021-12-12 23:46:31,890 iteration 1752 : loss : 0.027084, loss_ce: 0.010604
2021-12-12 23:46:33,424 iteration 1753 : loss : 0.051491, loss_ce: 0.022566
2021-12-12 23:46:34,904 iteration 1754 : loss : 0.033940, loss_ce: 0.014252
2021-12-12 23:46:36,379 iteration 1755 : loss : 0.053114, loss_ce: 0.021462
2021-12-12 23:46:37,883 iteration 1756 : loss : 0.068973, loss_ce: 0.053312
2021-12-12 23:46:39,352 iteration 1757 : loss : 0.049967, loss_ce: 0.015453
2021-12-12 23:46:40,845 iteration 1758 : loss : 0.047105, loss_ce: 0.018023
2021-12-12 23:46:42,304 iteration 1759 : loss : 0.042735, loss_ce: 0.013941
2021-12-12 23:46:43,814 iteration 1760 : loss : 0.046838, loss_ce: 0.024147
2021-12-12 23:46:45,204 iteration 1761 : loss : 0.024562, loss_ce: 0.010579
2021-12-12 23:46:46,709 iteration 1762 : loss : 0.064775, loss_ce: 0.026766
2021-12-12 23:46:48,135 iteration 1763 : loss : 0.040934, loss_ce: 0.012321
2021-12-12 23:46:49,639 iteration 1764 : loss : 0.105156, loss_ce: 0.035349
2021-12-12 23:46:51,141 iteration 1765 : loss : 0.044112, loss_ce: 0.011737
2021-12-12 23:46:52,553 iteration 1766 : loss : 0.031834, loss_ce: 0.013998
2021-12-12 23:46:54,004 iteration 1767 : loss : 0.045400, loss_ce: 0.018164
2021-12-12 23:46:55,524 iteration 1768 : loss : 0.044149, loss_ce: 0.017317
 26%|███████▌                     | 104/400 [47:13<2:08:23, 26.02s/it]2021-12-12 23:46:57,011 iteration 1769 : loss : 0.027296, loss_ce: 0.008598
2021-12-12 23:46:58,626 iteration 1770 : loss : 0.060928, loss_ce: 0.025741
2021-12-12 23:47:00,069 iteration 1771 : loss : 0.046747, loss_ce: 0.020759
2021-12-12 23:47:01,478 iteration 1772 : loss : 0.026877, loss_ce: 0.008411
2021-12-12 23:47:02,879 iteration 1773 : loss : 0.035095, loss_ce: 0.010585
2021-12-12 23:47:04,351 iteration 1774 : loss : 0.032651, loss_ce: 0.014594
2021-12-12 23:47:05,862 iteration 1775 : loss : 0.037676, loss_ce: 0.016679
2021-12-12 23:47:07,296 iteration 1776 : loss : 0.047017, loss_ce: 0.013392
2021-12-12 23:47:08,718 iteration 1777 : loss : 0.054585, loss_ce: 0.020565
2021-12-12 23:47:10,166 iteration 1778 : loss : 0.050712, loss_ce: 0.016131
2021-12-12 23:47:11,641 iteration 1779 : loss : 0.050340, loss_ce: 0.018580
2021-12-12 23:47:13,080 iteration 1780 : loss : 0.041170, loss_ce: 0.014820
2021-12-12 23:47:14,529 iteration 1781 : loss : 0.035695, loss_ce: 0.016669
2021-12-12 23:47:16,016 iteration 1782 : loss : 0.038729, loss_ce: 0.013910
2021-12-12 23:47:17,448 iteration 1783 : loss : 0.032741, loss_ce: 0.017129
2021-12-12 23:47:19,005 iteration 1784 : loss : 0.033524, loss_ce: 0.012822
2021-12-12 23:47:19,006 Training Data Eval:
2021-12-12 23:47:26,454   Average segmentation loss on training set: 0.0301
2021-12-12 23:47:26,455 Validation Data Eval:
2021-12-12 23:47:29,057   Average segmentation loss on validation set: 0.0620
2021-12-12 23:47:35,374 Found new lowest validation loss at iteration 1784! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-12 23:47:36,780 iteration 1785 : loss : 0.036046, loss_ce: 0.013824
 26%|███████▌                     | 105/400 [47:54<2:30:25, 30.59s/it]2021-12-12 23:47:38,315 iteration 1786 : loss : 0.035556, loss_ce: 0.017315
2021-12-12 23:47:39,795 iteration 1787 : loss : 0.038390, loss_ce: 0.014634
2021-12-12 23:47:41,206 iteration 1788 : loss : 0.044470, loss_ce: 0.018464
2021-12-12 23:47:42,599 iteration 1789 : loss : 0.041035, loss_ce: 0.012398
2021-12-12 23:47:43,962 iteration 1790 : loss : 0.035281, loss_ce: 0.017534
2021-12-12 23:47:45,272 iteration 1791 : loss : 0.025184, loss_ce: 0.011272
2021-12-12 23:47:46,676 iteration 1792 : loss : 0.034374, loss_ce: 0.010053
2021-12-12 23:47:48,096 iteration 1793 : loss : 0.032124, loss_ce: 0.014300
2021-12-12 23:47:49,438 iteration 1794 : loss : 0.029296, loss_ce: 0.013043
2021-12-12 23:47:50,829 iteration 1795 : loss : 0.036604, loss_ce: 0.015812
2021-12-12 23:47:52,249 iteration 1796 : loss : 0.031943, loss_ce: 0.009941
2021-12-12 23:47:53,803 iteration 1797 : loss : 0.029551, loss_ce: 0.011986
2021-12-12 23:47:55,289 iteration 1798 : loss : 0.031747, loss_ce: 0.011316
2021-12-12 23:47:56,805 iteration 1799 : loss : 0.034790, loss_ce: 0.012545
2021-12-12 23:47:58,317 iteration 1800 : loss : 0.042752, loss_ce: 0.018989
2021-12-12 23:47:59,834 iteration 1801 : loss : 0.027309, loss_ce: 0.011190
2021-12-12 23:48:01,244 iteration 1802 : loss : 0.060798, loss_ce: 0.018995
 26%|███████▋                     | 106/400 [48:19<2:20:53, 28.76s/it]2021-12-12 23:48:02,787 iteration 1803 : loss : 0.036364, loss_ce: 0.012040
2021-12-12 23:48:04,239 iteration 1804 : loss : 0.022379, loss_ce: 0.005552
2021-12-12 23:48:05,656 iteration 1805 : loss : 0.026129, loss_ce: 0.012472
2021-12-12 23:48:07,100 iteration 1806 : loss : 0.033361, loss_ce: 0.011459
2021-12-12 23:48:08,587 iteration 1807 : loss : 0.028222, loss_ce: 0.008340
2021-12-12 23:48:10,068 iteration 1808 : loss : 0.035999, loss_ce: 0.015072
2021-12-12 23:48:11,532 iteration 1809 : loss : 0.044346, loss_ce: 0.019120
2021-12-12 23:48:13,024 iteration 1810 : loss : 0.032994, loss_ce: 0.012225
2021-12-12 23:48:14,519 iteration 1811 : loss : 0.033330, loss_ce: 0.014173
2021-12-12 23:48:16,053 iteration 1812 : loss : 0.031847, loss_ce: 0.015849
2021-12-12 23:48:17,561 iteration 1813 : loss : 0.049419, loss_ce: 0.016616
2021-12-12 23:48:19,120 iteration 1814 : loss : 0.058249, loss_ce: 0.023069
2021-12-12 23:48:20,605 iteration 1815 : loss : 0.026809, loss_ce: 0.012301
2021-12-12 23:48:22,124 iteration 1816 : loss : 0.051851, loss_ce: 0.018616
2021-12-12 23:48:23,605 iteration 1817 : loss : 0.032553, loss_ce: 0.010250
2021-12-12 23:48:25,176 iteration 1818 : loss : 0.029905, loss_ce: 0.014929
2021-12-12 23:48:26,611 iteration 1819 : loss : 0.038602, loss_ce: 0.016545
 27%|███████▊                     | 107/400 [48:44<2:15:26, 27.74s/it]2021-12-12 23:48:28,154 iteration 1820 : loss : 0.057685, loss_ce: 0.018469
2021-12-12 23:48:29,587 iteration 1821 : loss : 0.030556, loss_ce: 0.010967
2021-12-12 23:48:31,030 iteration 1822 : loss : 0.028408, loss_ce: 0.013977
2021-12-12 23:48:32,544 iteration 1823 : loss : 0.031875, loss_ce: 0.012040
2021-12-12 23:48:33,997 iteration 1824 : loss : 0.024681, loss_ce: 0.009071
2021-12-12 23:48:35,480 iteration 1825 : loss : 0.036328, loss_ce: 0.012010
2021-12-12 23:48:36,882 iteration 1826 : loss : 0.026409, loss_ce: 0.009903
2021-12-12 23:48:38,323 iteration 1827 : loss : 0.040582, loss_ce: 0.011026
2021-12-12 23:48:39,841 iteration 1828 : loss : 0.032058, loss_ce: 0.014907
2021-12-12 23:48:41,341 iteration 1829 : loss : 0.062089, loss_ce: 0.015933
2021-12-12 23:48:42,809 iteration 1830 : loss : 0.029114, loss_ce: 0.012226
2021-12-12 23:48:44,266 iteration 1831 : loss : 0.037563, loss_ce: 0.016610
2021-12-12 23:48:45,723 iteration 1832 : loss : 0.028761, loss_ce: 0.009968
2021-12-12 23:48:47,165 iteration 1833 : loss : 0.027674, loss_ce: 0.015529
2021-12-12 23:48:48,703 iteration 1834 : loss : 0.040503, loss_ce: 0.014699
2021-12-12 23:48:50,094 iteration 1835 : loss : 0.037067, loss_ce: 0.012890
2021-12-12 23:48:51,524 iteration 1836 : loss : 0.029965, loss_ce: 0.011378
 27%|███████▊                     | 108/400 [49:09<2:10:52, 26.89s/it]2021-12-12 23:48:52,965 iteration 1837 : loss : 0.037761, loss_ce: 0.007829
2021-12-12 23:48:54,496 iteration 1838 : loss : 0.037382, loss_ce: 0.016854
2021-12-12 23:48:55,905 iteration 1839 : loss : 0.029284, loss_ce: 0.012002
2021-12-12 23:48:57,374 iteration 1840 : loss : 0.031106, loss_ce: 0.008162
2021-12-12 23:48:58,862 iteration 1841 : loss : 0.027713, loss_ce: 0.008908
2021-12-12 23:49:00,404 iteration 1842 : loss : 0.027395, loss_ce: 0.010913
2021-12-12 23:49:01,859 iteration 1843 : loss : 0.043366, loss_ce: 0.019679
2021-12-12 23:49:03,321 iteration 1844 : loss : 0.036644, loss_ce: 0.014788
2021-12-12 23:49:04,790 iteration 1845 : loss : 0.035870, loss_ce: 0.012506
2021-12-12 23:49:06,288 iteration 1846 : loss : 0.044537, loss_ce: 0.015261
2021-12-12 23:49:07,674 iteration 1847 : loss : 0.023960, loss_ce: 0.008966
2021-12-12 23:49:09,138 iteration 1848 : loss : 0.033093, loss_ce: 0.011307
2021-12-12 23:49:10,591 iteration 1849 : loss : 0.034179, loss_ce: 0.012976
2021-12-12 23:49:12,077 iteration 1850 : loss : 0.039826, loss_ce: 0.014747
2021-12-12 23:49:13,595 iteration 1851 : loss : 0.033760, loss_ce: 0.015055
2021-12-12 23:49:14,983 iteration 1852 : loss : 0.026452, loss_ce: 0.013150
2021-12-12 23:49:16,500 iteration 1853 : loss : 0.029636, loss_ce: 0.013076
 27%|███████▉                     | 109/400 [49:34<2:07:38, 26.32s/it]2021-12-12 23:49:18,036 iteration 1854 : loss : 0.051149, loss_ce: 0.018560
2021-12-12 23:49:19,561 iteration 1855 : loss : 0.036433, loss_ce: 0.014449
2021-12-12 23:49:20,929 iteration 1856 : loss : 0.031866, loss_ce: 0.014124
2021-12-12 23:49:22,318 iteration 1857 : loss : 0.032305, loss_ce: 0.014826
2021-12-12 23:49:23,736 iteration 1858 : loss : 0.031516, loss_ce: 0.016550
2021-12-12 23:49:25,208 iteration 1859 : loss : 0.036448, loss_ce: 0.014426
2021-12-12 23:49:26,706 iteration 1860 : loss : 0.049186, loss_ce: 0.016758
2021-12-12 23:49:28,185 iteration 1861 : loss : 0.031310, loss_ce: 0.014330
2021-12-12 23:49:29,680 iteration 1862 : loss : 0.028634, loss_ce: 0.014045
2021-12-12 23:49:31,187 iteration 1863 : loss : 0.045700, loss_ce: 0.015244
2021-12-12 23:49:32,690 iteration 1864 : loss : 0.028866, loss_ce: 0.010205
2021-12-12 23:49:34,166 iteration 1865 : loss : 0.052465, loss_ce: 0.016400
2021-12-12 23:49:35,649 iteration 1866 : loss : 0.023446, loss_ce: 0.009078
2021-12-12 23:49:37,034 iteration 1867 : loss : 0.026766, loss_ce: 0.008672
2021-12-12 23:49:38,476 iteration 1868 : loss : 0.039900, loss_ce: 0.014584
2021-12-12 23:49:39,909 iteration 1869 : loss : 0.035835, loss_ce: 0.019589
2021-12-12 23:49:39,910 Training Data Eval:
2021-12-12 23:49:47,430   Average segmentation loss on training set: 0.0301
2021-12-12 23:49:47,430 Validation Data Eval:
2021-12-12 23:49:50,035   Average segmentation loss on validation set: 0.1591
2021-12-12 23:49:51,544 iteration 1870 : loss : 0.037019, loss_ce: 0.013128
 28%|███████▉                     | 110/400 [50:09<2:19:51, 28.94s/it]2021-12-12 23:49:53,127 iteration 1871 : loss : 0.049137, loss_ce: 0.012902
2021-12-12 23:49:54,643 iteration 1872 : loss : 0.027637, loss_ce: 0.008924
2021-12-12 23:49:56,175 iteration 1873 : loss : 0.024292, loss_ce: 0.008437
2021-12-12 23:49:57,687 iteration 1874 : loss : 0.039007, loss_ce: 0.010781
2021-12-12 23:49:59,096 iteration 1875 : loss : 0.023127, loss_ce: 0.009262
2021-12-12 23:50:00,480 iteration 1876 : loss : 0.028757, loss_ce: 0.013758
2021-12-12 23:50:01,983 iteration 1877 : loss : 0.032727, loss_ce: 0.011315
2021-12-12 23:50:03,465 iteration 1878 : loss : 0.040291, loss_ce: 0.019706
2021-12-12 23:50:04,924 iteration 1879 : loss : 0.035282, loss_ce: 0.012733
2021-12-12 23:50:06,422 iteration 1880 : loss : 0.047944, loss_ce: 0.018165
2021-12-12 23:50:07,900 iteration 1881 : loss : 0.042135, loss_ce: 0.021323
2021-12-12 23:50:09,426 iteration 1882 : loss : 0.046824, loss_ce: 0.016498
2021-12-12 23:50:10,902 iteration 1883 : loss : 0.025052, loss_ce: 0.008438
2021-12-12 23:50:12,344 iteration 1884 : loss : 0.029925, loss_ce: 0.010322
2021-12-12 23:50:13,758 iteration 1885 : loss : 0.025847, loss_ce: 0.009648
2021-12-12 23:50:15,252 iteration 1886 : loss : 0.038734, loss_ce: 0.014851
2021-12-12 23:50:16,725 iteration 1887 : loss : 0.047670, loss_ce: 0.020466
 28%|████████                     | 111/400 [50:34<2:13:56, 27.81s/it]2021-12-12 23:50:18,320 iteration 1888 : loss : 0.049190, loss_ce: 0.018563
2021-12-12 23:50:19,720 iteration 1889 : loss : 0.031918, loss_ce: 0.011410
2021-12-12 23:50:21,116 iteration 1890 : loss : 0.033026, loss_ce: 0.013924
2021-12-12 23:50:22,545 iteration 1891 : loss : 0.031459, loss_ce: 0.010329
2021-12-12 23:50:24,010 iteration 1892 : loss : 0.031902, loss_ce: 0.014532
2021-12-12 23:50:25,504 iteration 1893 : loss : 0.025475, loss_ce: 0.006719
2021-12-12 23:50:26,971 iteration 1894 : loss : 0.040288, loss_ce: 0.015278
2021-12-12 23:50:28,386 iteration 1895 : loss : 0.025417, loss_ce: 0.009931
2021-12-12 23:50:29,923 iteration 1896 : loss : 0.053126, loss_ce: 0.023788
2021-12-12 23:50:31,414 iteration 1897 : loss : 0.034136, loss_ce: 0.010080
2021-12-12 23:50:32,945 iteration 1898 : loss : 0.041162, loss_ce: 0.019565
2021-12-12 23:50:34,392 iteration 1899 : loss : 0.038119, loss_ce: 0.011530
2021-12-12 23:50:35,813 iteration 1900 : loss : 0.035103, loss_ce: 0.013278
2021-12-12 23:50:37,227 iteration 1901 : loss : 0.028291, loss_ce: 0.009593
2021-12-12 23:50:38,683 iteration 1902 : loss : 0.032598, loss_ce: 0.013233
2021-12-12 23:50:40,189 iteration 1903 : loss : 0.031605, loss_ce: 0.013187
2021-12-12 23:50:41,705 iteration 1904 : loss : 0.035657, loss_ce: 0.013026
 28%|████████                     | 112/400 [50:59<2:09:24, 26.96s/it]2021-12-12 23:50:43,144 iteration 1905 : loss : 0.029109, loss_ce: 0.014463
2021-12-12 23:50:44,641 iteration 1906 : loss : 0.026241, loss_ce: 0.008719
2021-12-12 23:50:46,147 iteration 1907 : loss : 0.032855, loss_ce: 0.015954
2021-12-12 23:50:47,743 iteration 1908 : loss : 0.032198, loss_ce: 0.013604
2021-12-12 23:50:49,130 iteration 1909 : loss : 0.023659, loss_ce: 0.010014
2021-12-12 23:50:50,580 iteration 1910 : loss : 0.033393, loss_ce: 0.012268
2021-12-12 23:50:52,081 iteration 1911 : loss : 0.040149, loss_ce: 0.017147
2021-12-12 23:50:53,638 iteration 1912 : loss : 0.051246, loss_ce: 0.018189
2021-12-12 23:50:55,116 iteration 1913 : loss : 0.034991, loss_ce: 0.015657
2021-12-12 23:50:56,657 iteration 1914 : loss : 0.037813, loss_ce: 0.015423
2021-12-12 23:50:58,122 iteration 1915 : loss : 0.029584, loss_ce: 0.011057
2021-12-12 23:50:59,556 iteration 1916 : loss : 0.039562, loss_ce: 0.015983
2021-12-12 23:51:00,994 iteration 1917 : loss : 0.029812, loss_ce: 0.011843
2021-12-12 23:51:02,511 iteration 1918 : loss : 0.029871, loss_ce: 0.013557
2021-12-12 23:51:03,955 iteration 1919 : loss : 0.040960, loss_ce: 0.011279
2021-12-12 23:51:05,358 iteration 1920 : loss : 0.028906, loss_ce: 0.012634
2021-12-12 23:51:06,899 iteration 1921 : loss : 0.037691, loss_ce: 0.013888
 28%|████████▏                    | 113/400 [51:24<2:06:25, 26.43s/it]2021-12-12 23:51:08,455 iteration 1922 : loss : 0.046951, loss_ce: 0.023418
2021-12-12 23:51:09,884 iteration 1923 : loss : 0.027734, loss_ce: 0.010253
2021-12-12 23:51:11,410 iteration 1924 : loss : 0.049928, loss_ce: 0.019682
2021-12-12 23:51:12,817 iteration 1925 : loss : 0.041422, loss_ce: 0.011903
2021-12-12 23:51:14,346 iteration 1926 : loss : 0.040791, loss_ce: 0.016107
2021-12-12 23:51:15,875 iteration 1927 : loss : 0.030591, loss_ce: 0.012869
2021-12-12 23:51:17,302 iteration 1928 : loss : 0.034990, loss_ce: 0.010771
2021-12-12 23:51:18,902 iteration 1929 : loss : 0.053848, loss_ce: 0.026740
2021-12-12 23:51:20,376 iteration 1930 : loss : 0.032268, loss_ce: 0.014100
2021-12-12 23:51:21,897 iteration 1931 : loss : 0.036582, loss_ce: 0.013401
2021-12-12 23:51:23,374 iteration 1932 : loss : 0.048045, loss_ce: 0.012860
2021-12-12 23:51:24,871 iteration 1933 : loss : 0.037795, loss_ce: 0.014662
2021-12-12 23:51:26,321 iteration 1934 : loss : 0.035630, loss_ce: 0.010691
2021-12-12 23:51:27,787 iteration 1935 : loss : 0.028018, loss_ce: 0.010860
2021-12-12 23:51:29,226 iteration 1936 : loss : 0.031439, loss_ce: 0.013100
2021-12-12 23:51:30,639 iteration 1937 : loss : 0.035208, loss_ce: 0.013611
2021-12-12 23:51:32,132 iteration 1938 : loss : 0.040302, loss_ce: 0.020574
 28%|████████▎                    | 114/400 [51:50<2:04:16, 26.07s/it]2021-12-12 23:51:33,671 iteration 1939 : loss : 0.038987, loss_ce: 0.016769
2021-12-12 23:51:35,097 iteration 1940 : loss : 0.029897, loss_ce: 0.013953
2021-12-12 23:51:36,567 iteration 1941 : loss : 0.022735, loss_ce: 0.008109
2021-12-12 23:51:38,052 iteration 1942 : loss : 0.028900, loss_ce: 0.010613
2021-12-12 23:51:39,511 iteration 1943 : loss : 0.036032, loss_ce: 0.013678
2021-12-12 23:51:40,978 iteration 1944 : loss : 0.044300, loss_ce: 0.018362
2021-12-12 23:51:42,461 iteration 1945 : loss : 0.032561, loss_ce: 0.011801
2021-12-12 23:51:43,889 iteration 1946 : loss : 0.048030, loss_ce: 0.012825
2021-12-12 23:51:45,345 iteration 1947 : loss : 0.036143, loss_ce: 0.007772
2021-12-12 23:51:46,837 iteration 1948 : loss : 0.039569, loss_ce: 0.017379
2021-12-12 23:51:48,259 iteration 1949 : loss : 0.028333, loss_ce: 0.010594
2021-12-12 23:51:49,761 iteration 1950 : loss : 0.033546, loss_ce: 0.011677
2021-12-12 23:51:51,253 iteration 1951 : loss : 0.049155, loss_ce: 0.017386
2021-12-12 23:51:52,724 iteration 1952 : loss : 0.029954, loss_ce: 0.012505
2021-12-12 23:51:54,124 iteration 1953 : loss : 0.043734, loss_ce: 0.027646
2021-12-12 23:51:55,613 iteration 1954 : loss : 0.027272, loss_ce: 0.011982
2021-12-12 23:51:55,614 Training Data Eval:
2021-12-12 23:52:03,103   Average segmentation loss on training set: 0.0295
2021-12-12 23:52:03,104 Validation Data Eval:
2021-12-12 23:52:05,702   Average segmentation loss on validation set: 0.0973
2021-12-12 23:52:07,214 iteration 1955 : loss : 0.033578, loss_ce: 0.015422
 29%|████████▎                    | 115/400 [52:25<2:16:40, 28.77s/it]2021-12-12 23:52:08,720 iteration 1956 : loss : 0.043313, loss_ce: 0.016933
2021-12-12 23:52:10,235 iteration 1957 : loss : 0.044236, loss_ce: 0.021587
2021-12-12 23:52:11,688 iteration 1958 : loss : 0.051009, loss_ce: 0.016114
2021-12-12 23:52:13,136 iteration 1959 : loss : 0.037015, loss_ce: 0.011882
2021-12-12 23:52:14,523 iteration 1960 : loss : 0.026620, loss_ce: 0.010683
2021-12-12 23:52:15,888 iteration 1961 : loss : 0.024274, loss_ce: 0.009945
2021-12-12 23:52:17,400 iteration 1962 : loss : 0.040664, loss_ce: 0.016282
2021-12-12 23:52:18,811 iteration 1963 : loss : 0.029723, loss_ce: 0.010448
2021-12-12 23:52:20,306 iteration 1964 : loss : 0.039164, loss_ce: 0.012479
2021-12-12 23:52:21,688 iteration 1965 : loss : 0.026267, loss_ce: 0.011429
2021-12-12 23:52:23,142 iteration 1966 : loss : 0.031936, loss_ce: 0.012555
2021-12-12 23:52:24,706 iteration 1967 : loss : 0.041129, loss_ce: 0.014301
2021-12-12 23:52:26,320 iteration 1968 : loss : 0.042663, loss_ce: 0.016439
2021-12-12 23:52:27,819 iteration 1969 : loss : 0.043993, loss_ce: 0.016486
2021-12-12 23:52:29,211 iteration 1970 : loss : 0.028117, loss_ce: 0.011758
2021-12-12 23:52:30,682 iteration 1971 : loss : 0.028959, loss_ce: 0.013007
2021-12-12 23:52:32,151 iteration 1972 : loss : 0.032991, loss_ce: 0.009613
 29%|████████▍                    | 116/400 [52:50<2:10:45, 27.62s/it]2021-12-12 23:52:33,589 iteration 1973 : loss : 0.029755, loss_ce: 0.012570
2021-12-12 23:52:35,010 iteration 1974 : loss : 0.033078, loss_ce: 0.013454
2021-12-12 23:52:36,510 iteration 1975 : loss : 0.035641, loss_ce: 0.014243
2021-12-12 23:52:37,958 iteration 1976 : loss : 0.031256, loss_ce: 0.013073
2021-12-12 23:52:39,486 iteration 1977 : loss : 0.034932, loss_ce: 0.012958
2021-12-12 23:52:41,025 iteration 1978 : loss : 0.063530, loss_ce: 0.023046
2021-12-12 23:52:42,442 iteration 1979 : loss : 0.031678, loss_ce: 0.011696
2021-12-12 23:52:43,864 iteration 1980 : loss : 0.024366, loss_ce: 0.007826
2021-12-12 23:52:45,305 iteration 1981 : loss : 0.028509, loss_ce: 0.012072
2021-12-12 23:52:46,822 iteration 1982 : loss : 0.038818, loss_ce: 0.015475
2021-12-12 23:52:48,227 iteration 1983 : loss : 0.035020, loss_ce: 0.012170
2021-12-12 23:52:49,745 iteration 1984 : loss : 0.047062, loss_ce: 0.017636
2021-12-12 23:52:51,203 iteration 1985 : loss : 0.034365, loss_ce: 0.013453
2021-12-12 23:52:52,711 iteration 1986 : loss : 0.031413, loss_ce: 0.009736
2021-12-12 23:52:54,150 iteration 1987 : loss : 0.030862, loss_ce: 0.010553
2021-12-12 23:52:55,549 iteration 1988 : loss : 0.028702, loss_ce: 0.011366
2021-12-12 23:52:57,020 iteration 1989 : loss : 0.031637, loss_ce: 0.012047
 29%|████████▍                    | 117/400 [53:15<2:06:23, 26.80s/it]2021-12-12 23:52:58,524 iteration 1990 : loss : 0.035420, loss_ce: 0.009924
2021-12-12 23:52:59,912 iteration 1991 : loss : 0.025487, loss_ce: 0.010270
2021-12-12 23:53:01,393 iteration 1992 : loss : 0.024075, loss_ce: 0.007876
2021-12-12 23:53:02,877 iteration 1993 : loss : 0.037711, loss_ce: 0.014750
2021-12-12 23:53:04,394 iteration 1994 : loss : 0.025588, loss_ce: 0.010784
2021-12-12 23:53:05,832 iteration 1995 : loss : 0.028297, loss_ce: 0.010593
2021-12-12 23:53:07,332 iteration 1996 : loss : 0.033973, loss_ce: 0.013396
2021-12-12 23:53:08,753 iteration 1997 : loss : 0.026482, loss_ce: 0.012460
2021-12-12 23:53:10,215 iteration 1998 : loss : 0.030787, loss_ce: 0.011872
2021-12-12 23:53:11,695 iteration 1999 : loss : 0.038074, loss_ce: 0.016447
2021-12-12 23:53:13,153 iteration 2000 : loss : 0.029365, loss_ce: 0.013299
2021-12-12 23:53:14,561 iteration 2001 : loss : 0.041834, loss_ce: 0.014019
2021-12-12 23:53:16,075 iteration 2002 : loss : 0.024547, loss_ce: 0.009630
2021-12-12 23:53:17,492 iteration 2003 : loss : 0.028246, loss_ce: 0.008340
2021-12-12 23:53:18,984 iteration 2004 : loss : 0.032725, loss_ce: 0.015771
2021-12-12 23:53:20,407 iteration 2005 : loss : 0.034458, loss_ce: 0.014233
2021-12-12 23:53:21,866 iteration 2006 : loss : 0.045060, loss_ce: 0.015659
 30%|████████▌                    | 118/400 [53:39<2:03:11, 26.21s/it]2021-12-12 23:53:23,453 iteration 2007 : loss : 0.035954, loss_ce: 0.013493
2021-12-12 23:53:24,943 iteration 2008 : loss : 0.028167, loss_ce: 0.011905
2021-12-12 23:53:26,357 iteration 2009 : loss : 0.027690, loss_ce: 0.013219
2021-12-12 23:53:27,817 iteration 2010 : loss : 0.028451, loss_ce: 0.010479
2021-12-12 23:53:29,215 iteration 2011 : loss : 0.043985, loss_ce: 0.013650
2021-12-12 23:53:30,609 iteration 2012 : loss : 0.023564, loss_ce: 0.008378
2021-12-12 23:53:32,044 iteration 2013 : loss : 0.032890, loss_ce: 0.019175
2021-12-12 23:53:33,526 iteration 2014 : loss : 0.022361, loss_ce: 0.008498
2021-12-12 23:53:35,012 iteration 2015 : loss : 0.036147, loss_ce: 0.012193
2021-12-12 23:53:36,527 iteration 2016 : loss : 0.031351, loss_ce: 0.012201
2021-12-12 23:53:38,023 iteration 2017 : loss : 0.040262, loss_ce: 0.014125
2021-12-12 23:53:39,422 iteration 2018 : loss : 0.034168, loss_ce: 0.010519
2021-12-12 23:53:40,893 iteration 2019 : loss : 0.023224, loss_ce: 0.008532
2021-12-12 23:53:42,354 iteration 2020 : loss : 0.030269, loss_ce: 0.010592
2021-12-12 23:53:43,804 iteration 2021 : loss : 0.027624, loss_ce: 0.010037
2021-12-12 23:53:45,266 iteration 2022 : loss : 0.025331, loss_ce: 0.008642
2021-12-12 23:53:46,740 iteration 2023 : loss : 0.023642, loss_ce: 0.007681
 30%|████████▋                    | 119/400 [54:04<2:00:52, 25.81s/it]2021-12-12 23:53:48,265 iteration 2024 : loss : 0.038265, loss_ce: 0.015551
2021-12-12 23:53:49,868 iteration 2025 : loss : 0.040684, loss_ce: 0.014120
2021-12-12 23:53:51,303 iteration 2026 : loss : 0.030002, loss_ce: 0.008222
2021-12-12 23:53:52,790 iteration 2027 : loss : 0.028191, loss_ce: 0.008548
2021-12-12 23:53:54,146 iteration 2028 : loss : 0.026692, loss_ce: 0.011317
2021-12-12 23:53:55,552 iteration 2029 : loss : 0.033843, loss_ce: 0.011244
2021-12-12 23:53:57,049 iteration 2030 : loss : 0.023026, loss_ce: 0.007339
2021-12-12 23:53:58,544 iteration 2031 : loss : 0.036623, loss_ce: 0.014043
2021-12-12 23:54:00,011 iteration 2032 : loss : 0.031740, loss_ce: 0.015803
2021-12-12 23:54:01,375 iteration 2033 : loss : 0.023290, loss_ce: 0.010024
2021-12-12 23:54:02,801 iteration 2034 : loss : 0.021736, loss_ce: 0.006734
2021-12-12 23:54:04,287 iteration 2035 : loss : 0.029468, loss_ce: 0.010742
2021-12-12 23:54:05,708 iteration 2036 : loss : 0.031318, loss_ce: 0.013104
2021-12-12 23:54:07,117 iteration 2037 : loss : 0.026834, loss_ce: 0.011562
2021-12-12 23:54:08,668 iteration 2038 : loss : 0.090601, loss_ce: 0.031528
2021-12-12 23:54:10,172 iteration 2039 : loss : 0.045300, loss_ce: 0.016863
2021-12-12 23:54:10,172 Training Data Eval:
2021-12-12 23:54:17,671   Average segmentation loss on training set: 0.0359
2021-12-12 23:54:17,672 Validation Data Eval:
2021-12-12 23:54:20,266   Average segmentation loss on validation set: 0.0741
2021-12-12 23:54:21,807 iteration 2040 : loss : 0.031557, loss_ce: 0.013156
 30%|████████▋                    | 120/400 [54:39<2:13:24, 28.59s/it]2021-12-12 23:54:23,300 iteration 2041 : loss : 0.022316, loss_ce: 0.008992
2021-12-12 23:54:24,801 iteration 2042 : loss : 0.034431, loss_ce: 0.011968
2021-12-12 23:54:26,281 iteration 2043 : loss : 0.031456, loss_ce: 0.010215
2021-12-12 23:54:27,740 iteration 2044 : loss : 0.050190, loss_ce: 0.028189
2021-12-12 23:54:29,303 iteration 2045 : loss : 0.032472, loss_ce: 0.012545
2021-12-12 23:54:30,766 iteration 2046 : loss : 0.068365, loss_ce: 0.016481
2021-12-12 23:54:32,204 iteration 2047 : loss : 0.025787, loss_ce: 0.010501
2021-12-12 23:54:33,617 iteration 2048 : loss : 0.025840, loss_ce: 0.009327
2021-12-12 23:54:35,132 iteration 2049 : loss : 0.034258, loss_ce: 0.016323
2021-12-12 23:54:36,626 iteration 2050 : loss : 0.030423, loss_ce: 0.008099
2021-12-12 23:54:38,061 iteration 2051 : loss : 0.034731, loss_ce: 0.013210
2021-12-12 23:54:39,568 iteration 2052 : loss : 0.029904, loss_ce: 0.012274
2021-12-12 23:54:41,044 iteration 2053 : loss : 0.035576, loss_ce: 0.012866
2021-12-12 23:54:42,509 iteration 2054 : loss : 0.029130, loss_ce: 0.010648
2021-12-12 23:54:43,993 iteration 2055 : loss : 0.044982, loss_ce: 0.015200
2021-12-12 23:54:45,423 iteration 2056 : loss : 0.025322, loss_ce: 0.008842
2021-12-12 23:54:46,853 iteration 2057 : loss : 0.032885, loss_ce: 0.011985
 30%|████████▊                    | 121/400 [55:04<2:07:59, 27.52s/it]2021-12-12 23:54:48,345 iteration 2058 : loss : 0.033526, loss_ce: 0.018049
2021-12-12 23:54:49,848 iteration 2059 : loss : 0.058695, loss_ce: 0.027755
2021-12-12 23:54:51,373 iteration 2060 : loss : 0.041599, loss_ce: 0.015554
2021-12-12 23:54:52,822 iteration 2061 : loss : 0.028488, loss_ce: 0.013019
2021-12-12 23:54:54,231 iteration 2062 : loss : 0.041626, loss_ce: 0.014268
2021-12-12 23:54:55,838 iteration 2063 : loss : 0.047816, loss_ce: 0.022580
2021-12-12 23:54:57,294 iteration 2064 : loss : 0.041650, loss_ce: 0.016574
2021-12-12 23:54:58,822 iteration 2065 : loss : 0.045179, loss_ce: 0.015344
2021-12-12 23:55:00,286 iteration 2066 : loss : 0.026228, loss_ce: 0.011431
2021-12-12 23:55:01,796 iteration 2067 : loss : 0.030781, loss_ce: 0.011076
2021-12-12 23:55:03,202 iteration 2068 : loss : 0.024168, loss_ce: 0.009280
2021-12-12 23:55:04,668 iteration 2069 : loss : 0.028733, loss_ce: 0.013011
2021-12-12 23:55:06,172 iteration 2070 : loss : 0.036864, loss_ce: 0.015777
2021-12-12 23:55:07,576 iteration 2071 : loss : 0.021664, loss_ce: 0.008391
2021-12-12 23:55:08,993 iteration 2072 : loss : 0.025491, loss_ce: 0.012532
2021-12-12 23:55:10,501 iteration 2073 : loss : 0.036433, loss_ce: 0.014029
2021-12-12 23:55:11,907 iteration 2074 : loss : 0.025027, loss_ce: 0.006542
 30%|████████▊                    | 122/400 [55:29<2:04:05, 26.78s/it]2021-12-12 23:55:13,411 iteration 2075 : loss : 0.033747, loss_ce: 0.016799
2021-12-12 23:55:14,906 iteration 2076 : loss : 0.033153, loss_ce: 0.012877
2021-12-12 23:55:16,392 iteration 2077 : loss : 0.041666, loss_ce: 0.016404
2021-12-12 23:55:17,897 iteration 2078 : loss : 0.031252, loss_ce: 0.010870
2021-12-12 23:55:19,402 iteration 2079 : loss : 0.032320, loss_ce: 0.011208
2021-12-12 23:55:20,824 iteration 2080 : loss : 0.032670, loss_ce: 0.010846
2021-12-12 23:55:22,217 iteration 2081 : loss : 0.030225, loss_ce: 0.010436
2021-12-12 23:55:23,682 iteration 2082 : loss : 0.041156, loss_ce: 0.010165
2021-12-12 23:55:25,141 iteration 2083 : loss : 0.029509, loss_ce: 0.011275
2021-12-12 23:55:26,546 iteration 2084 : loss : 0.029675, loss_ce: 0.013679
2021-12-12 23:55:28,032 iteration 2085 : loss : 0.063497, loss_ce: 0.013214
2021-12-12 23:55:29,588 iteration 2086 : loss : 0.029857, loss_ce: 0.009330
2021-12-12 23:55:30,980 iteration 2087 : loss : 0.030581, loss_ce: 0.011151
2021-12-12 23:55:32,431 iteration 2088 : loss : 0.034266, loss_ce: 0.012869
2021-12-12 23:55:33,901 iteration 2089 : loss : 0.032824, loss_ce: 0.013795
2021-12-12 23:55:35,362 iteration 2090 : loss : 0.034230, loss_ce: 0.016356
2021-12-12 23:55:36,899 iteration 2091 : loss : 0.060337, loss_ce: 0.021934
 31%|████████▉                    | 123/400 [55:54<2:01:10, 26.25s/it]2021-12-12 23:55:38,376 iteration 2092 : loss : 0.027125, loss_ce: 0.008750
2021-12-12 23:55:39,772 iteration 2093 : loss : 0.021185, loss_ce: 0.008466
2021-12-12 23:55:41,257 iteration 2094 : loss : 0.034061, loss_ce: 0.011619
2021-12-12 23:55:42,889 iteration 2095 : loss : 0.030893, loss_ce: 0.010666
2021-12-12 23:55:44,332 iteration 2096 : loss : 0.028586, loss_ce: 0.012168
2021-12-12 23:55:45,788 iteration 2097 : loss : 0.064422, loss_ce: 0.019003
2021-12-12 23:55:47,191 iteration 2098 : loss : 0.028394, loss_ce: 0.011145
2021-12-12 23:55:48,650 iteration 2099 : loss : 0.023917, loss_ce: 0.009460
2021-12-12 23:55:50,162 iteration 2100 : loss : 0.045722, loss_ce: 0.017403
2021-12-12 23:55:51,534 iteration 2101 : loss : 0.039533, loss_ce: 0.014486
2021-12-12 23:55:53,034 iteration 2102 : loss : 0.037645, loss_ce: 0.016368
2021-12-12 23:55:54,456 iteration 2103 : loss : 0.034114, loss_ce: 0.018611
2021-12-12 23:55:55,853 iteration 2104 : loss : 0.028537, loss_ce: 0.009650
2021-12-12 23:55:57,341 iteration 2105 : loss : 0.038991, loss_ce: 0.016905
2021-12-12 23:55:58,821 iteration 2106 : loss : 0.029716, loss_ce: 0.012741
2021-12-12 23:56:00,238 iteration 2107 : loss : 0.025061, loss_ce: 0.009474
2021-12-12 23:56:01,637 iteration 2108 : loss : 0.028422, loss_ce: 0.010861
 31%|████████▉                    | 124/400 [56:19<1:58:39, 25.80s/it]2021-12-12 23:56:03,141 iteration 2109 : loss : 0.049178, loss_ce: 0.017326
2021-12-12 23:56:04,634 iteration 2110 : loss : 0.032872, loss_ce: 0.013081
2021-12-12 23:56:06,161 iteration 2111 : loss : 0.026437, loss_ce: 0.008915
2021-12-12 23:56:07,713 iteration 2112 : loss : 0.041658, loss_ce: 0.018379
2021-12-12 23:56:09,221 iteration 2113 : loss : 0.046379, loss_ce: 0.018235
2021-12-12 23:56:10,714 iteration 2114 : loss : 0.043725, loss_ce: 0.012677
2021-12-12 23:56:12,144 iteration 2115 : loss : 0.026182, loss_ce: 0.008848
2021-12-12 23:56:13,574 iteration 2116 : loss : 0.028243, loss_ce: 0.008931
2021-12-12 23:56:15,131 iteration 2117 : loss : 0.037934, loss_ce: 0.012914
2021-12-12 23:56:16,600 iteration 2118 : loss : 0.045584, loss_ce: 0.019705
2021-12-12 23:56:18,163 iteration 2119 : loss : 0.048815, loss_ce: 0.019410
2021-12-12 23:56:19,665 iteration 2120 : loss : 0.030186, loss_ce: 0.017129
2021-12-12 23:56:21,172 iteration 2121 : loss : 0.037071, loss_ce: 0.015000
2021-12-12 23:56:22,689 iteration 2122 : loss : 0.037863, loss_ce: 0.022107
2021-12-12 23:56:24,092 iteration 2123 : loss : 0.032702, loss_ce: 0.010034
2021-12-12 23:56:25,616 iteration 2124 : loss : 0.051478, loss_ce: 0.018890
2021-12-12 23:56:25,616 Training Data Eval:
2021-12-12 23:56:33,093   Average segmentation loss on training set: 0.0223
2021-12-12 23:56:33,093 Validation Data Eval:
2021-12-12 23:56:35,689   Average segmentation loss on validation set: 0.0928
2021-12-12 23:56:37,145 iteration 2125 : loss : 0.023380, loss_ce: 0.010618
 31%|█████████                    | 125/400 [56:55<2:11:35, 28.71s/it]2021-12-12 23:56:38,702 iteration 2126 : loss : 0.051049, loss_ce: 0.016688
2021-12-12 23:56:40,109 iteration 2127 : loss : 0.022462, loss_ce: 0.008963
2021-12-12 23:56:41,504 iteration 2128 : loss : 0.029812, loss_ce: 0.011765
2021-12-12 23:56:43,033 iteration 2129 : loss : 0.041517, loss_ce: 0.014956
2021-12-12 23:56:44,481 iteration 2130 : loss : 0.038650, loss_ce: 0.014016
2021-12-12 23:56:45,888 iteration 2131 : loss : 0.028521, loss_ce: 0.009867
2021-12-12 23:56:47,373 iteration 2132 : loss : 0.037748, loss_ce: 0.010496
2021-12-12 23:56:48,826 iteration 2133 : loss : 0.023920, loss_ce: 0.009492
2021-12-12 23:56:50,360 iteration 2134 : loss : 0.039378, loss_ce: 0.013496
2021-12-12 23:56:51,759 iteration 2135 : loss : 0.032228, loss_ce: 0.009502
2021-12-12 23:56:53,270 iteration 2136 : loss : 0.033993, loss_ce: 0.013675
2021-12-12 23:56:54,715 iteration 2137 : loss : 0.032551, loss_ce: 0.013919
2021-12-12 23:56:56,247 iteration 2138 : loss : 0.040766, loss_ce: 0.014063
2021-12-12 23:56:57,687 iteration 2139 : loss : 0.029981, loss_ce: 0.013418
2021-12-12 23:56:59,182 iteration 2140 : loss : 0.037514, loss_ce: 0.022132
2021-12-12 23:57:00,650 iteration 2141 : loss : 0.034013, loss_ce: 0.011353
2021-12-12 23:57:02,141 iteration 2142 : loss : 0.045129, loss_ce: 0.014880
 32%|█████████▏                   | 126/400 [57:20<2:06:01, 27.60s/it]2021-12-12 23:57:03,656 iteration 2143 : loss : 0.026287, loss_ce: 0.013699
2021-12-12 23:57:05,136 iteration 2144 : loss : 0.027681, loss_ce: 0.010712
2021-12-12 23:57:06,590 iteration 2145 : loss : 0.027254, loss_ce: 0.011086
2021-12-12 23:57:08,011 iteration 2146 : loss : 0.033286, loss_ce: 0.012003
2021-12-12 23:57:09,416 iteration 2147 : loss : 0.022637, loss_ce: 0.007873
2021-12-12 23:57:10,856 iteration 2148 : loss : 0.030932, loss_ce: 0.012174
2021-12-12 23:57:12,368 iteration 2149 : loss : 0.047253, loss_ce: 0.014888
2021-12-12 23:57:13,798 iteration 2150 : loss : 0.030041, loss_ce: 0.011582
2021-12-12 23:57:15,266 iteration 2151 : loss : 0.035641, loss_ce: 0.013220
2021-12-12 23:57:16,680 iteration 2152 : loss : 0.031386, loss_ce: 0.014316
2021-12-12 23:57:18,137 iteration 2153 : loss : 0.039028, loss_ce: 0.012598
2021-12-12 23:57:19,596 iteration 2154 : loss : 0.028164, loss_ce: 0.010084
2021-12-12 23:57:21,072 iteration 2155 : loss : 0.031126, loss_ce: 0.014914
2021-12-12 23:57:22,471 iteration 2156 : loss : 0.034601, loss_ce: 0.011983
2021-12-12 23:57:24,025 iteration 2157 : loss : 0.038924, loss_ce: 0.014679
2021-12-12 23:57:25,538 iteration 2158 : loss : 0.043466, loss_ce: 0.016612
2021-12-12 23:57:27,029 iteration 2159 : loss : 0.041301, loss_ce: 0.014134
 32%|█████████▏                   | 127/400 [57:45<2:01:50, 26.78s/it]2021-12-12 23:57:28,536 iteration 2160 : loss : 0.033415, loss_ce: 0.011171
2021-12-12 23:57:30,073 iteration 2161 : loss : 0.058140, loss_ce: 0.030906
2021-12-12 23:57:31,574 iteration 2162 : loss : 0.033452, loss_ce: 0.014063
2021-12-12 23:57:32,969 iteration 2163 : loss : 0.042536, loss_ce: 0.016971
2021-12-12 23:57:34,474 iteration 2164 : loss : 0.036734, loss_ce: 0.012995
2021-12-12 23:57:35,976 iteration 2165 : loss : 0.030784, loss_ce: 0.013254
2021-12-12 23:57:37,468 iteration 2166 : loss : 0.056143, loss_ce: 0.014170
2021-12-12 23:57:38,982 iteration 2167 : loss : 0.025441, loss_ce: 0.007872
2021-12-12 23:57:40,451 iteration 2168 : loss : 0.034006, loss_ce: 0.014171
2021-12-12 23:57:41,922 iteration 2169 : loss : 0.029805, loss_ce: 0.010664
2021-12-12 23:57:43,335 iteration 2170 : loss : 0.039321, loss_ce: 0.016917
2021-12-12 23:57:44,829 iteration 2171 : loss : 0.044543, loss_ce: 0.016040
2021-12-12 23:57:46,384 iteration 2172 : loss : 0.044992, loss_ce: 0.013728
2021-12-12 23:57:47,791 iteration 2173 : loss : 0.046126, loss_ce: 0.014927
2021-12-12 23:57:49,165 iteration 2174 : loss : 0.023120, loss_ce: 0.010842
2021-12-12 23:57:50,567 iteration 2175 : loss : 0.025796, loss_ce: 0.008744
2021-12-12 23:57:52,121 iteration 2176 : loss : 0.035428, loss_ce: 0.012409
 32%|█████████▎                   | 128/400 [58:10<1:59:07, 26.28s/it]2021-12-12 23:57:53,634 iteration 2177 : loss : 0.027890, loss_ce: 0.009559
2021-12-12 23:57:55,127 iteration 2178 : loss : 0.040720, loss_ce: 0.017857
2021-12-12 23:57:56,555 iteration 2179 : loss : 0.032657, loss_ce: 0.014892
2021-12-12 23:57:57,993 iteration 2180 : loss : 0.023756, loss_ce: 0.008671
2021-12-12 23:57:59,496 iteration 2181 : loss : 0.038459, loss_ce: 0.018159
2021-12-12 23:58:00,952 iteration 2182 : loss : 0.038056, loss_ce: 0.010248
2021-12-12 23:58:02,355 iteration 2183 : loss : 0.025069, loss_ce: 0.010205
2021-12-12 23:58:03,874 iteration 2184 : loss : 0.041137, loss_ce: 0.016123
2021-12-12 23:58:05,292 iteration 2185 : loss : 0.026689, loss_ce: 0.009742
2021-12-12 23:58:06,741 iteration 2186 : loss : 0.051341, loss_ce: 0.016677
2021-12-12 23:58:08,200 iteration 2187 : loss : 0.029359, loss_ce: 0.012718
2021-12-12 23:58:09,622 iteration 2188 : loss : 0.042475, loss_ce: 0.011027
2021-12-12 23:58:11,141 iteration 2189 : loss : 0.041370, loss_ce: 0.013876
2021-12-12 23:58:12,586 iteration 2190 : loss : 0.033858, loss_ce: 0.012915
2021-12-12 23:58:14,071 iteration 2191 : loss : 0.041921, loss_ce: 0.013581
2021-12-12 23:58:15,504 iteration 2192 : loss : 0.033156, loss_ce: 0.014591
2021-12-12 23:58:16,965 iteration 2193 : loss : 0.040249, loss_ce: 0.015156
 32%|█████████▎                   | 129/400 [58:35<1:56:44, 25.85s/it]2021-12-12 23:58:18,498 iteration 2194 : loss : 0.043163, loss_ce: 0.023668
2021-12-12 23:58:19,927 iteration 2195 : loss : 0.029088, loss_ce: 0.010984
2021-12-12 23:58:21,360 iteration 2196 : loss : 0.028018, loss_ce: 0.009789
2021-12-12 23:58:22,844 iteration 2197 : loss : 0.033530, loss_ce: 0.016614
2021-12-12 23:58:24,340 iteration 2198 : loss : 0.036285, loss_ce: 0.016552
2021-12-12 23:58:25,799 iteration 2199 : loss : 0.040633, loss_ce: 0.020999
2021-12-12 23:58:27,223 iteration 2200 : loss : 0.033691, loss_ce: 0.011315
2021-12-12 23:58:28,637 iteration 2201 : loss : 0.030111, loss_ce: 0.011753
2021-12-12 23:58:30,140 iteration 2202 : loss : 0.082054, loss_ce: 0.020431
2021-12-12 23:58:31,648 iteration 2203 : loss : 0.025275, loss_ce: 0.012001
2021-12-12 23:58:33,076 iteration 2204 : loss : 0.025415, loss_ce: 0.011229
2021-12-12 23:58:34,456 iteration 2205 : loss : 0.026353, loss_ce: 0.010705
2021-12-12 23:58:35,845 iteration 2206 : loss : 0.036845, loss_ce: 0.010256
2021-12-12 23:58:37,270 iteration 2207 : loss : 0.039435, loss_ce: 0.013910
2021-12-12 23:58:38,748 iteration 2208 : loss : 0.042562, loss_ce: 0.012705
2021-12-12 23:58:40,189 iteration 2209 : loss : 0.042923, loss_ce: 0.014493
2021-12-12 23:58:40,189 Training Data Eval:
2021-12-12 23:58:47,677   Average segmentation loss on training set: 0.0224
2021-12-12 23:58:47,677 Validation Data Eval:
2021-12-12 23:58:50,271   Average segmentation loss on validation set: 0.0932
2021-12-12 23:58:51,755 iteration 2210 : loss : 0.038204, loss_ce: 0.011551
 32%|█████████▍                   | 130/400 [59:09<2:08:23, 28.53s/it]2021-12-12 23:58:53,285 iteration 2211 : loss : 0.037401, loss_ce: 0.012705
2021-12-12 23:58:54,765 iteration 2212 : loss : 0.026973, loss_ce: 0.011621
2021-12-12 23:58:56,256 iteration 2213 : loss : 0.034457, loss_ce: 0.013129
2021-12-12 23:58:57,745 iteration 2214 : loss : 0.041353, loss_ce: 0.015702
2021-12-12 23:58:59,251 iteration 2215 : loss : 0.037824, loss_ce: 0.017648
2021-12-12 23:59:00,635 iteration 2216 : loss : 0.029075, loss_ce: 0.008999
2021-12-12 23:59:02,146 iteration 2217 : loss : 0.036046, loss_ce: 0.013688
2021-12-12 23:59:03,571 iteration 2218 : loss : 0.026465, loss_ce: 0.009433
2021-12-12 23:59:05,078 iteration 2219 : loss : 0.025081, loss_ce: 0.009449
2021-12-12 23:59:06,450 iteration 2220 : loss : 0.036100, loss_ce: 0.011447
2021-12-12 23:59:07,888 iteration 2221 : loss : 0.028441, loss_ce: 0.009645
2021-12-12 23:59:09,382 iteration 2222 : loss : 0.039589, loss_ce: 0.015639
2021-12-12 23:59:10,838 iteration 2223 : loss : 0.033922, loss_ce: 0.009792
2021-12-12 23:59:12,359 iteration 2224 : loss : 0.042790, loss_ce: 0.017871
2021-12-12 23:59:13,753 iteration 2225 : loss : 0.021151, loss_ce: 0.007430
2021-12-12 23:59:15,281 iteration 2226 : loss : 0.044586, loss_ce: 0.021897
2021-12-12 23:59:16,764 iteration 2227 : loss : 0.021577, loss_ce: 0.007767
 33%|█████████▍                   | 131/400 [59:34<2:03:10, 27.47s/it]2021-12-12 23:59:18,305 iteration 2228 : loss : 0.023435, loss_ce: 0.010904
2021-12-12 23:59:19,757 iteration 2229 : loss : 0.032478, loss_ce: 0.014168
2021-12-12 23:59:21,265 iteration 2230 : loss : 0.039491, loss_ce: 0.012697
2021-12-12 23:59:22,628 iteration 2231 : loss : 0.020838, loss_ce: 0.008652
2021-12-12 23:59:24,057 iteration 2232 : loss : 0.044830, loss_ce: 0.016665
2021-12-12 23:59:25,505 iteration 2233 : loss : 0.034892, loss_ce: 0.010791
2021-12-12 23:59:26,997 iteration 2234 : loss : 0.034434, loss_ce: 0.012638
2021-12-12 23:59:28,431 iteration 2235 : loss : 0.055042, loss_ce: 0.011909
2021-12-12 23:59:30,026 iteration 2236 : loss : 0.051985, loss_ce: 0.021650
2021-12-12 23:59:31,501 iteration 2237 : loss : 0.028755, loss_ce: 0.012779
2021-12-12 23:59:32,974 iteration 2238 : loss : 0.039909, loss_ce: 0.021381
2021-12-12 23:59:34,420 iteration 2239 : loss : 0.032188, loss_ce: 0.010784
2021-12-12 23:59:35,905 iteration 2240 : loss : 0.051039, loss_ce: 0.016411
2021-12-12 23:59:37,423 iteration 2241 : loss : 0.044195, loss_ce: 0.013785
2021-12-12 23:59:38,934 iteration 2242 : loss : 0.030624, loss_ce: 0.010673
2021-12-12 23:59:40,488 iteration 2243 : loss : 0.033685, loss_ce: 0.011368
2021-12-12 23:59:41,934 iteration 2244 : loss : 0.031580, loss_ce: 0.014358
 33%|████████▉                  | 132/400 [1:00:00<1:59:37, 26.78s/it]2021-12-12 23:59:43,517 iteration 2245 : loss : 0.039089, loss_ce: 0.013493
2021-12-12 23:59:44,940 iteration 2246 : loss : 0.022098, loss_ce: 0.008203
2021-12-12 23:59:46,489 iteration 2247 : loss : 0.082324, loss_ce: 0.027678
2021-12-12 23:59:47,967 iteration 2248 : loss : 0.040201, loss_ce: 0.016135
2021-12-12 23:59:49,425 iteration 2249 : loss : 0.032188, loss_ce: 0.011169
2021-12-12 23:59:50,864 iteration 2250 : loss : 0.064162, loss_ce: 0.024031
2021-12-12 23:59:52,248 iteration 2251 : loss : 0.028523, loss_ce: 0.009329
2021-12-12 23:59:53,810 iteration 2252 : loss : 0.063069, loss_ce: 0.027006
2021-12-12 23:59:55,359 iteration 2253 : loss : 0.035365, loss_ce: 0.013794
2021-12-12 23:59:56,807 iteration 2254 : loss : 0.029483, loss_ce: 0.013758
2021-12-12 23:59:58,232 iteration 2255 : loss : 0.032287, loss_ce: 0.010736
2021-12-12 23:59:59,710 iteration 2256 : loss : 0.035055, loss_ce: 0.013269
2021-12-13 00:00:01,170 iteration 2257 : loss : 0.027860, loss_ce: 0.010195
2021-12-13 00:00:02,573 iteration 2258 : loss : 0.026077, loss_ce: 0.011067
2021-12-13 00:00:04,106 iteration 2259 : loss : 0.043131, loss_ce: 0.018248
2021-12-13 00:00:05,534 iteration 2260 : loss : 0.032378, loss_ce: 0.012727
2021-12-13 00:00:07,013 iteration 2261 : loss : 0.029486, loss_ce: 0.011140
 33%|████████▉                  | 133/400 [1:00:25<1:56:54, 26.27s/it]2021-12-13 00:00:08,535 iteration 2262 : loss : 0.032353, loss_ce: 0.013374
2021-12-13 00:00:10,006 iteration 2263 : loss : 0.027880, loss_ce: 0.011940
2021-12-13 00:00:11,508 iteration 2264 : loss : 0.061691, loss_ce: 0.028228
2021-12-13 00:00:12,946 iteration 2265 : loss : 0.031326, loss_ce: 0.011398
2021-12-13 00:00:14,388 iteration 2266 : loss : 0.027423, loss_ce: 0.008370
2021-12-13 00:00:15,776 iteration 2267 : loss : 0.022608, loss_ce: 0.008520
2021-12-13 00:00:17,226 iteration 2268 : loss : 0.027544, loss_ce: 0.012580
2021-12-13 00:00:18,652 iteration 2269 : loss : 0.033168, loss_ce: 0.015852
2021-12-13 00:00:20,057 iteration 2270 : loss : 0.020789, loss_ce: 0.007613
2021-12-13 00:00:21,498 iteration 2271 : loss : 0.044319, loss_ce: 0.021397
2021-12-13 00:00:22,996 iteration 2272 : loss : 0.036593, loss_ce: 0.015710
2021-12-13 00:00:24,502 iteration 2273 : loss : 0.037282, loss_ce: 0.014084
2021-12-13 00:00:25,958 iteration 2274 : loss : 0.026322, loss_ce: 0.010542
2021-12-13 00:00:27,399 iteration 2275 : loss : 0.047850, loss_ce: 0.018341
2021-12-13 00:00:28,810 iteration 2276 : loss : 0.029395, loss_ce: 0.011559
2021-12-13 00:00:30,262 iteration 2277 : loss : 0.023036, loss_ce: 0.006144
2021-12-13 00:00:31,741 iteration 2278 : loss : 0.033741, loss_ce: 0.010786
 34%|█████████                  | 134/400 [1:00:49<1:54:25, 25.81s/it]2021-12-13 00:00:33,166 iteration 2279 : loss : 0.023134, loss_ce: 0.008274
2021-12-13 00:00:34,569 iteration 2280 : loss : 0.026922, loss_ce: 0.011192
2021-12-13 00:00:36,032 iteration 2281 : loss : 0.035551, loss_ce: 0.010800
2021-12-13 00:00:37,432 iteration 2282 : loss : 0.033754, loss_ce: 0.011754
2021-12-13 00:00:38,906 iteration 2283 : loss : 0.037361, loss_ce: 0.011194
2021-12-13 00:00:40,293 iteration 2284 : loss : 0.043294, loss_ce: 0.020764
2021-12-13 00:00:41,778 iteration 2285 : loss : 0.027473, loss_ce: 0.011669
2021-12-13 00:00:43,200 iteration 2286 : loss : 0.050748, loss_ce: 0.025644
2021-12-13 00:00:44,644 iteration 2287 : loss : 0.023880, loss_ce: 0.006393
2021-12-13 00:00:46,086 iteration 2288 : loss : 0.044009, loss_ce: 0.017983
2021-12-13 00:00:47,554 iteration 2289 : loss : 0.031738, loss_ce: 0.012677
2021-12-13 00:00:49,007 iteration 2290 : loss : 0.031061, loss_ce: 0.012710
2021-12-13 00:00:50,551 iteration 2291 : loss : 0.040268, loss_ce: 0.014850
2021-12-13 00:00:52,045 iteration 2292 : loss : 0.034627, loss_ce: 0.014668
2021-12-13 00:00:53,517 iteration 2293 : loss : 0.037761, loss_ce: 0.013893
2021-12-13 00:00:54,959 iteration 2294 : loss : 0.030600, loss_ce: 0.014445
2021-12-13 00:00:54,959 Training Data Eval:
2021-12-13 00:01:02,469   Average segmentation loss on training set: 0.0379
2021-12-13 00:01:02,470 Validation Data Eval:
2021-12-13 00:01:05,072   Average segmentation loss on validation set: 0.0924
2021-12-13 00:01:06,556 iteration 2295 : loss : 0.037216, loss_ce: 0.012249
 34%|█████████                  | 135/400 [1:01:24<2:05:54, 28.51s/it]2021-12-13 00:01:08,008 iteration 2296 : loss : 0.026158, loss_ce: 0.010772
2021-12-13 00:01:09,523 iteration 2297 : loss : 0.026971, loss_ce: 0.010355
2021-12-13 00:01:10,994 iteration 2298 : loss : 0.033126, loss_ce: 0.012703
2021-12-13 00:01:12,493 iteration 2299 : loss : 0.041593, loss_ce: 0.013171
2021-12-13 00:01:13,925 iteration 2300 : loss : 0.024336, loss_ce: 0.009906
2021-12-13 00:01:15,383 iteration 2301 : loss : 0.028032, loss_ce: 0.011459
2021-12-13 00:01:16,881 iteration 2302 : loss : 0.033809, loss_ce: 0.014071
2021-12-13 00:01:18,383 iteration 2303 : loss : 0.039035, loss_ce: 0.012522
2021-12-13 00:01:19,878 iteration 2304 : loss : 0.037225, loss_ce: 0.013594
2021-12-13 00:01:21,323 iteration 2305 : loss : 0.029182, loss_ce: 0.013958
2021-12-13 00:01:22,757 iteration 2306 : loss : 0.032368, loss_ce: 0.013034
2021-12-13 00:01:24,286 iteration 2307 : loss : 0.030747, loss_ce: 0.011456
2021-12-13 00:01:25,721 iteration 2308 : loss : 0.028840, loss_ce: 0.011561
2021-12-13 00:01:27,240 iteration 2309 : loss : 0.029947, loss_ce: 0.012410
2021-12-13 00:01:28,726 iteration 2310 : loss : 0.035441, loss_ce: 0.015640
2021-12-13 00:01:30,136 iteration 2311 : loss : 0.027539, loss_ce: 0.011400
2021-12-13 00:01:31,523 iteration 2312 : loss : 0.033758, loss_ce: 0.012161
 34%|█████████▏                 | 136/400 [1:01:49<2:00:46, 27.45s/it]2021-12-13 00:01:33,006 iteration 2313 : loss : 0.040749, loss_ce: 0.015770
2021-12-13 00:01:34,483 iteration 2314 : loss : 0.026405, loss_ce: 0.008522
2021-12-13 00:01:36,022 iteration 2315 : loss : 0.045618, loss_ce: 0.013747
2021-12-13 00:01:37,412 iteration 2316 : loss : 0.030949, loss_ce: 0.011517
2021-12-13 00:01:38,947 iteration 2317 : loss : 0.032301, loss_ce: 0.008306
2021-12-13 00:01:40,420 iteration 2318 : loss : 0.033545, loss_ce: 0.013600
2021-12-13 00:01:41,882 iteration 2319 : loss : 0.031302, loss_ce: 0.013311
2021-12-13 00:01:43,391 iteration 2320 : loss : 0.038105, loss_ce: 0.017383
2021-12-13 00:01:44,802 iteration 2321 : loss : 0.031381, loss_ce: 0.008710
2021-12-13 00:01:46,255 iteration 2322 : loss : 0.032444, loss_ce: 0.014892
2021-12-13 00:01:47,704 iteration 2323 : loss : 0.028785, loss_ce: 0.014099
2021-12-13 00:01:49,183 iteration 2324 : loss : 0.029394, loss_ce: 0.009533
2021-12-13 00:01:50,620 iteration 2325 : loss : 0.024754, loss_ce: 0.009397
2021-12-13 00:01:52,086 iteration 2326 : loss : 0.027512, loss_ce: 0.012652
2021-12-13 00:01:53,525 iteration 2327 : loss : 0.025590, loss_ce: 0.010684
2021-12-13 00:01:55,023 iteration 2328 : loss : 0.039063, loss_ce: 0.018911
2021-12-13 00:01:56,461 iteration 2329 : loss : 0.024199, loss_ce: 0.009798
 34%|█████████▏                 | 137/400 [1:02:14<1:57:00, 26.69s/it]2021-12-13 00:01:57,946 iteration 2330 : loss : 0.026238, loss_ce: 0.010369
2021-12-13 00:01:59,398 iteration 2331 : loss : 0.032666, loss_ce: 0.014315
2021-12-13 00:02:00,899 iteration 2332 : loss : 0.036592, loss_ce: 0.014600
2021-12-13 00:02:02,406 iteration 2333 : loss : 0.024346, loss_ce: 0.011245
2021-12-13 00:02:03,843 iteration 2334 : loss : 0.029711, loss_ce: 0.013977
2021-12-13 00:02:05,309 iteration 2335 : loss : 0.031731, loss_ce: 0.009928
2021-12-13 00:02:06,832 iteration 2336 : loss : 0.058936, loss_ce: 0.016680
2021-12-13 00:02:08,323 iteration 2337 : loss : 0.027112, loss_ce: 0.013006
2021-12-13 00:02:09,763 iteration 2338 : loss : 0.026477, loss_ce: 0.010265
2021-12-13 00:02:11,245 iteration 2339 : loss : 0.028699, loss_ce: 0.009567
2021-12-13 00:02:12,760 iteration 2340 : loss : 0.036529, loss_ce: 0.015925
2021-12-13 00:02:14,151 iteration 2341 : loss : 0.019137, loss_ce: 0.004709
2021-12-13 00:02:15,603 iteration 2342 : loss : 0.024922, loss_ce: 0.010486
2021-12-13 00:02:17,124 iteration 2343 : loss : 0.040607, loss_ce: 0.016125
2021-12-13 00:02:18,624 iteration 2344 : loss : 0.032667, loss_ce: 0.014849
2021-12-13 00:02:20,151 iteration 2345 : loss : 0.030519, loss_ce: 0.011119
2021-12-13 00:02:21,624 iteration 2346 : loss : 0.027498, loss_ce: 0.012209
 34%|█████████▎                 | 138/400 [1:02:39<1:54:33, 26.23s/it]2021-12-13 00:02:23,138 iteration 2347 : loss : 0.030199, loss_ce: 0.010536
2021-12-13 00:02:24,581 iteration 2348 : loss : 0.042182, loss_ce: 0.015426
2021-12-13 00:02:26,099 iteration 2349 : loss : 0.032890, loss_ce: 0.014583
2021-12-13 00:02:27,549 iteration 2350 : loss : 0.038847, loss_ce: 0.013978
2021-12-13 00:02:29,036 iteration 2351 : loss : 0.065433, loss_ce: 0.013960
2021-12-13 00:02:30,520 iteration 2352 : loss : 0.022714, loss_ce: 0.007198
2021-12-13 00:02:32,038 iteration 2353 : loss : 0.031744, loss_ce: 0.012611
2021-12-13 00:02:33,559 iteration 2354 : loss : 0.032978, loss_ce: 0.013786
2021-12-13 00:02:34,950 iteration 2355 : loss : 0.029354, loss_ce: 0.010919
2021-12-13 00:02:36,415 iteration 2356 : loss : 0.039495, loss_ce: 0.018210
2021-12-13 00:02:37,876 iteration 2357 : loss : 0.042083, loss_ce: 0.014401
2021-12-13 00:02:39,354 iteration 2358 : loss : 0.026287, loss_ce: 0.011177
2021-12-13 00:02:40,914 iteration 2359 : loss : 0.029835, loss_ce: 0.011147
2021-12-13 00:02:42,338 iteration 2360 : loss : 0.023338, loss_ce: 0.009572
2021-12-13 00:02:43,828 iteration 2361 : loss : 0.035649, loss_ce: 0.013322
2021-12-13 00:02:45,395 iteration 2362 : loss : 0.054300, loss_ce: 0.022603
2021-12-13 00:02:46,813 iteration 2363 : loss : 0.026798, loss_ce: 0.012888
 35%|█████████▍                 | 139/400 [1:03:04<1:52:45, 25.92s/it]2021-12-13 00:02:48,250 iteration 2364 : loss : 0.045139, loss_ce: 0.009081
2021-12-13 00:02:49,684 iteration 2365 : loss : 0.052193, loss_ce: 0.015784
2021-12-13 00:02:51,167 iteration 2366 : loss : 0.034906, loss_ce: 0.013924
2021-12-13 00:02:52,611 iteration 2367 : loss : 0.046254, loss_ce: 0.021977
2021-12-13 00:02:54,041 iteration 2368 : loss : 0.042887, loss_ce: 0.020520
2021-12-13 00:02:55,505 iteration 2369 : loss : 0.048375, loss_ce: 0.023945
2021-12-13 00:02:56,880 iteration 2370 : loss : 0.027060, loss_ce: 0.009609
2021-12-13 00:02:58,392 iteration 2371 : loss : 0.032390, loss_ce: 0.012627
2021-12-13 00:02:59,842 iteration 2372 : loss : 0.031625, loss_ce: 0.013296
2021-12-13 00:03:01,253 iteration 2373 : loss : 0.031890, loss_ce: 0.012585
2021-12-13 00:03:02,686 iteration 2374 : loss : 0.033078, loss_ce: 0.012012
2021-12-13 00:03:04,174 iteration 2375 : loss : 0.044637, loss_ce: 0.014750
2021-12-13 00:03:05,668 iteration 2376 : loss : 0.032447, loss_ce: 0.012797
2021-12-13 00:03:07,117 iteration 2377 : loss : 0.035140, loss_ce: 0.014865
2021-12-13 00:03:08,573 iteration 2378 : loss : 0.022249, loss_ce: 0.007955
2021-12-13 00:03:10,036 iteration 2379 : loss : 0.037646, loss_ce: 0.020351
2021-12-13 00:03:10,036 Training Data Eval:
2021-12-13 00:03:17,523   Average segmentation loss on training set: 0.0250
2021-12-13 00:03:17,523 Validation Data Eval:
2021-12-13 00:03:20,120   Average segmentation loss on validation set: 0.1087
2021-12-13 00:03:21,555 iteration 2380 : loss : 0.024575, loss_ce: 0.010394
 35%|█████████▍                 | 140/400 [1:03:39<2:03:47, 28.57s/it]2021-12-13 00:03:23,155 iteration 2381 : loss : 0.038306, loss_ce: 0.010365
2021-12-13 00:03:24,633 iteration 2382 : loss : 0.034675, loss_ce: 0.012738
2021-12-13 00:03:26,080 iteration 2383 : loss : 0.029910, loss_ce: 0.011768
2021-12-13 00:03:27,488 iteration 2384 : loss : 0.028979, loss_ce: 0.009484
2021-12-13 00:03:28,941 iteration 2385 : loss : 0.031751, loss_ce: 0.010089
2021-12-13 00:03:30,442 iteration 2386 : loss : 0.038680, loss_ce: 0.010833
2021-12-13 00:03:31,958 iteration 2387 : loss : 0.027030, loss_ce: 0.010075
2021-12-13 00:03:33,433 iteration 2388 : loss : 0.027821, loss_ce: 0.012976
2021-12-13 00:03:34,895 iteration 2389 : loss : 0.025475, loss_ce: 0.008328
2021-12-13 00:03:36,325 iteration 2390 : loss : 0.028828, loss_ce: 0.014051
2021-12-13 00:03:37,733 iteration 2391 : loss : 0.030425, loss_ce: 0.010904
2021-12-13 00:03:39,313 iteration 2392 : loss : 0.031744, loss_ce: 0.007177
2021-12-13 00:03:40,815 iteration 2393 : loss : 0.034910, loss_ce: 0.011872
2021-12-13 00:03:42,275 iteration 2394 : loss : 0.042650, loss_ce: 0.018863
2021-12-13 00:03:43,804 iteration 2395 : loss : 0.040829, loss_ce: 0.020104
2021-12-13 00:03:45,227 iteration 2396 : loss : 0.028318, loss_ce: 0.011582
2021-12-13 00:03:46,742 iteration 2397 : loss : 0.038235, loss_ce: 0.020410
 35%|█████████▌                 | 141/400 [1:04:04<1:58:56, 27.55s/it]2021-12-13 00:03:48,200 iteration 2398 : loss : 0.032869, loss_ce: 0.017256
2021-12-13 00:03:49,749 iteration 2399 : loss : 0.032271, loss_ce: 0.012824
2021-12-13 00:03:51,210 iteration 2400 : loss : 0.033297, loss_ce: 0.013356
2021-12-13 00:03:52,795 iteration 2401 : loss : 0.051673, loss_ce: 0.018545
2021-12-13 00:03:54,247 iteration 2402 : loss : 0.044105, loss_ce: 0.016649
2021-12-13 00:03:55,696 iteration 2403 : loss : 0.028390, loss_ce: 0.010291
2021-12-13 00:03:57,136 iteration 2404 : loss : 0.026871, loss_ce: 0.009546
2021-12-13 00:03:58,651 iteration 2405 : loss : 0.035492, loss_ce: 0.011354
2021-12-13 00:04:00,048 iteration 2406 : loss : 0.036582, loss_ce: 0.016715
2021-12-13 00:04:01,482 iteration 2407 : loss : 0.032333, loss_ce: 0.010941
2021-12-13 00:04:03,073 iteration 2408 : loss : 0.044948, loss_ce: 0.015538
2021-12-13 00:04:04,496 iteration 2409 : loss : 0.032193, loss_ce: 0.012763
2021-12-13 00:04:05,937 iteration 2410 : loss : 0.041801, loss_ce: 0.015915
2021-12-13 00:04:07,380 iteration 2411 : loss : 0.029593, loss_ce: 0.011893
2021-12-13 00:04:08,832 iteration 2412 : loss : 0.033173, loss_ce: 0.013787
2021-12-13 00:04:10,253 iteration 2413 : loss : 0.029997, loss_ce: 0.011121
2021-12-13 00:04:11,670 iteration 2414 : loss : 0.027050, loss_ce: 0.011140
 36%|█████████▌                 | 142/400 [1:04:29<1:55:05, 26.76s/it]2021-12-13 00:04:13,210 iteration 2415 : loss : 0.030833, loss_ce: 0.010569
2021-12-13 00:04:14,625 iteration 2416 : loss : 0.029393, loss_ce: 0.011558
2021-12-13 00:04:16,072 iteration 2417 : loss : 0.024913, loss_ce: 0.011937
2021-12-13 00:04:17,477 iteration 2418 : loss : 0.032527, loss_ce: 0.011533
2021-12-13 00:04:18,930 iteration 2419 : loss : 0.046502, loss_ce: 0.016198
2021-12-13 00:04:20,453 iteration 2420 : loss : 0.031579, loss_ce: 0.012752
2021-12-13 00:04:21,912 iteration 2421 : loss : 0.027219, loss_ce: 0.011752
2021-12-13 00:04:23,371 iteration 2422 : loss : 0.027927, loss_ce: 0.012145
2021-12-13 00:04:24,766 iteration 2423 : loss : 0.032677, loss_ce: 0.016154
2021-12-13 00:04:26,245 iteration 2424 : loss : 0.033991, loss_ce: 0.018029
2021-12-13 00:04:27,740 iteration 2425 : loss : 0.049372, loss_ce: 0.014046
2021-12-13 00:04:29,183 iteration 2426 : loss : 0.035481, loss_ce: 0.012198
2021-12-13 00:04:30,587 iteration 2427 : loss : 0.028387, loss_ce: 0.013732
2021-12-13 00:04:32,030 iteration 2428 : loss : 0.027537, loss_ce: 0.008515
2021-12-13 00:04:33,455 iteration 2429 : loss : 0.041796, loss_ce: 0.012436
2021-12-13 00:04:34,903 iteration 2430 : loss : 0.034287, loss_ce: 0.014831
2021-12-13 00:04:36,378 iteration 2431 : loss : 0.026650, loss_ce: 0.009888
 36%|█████████▋                 | 143/400 [1:04:54<1:52:00, 26.15s/it]2021-12-13 00:04:37,819 iteration 2432 : loss : 0.025112, loss_ce: 0.008538
2021-12-13 00:04:39,268 iteration 2433 : loss : 0.028511, loss_ce: 0.011528
2021-12-13 00:04:40,760 iteration 2434 : loss : 0.029307, loss_ce: 0.011280
2021-12-13 00:04:42,206 iteration 2435 : loss : 0.021879, loss_ce: 0.008870
2021-12-13 00:04:43,709 iteration 2436 : loss : 0.022145, loss_ce: 0.008502
2021-12-13 00:04:45,149 iteration 2437 : loss : 0.022981, loss_ce: 0.009187
2021-12-13 00:04:46,543 iteration 2438 : loss : 0.020829, loss_ce: 0.008773
2021-12-13 00:04:47,992 iteration 2439 : loss : 0.027419, loss_ce: 0.009201
2021-12-13 00:04:49,446 iteration 2440 : loss : 0.030271, loss_ce: 0.010396
2021-12-13 00:04:51,011 iteration 2441 : loss : 0.038545, loss_ce: 0.010727
2021-12-13 00:04:52,499 iteration 2442 : loss : 0.028387, loss_ce: 0.009696
2021-12-13 00:04:53,996 iteration 2443 : loss : 0.026652, loss_ce: 0.010787
2021-12-13 00:04:55,509 iteration 2444 : loss : 0.038109, loss_ce: 0.013430
2021-12-13 00:04:57,074 iteration 2445 : loss : 0.028864, loss_ce: 0.011920
2021-12-13 00:04:58,521 iteration 2446 : loss : 0.026785, loss_ce: 0.011079
2021-12-13 00:05:00,055 iteration 2447 : loss : 0.032499, loss_ce: 0.011428
2021-12-13 00:05:01,468 iteration 2448 : loss : 0.035502, loss_ce: 0.020224
 36%|█████████▋                 | 144/400 [1:05:19<1:50:12, 25.83s/it]2021-12-13 00:05:02,977 iteration 2449 : loss : 0.022015, loss_ce: 0.006887
2021-12-13 00:05:04,384 iteration 2450 : loss : 0.030083, loss_ce: 0.010411
2021-12-13 00:05:05,805 iteration 2451 : loss : 0.023517, loss_ce: 0.007938
2021-12-13 00:05:07,252 iteration 2452 : loss : 0.028654, loss_ce: 0.012293
2021-12-13 00:05:08,694 iteration 2453 : loss : 0.049646, loss_ce: 0.022208
2021-12-13 00:05:10,122 iteration 2454 : loss : 0.047282, loss_ce: 0.015228
2021-12-13 00:05:11,676 iteration 2455 : loss : 0.034285, loss_ce: 0.011965
2021-12-13 00:05:13,159 iteration 2456 : loss : 0.022459, loss_ce: 0.009966
2021-12-13 00:05:14,585 iteration 2457 : loss : 0.025387, loss_ce: 0.013061
2021-12-13 00:05:16,077 iteration 2458 : loss : 0.038667, loss_ce: 0.013057
2021-12-13 00:05:17,527 iteration 2459 : loss : 0.032586, loss_ce: 0.011330
2021-12-13 00:05:19,050 iteration 2460 : loss : 0.040855, loss_ce: 0.011199
2021-12-13 00:05:20,540 iteration 2461 : loss : 0.038196, loss_ce: 0.010327
2021-12-13 00:05:22,098 iteration 2462 : loss : 0.031583, loss_ce: 0.012657
2021-12-13 00:05:23,543 iteration 2463 : loss : 0.027442, loss_ce: 0.009323
2021-12-13 00:05:25,029 iteration 2464 : loss : 0.034129, loss_ce: 0.019110
2021-12-13 00:05:25,029 Training Data Eval:
2021-12-13 00:05:32,526   Average segmentation loss on training set: 0.0446
2021-12-13 00:05:32,527 Validation Data Eval:
2021-12-13 00:05:35,131   Average segmentation loss on validation set: 0.0970
2021-12-13 00:05:36,619 iteration 2465 : loss : 0.028117, loss_ce: 0.010980
 36%|█████████▊                 | 145/400 [1:05:54<2:01:39, 28.63s/it]2021-12-13 00:05:38,175 iteration 2466 : loss : 0.025124, loss_ce: 0.009360
2021-12-13 00:05:39,626 iteration 2467 : loss : 0.021776, loss_ce: 0.007897
2021-12-13 00:05:41,165 iteration 2468 : loss : 0.031849, loss_ce: 0.010822
2021-12-13 00:05:42,589 iteration 2469 : loss : 0.029764, loss_ce: 0.013920
2021-12-13 00:05:44,092 iteration 2470 : loss : 0.033544, loss_ce: 0.011999
2021-12-13 00:05:45,580 iteration 2471 : loss : 0.034438, loss_ce: 0.017501
2021-12-13 00:05:47,077 iteration 2472 : loss : 0.023299, loss_ce: 0.007823
2021-12-13 00:05:48,543 iteration 2473 : loss : 0.028736, loss_ce: 0.010649
2021-12-13 00:05:49,920 iteration 2474 : loss : 0.021854, loss_ce: 0.008503
2021-12-13 00:05:51,422 iteration 2475 : loss : 0.030575, loss_ce: 0.018576
2021-12-13 00:05:52,907 iteration 2476 : loss : 0.037871, loss_ce: 0.010377
2021-12-13 00:05:54,371 iteration 2477 : loss : 0.033725, loss_ce: 0.015051
2021-12-13 00:05:55,811 iteration 2478 : loss : 0.028185, loss_ce: 0.009161
2021-12-13 00:05:57,319 iteration 2479 : loss : 0.034690, loss_ce: 0.010819
2021-12-13 00:05:58,778 iteration 2480 : loss : 0.021273, loss_ce: 0.007322
2021-12-13 00:06:00,225 iteration 2481 : loss : 0.024272, loss_ce: 0.009272
2021-12-13 00:06:01,809 iteration 2482 : loss : 0.050234, loss_ce: 0.014638
 36%|█████████▊                 | 146/400 [1:06:19<1:56:49, 27.60s/it]2021-12-13 00:06:03,307 iteration 2483 : loss : 0.028851, loss_ce: 0.012294
2021-12-13 00:06:04,800 iteration 2484 : loss : 0.042650, loss_ce: 0.011663
2021-12-13 00:06:06,271 iteration 2485 : loss : 0.042233, loss_ce: 0.012234
2021-12-13 00:06:07,746 iteration 2486 : loss : 0.030015, loss_ce: 0.011419
2021-12-13 00:06:09,173 iteration 2487 : loss : 0.021097, loss_ce: 0.008589
2021-12-13 00:06:10,709 iteration 2488 : loss : 0.048537, loss_ce: 0.025709
2021-12-13 00:06:12,193 iteration 2489 : loss : 0.034744, loss_ce: 0.014801
2021-12-13 00:06:13,710 iteration 2490 : loss : 0.037243, loss_ce: 0.016583
2021-12-13 00:06:15,192 iteration 2491 : loss : 0.029214, loss_ce: 0.009227
2021-12-13 00:06:16,677 iteration 2492 : loss : 0.028342, loss_ce: 0.011531
2021-12-13 00:06:18,084 iteration 2493 : loss : 0.032485, loss_ce: 0.010475
2021-12-13 00:06:19,539 iteration 2494 : loss : 0.024502, loss_ce: 0.009163
2021-12-13 00:06:21,082 iteration 2495 : loss : 0.024798, loss_ce: 0.011084
2021-12-13 00:06:22,446 iteration 2496 : loss : 0.018557, loss_ce: 0.007103
2021-12-13 00:06:23,864 iteration 2497 : loss : 0.022082, loss_ce: 0.007662
2021-12-13 00:06:25,445 iteration 2498 : loss : 0.033053, loss_ce: 0.013344
2021-12-13 00:06:26,904 iteration 2499 : loss : 0.027618, loss_ce: 0.013580
 37%|█████████▉                 | 147/400 [1:06:45<1:53:12, 26.85s/it]2021-12-13 00:06:28,424 iteration 2500 : loss : 0.027389, loss_ce: 0.010397
2021-12-13 00:06:29,929 iteration 2501 : loss : 0.022039, loss_ce: 0.008450
2021-12-13 00:06:31,416 iteration 2502 : loss : 0.028536, loss_ce: 0.012696
2021-12-13 00:06:32,843 iteration 2503 : loss : 0.020745, loss_ce: 0.008423
2021-12-13 00:06:34,318 iteration 2504 : loss : 0.027895, loss_ce: 0.009993
2021-12-13 00:06:35,774 iteration 2505 : loss : 0.021978, loss_ce: 0.006505
2021-12-13 00:06:37,244 iteration 2506 : loss : 0.022254, loss_ce: 0.010734
2021-12-13 00:06:38,672 iteration 2507 : loss : 0.017600, loss_ce: 0.006580
2021-12-13 00:06:40,069 iteration 2508 : loss : 0.025065, loss_ce: 0.010381
2021-12-13 00:06:41,513 iteration 2509 : loss : 0.024603, loss_ce: 0.011619
2021-12-13 00:06:42,910 iteration 2510 : loss : 0.033516, loss_ce: 0.009444
2021-12-13 00:06:44,350 iteration 2511 : loss : 0.022741, loss_ce: 0.009517
2021-12-13 00:06:45,782 iteration 2512 : loss : 0.021031, loss_ce: 0.007215
2021-12-13 00:06:47,232 iteration 2513 : loss : 0.025884, loss_ce: 0.009678
2021-12-13 00:06:48,717 iteration 2514 : loss : 0.029533, loss_ce: 0.012066
2021-12-13 00:06:50,172 iteration 2515 : loss : 0.032600, loss_ce: 0.013090
2021-12-13 00:06:51,603 iteration 2516 : loss : 0.034495, loss_ce: 0.015450
 37%|█████████▉                 | 148/400 [1:07:09<1:50:02, 26.20s/it]2021-12-13 00:06:53,096 iteration 2517 : loss : 0.031008, loss_ce: 0.011783
2021-12-13 00:06:54,658 iteration 2518 : loss : 0.030083, loss_ce: 0.013625
2021-12-13 00:06:56,126 iteration 2519 : loss : 0.028618, loss_ce: 0.010585
2021-12-13 00:06:57,566 iteration 2520 : loss : 0.024823, loss_ce: 0.007453
2021-12-13 00:06:59,045 iteration 2521 : loss : 0.022173, loss_ce: 0.010845
2021-12-13 00:07:00,430 iteration 2522 : loss : 0.021878, loss_ce: 0.007407
2021-12-13 00:07:01,781 iteration 2523 : loss : 0.036174, loss_ce: 0.009737
2021-12-13 00:07:03,284 iteration 2524 : loss : 0.024251, loss_ce: 0.011489
2021-12-13 00:07:04,714 iteration 2525 : loss : 0.024570, loss_ce: 0.010385
2021-12-13 00:07:06,149 iteration 2526 : loss : 0.026030, loss_ce: 0.009417
2021-12-13 00:07:07,667 iteration 2527 : loss : 0.035815, loss_ce: 0.017660
2021-12-13 00:07:09,096 iteration 2528 : loss : 0.027290, loss_ce: 0.010753
2021-12-13 00:07:10,579 iteration 2529 : loss : 0.033443, loss_ce: 0.015451
2021-12-13 00:07:12,051 iteration 2530 : loss : 0.023212, loss_ce: 0.007012
2021-12-13 00:07:13,510 iteration 2531 : loss : 0.030936, loss_ce: 0.010243
2021-12-13 00:07:15,004 iteration 2532 : loss : 0.046124, loss_ce: 0.017217
2021-12-13 00:07:16,472 iteration 2533 : loss : 0.030698, loss_ce: 0.018296
 37%|██████████                 | 149/400 [1:07:34<1:47:56, 25.80s/it]2021-12-13 00:07:17,913 iteration 2534 : loss : 0.021667, loss_ce: 0.009962
2021-12-13 00:07:19,398 iteration 2535 : loss : 0.021627, loss_ce: 0.006615
2021-12-13 00:07:20,920 iteration 2536 : loss : 0.027213, loss_ce: 0.011366
2021-12-13 00:07:22,435 iteration 2537 : loss : 0.043437, loss_ce: 0.015860
2021-12-13 00:07:23,958 iteration 2538 : loss : 0.034224, loss_ce: 0.012598
2021-12-13 00:07:25,373 iteration 2539 : loss : 0.025530, loss_ce: 0.011146
2021-12-13 00:07:26,839 iteration 2540 : loss : 0.026500, loss_ce: 0.010045
2021-12-13 00:07:28,422 iteration 2541 : loss : 0.042670, loss_ce: 0.012392
2021-12-13 00:07:29,823 iteration 2542 : loss : 0.026175, loss_ce: 0.009867
2021-12-13 00:07:31,289 iteration 2543 : loss : 0.023215, loss_ce: 0.007840
2021-12-13 00:07:32,811 iteration 2544 : loss : 0.051535, loss_ce: 0.019869
2021-12-13 00:07:34,297 iteration 2545 : loss : 0.032695, loss_ce: 0.015635
2021-12-13 00:07:35,693 iteration 2546 : loss : 0.023131, loss_ce: 0.009593
2021-12-13 00:07:37,157 iteration 2547 : loss : 0.028810, loss_ce: 0.005976
2021-12-13 00:07:38,614 iteration 2548 : loss : 0.026348, loss_ce: 0.009798
2021-12-13 00:07:40,122 iteration 2549 : loss : 0.053096, loss_ce: 0.018039
2021-12-13 00:07:40,123 Training Data Eval:
2021-12-13 00:07:47,650   Average segmentation loss on training set: 0.0204
2021-12-13 00:07:47,651 Validation Data Eval:
2021-12-13 00:07:50,249   Average segmentation loss on validation set: 0.0887
2021-12-13 00:07:51,700 iteration 2550 : loss : 0.030621, loss_ce: 0.016247
 38%|██████████▏                | 150/400 [1:08:09<1:59:17, 28.63s/it]2021-12-13 00:07:53,166 iteration 2551 : loss : 0.020342, loss_ce: 0.007335
2021-12-13 00:07:54,616 iteration 2552 : loss : 0.028606, loss_ce: 0.013833
2021-12-13 00:07:56,134 iteration 2553 : loss : 0.028425, loss_ce: 0.010918
2021-12-13 00:07:57,625 iteration 2554 : loss : 0.058850, loss_ce: 0.011469
2021-12-13 00:07:59,056 iteration 2555 : loss : 0.028048, loss_ce: 0.008059
2021-12-13 00:08:00,444 iteration 2556 : loss : 0.022682, loss_ce: 0.010333
2021-12-13 00:08:01,949 iteration 2557 : loss : 0.042327, loss_ce: 0.019454
2021-12-13 00:08:03,451 iteration 2558 : loss : 0.022883, loss_ce: 0.009916
2021-12-13 00:08:04,959 iteration 2559 : loss : 0.063978, loss_ce: 0.015434
2021-12-13 00:08:06,443 iteration 2560 : loss : 0.030113, loss_ce: 0.012942
2021-12-13 00:08:07,879 iteration 2561 : loss : 0.032367, loss_ce: 0.013528
2021-12-13 00:08:09,285 iteration 2562 : loss : 0.033988, loss_ce: 0.019413
2021-12-13 00:08:10,728 iteration 2563 : loss : 0.028834, loss_ce: 0.010460
2021-12-13 00:08:12,186 iteration 2564 : loss : 0.034128, loss_ce: 0.014977
2021-12-13 00:08:13,642 iteration 2565 : loss : 0.024903, loss_ce: 0.007322
2021-12-13 00:08:15,090 iteration 2566 : loss : 0.022136, loss_ce: 0.010488
2021-12-13 00:08:16,632 iteration 2567 : loss : 0.033378, loss_ce: 0.013351
 38%|██████████▏                | 151/400 [1:08:34<1:54:13, 27.52s/it]2021-12-13 00:08:18,118 iteration 2568 : loss : 0.023370, loss_ce: 0.010965
2021-12-13 00:08:19,568 iteration 2569 : loss : 0.034262, loss_ce: 0.013022
2021-12-13 00:08:20,992 iteration 2570 : loss : 0.041053, loss_ce: 0.011784
2021-12-13 00:08:22,445 iteration 2571 : loss : 0.038286, loss_ce: 0.014908
2021-12-13 00:08:23,845 iteration 2572 : loss : 0.023239, loss_ce: 0.007573
2021-12-13 00:08:25,276 iteration 2573 : loss : 0.021939, loss_ce: 0.008358
2021-12-13 00:08:26,730 iteration 2574 : loss : 0.033454, loss_ce: 0.010195
2021-12-13 00:08:28,220 iteration 2575 : loss : 0.031621, loss_ce: 0.010472
2021-12-13 00:08:29,781 iteration 2576 : loss : 0.028599, loss_ce: 0.012165
2021-12-13 00:08:31,211 iteration 2577 : loss : 0.031202, loss_ce: 0.010474
2021-12-13 00:08:32,685 iteration 2578 : loss : 0.025501, loss_ce: 0.012358
2021-12-13 00:08:34,113 iteration 2579 : loss : 0.025894, loss_ce: 0.009877
2021-12-13 00:08:35,599 iteration 2580 : loss : 0.025735, loss_ce: 0.008750
2021-12-13 00:08:37,158 iteration 2581 : loss : 0.027683, loss_ce: 0.010942
2021-12-13 00:08:38,525 iteration 2582 : loss : 0.028771, loss_ce: 0.011635
2021-12-13 00:08:40,020 iteration 2583 : loss : 0.024142, loss_ce: 0.007743
2021-12-13 00:08:41,451 iteration 2584 : loss : 0.023993, loss_ce: 0.009072
 38%|██████████▎                | 152/400 [1:08:59<1:50:23, 26.71s/it]2021-12-13 00:08:42,984 iteration 2585 : loss : 0.035763, loss_ce: 0.015199
2021-12-13 00:08:44,450 iteration 2586 : loss : 0.026161, loss_ce: 0.010770
2021-12-13 00:08:45,864 iteration 2587 : loss : 0.020946, loss_ce: 0.007555
2021-12-13 00:08:47,304 iteration 2588 : loss : 0.025804, loss_ce: 0.011478
2021-12-13 00:08:48,700 iteration 2589 : loss : 0.025800, loss_ce: 0.011564
2021-12-13 00:08:50,202 iteration 2590 : loss : 0.026967, loss_ce: 0.009639
2021-12-13 00:08:51,661 iteration 2591 : loss : 0.032851, loss_ce: 0.015476
2021-12-13 00:08:53,108 iteration 2592 : loss : 0.020935, loss_ce: 0.008282
2021-12-13 00:08:54,526 iteration 2593 : loss : 0.032456, loss_ce: 0.013517
2021-12-13 00:08:55,992 iteration 2594 : loss : 0.027530, loss_ce: 0.009630
2021-12-13 00:08:57,545 iteration 2595 : loss : 0.062192, loss_ce: 0.017601
2021-12-13 00:08:58,946 iteration 2596 : loss : 0.022020, loss_ce: 0.007305
2021-12-13 00:09:00,427 iteration 2597 : loss : 0.042139, loss_ce: 0.013304
2021-12-13 00:09:01,869 iteration 2598 : loss : 0.022368, loss_ce: 0.009429
2021-12-13 00:09:03,358 iteration 2599 : loss : 0.020947, loss_ce: 0.009420
2021-12-13 00:09:04,787 iteration 2600 : loss : 0.030225, loss_ce: 0.009421
2021-12-13 00:09:06,239 iteration 2601 : loss : 0.025915, loss_ce: 0.010087
 38%|██████████▎                | 153/400 [1:09:24<1:47:35, 26.13s/it]2021-12-13 00:09:07,750 iteration 2602 : loss : 0.021871, loss_ce: 0.006713
2021-12-13 00:09:09,295 iteration 2603 : loss : 0.029860, loss_ce: 0.010188
2021-12-13 00:09:10,753 iteration 2604 : loss : 0.028673, loss_ce: 0.012739
2021-12-13 00:09:12,106 iteration 2605 : loss : 0.020376, loss_ce: 0.006386
2021-12-13 00:09:13,702 iteration 2606 : loss : 0.051879, loss_ce: 0.017408
2021-12-13 00:09:15,199 iteration 2607 : loss : 0.026653, loss_ce: 0.009139
2021-12-13 00:09:16,658 iteration 2608 : loss : 0.022184, loss_ce: 0.010179
2021-12-13 00:09:18,194 iteration 2609 : loss : 0.033160, loss_ce: 0.012106
2021-12-13 00:09:19,688 iteration 2610 : loss : 0.028395, loss_ce: 0.010007
2021-12-13 00:09:21,151 iteration 2611 : loss : 0.030677, loss_ce: 0.013170
2021-12-13 00:09:22,647 iteration 2612 : loss : 0.037842, loss_ce: 0.019770
2021-12-13 00:09:24,055 iteration 2613 : loss : 0.022868, loss_ce: 0.009211
2021-12-13 00:09:25,574 iteration 2614 : loss : 0.033763, loss_ce: 0.010407
2021-12-13 00:09:27,011 iteration 2615 : loss : 0.038900, loss_ce: 0.011506
2021-12-13 00:09:28,526 iteration 2616 : loss : 0.026150, loss_ce: 0.012516
2021-12-13 00:09:29,978 iteration 2617 : loss : 0.022362, loss_ce: 0.006996
2021-12-13 00:09:31,392 iteration 2618 : loss : 0.024196, loss_ce: 0.009726
 38%|██████████▍                | 154/400 [1:09:49<1:45:56, 25.84s/it]2021-12-13 00:09:32,851 iteration 2619 : loss : 0.038721, loss_ce: 0.014106
2021-12-13 00:09:34,272 iteration 2620 : loss : 0.021066, loss_ce: 0.009667
2021-12-13 00:09:35,779 iteration 2621 : loss : 0.050644, loss_ce: 0.021222
2021-12-13 00:09:37,225 iteration 2622 : loss : 0.031646, loss_ce: 0.008235
2021-12-13 00:09:38,708 iteration 2623 : loss : 0.025647, loss_ce: 0.011023
2021-12-13 00:09:40,131 iteration 2624 : loss : 0.021672, loss_ce: 0.006976
2021-12-13 00:09:41,629 iteration 2625 : loss : 0.035936, loss_ce: 0.008972
2021-12-13 00:09:43,111 iteration 2626 : loss : 0.033757, loss_ce: 0.012222
2021-12-13 00:09:44,710 iteration 2627 : loss : 0.058426, loss_ce: 0.025481
2021-12-13 00:09:46,106 iteration 2628 : loss : 0.034200, loss_ce: 0.014684
2021-12-13 00:09:47,626 iteration 2629 : loss : 0.035466, loss_ce: 0.018237
2021-12-13 00:09:49,105 iteration 2630 : loss : 0.030555, loss_ce: 0.011896
2021-12-13 00:09:50,568 iteration 2631 : loss : 0.022466, loss_ce: 0.008543
2021-12-13 00:09:52,024 iteration 2632 : loss : 0.022215, loss_ce: 0.007588
2021-12-13 00:09:53,517 iteration 2633 : loss : 0.030396, loss_ce: 0.014217
2021-12-13 00:09:54,985 iteration 2634 : loss : 0.033041, loss_ce: 0.010757
2021-12-13 00:09:54,985 Training Data Eval:
2021-12-13 00:10:02,477   Average segmentation loss on training set: 0.0390
2021-12-13 00:10:02,478 Validation Data Eval:
2021-12-13 00:10:05,085   Average segmentation loss on validation set: 0.0775
2021-12-13 00:10:06,568 iteration 2635 : loss : 0.021289, loss_ce: 0.007758
 39%|██████████▍                | 155/400 [1:10:24<1:56:56, 28.64s/it]2021-12-13 00:10:08,073 iteration 2636 : loss : 0.032297, loss_ce: 0.014772
2021-12-13 00:10:09,606 iteration 2637 : loss : 0.036768, loss_ce: 0.012494
2021-12-13 00:10:11,042 iteration 2638 : loss : 0.037423, loss_ce: 0.012506
2021-12-13 00:10:12,458 iteration 2639 : loss : 0.024631, loss_ce: 0.011468
2021-12-13 00:10:13,885 iteration 2640 : loss : 0.028959, loss_ce: 0.009755
2021-12-13 00:10:15,329 iteration 2641 : loss : 0.032819, loss_ce: 0.013275
2021-12-13 00:10:16,753 iteration 2642 : loss : 0.026906, loss_ce: 0.010753
2021-12-13 00:10:18,311 iteration 2643 : loss : 0.026605, loss_ce: 0.009926
2021-12-13 00:10:19,741 iteration 2644 : loss : 0.021670, loss_ce: 0.007469
2021-12-13 00:10:21,155 iteration 2645 : loss : 0.024550, loss_ce: 0.007820
2021-12-13 00:10:22,772 iteration 2646 : loss : 0.026705, loss_ce: 0.009621
2021-12-13 00:10:24,281 iteration 2647 : loss : 0.042013, loss_ce: 0.020526
2021-12-13 00:10:25,711 iteration 2648 : loss : 0.027681, loss_ce: 0.011087
2021-12-13 00:10:27,180 iteration 2649 : loss : 0.030508, loss_ce: 0.013304
2021-12-13 00:10:28,692 iteration 2650 : loss : 0.030433, loss_ce: 0.011478
2021-12-13 00:10:30,172 iteration 2651 : loss : 0.032508, loss_ce: 0.014943
2021-12-13 00:10:31,573 iteration 2652 : loss : 0.021791, loss_ce: 0.008119
 39%|██████████▌                | 156/400 [1:10:49<1:52:02, 27.55s/it]2021-12-13 00:10:33,113 iteration 2653 : loss : 0.024950, loss_ce: 0.010872
2021-12-13 00:10:34,576 iteration 2654 : loss : 0.035359, loss_ce: 0.013698
2021-12-13 00:10:36,123 iteration 2655 : loss : 0.036319, loss_ce: 0.018572
2021-12-13 00:10:37,565 iteration 2656 : loss : 0.024965, loss_ce: 0.007921
2021-12-13 00:10:39,006 iteration 2657 : loss : 0.027959, loss_ce: 0.010842
2021-12-13 00:10:40,352 iteration 2658 : loss : 0.020657, loss_ce: 0.009918
2021-12-13 00:10:41,768 iteration 2659 : loss : 0.034286, loss_ce: 0.009188
2021-12-13 00:10:43,261 iteration 2660 : loss : 0.031086, loss_ce: 0.010250
2021-12-13 00:10:44,693 iteration 2661 : loss : 0.025259, loss_ce: 0.010430
2021-12-13 00:10:46,156 iteration 2662 : loss : 0.028046, loss_ce: 0.013029
2021-12-13 00:10:47,589 iteration 2663 : loss : 0.026968, loss_ce: 0.007656
2021-12-13 00:10:49,127 iteration 2664 : loss : 0.031450, loss_ce: 0.014988
2021-12-13 00:10:50,590 iteration 2665 : loss : 0.032536, loss_ce: 0.014928
2021-12-13 00:10:52,016 iteration 2666 : loss : 0.015778, loss_ce: 0.005182
2021-12-13 00:10:53,530 iteration 2667 : loss : 0.048411, loss_ce: 0.018490
2021-12-13 00:10:54,952 iteration 2668 : loss : 0.029039, loss_ce: 0.013108
2021-12-13 00:10:56,371 iteration 2669 : loss : 0.026805, loss_ce: 0.009781
 39%|██████████▌                | 157/400 [1:11:14<1:48:13, 26.72s/it]2021-12-13 00:10:57,879 iteration 2670 : loss : 0.025530, loss_ce: 0.012145
2021-12-13 00:10:59,421 iteration 2671 : loss : 0.053079, loss_ce: 0.015047
2021-12-13 00:11:00,897 iteration 2672 : loss : 0.023335, loss_ce: 0.008127
2021-12-13 00:11:02,315 iteration 2673 : loss : 0.023628, loss_ce: 0.012348
2021-12-13 00:11:03,819 iteration 2674 : loss : 0.035380, loss_ce: 0.016465
2021-12-13 00:11:05,178 iteration 2675 : loss : 0.020747, loss_ce: 0.009391
2021-12-13 00:11:06,734 iteration 2676 : loss : 0.065863, loss_ce: 0.028779
2021-12-13 00:11:08,220 iteration 2677 : loss : 0.030036, loss_ce: 0.011081
2021-12-13 00:11:09,671 iteration 2678 : loss : 0.023917, loss_ce: 0.009490
2021-12-13 00:11:11,131 iteration 2679 : loss : 0.029204, loss_ce: 0.009471
2021-12-13 00:11:12,582 iteration 2680 : loss : 0.021136, loss_ce: 0.007969
2021-12-13 00:11:14,050 iteration 2681 : loss : 0.030210, loss_ce: 0.009957
2021-12-13 00:11:15,515 iteration 2682 : loss : 0.027729, loss_ce: 0.010879
2021-12-13 00:11:16,955 iteration 2683 : loss : 0.031260, loss_ce: 0.008575
2021-12-13 00:11:18,365 iteration 2684 : loss : 0.029006, loss_ce: 0.014365
2021-12-13 00:11:19,852 iteration 2685 : loss : 0.022974, loss_ce: 0.009834
2021-12-13 00:11:21,286 iteration 2686 : loss : 0.034105, loss_ce: 0.016455
 40%|██████████▋                | 158/400 [1:11:39<1:45:36, 26.18s/it]2021-12-13 00:11:22,708 iteration 2687 : loss : 0.030870, loss_ce: 0.008254
2021-12-13 00:11:24,173 iteration 2688 : loss : 0.031404, loss_ce: 0.010190
2021-12-13 00:11:25,616 iteration 2689 : loss : 0.032323, loss_ce: 0.011369
2021-12-13 00:11:27,174 iteration 2690 : loss : 0.033967, loss_ce: 0.015087
2021-12-13 00:11:28,570 iteration 2691 : loss : 0.020414, loss_ce: 0.008097
2021-12-13 00:11:29,989 iteration 2692 : loss : 0.028100, loss_ce: 0.009342
2021-12-13 00:11:31,454 iteration 2693 : loss : 0.024150, loss_ce: 0.007893
2021-12-13 00:11:32,987 iteration 2694 : loss : 0.035700, loss_ce: 0.011982
2021-12-13 00:11:34,430 iteration 2695 : loss : 0.024955, loss_ce: 0.010328
2021-12-13 00:11:35,911 iteration 2696 : loss : 0.022698, loss_ce: 0.009291
2021-12-13 00:11:37,318 iteration 2697 : loss : 0.025703, loss_ce: 0.011838
2021-12-13 00:11:38,661 iteration 2698 : loss : 0.020122, loss_ce: 0.009341
2021-12-13 00:11:40,140 iteration 2699 : loss : 0.029717, loss_ce: 0.011488
2021-12-13 00:11:41,671 iteration 2700 : loss : 0.028062, loss_ce: 0.013323
2021-12-13 00:11:43,126 iteration 2701 : loss : 0.025751, loss_ce: 0.009010
2021-12-13 00:11:44,613 iteration 2702 : loss : 0.037786, loss_ce: 0.006706
2021-12-13 00:11:46,063 iteration 2703 : loss : 0.022602, loss_ce: 0.008171
 40%|██████████▋                | 159/400 [1:12:04<1:43:28, 25.76s/it]2021-12-13 00:11:47,661 iteration 2704 : loss : 0.032994, loss_ce: 0.014464
2021-12-13 00:11:49,068 iteration 2705 : loss : 0.027704, loss_ce: 0.007400
2021-12-13 00:11:50,479 iteration 2706 : loss : 0.020744, loss_ce: 0.011758
2021-12-13 00:11:52,016 iteration 2707 : loss : 0.044182, loss_ce: 0.011970
2021-12-13 00:11:53,403 iteration 2708 : loss : 0.018662, loss_ce: 0.007135
2021-12-13 00:11:54,872 iteration 2709 : loss : 0.029051, loss_ce: 0.008434
2021-12-13 00:11:56,277 iteration 2710 : loss : 0.028396, loss_ce: 0.009765
2021-12-13 00:11:57,827 iteration 2711 : loss : 0.051273, loss_ce: 0.019300
2021-12-13 00:11:59,228 iteration 2712 : loss : 0.023669, loss_ce: 0.008651
2021-12-13 00:12:00,784 iteration 2713 : loss : 0.034839, loss_ce: 0.010589
2021-12-13 00:12:02,180 iteration 2714 : loss : 0.024660, loss_ce: 0.008620
2021-12-13 00:12:03,658 iteration 2715 : loss : 0.028333, loss_ce: 0.014412
2021-12-13 00:12:05,093 iteration 2716 : loss : 0.033867, loss_ce: 0.013070
2021-12-13 00:12:06,488 iteration 2717 : loss : 0.021634, loss_ce: 0.009781
2021-12-13 00:12:07,888 iteration 2718 : loss : 0.032228, loss_ce: 0.013001
2021-12-13 00:12:09,410 iteration 2719 : loss : 0.052806, loss_ce: 0.017482
2021-12-13 00:12:09,410 Training Data Eval:
2021-12-13 00:12:16,918   Average segmentation loss on training set: 0.0206
2021-12-13 00:12:16,919 Validation Data Eval:
2021-12-13 00:12:19,506   Average segmentation loss on validation set: 0.0952
2021-12-13 00:12:20,918 iteration 2720 : loss : 0.024678, loss_ce: 0.009948
 40%|██████████▊                | 160/400 [1:12:39<1:53:57, 28.49s/it]2021-12-13 00:12:22,437 iteration 2721 : loss : 0.032625, loss_ce: 0.012285
2021-12-13 00:12:23,913 iteration 2722 : loss : 0.036852, loss_ce: 0.016376
2021-12-13 00:12:25,399 iteration 2723 : loss : 0.026018, loss_ce: 0.008856
2021-12-13 00:12:26,810 iteration 2724 : loss : 0.024138, loss_ce: 0.007268
2021-12-13 00:12:28,180 iteration 2725 : loss : 0.032263, loss_ce: 0.010721
2021-12-13 00:12:29,599 iteration 2726 : loss : 0.027458, loss_ce: 0.009697
2021-12-13 00:12:30,980 iteration 2727 : loss : 0.024810, loss_ce: 0.007557
2021-12-13 00:12:32,549 iteration 2728 : loss : 0.031921, loss_ce: 0.015141
2021-12-13 00:12:34,018 iteration 2729 : loss : 0.035305, loss_ce: 0.012014
2021-12-13 00:12:35,514 iteration 2730 : loss : 0.024296, loss_ce: 0.009326
2021-12-13 00:12:36,993 iteration 2731 : loss : 0.028293, loss_ce: 0.011194
2021-12-13 00:12:38,536 iteration 2732 : loss : 0.028725, loss_ce: 0.010229
2021-12-13 00:12:40,012 iteration 2733 : loss : 0.035220, loss_ce: 0.011975
2021-12-13 00:12:41,471 iteration 2734 : loss : 0.019768, loss_ce: 0.005435
2021-12-13 00:12:42,839 iteration 2735 : loss : 0.026917, loss_ce: 0.010813
2021-12-13 00:12:44,350 iteration 2736 : loss : 0.029670, loss_ce: 0.015190
2021-12-13 00:12:45,788 iteration 2737 : loss : 0.034954, loss_ce: 0.014282
 40%|██████████▊                | 161/400 [1:13:03<1:49:08, 27.40s/it]2021-12-13 00:12:47,255 iteration 2738 : loss : 0.027491, loss_ce: 0.011849
2021-12-13 00:12:48,672 iteration 2739 : loss : 0.024965, loss_ce: 0.012161
2021-12-13 00:12:50,139 iteration 2740 : loss : 0.025630, loss_ce: 0.009704
2021-12-13 00:12:51,615 iteration 2741 : loss : 0.022871, loss_ce: 0.007206
2021-12-13 00:12:53,013 iteration 2742 : loss : 0.022613, loss_ce: 0.010201
2021-12-13 00:12:54,472 iteration 2743 : loss : 0.035088, loss_ce: 0.017236
2021-12-13 00:12:55,954 iteration 2744 : loss : 0.027314, loss_ce: 0.010821
2021-12-13 00:12:57,405 iteration 2745 : loss : 0.040704, loss_ce: 0.019813
2021-12-13 00:12:58,806 iteration 2746 : loss : 0.055531, loss_ce: 0.015065
2021-12-13 00:13:00,277 iteration 2747 : loss : 0.026172, loss_ce: 0.007102
2021-12-13 00:13:01,762 iteration 2748 : loss : 0.033079, loss_ce: 0.016278
2021-12-13 00:13:03,147 iteration 2749 : loss : 0.027622, loss_ce: 0.012543
2021-12-13 00:13:04,625 iteration 2750 : loss : 0.029577, loss_ce: 0.008418
2021-12-13 00:13:06,037 iteration 2751 : loss : 0.023371, loss_ce: 0.010601
2021-12-13 00:13:07,408 iteration 2752 : loss : 0.042248, loss_ce: 0.009012
2021-12-13 00:13:08,941 iteration 2753 : loss : 0.033606, loss_ce: 0.016009
2021-12-13 00:13:10,433 iteration 2754 : loss : 0.023184, loss_ce: 0.009540
 40%|██████████▉                | 162/400 [1:13:28<1:45:25, 26.58s/it]2021-12-13 00:13:11,924 iteration 2755 : loss : 0.023162, loss_ce: 0.009142
2021-12-13 00:13:13,382 iteration 2756 : loss : 0.029977, loss_ce: 0.014807
2021-12-13 00:13:14,836 iteration 2757 : loss : 0.030511, loss_ce: 0.012098
2021-12-13 00:13:16,343 iteration 2758 : loss : 0.038739, loss_ce: 0.013953
2021-12-13 00:13:17,792 iteration 2759 : loss : 0.032141, loss_ce: 0.010257
2021-12-13 00:13:19,230 iteration 2760 : loss : 0.034314, loss_ce: 0.012924
2021-12-13 00:13:20,602 iteration 2761 : loss : 0.030516, loss_ce: 0.013064
2021-12-13 00:13:22,004 iteration 2762 : loss : 0.023018, loss_ce: 0.009688
2021-12-13 00:13:23,499 iteration 2763 : loss : 0.033349, loss_ce: 0.010338
2021-12-13 00:13:24,938 iteration 2764 : loss : 0.022096, loss_ce: 0.008520
2021-12-13 00:13:26,378 iteration 2765 : loss : 0.033680, loss_ce: 0.013266
2021-12-13 00:13:27,796 iteration 2766 : loss : 0.025538, loss_ce: 0.010234
2021-12-13 00:13:29,280 iteration 2767 : loss : 0.025089, loss_ce: 0.008828
2021-12-13 00:13:30,703 iteration 2768 : loss : 0.020631, loss_ce: 0.006073
2021-12-13 00:13:32,153 iteration 2769 : loss : 0.022326, loss_ce: 0.008626
2021-12-13 00:13:33,616 iteration 2770 : loss : 0.026703, loss_ce: 0.012920
2021-12-13 00:13:35,049 iteration 2771 : loss : 0.018018, loss_ce: 0.005370
 41%|███████████                | 163/400 [1:13:53<1:42:39, 25.99s/it]2021-12-13 00:13:36,593 iteration 2772 : loss : 0.023454, loss_ce: 0.010640
2021-12-13 00:13:37,988 iteration 2773 : loss : 0.020156, loss_ce: 0.008560
2021-12-13 00:13:39,371 iteration 2774 : loss : 0.028018, loss_ce: 0.006173
2021-12-13 00:13:40,812 iteration 2775 : loss : 0.027903, loss_ce: 0.009690
2021-12-13 00:13:42,242 iteration 2776 : loss : 0.019360, loss_ce: 0.007180
2021-12-13 00:13:43,699 iteration 2777 : loss : 0.022620, loss_ce: 0.008648
2021-12-13 00:13:45,215 iteration 2778 : loss : 0.030960, loss_ce: 0.011881
2021-12-13 00:13:46,743 iteration 2779 : loss : 0.027748, loss_ce: 0.012287
2021-12-13 00:13:48,131 iteration 2780 : loss : 0.018651, loss_ce: 0.006114
2021-12-13 00:13:49,627 iteration 2781 : loss : 0.035343, loss_ce: 0.013352
2021-12-13 00:13:51,069 iteration 2782 : loss : 0.027768, loss_ce: 0.009733
2021-12-13 00:13:52,484 iteration 2783 : loss : 0.028563, loss_ce: 0.013569
2021-12-13 00:13:54,039 iteration 2784 : loss : 0.034396, loss_ce: 0.010061
2021-12-13 00:13:55,544 iteration 2785 : loss : 0.035745, loss_ce: 0.008953
2021-12-13 00:13:57,027 iteration 2786 : loss : 0.028812, loss_ce: 0.012575
2021-12-13 00:13:58,505 iteration 2787 : loss : 0.020029, loss_ce: 0.008780
2021-12-13 00:13:59,905 iteration 2788 : loss : 0.022484, loss_ce: 0.011545
 41%|███████████                | 164/400 [1:14:18<1:40:53, 25.65s/it]2021-12-13 00:14:01,351 iteration 2789 : loss : 0.026954, loss_ce: 0.011308
2021-12-13 00:14:02,828 iteration 2790 : loss : 0.026483, loss_ce: 0.008131
2021-12-13 00:14:04,247 iteration 2791 : loss : 0.023716, loss_ce: 0.009781
2021-12-13 00:14:05,757 iteration 2792 : loss : 0.041209, loss_ce: 0.014990
2021-12-13 00:14:07,174 iteration 2793 : loss : 0.025017, loss_ce: 0.009302
2021-12-13 00:14:08,671 iteration 2794 : loss : 0.020784, loss_ce: 0.006719
2021-12-13 00:14:10,082 iteration 2795 : loss : 0.022451, loss_ce: 0.006205
2021-12-13 00:14:11,569 iteration 2796 : loss : 0.023593, loss_ce: 0.008862
2021-12-13 00:14:13,038 iteration 2797 : loss : 0.022887, loss_ce: 0.009169
2021-12-13 00:14:14,535 iteration 2798 : loss : 0.028416, loss_ce: 0.014175
2021-12-13 00:14:15,953 iteration 2799 : loss : 0.018954, loss_ce: 0.008005
2021-12-13 00:14:17,353 iteration 2800 : loss : 0.043040, loss_ce: 0.014005
2021-12-13 00:14:18,740 iteration 2801 : loss : 0.018643, loss_ce: 0.006205
2021-12-13 00:14:20,236 iteration 2802 : loss : 0.030649, loss_ce: 0.009620
2021-12-13 00:14:21,682 iteration 2803 : loss : 0.021170, loss_ce: 0.008948
2021-12-13 00:14:23,110 iteration 2804 : loss : 0.018873, loss_ce: 0.006195
2021-12-13 00:14:23,110 Training Data Eval:
2021-12-13 00:14:30,613   Average segmentation loss on training set: 0.0181
2021-12-13 00:14:30,613 Validation Data Eval:
2021-12-13 00:14:33,213   Average segmentation loss on validation set: 0.0867
2021-12-13 00:14:34,650 iteration 2805 : loss : 0.022412, loss_ce: 0.008976
 41%|███████████▏               | 165/400 [1:14:52<1:51:08, 28.38s/it]2021-12-13 00:14:36,255 iteration 2806 : loss : 0.031198, loss_ce: 0.013743
2021-12-13 00:14:37,629 iteration 2807 : loss : 0.019754, loss_ce: 0.007361
2021-12-13 00:14:39,035 iteration 2808 : loss : 0.018345, loss_ce: 0.006987
2021-12-13 00:14:40,513 iteration 2809 : loss : 0.018696, loss_ce: 0.006338
2021-12-13 00:14:41,943 iteration 2810 : loss : 0.058760, loss_ce: 0.032209
2021-12-13 00:14:43,476 iteration 2811 : loss : 0.033494, loss_ce: 0.011274
2021-12-13 00:14:45,013 iteration 2812 : loss : 0.024457, loss_ce: 0.008109
2021-12-13 00:14:46,375 iteration 2813 : loss : 0.024937, loss_ce: 0.009439
2021-12-13 00:14:47,833 iteration 2814 : loss : 0.026713, loss_ce: 0.013449
2021-12-13 00:14:49,322 iteration 2815 : loss : 0.031360, loss_ce: 0.014765
2021-12-13 00:14:50,754 iteration 2816 : loss : 0.033765, loss_ce: 0.015895
2021-12-13 00:14:52,196 iteration 2817 : loss : 0.030453, loss_ce: 0.011190
2021-12-13 00:14:53,737 iteration 2818 : loss : 0.032639, loss_ce: 0.011733
2021-12-13 00:14:55,232 iteration 2819 : loss : 0.026101, loss_ce: 0.010851
2021-12-13 00:14:56,651 iteration 2820 : loss : 0.030522, loss_ce: 0.009725
2021-12-13 00:14:58,110 iteration 2821 : loss : 0.023309, loss_ce: 0.009005
2021-12-13 00:14:59,610 iteration 2822 : loss : 0.069808, loss_ce: 0.010393
 42%|███████████▏               | 166/400 [1:15:17<1:46:40, 27.35s/it]2021-12-13 00:15:01,147 iteration 2823 : loss : 0.024091, loss_ce: 0.008159
2021-12-13 00:15:02,639 iteration 2824 : loss : 0.035363, loss_ce: 0.009230
2021-12-13 00:15:04,116 iteration 2825 : loss : 0.066255, loss_ce: 0.030807
2021-12-13 00:15:05,529 iteration 2826 : loss : 0.023458, loss_ce: 0.007602
2021-12-13 00:15:07,036 iteration 2827 : loss : 0.022309, loss_ce: 0.007273
2021-12-13 00:15:08,482 iteration 2828 : loss : 0.030356, loss_ce: 0.013591
2021-12-13 00:15:09,914 iteration 2829 : loss : 0.040572, loss_ce: 0.014159
2021-12-13 00:15:11,398 iteration 2830 : loss : 0.043556, loss_ce: 0.019711
2021-12-13 00:15:12,840 iteration 2831 : loss : 0.052593, loss_ce: 0.014660
2021-12-13 00:15:14,230 iteration 2832 : loss : 0.025376, loss_ce: 0.010214
2021-12-13 00:15:15,753 iteration 2833 : loss : 0.023277, loss_ce: 0.009291
2021-12-13 00:15:17,219 iteration 2834 : loss : 0.028971, loss_ce: 0.012618
2021-12-13 00:15:18,686 iteration 2835 : loss : 0.033548, loss_ce: 0.011779
2021-12-13 00:15:20,157 iteration 2836 : loss : 0.030617, loss_ce: 0.010487
2021-12-13 00:15:21,644 iteration 2837 : loss : 0.021824, loss_ce: 0.006918
2021-12-13 00:15:23,130 iteration 2838 : loss : 0.032460, loss_ce: 0.011332
2021-12-13 00:15:24,526 iteration 2839 : loss : 0.026197, loss_ce: 0.010505
 42%|███████████▎               | 167/400 [1:15:42<1:43:22, 26.62s/it]2021-12-13 00:15:26,007 iteration 2840 : loss : 0.038755, loss_ce: 0.013320
2021-12-13 00:15:27,431 iteration 2841 : loss : 0.022454, loss_ce: 0.009313
2021-12-13 00:15:28,830 iteration 2842 : loss : 0.022161, loss_ce: 0.007887
2021-12-13 00:15:30,273 iteration 2843 : loss : 0.039102, loss_ce: 0.009918
2021-12-13 00:15:31,769 iteration 2844 : loss : 0.030558, loss_ce: 0.011866
2021-12-13 00:15:33,277 iteration 2845 : loss : 0.024632, loss_ce: 0.008198
2021-12-13 00:15:34,711 iteration 2846 : loss : 0.043555, loss_ce: 0.018651
2021-12-13 00:15:36,175 iteration 2847 : loss : 0.028549, loss_ce: 0.011501
2021-12-13 00:15:37,721 iteration 2848 : loss : 0.029266, loss_ce: 0.013620
2021-12-13 00:15:39,146 iteration 2849 : loss : 0.036891, loss_ce: 0.012108
2021-12-13 00:15:40,565 iteration 2850 : loss : 0.024474, loss_ce: 0.008571
2021-12-13 00:15:42,042 iteration 2851 : loss : 0.026038, loss_ce: 0.011629
2021-12-13 00:15:43,517 iteration 2852 : loss : 0.043420, loss_ce: 0.018565
2021-12-13 00:15:44,940 iteration 2853 : loss : 0.027859, loss_ce: 0.011127
2021-12-13 00:15:46,432 iteration 2854 : loss : 0.029689, loss_ce: 0.013715
2021-12-13 00:15:47,878 iteration 2855 : loss : 0.034085, loss_ce: 0.013927
2021-12-13 00:15:49,378 iteration 2856 : loss : 0.033329, loss_ce: 0.012636
 42%|███████████▎               | 168/400 [1:16:07<1:40:52, 26.09s/it]2021-12-13 00:15:50,930 iteration 2857 : loss : 0.037424, loss_ce: 0.008599
2021-12-13 00:15:52,413 iteration 2858 : loss : 0.040678, loss_ce: 0.018005
2021-12-13 00:15:53,820 iteration 2859 : loss : 0.022334, loss_ce: 0.007359
2021-12-13 00:15:55,345 iteration 2860 : loss : 0.035578, loss_ce: 0.014813
2021-12-13 00:15:56,783 iteration 2861 : loss : 0.028361, loss_ce: 0.010675
2021-12-13 00:15:58,281 iteration 2862 : loss : 0.027183, loss_ce: 0.010413
2021-12-13 00:15:59,818 iteration 2863 : loss : 0.038755, loss_ce: 0.013522
2021-12-13 00:16:01,290 iteration 2864 : loss : 0.026598, loss_ce: 0.013877
2021-12-13 00:16:02,673 iteration 2865 : loss : 0.027911, loss_ce: 0.011959
2021-12-13 00:16:04,119 iteration 2866 : loss : 0.026113, loss_ce: 0.007797
2021-12-13 00:16:05,645 iteration 2867 : loss : 0.031790, loss_ce: 0.014274
2021-12-13 00:16:07,149 iteration 2868 : loss : 0.027569, loss_ce: 0.014417
2021-12-13 00:16:08,566 iteration 2869 : loss : 0.021045, loss_ce: 0.009059
2021-12-13 00:16:10,041 iteration 2870 : loss : 0.030549, loss_ce: 0.013584
2021-12-13 00:16:11,431 iteration 2871 : loss : 0.021713, loss_ce: 0.010273
2021-12-13 00:16:12,892 iteration 2872 : loss : 0.037231, loss_ce: 0.012444
2021-12-13 00:16:14,391 iteration 2873 : loss : 0.029843, loss_ce: 0.014085
 42%|███████████▍               | 169/400 [1:16:32<1:39:12, 25.77s/it]2021-12-13 00:16:15,858 iteration 2874 : loss : 0.028436, loss_ce: 0.008037
2021-12-13 00:16:17,239 iteration 2875 : loss : 0.018499, loss_ce: 0.007614
2021-12-13 00:16:18,680 iteration 2876 : loss : 0.019702, loss_ce: 0.008159
2021-12-13 00:16:20,159 iteration 2877 : loss : 0.033884, loss_ce: 0.010043
2021-12-13 00:16:21,641 iteration 2878 : loss : 0.036593, loss_ce: 0.013393
2021-12-13 00:16:23,039 iteration 2879 : loss : 0.020486, loss_ce: 0.009996
2021-12-13 00:16:24,564 iteration 2880 : loss : 0.031077, loss_ce: 0.012872
2021-12-13 00:16:26,003 iteration 2881 : loss : 0.024417, loss_ce: 0.010385
2021-12-13 00:16:27,536 iteration 2882 : loss : 0.037646, loss_ce: 0.011614
2021-12-13 00:16:29,067 iteration 2883 : loss : 0.030793, loss_ce: 0.012913
2021-12-13 00:16:30,600 iteration 2884 : loss : 0.030028, loss_ce: 0.010149
2021-12-13 00:16:32,069 iteration 2885 : loss : 0.027130, loss_ce: 0.012354
2021-12-13 00:16:33,495 iteration 2886 : loss : 0.027767, loss_ce: 0.007203
2021-12-13 00:16:34,945 iteration 2887 : loss : 0.024044, loss_ce: 0.008717
2021-12-13 00:16:36,500 iteration 2888 : loss : 0.021993, loss_ce: 0.009375
2021-12-13 00:16:37,984 iteration 2889 : loss : 0.029413, loss_ce: 0.013325
2021-12-13 00:16:37,985 Training Data Eval:
2021-12-13 00:16:45,467   Average segmentation loss on training set: 0.0165
2021-12-13 00:16:45,467 Validation Data Eval:
2021-12-13 00:16:48,063   Average segmentation loss on validation set: 0.1079
2021-12-13 00:16:49,588 iteration 2890 : loss : 0.025452, loss_ce: 0.009361
 42%|███████████▍               | 170/400 [1:17:07<1:49:36, 28.60s/it]2021-12-13 00:16:51,152 iteration 2891 : loss : 0.031041, loss_ce: 0.015684
2021-12-13 00:16:52,563 iteration 2892 : loss : 0.023448, loss_ce: 0.011060
2021-12-13 00:16:53,996 iteration 2893 : loss : 0.024466, loss_ce: 0.007915
2021-12-13 00:16:55,486 iteration 2894 : loss : 0.016945, loss_ce: 0.006574
2021-12-13 00:16:56,919 iteration 2895 : loss : 0.025928, loss_ce: 0.007801
2021-12-13 00:16:58,334 iteration 2896 : loss : 0.025363, loss_ce: 0.009843
2021-12-13 00:16:59,782 iteration 2897 : loss : 0.028085, loss_ce: 0.011553
2021-12-13 00:17:01,238 iteration 2898 : loss : 0.026469, loss_ce: 0.014799
2021-12-13 00:17:02,743 iteration 2899 : loss : 0.028330, loss_ce: 0.010351
2021-12-13 00:17:04,163 iteration 2900 : loss : 0.021119, loss_ce: 0.007553
2021-12-13 00:17:05,728 iteration 2901 : loss : 0.021075, loss_ce: 0.007409
2021-12-13 00:17:07,102 iteration 2902 : loss : 0.017908, loss_ce: 0.005609
2021-12-13 00:17:08,611 iteration 2903 : loss : 0.027750, loss_ce: 0.011894
2021-12-13 00:17:10,122 iteration 2904 : loss : 0.037745, loss_ce: 0.011738
2021-12-13 00:17:11,568 iteration 2905 : loss : 0.035635, loss_ce: 0.012435
2021-12-13 00:17:13,074 iteration 2906 : loss : 0.030449, loss_ce: 0.011997
2021-12-13 00:17:14,486 iteration 2907 : loss : 0.025182, loss_ce: 0.009897
 43%|███████████▌               | 171/400 [1:17:32<1:44:54, 27.49s/it]2021-12-13 00:17:15,982 iteration 2908 : loss : 0.028478, loss_ce: 0.009777
2021-12-13 00:17:17,377 iteration 2909 : loss : 0.020036, loss_ce: 0.005281
2021-12-13 00:17:18,879 iteration 2910 : loss : 0.024760, loss_ce: 0.009700
2021-12-13 00:17:20,366 iteration 2911 : loss : 0.022989, loss_ce: 0.009610
2021-12-13 00:17:21,842 iteration 2912 : loss : 0.032682, loss_ce: 0.012351
2021-12-13 00:17:23,348 iteration 2913 : loss : 0.030370, loss_ce: 0.013144
2021-12-13 00:17:24,823 iteration 2914 : loss : 0.025311, loss_ce: 0.010211
2021-12-13 00:17:26,329 iteration 2915 : loss : 0.022339, loss_ce: 0.007639
2021-12-13 00:17:27,720 iteration 2916 : loss : 0.020659, loss_ce: 0.010584
2021-12-13 00:17:29,219 iteration 2917 : loss : 0.029640, loss_ce: 0.012218
2021-12-13 00:17:30,684 iteration 2918 : loss : 0.022489, loss_ce: 0.007261
2021-12-13 00:17:32,172 iteration 2919 : loss : 0.045045, loss_ce: 0.023004
2021-12-13 00:17:33,663 iteration 2920 : loss : 0.025978, loss_ce: 0.007706
2021-12-13 00:17:35,196 iteration 2921 : loss : 0.021890, loss_ce: 0.007175
2021-12-13 00:17:36,624 iteration 2922 : loss : 0.025149, loss_ce: 0.009637
2021-12-13 00:17:38,105 iteration 2923 : loss : 0.035372, loss_ce: 0.014308
2021-12-13 00:17:39,560 iteration 2924 : loss : 0.025893, loss_ce: 0.007485
 43%|███████████▌               | 172/400 [1:17:57<1:41:42, 26.76s/it]2021-12-13 00:17:41,166 iteration 2925 : loss : 0.029501, loss_ce: 0.012487
2021-12-13 00:17:42,594 iteration 2926 : loss : 0.023835, loss_ce: 0.007678
2021-12-13 00:17:44,111 iteration 2927 : loss : 0.041144, loss_ce: 0.020404
2021-12-13 00:17:45,687 iteration 2928 : loss : 0.028802, loss_ce: 0.007355
2021-12-13 00:17:47,120 iteration 2929 : loss : 0.019267, loss_ce: 0.005906
2021-12-13 00:17:48,563 iteration 2930 : loss : 0.023425, loss_ce: 0.009374
2021-12-13 00:17:49,962 iteration 2931 : loss : 0.028057, loss_ce: 0.010091
2021-12-13 00:17:51,488 iteration 2932 : loss : 0.020969, loss_ce: 0.007378
2021-12-13 00:17:52,939 iteration 2933 : loss : 0.039800, loss_ce: 0.015580
2021-12-13 00:17:54,446 iteration 2934 : loss : 0.031590, loss_ce: 0.015866
2021-12-13 00:17:55,901 iteration 2935 : loss : 0.035347, loss_ce: 0.010293
2021-12-13 00:17:57,421 iteration 2936 : loss : 0.023451, loss_ce: 0.011014
2021-12-13 00:17:58,869 iteration 2937 : loss : 0.020950, loss_ce: 0.008344
2021-12-13 00:18:00,342 iteration 2938 : loss : 0.024570, loss_ce: 0.009128
2021-12-13 00:18:01,787 iteration 2939 : loss : 0.027681, loss_ce: 0.010984
2021-12-13 00:18:03,272 iteration 2940 : loss : 0.024291, loss_ce: 0.007819
2021-12-13 00:18:04,715 iteration 2941 : loss : 0.025831, loss_ce: 0.008221
 43%|███████████▋               | 173/400 [1:18:22<1:39:25, 26.28s/it]2021-12-13 00:18:06,249 iteration 2942 : loss : 0.023920, loss_ce: 0.008454
2021-12-13 00:18:07,649 iteration 2943 : loss : 0.020210, loss_ce: 0.008054
2021-12-13 00:18:09,072 iteration 2944 : loss : 0.025663, loss_ce: 0.009179
2021-12-13 00:18:10,588 iteration 2945 : loss : 0.049219, loss_ce: 0.021998
2021-12-13 00:18:12,007 iteration 2946 : loss : 0.022070, loss_ce: 0.009105
2021-12-13 00:18:13,421 iteration 2947 : loss : 0.014664, loss_ce: 0.004931
2021-12-13 00:18:14,875 iteration 2948 : loss : 0.023297, loss_ce: 0.008041
2021-12-13 00:18:16,356 iteration 2949 : loss : 0.021719, loss_ce: 0.007653
2021-12-13 00:18:17,795 iteration 2950 : loss : 0.023447, loss_ce: 0.009468
2021-12-13 00:18:19,204 iteration 2951 : loss : 0.024288, loss_ce: 0.008787
2021-12-13 00:18:20,666 iteration 2952 : loss : 0.023134, loss_ce: 0.005302
2021-12-13 00:18:22,112 iteration 2953 : loss : 0.025944, loss_ce: 0.010722
2021-12-13 00:18:23,598 iteration 2954 : loss : 0.045083, loss_ce: 0.013157
2021-12-13 00:18:25,028 iteration 2955 : loss : 0.019124, loss_ce: 0.008442
2021-12-13 00:18:26,487 iteration 2956 : loss : 0.019944, loss_ce: 0.009312
2021-12-13 00:18:27,952 iteration 2957 : loss : 0.030304, loss_ce: 0.007155
2021-12-13 00:18:29,411 iteration 2958 : loss : 0.036525, loss_ce: 0.012220
 44%|███████████▋               | 174/400 [1:18:47<1:37:11, 25.80s/it]2021-12-13 00:18:30,987 iteration 2959 : loss : 0.023973, loss_ce: 0.010549
2021-12-13 00:18:32,477 iteration 2960 : loss : 0.022605, loss_ce: 0.008004
2021-12-13 00:18:33,977 iteration 2961 : loss : 0.020802, loss_ce: 0.009052
2021-12-13 00:18:35,387 iteration 2962 : loss : 0.021253, loss_ce: 0.006386
2021-12-13 00:18:36,828 iteration 2963 : loss : 0.027928, loss_ce: 0.009772
2021-12-13 00:18:38,343 iteration 2964 : loss : 0.029360, loss_ce: 0.009342
2021-12-13 00:18:39,827 iteration 2965 : loss : 0.024806, loss_ce: 0.011728
2021-12-13 00:18:41,288 iteration 2966 : loss : 0.024084, loss_ce: 0.008127
2021-12-13 00:18:42,834 iteration 2967 : loss : 0.035899, loss_ce: 0.012080
2021-12-13 00:18:44,302 iteration 2968 : loss : 0.042590, loss_ce: 0.012771
2021-12-13 00:18:45,722 iteration 2969 : loss : 0.024246, loss_ce: 0.006331
2021-12-13 00:18:47,175 iteration 2970 : loss : 0.028340, loss_ce: 0.010612
2021-12-13 00:18:48,659 iteration 2971 : loss : 0.039142, loss_ce: 0.015674
2021-12-13 00:18:50,155 iteration 2972 : loss : 0.023913, loss_ce: 0.007806
2021-12-13 00:18:51,614 iteration 2973 : loss : 0.020459, loss_ce: 0.008809
2021-12-13 00:18:53,182 iteration 2974 : loss : 0.036056, loss_ce: 0.014352
2021-12-13 00:18:53,182 Training Data Eval:
2021-12-13 00:19:00,680   Average segmentation loss on training set: 0.0188
2021-12-13 00:19:00,681 Validation Data Eval:
2021-12-13 00:19:03,282   Average segmentation loss on validation set: 0.0840
2021-12-13 00:19:04,745 iteration 2975 : loss : 0.028440, loss_ce: 0.011439
 44%|███████████▊               | 175/400 [1:19:22<1:47:29, 28.67s/it]2021-12-13 00:19:06,289 iteration 2976 : loss : 0.030265, loss_ce: 0.012054
2021-12-13 00:19:07,882 iteration 2977 : loss : 0.025382, loss_ce: 0.009265
2021-12-13 00:19:09,352 iteration 2978 : loss : 0.028405, loss_ce: 0.011111
2021-12-13 00:19:10,878 iteration 2979 : loss : 0.034644, loss_ce: 0.011103
2021-12-13 00:19:12,470 iteration 2980 : loss : 0.028513, loss_ce: 0.011487
2021-12-13 00:19:13,906 iteration 2981 : loss : 0.019998, loss_ce: 0.008597
2021-12-13 00:19:15,349 iteration 2982 : loss : 0.032043, loss_ce: 0.011996
2021-12-13 00:19:16,841 iteration 2983 : loss : 0.017809, loss_ce: 0.003874
2021-12-13 00:19:18,337 iteration 2984 : loss : 0.023424, loss_ce: 0.009028
2021-12-13 00:19:19,819 iteration 2985 : loss : 0.024095, loss_ce: 0.010420
2021-12-13 00:19:21,277 iteration 2986 : loss : 0.033731, loss_ce: 0.012033
2021-12-13 00:19:22,717 iteration 2987 : loss : 0.021899, loss_ce: 0.007646
2021-12-13 00:19:24,206 iteration 2988 : loss : 0.028716, loss_ce: 0.012457
2021-12-13 00:19:25,657 iteration 2989 : loss : 0.023094, loss_ce: 0.008262
2021-12-13 00:19:27,134 iteration 2990 : loss : 0.027789, loss_ce: 0.012322
2021-12-13 00:19:28,558 iteration 2991 : loss : 0.022386, loss_ce: 0.006606
2021-12-13 00:19:30,045 iteration 2992 : loss : 0.025091, loss_ce: 0.011719
 44%|███████████▉               | 176/400 [1:19:48<1:43:14, 27.66s/it]2021-12-13 00:19:31,562 iteration 2993 : loss : 0.026335, loss_ce: 0.012034
2021-12-13 00:19:33,019 iteration 2994 : loss : 0.024124, loss_ce: 0.008954
2021-12-13 00:19:34,535 iteration 2995 : loss : 0.040166, loss_ce: 0.017191
2021-12-13 00:19:35,963 iteration 2996 : loss : 0.030817, loss_ce: 0.010734
2021-12-13 00:19:37,415 iteration 2997 : loss : 0.031999, loss_ce: 0.011333
2021-12-13 00:19:38,888 iteration 2998 : loss : 0.022294, loss_ce: 0.009967
2021-12-13 00:19:40,343 iteration 2999 : loss : 0.024108, loss_ce: 0.008846
2021-12-13 00:19:41,799 iteration 3000 : loss : 0.022496, loss_ce: 0.008529
2021-12-13 00:19:43,346 iteration 3001 : loss : 0.026542, loss_ce: 0.012064
2021-12-13 00:19:44,847 iteration 3002 : loss : 0.026629, loss_ce: 0.011375
2021-12-13 00:19:46,246 iteration 3003 : loss : 0.021971, loss_ce: 0.009025
2021-12-13 00:19:47,700 iteration 3004 : loss : 0.023835, loss_ce: 0.010802
2021-12-13 00:19:49,128 iteration 3005 : loss : 0.028017, loss_ce: 0.011661
2021-12-13 00:19:50,559 iteration 3006 : loss : 0.024847, loss_ce: 0.008166
2021-12-13 00:19:52,035 iteration 3007 : loss : 0.025581, loss_ce: 0.009637
2021-12-13 00:19:53,450 iteration 3008 : loss : 0.024410, loss_ce: 0.008902
2021-12-13 00:19:54,868 iteration 3009 : loss : 0.026379, loss_ce: 0.007344
 44%|███████████▉               | 177/400 [1:20:12<1:39:37, 26.80s/it]2021-12-13 00:19:56,444 iteration 3010 : loss : 0.025026, loss_ce: 0.009574
2021-12-13 00:19:57,892 iteration 3011 : loss : 0.035159, loss_ce: 0.010545
2021-12-13 00:19:59,328 iteration 3012 : loss : 0.024673, loss_ce: 0.008236
2021-12-13 00:20:00,868 iteration 3013 : loss : 0.027982, loss_ce: 0.008484
2021-12-13 00:20:02,371 iteration 3014 : loss : 0.036321, loss_ce: 0.015401
2021-12-13 00:20:03,853 iteration 3015 : loss : 0.027121, loss_ce: 0.007850
2021-12-13 00:20:05,243 iteration 3016 : loss : 0.021264, loss_ce: 0.006522
2021-12-13 00:20:06,761 iteration 3017 : loss : 0.033502, loss_ce: 0.021100
2021-12-13 00:20:08,308 iteration 3018 : loss : 0.022317, loss_ce: 0.010890
2021-12-13 00:20:09,903 iteration 3019 : loss : 0.050451, loss_ce: 0.020143
2021-12-13 00:20:11,342 iteration 3020 : loss : 0.029954, loss_ce: 0.010874
2021-12-13 00:20:12,805 iteration 3021 : loss : 0.032640, loss_ce: 0.013894
2021-12-13 00:20:14,201 iteration 3022 : loss : 0.018652, loss_ce: 0.009254
2021-12-13 00:20:15,641 iteration 3023 : loss : 0.032089, loss_ce: 0.016713
2021-12-13 00:20:17,112 iteration 3024 : loss : 0.026838, loss_ce: 0.011394
2021-12-13 00:20:18,580 iteration 3025 : loss : 0.025077, loss_ce: 0.009677
2021-12-13 00:20:20,005 iteration 3026 : loss : 0.025649, loss_ce: 0.007451
 44%|████████████               | 178/400 [1:20:38<1:37:19, 26.30s/it]2021-12-13 00:20:21,510 iteration 3027 : loss : 0.025974, loss_ce: 0.011544
2021-12-13 00:20:23,071 iteration 3028 : loss : 0.023998, loss_ce: 0.008795
2021-12-13 00:20:24,500 iteration 3029 : loss : 0.014892, loss_ce: 0.004945
2021-12-13 00:20:26,021 iteration 3030 : loss : 0.036221, loss_ce: 0.013035
2021-12-13 00:20:27,553 iteration 3031 : loss : 0.033700, loss_ce: 0.012751
2021-12-13 00:20:29,080 iteration 3032 : loss : 0.016765, loss_ce: 0.006767
2021-12-13 00:20:30,549 iteration 3033 : loss : 0.025189, loss_ce: 0.008528
2021-12-13 00:20:31,970 iteration 3034 : loss : 0.022246, loss_ce: 0.006545
2021-12-13 00:20:33,376 iteration 3035 : loss : 0.025842, loss_ce: 0.010727
2021-12-13 00:20:34,887 iteration 3036 : loss : 0.032026, loss_ce: 0.015150
2021-12-13 00:20:36,318 iteration 3037 : loss : 0.023302, loss_ce: 0.010472
2021-12-13 00:20:37,738 iteration 3038 : loss : 0.022725, loss_ce: 0.011324
2021-12-13 00:20:39,167 iteration 3039 : loss : 0.022743, loss_ce: 0.008820
2021-12-13 00:20:40,708 iteration 3040 : loss : 0.029950, loss_ce: 0.010073
2021-12-13 00:20:42,075 iteration 3041 : loss : 0.020966, loss_ce: 0.008548
2021-12-13 00:20:43,499 iteration 3042 : loss : 0.024712, loss_ce: 0.011992
2021-12-13 00:20:44,921 iteration 3043 : loss : 0.034318, loss_ce: 0.013082
 45%|████████████               | 179/400 [1:21:03<1:35:21, 25.89s/it]2021-12-13 00:20:46,454 iteration 3044 : loss : 0.024329, loss_ce: 0.010209
2021-12-13 00:20:47,849 iteration 3045 : loss : 0.025614, loss_ce: 0.008818
2021-12-13 00:20:49,407 iteration 3046 : loss : 0.028144, loss_ce: 0.012254
2021-12-13 00:20:50,966 iteration 3047 : loss : 0.021013, loss_ce: 0.007932
2021-12-13 00:20:52,469 iteration 3048 : loss : 0.027776, loss_ce: 0.009746
2021-12-13 00:20:53,978 iteration 3049 : loss : 0.036545, loss_ce: 0.013627
2021-12-13 00:20:55,480 iteration 3050 : loss : 0.024377, loss_ce: 0.005760
2021-12-13 00:20:57,003 iteration 3051 : loss : 0.018128, loss_ce: 0.006821
2021-12-13 00:20:58,493 iteration 3052 : loss : 0.034690, loss_ce: 0.019218
2021-12-13 00:20:59,891 iteration 3053 : loss : 0.016066, loss_ce: 0.005289
2021-12-13 00:21:01,332 iteration 3054 : loss : 0.022879, loss_ce: 0.009859
2021-12-13 00:21:02,743 iteration 3055 : loss : 0.028413, loss_ce: 0.011744
2021-12-13 00:21:04,146 iteration 3056 : loss : 0.017837, loss_ce: 0.006007
2021-12-13 00:21:05,724 iteration 3057 : loss : 0.029039, loss_ce: 0.010292
2021-12-13 00:21:07,144 iteration 3058 : loss : 0.020791, loss_ce: 0.008272
2021-12-13 00:21:08,559 iteration 3059 : loss : 0.020982, loss_ce: 0.010645
2021-12-13 00:21:08,559 Training Data Eval:
2021-12-13 00:21:16,076   Average segmentation loss on training set: 0.0153
2021-12-13 00:21:16,077 Validation Data Eval:
2021-12-13 00:21:18,681   Average segmentation loss on validation set: 0.0802
2021-12-13 00:21:20,196 iteration 3060 : loss : 0.022972, loss_ce: 0.008824
 45%|████████████▏              | 180/400 [1:21:38<1:45:14, 28.70s/it]2021-12-13 00:21:21,712 iteration 3061 : loss : 0.019619, loss_ce: 0.006060
2021-12-13 00:21:23,208 iteration 3062 : loss : 0.030630, loss_ce: 0.013732
2021-12-13 00:21:24,662 iteration 3063 : loss : 0.022886, loss_ce: 0.009935
2021-12-13 00:21:26,139 iteration 3064 : loss : 0.031353, loss_ce: 0.016459
2021-12-13 00:21:27,650 iteration 3065 : loss : 0.028122, loss_ce: 0.008542
2021-12-13 00:21:29,066 iteration 3066 : loss : 0.021219, loss_ce: 0.006573
2021-12-13 00:21:30,587 iteration 3067 : loss : 0.030098, loss_ce: 0.013494
2021-12-13 00:21:32,130 iteration 3068 : loss : 0.028245, loss_ce: 0.010609
2021-12-13 00:21:33,578 iteration 3069 : loss : 0.011334, loss_ce: 0.004509
2021-12-13 00:21:35,042 iteration 3070 : loss : 0.033769, loss_ce: 0.012970
2021-12-13 00:21:36,622 iteration 3071 : loss : 0.035311, loss_ce: 0.011413
2021-12-13 00:21:38,053 iteration 3072 : loss : 0.018346, loss_ce: 0.007474
2021-12-13 00:21:39,498 iteration 3073 : loss : 0.026588, loss_ce: 0.008405
2021-12-13 00:21:40,949 iteration 3074 : loss : 0.026103, loss_ce: 0.010790
2021-12-13 00:21:42,433 iteration 3075 : loss : 0.033781, loss_ce: 0.011505
2021-12-13 00:21:43,846 iteration 3076 : loss : 0.018286, loss_ce: 0.006815
2021-12-13 00:21:45,380 iteration 3077 : loss : 0.037921, loss_ce: 0.010991
 45%|████████████▏              | 181/400 [1:22:03<1:40:54, 27.65s/it]2021-12-13 00:21:46,920 iteration 3078 : loss : 0.051290, loss_ce: 0.008108
2021-12-13 00:21:48,354 iteration 3079 : loss : 0.020368, loss_ce: 0.005968
2021-12-13 00:21:49,793 iteration 3080 : loss : 0.020020, loss_ce: 0.006016
2021-12-13 00:21:51,258 iteration 3081 : loss : 0.037231, loss_ce: 0.013246
2021-12-13 00:21:52,737 iteration 3082 : loss : 0.032507, loss_ce: 0.009698
2021-12-13 00:21:54,210 iteration 3083 : loss : 0.031946, loss_ce: 0.008937
2021-12-13 00:21:55,697 iteration 3084 : loss : 0.044284, loss_ce: 0.018663
2021-12-13 00:21:57,097 iteration 3085 : loss : 0.024427, loss_ce: 0.009003
2021-12-13 00:21:58,555 iteration 3086 : loss : 0.030354, loss_ce: 0.014353
2021-12-13 00:22:00,070 iteration 3087 : loss : 0.025625, loss_ce: 0.010543
2021-12-13 00:22:01,541 iteration 3088 : loss : 0.031839, loss_ce: 0.015170
2021-12-13 00:22:03,083 iteration 3089 : loss : 0.044981, loss_ce: 0.016768
2021-12-13 00:22:04,477 iteration 3090 : loss : 0.024174, loss_ce: 0.009907
2021-12-13 00:22:05,970 iteration 3091 : loss : 0.038409, loss_ce: 0.014713
2021-12-13 00:22:07,386 iteration 3092 : loss : 0.026266, loss_ce: 0.011220
2021-12-13 00:22:08,803 iteration 3093 : loss : 0.020793, loss_ce: 0.008744
2021-12-13 00:22:10,257 iteration 3094 : loss : 0.073398, loss_ce: 0.026463
 46%|████████████▎              | 182/400 [1:22:28<1:37:25, 26.82s/it]2021-12-13 00:22:11,789 iteration 3095 : loss : 0.021313, loss_ce: 0.009134
2021-12-13 00:22:13,261 iteration 3096 : loss : 0.022988, loss_ce: 0.008698
2021-12-13 00:22:14,749 iteration 3097 : loss : 0.023954, loss_ce: 0.009975
2021-12-13 00:22:16,236 iteration 3098 : loss : 0.031643, loss_ce: 0.009130
2021-12-13 00:22:17,738 iteration 3099 : loss : 0.034341, loss_ce: 0.014904
2021-12-13 00:22:19,212 iteration 3100 : loss : 0.022880, loss_ce: 0.008018
2021-12-13 00:22:20,638 iteration 3101 : loss : 0.019066, loss_ce: 0.007035
2021-12-13 00:22:22,023 iteration 3102 : loss : 0.022417, loss_ce: 0.008302
2021-12-13 00:22:23,517 iteration 3103 : loss : 0.036137, loss_ce: 0.020032
2021-12-13 00:22:24,974 iteration 3104 : loss : 0.023050, loss_ce: 0.007335
2021-12-13 00:22:26,472 iteration 3105 : loss : 0.030234, loss_ce: 0.014340
2021-12-13 00:22:27,947 iteration 3106 : loss : 0.021539, loss_ce: 0.008377
2021-12-13 00:22:29,474 iteration 3107 : loss : 0.024801, loss_ce: 0.009309
2021-12-13 00:22:30,963 iteration 3108 : loss : 0.030854, loss_ce: 0.011072
2021-12-13 00:22:32,362 iteration 3109 : loss : 0.019275, loss_ce: 0.008769
2021-12-13 00:22:33,800 iteration 3110 : loss : 0.022976, loss_ce: 0.008087
2021-12-13 00:22:35,263 iteration 3111 : loss : 0.036619, loss_ce: 0.010819
 46%|████████████▎              | 183/400 [1:22:53<1:35:01, 26.28s/it]2021-12-13 00:22:36,714 iteration 3112 : loss : 0.022846, loss_ce: 0.008565
2021-12-13 00:22:38,189 iteration 3113 : loss : 0.026869, loss_ce: 0.011338
2021-12-13 00:22:39,616 iteration 3114 : loss : 0.024774, loss_ce: 0.011109
2021-12-13 00:22:41,104 iteration 3115 : loss : 0.023260, loss_ce: 0.008646
2021-12-13 00:22:42,510 iteration 3116 : loss : 0.023850, loss_ce: 0.009627
2021-12-13 00:22:44,051 iteration 3117 : loss : 0.042719, loss_ce: 0.008979
2021-12-13 00:22:45,527 iteration 3118 : loss : 0.022238, loss_ce: 0.010155
2021-12-13 00:22:47,007 iteration 3119 : loss : 0.020165, loss_ce: 0.008221
2021-12-13 00:22:48,418 iteration 3120 : loss : 0.023269, loss_ce: 0.006752
2021-12-13 00:22:49,918 iteration 3121 : loss : 0.032407, loss_ce: 0.009562
2021-12-13 00:22:51,364 iteration 3122 : loss : 0.029146, loss_ce: 0.013316
2021-12-13 00:22:52,933 iteration 3123 : loss : 0.051766, loss_ce: 0.017892
2021-12-13 00:22:54,359 iteration 3124 : loss : 0.026701, loss_ce: 0.011218
2021-12-13 00:22:55,776 iteration 3125 : loss : 0.017872, loss_ce: 0.007430
2021-12-13 00:22:57,218 iteration 3126 : loss : 0.020284, loss_ce: 0.007844
2021-12-13 00:22:58,675 iteration 3127 : loss : 0.023364, loss_ce: 0.010012
2021-12-13 00:23:00,131 iteration 3128 : loss : 0.037981, loss_ce: 0.008333
 46%|████████████▍              | 184/400 [1:23:18<1:33:04, 25.85s/it]2021-12-13 00:23:01,602 iteration 3129 : loss : 0.025334, loss_ce: 0.008736
2021-12-13 00:23:03,032 iteration 3130 : loss : 0.023414, loss_ce: 0.009887
2021-12-13 00:23:04,547 iteration 3131 : loss : 0.025619, loss_ce: 0.013678
2021-12-13 00:23:06,032 iteration 3132 : loss : 0.023036, loss_ce: 0.008313
2021-12-13 00:23:07,461 iteration 3133 : loss : 0.020151, loss_ce: 0.008034
2021-12-13 00:23:08,958 iteration 3134 : loss : 0.025473, loss_ce: 0.009190
2021-12-13 00:23:10,439 iteration 3135 : loss : 0.033618, loss_ce: 0.006000
2021-12-13 00:23:11,839 iteration 3136 : loss : 0.019328, loss_ce: 0.008656
2021-12-13 00:23:13,255 iteration 3137 : loss : 0.019886, loss_ce: 0.008035
2021-12-13 00:23:14,696 iteration 3138 : loss : 0.021196, loss_ce: 0.008712
2021-12-13 00:23:16,281 iteration 3139 : loss : 0.038542, loss_ce: 0.011129
2021-12-13 00:23:17,774 iteration 3140 : loss : 0.024714, loss_ce: 0.008889
2021-12-13 00:23:19,215 iteration 3141 : loss : 0.022131, loss_ce: 0.009524
2021-12-13 00:23:20,615 iteration 3142 : loss : 0.023602, loss_ce: 0.008228
2021-12-13 00:23:22,113 iteration 3143 : loss : 0.042730, loss_ce: 0.013139
2021-12-13 00:23:23,627 iteration 3144 : loss : 0.029427, loss_ce: 0.007066
2021-12-13 00:23:23,627 Training Data Eval:
2021-12-13 00:23:31,139   Average segmentation loss on training set: 0.0171
2021-12-13 00:23:31,139 Validation Data Eval:
2021-12-13 00:23:33,736   Average segmentation loss on validation set: 0.0847
2021-12-13 00:23:35,153 iteration 3145 : loss : 0.028648, loss_ce: 0.011314
 46%|████████████▍              | 185/400 [1:23:53<1:42:29, 28.60s/it]2021-12-13 00:23:36,750 iteration 3146 : loss : 0.029255, loss_ce: 0.010501
2021-12-13 00:23:38,274 iteration 3147 : loss : 0.032023, loss_ce: 0.012993
2021-12-13 00:23:39,677 iteration 3148 : loss : 0.030782, loss_ce: 0.010891
2021-12-13 00:23:41,142 iteration 3149 : loss : 0.034816, loss_ce: 0.008840
2021-12-13 00:23:42,596 iteration 3150 : loss : 0.029018, loss_ce: 0.008564
2021-12-13 00:23:43,972 iteration 3151 : loss : 0.019912, loss_ce: 0.008885
2021-12-13 00:23:45,479 iteration 3152 : loss : 0.024057, loss_ce: 0.011575
2021-12-13 00:23:46,919 iteration 3153 : loss : 0.018989, loss_ce: 0.008671
2021-12-13 00:23:48,385 iteration 3154 : loss : 0.027543, loss_ce: 0.008905
2021-12-13 00:23:49,857 iteration 3155 : loss : 0.023612, loss_ce: 0.009156
2021-12-13 00:23:51,342 iteration 3156 : loss : 0.021943, loss_ce: 0.007185
2021-12-13 00:23:52,729 iteration 3157 : loss : 0.025394, loss_ce: 0.007459
2021-12-13 00:23:54,254 iteration 3158 : loss : 0.021975, loss_ce: 0.008146
2021-12-13 00:23:55,691 iteration 3159 : loss : 0.030762, loss_ce: 0.012194
2021-12-13 00:23:57,120 iteration 3160 : loss : 0.020785, loss_ce: 0.009891
2021-12-13 00:23:58,659 iteration 3161 : loss : 0.038085, loss_ce: 0.012893
2021-12-13 00:24:00,216 iteration 3162 : loss : 0.023569, loss_ce: 0.010177
 46%|████████████▌              | 186/400 [1:24:18<1:38:13, 27.54s/it]2021-12-13 00:24:01,657 iteration 3163 : loss : 0.026244, loss_ce: 0.007214
2021-12-13 00:24:03,058 iteration 3164 : loss : 0.030938, loss_ce: 0.007576
2021-12-13 00:24:04,486 iteration 3165 : loss : 0.015930, loss_ce: 0.006592
2021-12-13 00:24:05,939 iteration 3166 : loss : 0.027050, loss_ce: 0.012435
2021-12-13 00:24:07,404 iteration 3167 : loss : 0.029764, loss_ce: 0.010539
2021-12-13 00:24:08,816 iteration 3168 : loss : 0.020529, loss_ce: 0.009964
2021-12-13 00:24:10,284 iteration 3169 : loss : 0.021457, loss_ce: 0.008816
2021-12-13 00:24:11,771 iteration 3170 : loss : 0.023466, loss_ce: 0.010298
2021-12-13 00:24:13,303 iteration 3171 : loss : 0.033931, loss_ce: 0.010612
2021-12-13 00:24:14,808 iteration 3172 : loss : 0.025097, loss_ce: 0.010725
2021-12-13 00:24:16,303 iteration 3173 : loss : 0.020817, loss_ce: 0.007806
2021-12-13 00:24:17,815 iteration 3174 : loss : 0.025875, loss_ce: 0.010415
2021-12-13 00:24:19,254 iteration 3175 : loss : 0.019630, loss_ce: 0.007300
2021-12-13 00:24:20,717 iteration 3176 : loss : 0.023223, loss_ce: 0.012325
2021-12-13 00:24:22,130 iteration 3177 : loss : 0.022259, loss_ce: 0.010178
2021-12-13 00:24:23,592 iteration 3178 : loss : 0.025888, loss_ce: 0.007626
2021-12-13 00:24:25,078 iteration 3179 : loss : 0.038728, loss_ce: 0.012521
 47%|████████████▌              | 187/400 [1:24:43<1:34:55, 26.74s/it]2021-12-13 00:24:26,636 iteration 3180 : loss : 0.018974, loss_ce: 0.007206
2021-12-13 00:24:28,096 iteration 3181 : loss : 0.029036, loss_ce: 0.010482
2021-12-13 00:24:29,586 iteration 3182 : loss : 0.021154, loss_ce: 0.007430
2021-12-13 00:24:31,097 iteration 3183 : loss : 0.023345, loss_ce: 0.009729
2021-12-13 00:24:32,486 iteration 3184 : loss : 0.020136, loss_ce: 0.008730
2021-12-13 00:24:33,909 iteration 3185 : loss : 0.029850, loss_ce: 0.011859
2021-12-13 00:24:35,338 iteration 3186 : loss : 0.033866, loss_ce: 0.025299
2021-12-13 00:24:36,750 iteration 3187 : loss : 0.016597, loss_ce: 0.005103
2021-12-13 00:24:38,211 iteration 3188 : loss : 0.023435, loss_ce: 0.007435
2021-12-13 00:24:39,619 iteration 3189 : loss : 0.018399, loss_ce: 0.008652
2021-12-13 00:24:41,127 iteration 3190 : loss : 0.043347, loss_ce: 0.013865
2021-12-13 00:24:42,605 iteration 3191 : loss : 0.026187, loss_ce: 0.008691
2021-12-13 00:24:44,033 iteration 3192 : loss : 0.021430, loss_ce: 0.009249
2021-12-13 00:24:45,425 iteration 3193 : loss : 0.024385, loss_ce: 0.010009
2021-12-13 00:24:46,826 iteration 3194 : loss : 0.032129, loss_ce: 0.009932
2021-12-13 00:24:48,284 iteration 3195 : loss : 0.029399, loss_ce: 0.008186
2021-12-13 00:24:49,780 iteration 3196 : loss : 0.017569, loss_ce: 0.004782
 47%|████████████▋              | 188/400 [1:25:07<1:32:19, 26.13s/it]2021-12-13 00:24:51,256 iteration 3197 : loss : 0.020624, loss_ce: 0.006295
2021-12-13 00:24:52,659 iteration 3198 : loss : 0.023046, loss_ce: 0.007859
2021-12-13 00:24:54,059 iteration 3199 : loss : 0.025042, loss_ce: 0.008815
2021-12-13 00:24:55,493 iteration 3200 : loss : 0.029181, loss_ce: 0.016137
2021-12-13 00:24:56,988 iteration 3201 : loss : 0.026328, loss_ce: 0.008817
2021-12-13 00:24:58,467 iteration 3202 : loss : 0.022606, loss_ce: 0.008314
2021-12-13 00:24:59,859 iteration 3203 : loss : 0.020063, loss_ce: 0.004347
2021-12-13 00:25:01,345 iteration 3204 : loss : 0.021198, loss_ce: 0.010206
2021-12-13 00:25:02,838 iteration 3205 : loss : 0.019341, loss_ce: 0.006213
2021-12-13 00:25:04,253 iteration 3206 : loss : 0.027660, loss_ce: 0.012402
2021-12-13 00:25:05,664 iteration 3207 : loss : 0.018907, loss_ce: 0.005536
2021-12-13 00:25:07,098 iteration 3208 : loss : 0.032344, loss_ce: 0.011045
2021-12-13 00:25:08,602 iteration 3209 : loss : 0.019752, loss_ce: 0.007229
2021-12-13 00:25:10,066 iteration 3210 : loss : 0.027266, loss_ce: 0.007891
2021-12-13 00:25:11,568 iteration 3211 : loss : 0.022731, loss_ce: 0.010351
2021-12-13 00:25:13,074 iteration 3212 : loss : 0.022411, loss_ce: 0.009834
2021-12-13 00:25:14,515 iteration 3213 : loss : 0.022600, loss_ce: 0.010443
 47%|████████████▊              | 189/400 [1:25:32<1:30:24, 25.71s/it]2021-12-13 00:25:15,989 iteration 3214 : loss : 0.028173, loss_ce: 0.009847
2021-12-13 00:25:17,404 iteration 3215 : loss : 0.015569, loss_ce: 0.006644
2021-12-13 00:25:18,848 iteration 3216 : loss : 0.027402, loss_ce: 0.013989
2021-12-13 00:25:20,336 iteration 3217 : loss : 0.039040, loss_ce: 0.011295
2021-12-13 00:25:21,733 iteration 3218 : loss : 0.022316, loss_ce: 0.009436
2021-12-13 00:25:23,154 iteration 3219 : loss : 0.021432, loss_ce: 0.006780
2021-12-13 00:25:24,632 iteration 3220 : loss : 0.029956, loss_ce: 0.013621
2021-12-13 00:25:26,114 iteration 3221 : loss : 0.022191, loss_ce: 0.007708
2021-12-13 00:25:27,524 iteration 3222 : loss : 0.018284, loss_ce: 0.006790
2021-12-13 00:25:29,004 iteration 3223 : loss : 0.054024, loss_ce: 0.011052
2021-12-13 00:25:30,445 iteration 3224 : loss : 0.016331, loss_ce: 0.005877
2021-12-13 00:25:31,829 iteration 3225 : loss : 0.025520, loss_ce: 0.009053
2021-12-13 00:25:33,282 iteration 3226 : loss : 0.033266, loss_ce: 0.016895
2021-12-13 00:25:34,743 iteration 3227 : loss : 0.026372, loss_ce: 0.010285
2021-12-13 00:25:36,192 iteration 3228 : loss : 0.024857, loss_ce: 0.010190
2021-12-13 00:25:37,665 iteration 3229 : loss : 0.025016, loss_ce: 0.010097
2021-12-13 00:25:37,665 Training Data Eval:
2021-12-13 00:25:45,144   Average segmentation loss on training set: 0.0201
2021-12-13 00:25:45,145 Validation Data Eval:
2021-12-13 00:25:47,741   Average segmentation loss on validation set: 0.1095
2021-12-13 00:25:49,178 iteration 3230 : loss : 0.040476, loss_ce: 0.026900
 48%|████████████▊              | 190/400 [1:26:07<1:39:22, 28.39s/it]2021-12-13 00:25:50,570 iteration 3231 : loss : 0.027743, loss_ce: 0.010561
2021-12-13 00:25:52,024 iteration 3232 : loss : 0.021242, loss_ce: 0.008392
2021-12-13 00:25:53,481 iteration 3233 : loss : 0.034040, loss_ce: 0.009917
2021-12-13 00:25:54,904 iteration 3234 : loss : 0.019771, loss_ce: 0.007910
2021-12-13 00:25:56,368 iteration 3235 : loss : 0.022572, loss_ce: 0.009044
2021-12-13 00:25:57,718 iteration 3236 : loss : 0.022534, loss_ce: 0.011052
2021-12-13 00:25:59,156 iteration 3237 : loss : 0.022342, loss_ce: 0.009137
2021-12-13 00:26:00,614 iteration 3238 : loss : 0.035223, loss_ce: 0.015722
2021-12-13 00:26:01,998 iteration 3239 : loss : 0.023568, loss_ce: 0.010151
2021-12-13 00:26:03,487 iteration 3240 : loss : 0.027429, loss_ce: 0.011396
2021-12-13 00:26:05,025 iteration 3241 : loss : 0.031061, loss_ce: 0.009935
2021-12-13 00:26:06,506 iteration 3242 : loss : 0.022219, loss_ce: 0.007169
2021-12-13 00:26:08,002 iteration 3243 : loss : 0.035451, loss_ce: 0.013565
2021-12-13 00:26:09,407 iteration 3244 : loss : 0.025628, loss_ce: 0.008260
2021-12-13 00:26:10,867 iteration 3245 : loss : 0.024315, loss_ce: 0.007321
2021-12-13 00:26:12,336 iteration 3246 : loss : 0.039172, loss_ce: 0.012671
2021-12-13 00:26:13,877 iteration 3247 : loss : 0.082408, loss_ce: 0.032695
 48%|████████████▉              | 191/400 [1:26:31<1:35:02, 27.29s/it]2021-12-13 00:26:15,407 iteration 3248 : loss : 0.046770, loss_ce: 0.013727
2021-12-13 00:26:16,887 iteration 3249 : loss : 0.029973, loss_ce: 0.010907
2021-12-13 00:26:18,340 iteration 3250 : loss : 0.039744, loss_ce: 0.012998
2021-12-13 00:26:19,807 iteration 3251 : loss : 0.025800, loss_ce: 0.009063
2021-12-13 00:26:21,160 iteration 3252 : loss : 0.020993, loss_ce: 0.009646
2021-12-13 00:26:22,589 iteration 3253 : loss : 0.028828, loss_ce: 0.010327
2021-12-13 00:26:24,095 iteration 3254 : loss : 0.030475, loss_ce: 0.013000
2021-12-13 00:26:25,556 iteration 3255 : loss : 0.038469, loss_ce: 0.013836
2021-12-13 00:26:27,040 iteration 3256 : loss : 0.029266, loss_ce: 0.011666
2021-12-13 00:26:28,489 iteration 3257 : loss : 0.032820, loss_ce: 0.011220
2021-12-13 00:26:29,884 iteration 3258 : loss : 0.026308, loss_ce: 0.005563
2021-12-13 00:26:31,337 iteration 3259 : loss : 0.030320, loss_ce: 0.010293
2021-12-13 00:26:32,816 iteration 3260 : loss : 0.029164, loss_ce: 0.011711
2021-12-13 00:26:34,258 iteration 3261 : loss : 0.037613, loss_ce: 0.015101
2021-12-13 00:26:35,798 iteration 3262 : loss : 0.053357, loss_ce: 0.018404
2021-12-13 00:26:37,231 iteration 3263 : loss : 0.032055, loss_ce: 0.012736
2021-12-13 00:26:38,745 iteration 3264 : loss : 0.041094, loss_ce: 0.014795
 48%|████████████▉              | 192/400 [1:26:56<1:32:04, 26.56s/it]2021-12-13 00:26:40,232 iteration 3265 : loss : 0.033901, loss_ce: 0.014201
2021-12-13 00:26:41,712 iteration 3266 : loss : 0.024510, loss_ce: 0.008370
2021-12-13 00:26:43,169 iteration 3267 : loss : 0.022175, loss_ce: 0.006838
2021-12-13 00:26:44,636 iteration 3268 : loss : 0.029730, loss_ce: 0.010166
2021-12-13 00:26:46,044 iteration 3269 : loss : 0.023031, loss_ce: 0.011462
2021-12-13 00:26:47,488 iteration 3270 : loss : 0.024733, loss_ce: 0.009339
2021-12-13 00:26:48,858 iteration 3271 : loss : 0.025115, loss_ce: 0.007704
2021-12-13 00:26:50,388 iteration 3272 : loss : 0.036300, loss_ce: 0.011613
2021-12-13 00:26:51,845 iteration 3273 : loss : 0.025726, loss_ce: 0.010357
2021-12-13 00:26:53,244 iteration 3274 : loss : 0.027015, loss_ce: 0.009748
2021-12-13 00:26:54,673 iteration 3275 : loss : 0.031336, loss_ce: 0.012974
2021-12-13 00:26:56,099 iteration 3276 : loss : 0.022974, loss_ce: 0.006353
2021-12-13 00:26:57,479 iteration 3277 : loss : 0.016883, loss_ce: 0.005846
2021-12-13 00:26:58,932 iteration 3278 : loss : 0.021984, loss_ce: 0.008610
2021-12-13 00:27:00,316 iteration 3279 : loss : 0.025069, loss_ce: 0.014363
2021-12-13 00:27:01,856 iteration 3280 : loss : 0.017729, loss_ce: 0.006770
2021-12-13 00:27:03,306 iteration 3281 : loss : 0.023663, loss_ce: 0.007129
 48%|█████████████              | 193/400 [1:27:21<1:29:33, 25.96s/it]2021-12-13 00:27:04,832 iteration 3282 : loss : 0.029053, loss_ce: 0.007444
2021-12-13 00:27:06,320 iteration 3283 : loss : 0.034671, loss_ce: 0.014344
2021-12-13 00:27:07,785 iteration 3284 : loss : 0.024410, loss_ce: 0.009734
2021-12-13 00:27:09,273 iteration 3285 : loss : 0.040871, loss_ce: 0.020040
2021-12-13 00:27:10,728 iteration 3286 : loss : 0.034942, loss_ce: 0.010453
2021-12-13 00:27:12,261 iteration 3287 : loss : 0.034287, loss_ce: 0.015931
2021-12-13 00:27:13,664 iteration 3288 : loss : 0.025886, loss_ce: 0.010658
2021-12-13 00:27:15,223 iteration 3289 : loss : 0.020496, loss_ce: 0.007176
2021-12-13 00:27:16,733 iteration 3290 : loss : 0.031145, loss_ce: 0.012488
2021-12-13 00:27:18,245 iteration 3291 : loss : 0.025007, loss_ce: 0.011427
2021-12-13 00:27:19,692 iteration 3292 : loss : 0.036608, loss_ce: 0.011776
2021-12-13 00:27:21,132 iteration 3293 : loss : 0.028871, loss_ce: 0.007661
2021-12-13 00:27:22,675 iteration 3294 : loss : 0.030817, loss_ce: 0.012903
2021-12-13 00:27:24,167 iteration 3295 : loss : 0.022853, loss_ce: 0.010283
2021-12-13 00:27:25,572 iteration 3296 : loss : 0.026809, loss_ce: 0.009288
2021-12-13 00:27:27,011 iteration 3297 : loss : 0.022749, loss_ce: 0.008096
2021-12-13 00:27:28,573 iteration 3298 : loss : 0.020307, loss_ce: 0.009168
 48%|█████████████              | 194/400 [1:27:46<1:28:25, 25.75s/it]2021-12-13 00:27:29,998 iteration 3299 : loss : 0.022536, loss_ce: 0.005596
2021-12-13 00:27:31,497 iteration 3300 : loss : 0.026609, loss_ce: 0.009156
2021-12-13 00:27:32,950 iteration 3301 : loss : 0.023465, loss_ce: 0.010521
2021-12-13 00:27:34,386 iteration 3302 : loss : 0.029252, loss_ce: 0.009461
2021-12-13 00:27:35,900 iteration 3303 : loss : 0.022740, loss_ce: 0.010821
2021-12-13 00:27:37,395 iteration 3304 : loss : 0.041299, loss_ce: 0.016899
2021-12-13 00:27:38,838 iteration 3305 : loss : 0.020110, loss_ce: 0.006594
2021-12-13 00:27:40,283 iteration 3306 : loss : 0.019685, loss_ce: 0.005330
2021-12-13 00:27:41,848 iteration 3307 : loss : 0.049242, loss_ce: 0.028643
2021-12-13 00:27:43,359 iteration 3308 : loss : 0.031683, loss_ce: 0.014901
2021-12-13 00:27:44,852 iteration 3309 : loss : 0.026934, loss_ce: 0.010632
2021-12-13 00:27:46,257 iteration 3310 : loss : 0.020122, loss_ce: 0.010525
2021-12-13 00:27:47,788 iteration 3311 : loss : 0.039900, loss_ce: 0.012820
2021-12-13 00:27:49,242 iteration 3312 : loss : 0.021993, loss_ce: 0.005923
2021-12-13 00:27:50,755 iteration 3313 : loss : 0.023664, loss_ce: 0.009634
2021-12-13 00:27:52,199 iteration 3314 : loss : 0.023699, loss_ce: 0.007839
2021-12-13 00:27:52,199 Training Data Eval:
2021-12-13 00:27:59,674   Average segmentation loss on training set: 0.0196
2021-12-13 00:27:59,674 Validation Data Eval:
2021-12-13 00:28:02,272   Average segmentation loss on validation set: 0.0612
2021-12-13 00:28:08,638 Found new lowest validation loss at iteration 3314! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed2.pth
2021-12-13 00:28:09,963 iteration 3315 : loss : 0.019046, loss_ce: 0.007341
 49%|█████████████▏             | 195/400 [1:28:28<1:44:01, 30.44s/it]2021-12-13 00:28:11,325 iteration 3316 : loss : 0.016917, loss_ce: 0.007694
2021-12-13 00:28:12,702 iteration 3317 : loss : 0.024183, loss_ce: 0.010289
2021-12-13 00:28:14,055 iteration 3318 : loss : 0.031220, loss_ce: 0.013199
2021-12-13 00:28:15,370 iteration 3319 : loss : 0.020144, loss_ce: 0.007384
2021-12-13 00:28:16,823 iteration 3320 : loss : 0.057271, loss_ce: 0.026816
2021-12-13 00:28:18,164 iteration 3321 : loss : 0.017079, loss_ce: 0.005660
2021-12-13 00:28:19,585 iteration 3322 : loss : 0.034494, loss_ce: 0.012650
2021-12-13 00:28:20,902 iteration 3323 : loss : 0.019583, loss_ce: 0.006200
2021-12-13 00:28:22,269 iteration 3324 : loss : 0.023414, loss_ce: 0.009877
2021-12-13 00:28:23,687 iteration 3325 : loss : 0.023404, loss_ce: 0.008858
2021-12-13 00:28:25,078 iteration 3326 : loss : 0.020362, loss_ce: 0.007224
2021-12-13 00:28:26,536 iteration 3327 : loss : 0.020985, loss_ce: 0.007081
2021-12-13 00:28:28,095 iteration 3328 : loss : 0.021055, loss_ce: 0.007357
2021-12-13 00:28:29,584 iteration 3329 : loss : 0.034302, loss_ce: 0.014985
2021-12-13 00:28:31,047 iteration 3330 : loss : 0.020279, loss_ce: 0.009665
2021-12-13 00:28:32,458 iteration 3331 : loss : 0.022519, loss_ce: 0.010873
2021-12-13 00:28:33,965 iteration 3332 : loss : 0.020529, loss_ce: 0.006812
 49%|█████████████▏             | 196/400 [1:28:52<1:36:56, 28.51s/it]2021-12-13 00:28:35,510 iteration 3333 : loss : 0.027582, loss_ce: 0.009891
2021-12-13 00:28:36,987 iteration 3334 : loss : 0.025033, loss_ce: 0.011802
2021-12-13 00:28:38,532 iteration 3335 : loss : 0.025579, loss_ce: 0.010772
2021-12-13 00:28:39,991 iteration 3336 : loss : 0.039012, loss_ce: 0.010918
2021-12-13 00:28:41,505 iteration 3337 : loss : 0.028135, loss_ce: 0.011688
2021-12-13 00:28:43,089 iteration 3338 : loss : 0.025779, loss_ce: 0.012376
2021-12-13 00:28:44,500 iteration 3339 : loss : 0.017605, loss_ce: 0.006513
2021-12-13 00:28:45,907 iteration 3340 : loss : 0.028658, loss_ce: 0.007056
2021-12-13 00:28:47,369 iteration 3341 : loss : 0.029013, loss_ce: 0.011430
2021-12-13 00:28:48,819 iteration 3342 : loss : 0.021368, loss_ce: 0.009624
2021-12-13 00:28:50,313 iteration 3343 : loss : 0.019966, loss_ce: 0.008457
2021-12-13 00:28:51,789 iteration 3344 : loss : 0.024282, loss_ce: 0.008574
2021-12-13 00:28:53,267 iteration 3345 : loss : 0.023525, loss_ce: 0.008957
2021-12-13 00:28:54,704 iteration 3346 : loss : 0.017740, loss_ce: 0.007582
2021-12-13 00:28:56,140 iteration 3347 : loss : 0.021377, loss_ce: 0.008338
2021-12-13 00:28:57,534 iteration 3348 : loss : 0.019085, loss_ce: 0.006959
2021-12-13 00:28:59,066 iteration 3349 : loss : 0.037419, loss_ce: 0.011660
 49%|█████████████▎             | 197/400 [1:29:17<1:33:00, 27.49s/it]2021-12-13 00:29:00,587 iteration 3350 : loss : 0.025423, loss_ce: 0.008522
2021-12-13 00:29:02,099 iteration 3351 : loss : 0.024929, loss_ce: 0.008205
2021-12-13 00:29:03,595 iteration 3352 : loss : 0.034251, loss_ce: 0.015115
2021-12-13 00:29:05,146 iteration 3353 : loss : 0.022679, loss_ce: 0.007483
2021-12-13 00:29:06,584 iteration 3354 : loss : 0.023034, loss_ce: 0.010666
2021-12-13 00:29:08,109 iteration 3355 : loss : 0.035282, loss_ce: 0.013870
2021-12-13 00:29:09,627 iteration 3356 : loss : 0.029622, loss_ce: 0.009478
2021-12-13 00:29:11,076 iteration 3357 : loss : 0.038347, loss_ce: 0.010605
2021-12-13 00:29:12,587 iteration 3358 : loss : 0.016942, loss_ce: 0.006848
2021-12-13 00:29:13,981 iteration 3359 : loss : 0.022250, loss_ce: 0.008223
2021-12-13 00:29:15,419 iteration 3360 : loss : 0.022760, loss_ce: 0.008594
2021-12-13 00:29:16,881 iteration 3361 : loss : 0.021078, loss_ce: 0.008057
2021-12-13 00:29:18,350 iteration 3362 : loss : 0.025400, loss_ce: 0.009871
2021-12-13 00:29:19,895 iteration 3363 : loss : 0.025840, loss_ce: 0.007523
2021-12-13 00:29:21,310 iteration 3364 : loss : 0.018454, loss_ce: 0.008456
2021-12-13 00:29:22,816 iteration 3365 : loss : 0.033813, loss_ce: 0.016443
2021-12-13 00:29:24,200 iteration 3366 : loss : 0.020195, loss_ce: 0.008732
 50%|█████████████▎             | 198/400 [1:29:42<1:30:09, 26.78s/it]2021-12-13 00:29:25,704 iteration 3367 : loss : 0.019306, loss_ce: 0.007497
2021-12-13 00:29:27,154 iteration 3368 : loss : 0.016566, loss_ce: 0.007363
2021-12-13 00:29:28,557 iteration 3369 : loss : 0.020209, loss_ce: 0.006780
2021-12-13 00:29:30,077 iteration 3370 : loss : 0.040958, loss_ce: 0.023417
2021-12-13 00:29:31,656 iteration 3371 : loss : 0.037462, loss_ce: 0.014896
2021-12-13 00:29:33,081 iteration 3372 : loss : 0.016796, loss_ce: 0.006512
2021-12-13 00:29:34,561 iteration 3373 : loss : 0.022207, loss_ce: 0.008058
2021-12-13 00:29:35,982 iteration 3374 : loss : 0.021974, loss_ce: 0.007182
2021-12-13 00:29:37,413 iteration 3375 : loss : 0.028762, loss_ce: 0.011142
2021-12-13 00:29:38,886 iteration 3376 : loss : 0.027228, loss_ce: 0.008938
2021-12-13 00:29:40,263 iteration 3377 : loss : 0.013952, loss_ce: 0.005742
2021-12-13 00:29:41,766 iteration 3378 : loss : 0.036412, loss_ce: 0.008734
2021-12-13 00:29:43,337 iteration 3379 : loss : 0.034689, loss_ce: 0.016092
2021-12-13 00:29:44,852 iteration 3380 : loss : 0.034364, loss_ce: 0.012108
2021-12-13 00:29:46,357 iteration 3381 : loss : 0.028712, loss_ce: 0.010973
2021-12-13 00:29:47,839 iteration 3382 : loss : 0.021159, loss_ce: 0.008099
2021-12-13 00:29:49,282 iteration 3383 : loss : 0.024501, loss_ce: 0.008941
 50%|█████████████▍             | 199/400 [1:30:07<1:28:00, 26.27s/it]2021-12-13 00:29:50,853 iteration 3384 : loss : 0.026678, loss_ce: 0.008650
2021-12-13 00:29:52,350 iteration 3385 : loss : 0.029513, loss_ce: 0.011086
2021-12-13 00:29:53,777 iteration 3386 : loss : 0.018016, loss_ce: 0.005441
2021-12-13 00:29:55,301 iteration 3387 : loss : 0.035893, loss_ce: 0.014353
2021-12-13 00:29:56,781 iteration 3388 : loss : 0.023357, loss_ce: 0.009530
2021-12-13 00:29:58,209 iteration 3389 : loss : 0.017447, loss_ce: 0.007407
2021-12-13 00:29:59,574 iteration 3390 : loss : 0.016768, loss_ce: 0.006491
2021-12-13 00:30:01,084 iteration 3391 : loss : 0.024541, loss_ce: 0.008850
2021-12-13 00:30:02,587 iteration 3392 : loss : 0.027574, loss_ce: 0.009506
2021-12-13 00:30:04,085 iteration 3393 : loss : 0.022379, loss_ce: 0.009069
2021-12-13 00:30:05,590 iteration 3394 : loss : 0.021847, loss_ce: 0.007884
2021-12-13 00:30:06,991 iteration 3395 : loss : 0.018961, loss_ce: 0.008046
2021-12-13 00:30:08,495 iteration 3396 : loss : 0.020950, loss_ce: 0.007129
2021-12-13 00:30:09,992 iteration 3397 : loss : 0.022521, loss_ce: 0.008715
2021-12-13 00:30:11,488 iteration 3398 : loss : 0.023132, loss_ce: 0.009048
2021-12-13 00:30:12,941 iteration 3399 : loss : 0.021954, loss_ce: 0.008842
2021-12-13 00:30:12,942 Training Data Eval:
2021-12-13 00:30:20,447   Average segmentation loss on training set: 0.0153
2021-12-13 00:30:20,448 Validation Data Eval:
2021-12-13 00:30:23,045   Average segmentation loss on validation set: 0.0654
2021-12-13 00:30:24,457 iteration 3400 : loss : 0.021535, loss_ce: 0.007376
 50%|█████████████▌             | 200/400 [1:30:42<1:36:28, 28.94s/it]2021-12-13 00:30:25,983 iteration 3401 : loss : 0.022345, loss_ce: 0.010610
2021-12-13 00:30:27,398 iteration 3402 : loss : 0.019214, loss_ce: 0.007182
2021-12-13 00:30:28,951 iteration 3403 : loss : 0.033757, loss_ce: 0.011816
2021-12-13 00:30:30,472 iteration 3404 : loss : 0.029650, loss_ce: 0.010768
2021-12-13 00:30:31,887 iteration 3405 : loss : 0.024522, loss_ce: 0.007757
2021-12-13 00:30:33,415 iteration 3406 : loss : 0.019236, loss_ce: 0.008157
2021-12-13 00:30:34,848 iteration 3407 : loss : 0.025127, loss_ce: 0.009844
2021-12-13 00:30:36,242 iteration 3408 : loss : 0.021581, loss_ce: 0.008530
2021-12-13 00:30:37,719 iteration 3409 : loss : 0.020089, loss_ce: 0.006978
2021-12-13 00:30:39,217 iteration 3410 : loss : 0.023113, loss_ce: 0.009022
2021-12-13 00:30:40,724 iteration 3411 : loss : 0.052057, loss_ce: 0.023174
2021-12-13 00:30:42,217 iteration 3412 : loss : 0.024956, loss_ce: 0.009713
2021-12-13 00:30:43,682 iteration 3413 : loss : 0.024919, loss_ce: 0.006695
2021-12-13 00:30:45,202 iteration 3414 : loss : 0.026698, loss_ce: 0.011554
2021-12-13 00:30:46,690 iteration 3415 : loss : 0.021073, loss_ce: 0.010475
2021-12-13 00:30:48,231 iteration 3416 : loss : 0.039195, loss_ce: 0.011768
2021-12-13 00:30:49,745 iteration 3417 : loss : 0.046142, loss_ce: 0.021032
 50%|█████████████▌             | 201/400 [1:31:07<1:32:20, 27.84s/it]2021-12-13 00:30:51,192 iteration 3418 : loss : 0.019765, loss_ce: 0.007317
2021-12-13 00:30:52,570 iteration 3419 : loss : 0.020050, loss_ce: 0.009416
2021-12-13 00:30:54,010 iteration 3420 : loss : 0.026147, loss_ce: 0.009417
2021-12-13 00:30:55,429 iteration 3421 : loss : 0.030058, loss_ce: 0.010677
2021-12-13 00:30:56,839 iteration 3422 : loss : 0.025578, loss_ce: 0.008462
2021-12-13 00:30:58,328 iteration 3423 : loss : 0.040911, loss_ce: 0.020483
2021-12-13 00:30:59,810 iteration 3424 : loss : 0.038230, loss_ce: 0.017337
2021-12-13 00:31:01,301 iteration 3425 : loss : 0.025283, loss_ce: 0.009443
2021-12-13 00:31:02,667 iteration 3426 : loss : 0.031941, loss_ce: 0.013697
2021-12-13 00:31:04,142 iteration 3427 : loss : 0.033983, loss_ce: 0.010231
2021-12-13 00:31:05,638 iteration 3428 : loss : 0.030956, loss_ce: 0.013132
2021-12-13 00:31:07,064 iteration 3429 : loss : 0.021024, loss_ce: 0.006975
2021-12-13 00:31:08,554 iteration 3430 : loss : 0.030608, loss_ce: 0.011639
2021-12-13 00:31:10,030 iteration 3431 : loss : 0.026751, loss_ce: 0.009445
2021-12-13 00:31:11,564 iteration 3432 : loss : 0.029536, loss_ce: 0.011493
2021-12-13 00:31:13,080 iteration 3433 : loss : 0.031909, loss_ce: 0.011865
2021-12-13 00:31:14,556 iteration 3434 : loss : 0.025220, loss_ce: 0.008229
 50%|█████████████▋             | 202/400 [1:31:32<1:28:52, 26.93s/it]2021-12-13 00:31:16,047 iteration 3435 : loss : 0.029461, loss_ce: 0.010592
2021-12-13 00:31:17,558 iteration 3436 : loss : 0.035832, loss_ce: 0.015528
2021-12-13 00:31:19,086 iteration 3437 : loss : 0.024320, loss_ce: 0.008582
2021-12-13 00:31:20,615 iteration 3438 : loss : 0.037227, loss_ce: 0.013953
2021-12-13 00:31:22,049 iteration 3439 : loss : 0.021125, loss_ce: 0.007482
2021-12-13 00:31:23,552 iteration 3440 : loss : 0.028714, loss_ce: 0.011242
2021-12-13 00:31:24,998 iteration 3441 : loss : 0.027996, loss_ce: 0.009061
2021-12-13 00:31:26,472 iteration 3442 : loss : 0.021167, loss_ce: 0.008233
2021-12-13 00:31:28,027 iteration 3443 : loss : 0.025276, loss_ce: 0.010588
2021-12-13 00:31:29,485 iteration 3444 : loss : 0.036859, loss_ce: 0.011505
2021-12-13 00:31:30,981 iteration 3445 : loss : 0.024696, loss_ce: 0.010645
2021-12-13 00:31:32,505 iteration 3446 : loss : 0.024390, loss_ce: 0.010835
2021-12-13 00:31:34,020 iteration 3447 : loss : 0.037025, loss_ce: 0.014137
2021-12-13 00:31:35,434 iteration 3448 : loss : 0.023254, loss_ce: 0.008494
2021-12-13 00:31:36,867 iteration 3449 : loss : 0.021510, loss_ce: 0.008662
2021-12-13 00:31:38,314 iteration 3450 : loss : 0.021798, loss_ce: 0.007149
2021-12-13 00:31:39,760 iteration 3451 : loss : 0.016846, loss_ce: 0.008099
 51%|█████████████▋             | 203/400 [1:31:57<1:26:44, 26.42s/it]2021-12-13 00:31:41,175 iteration 3452 : loss : 0.019564, loss_ce: 0.009421
2021-12-13 00:31:42,682 iteration 3453 : loss : 0.024058, loss_ce: 0.007984
2021-12-13 00:31:44,280 iteration 3454 : loss : 0.030749, loss_ce: 0.012377
2021-12-13 00:31:45,719 iteration 3455 : loss : 0.026322, loss_ce: 0.011826
2021-12-13 00:31:47,207 iteration 3456 : loss : 0.031436, loss_ce: 0.008256
2021-12-13 00:31:48,627 iteration 3457 : loss : 0.020197, loss_ce: 0.008057
2021-12-13 00:31:50,028 iteration 3458 : loss : 0.035519, loss_ce: 0.009552
2021-12-13 00:31:51,558 iteration 3459 : loss : 0.024056, loss_ce: 0.010157
2021-12-13 00:31:52,975 iteration 3460 : loss : 0.018339, loss_ce: 0.007282
2021-12-13 00:31:54,401 iteration 3461 : loss : 0.018649, loss_ce: 0.006167
2021-12-13 00:31:55,765 iteration 3462 : loss : 0.017397, loss_ce: 0.007887
2021-12-13 00:31:57,273 iteration 3463 : loss : 0.023943, loss_ce: 0.010154
2021-12-13 00:31:58,765 iteration 3464 : loss : 0.025531, loss_ce: 0.007850
2021-12-13 00:32:00,200 iteration 3465 : loss : 0.019313, loss_ce: 0.007124
2021-12-13 00:32:01,745 iteration 3466 : loss : 0.026923, loss_ce: 0.010735
2021-12-13 00:32:03,123 iteration 3467 : loss : 0.018015, loss_ce: 0.007160
2021-12-13 00:32:04,562 iteration 3468 : loss : 0.021717, loss_ce: 0.006923
 51%|█████████████▊             | 204/400 [1:32:22<1:24:42, 25.93s/it]2021-12-13 00:32:06,042 iteration 3469 : loss : 0.019292, loss_ce: 0.007097
2021-12-13 00:32:07,508 iteration 3470 : loss : 0.021740, loss_ce: 0.008638
2021-12-13 00:32:09,054 iteration 3471 : loss : 0.022312, loss_ce: 0.008899
2021-12-13 00:32:10,597 iteration 3472 : loss : 0.025981, loss_ce: 0.008456
2021-12-13 00:32:12,020 iteration 3473 : loss : 0.017680, loss_ce: 0.007950
2021-12-13 00:32:13,549 iteration 3474 : loss : 0.021010, loss_ce: 0.007548
2021-12-13 00:32:15,014 iteration 3475 : loss : 0.018186, loss_ce: 0.007760
2021-12-13 00:32:16,444 iteration 3476 : loss : 0.030531, loss_ce: 0.010734
2021-12-13 00:32:17,894 iteration 3477 : loss : 0.019737, loss_ce: 0.006526
2021-12-13 00:32:19,367 iteration 3478 : loss : 0.019148, loss_ce: 0.008927
2021-12-13 00:32:20,828 iteration 3479 : loss : 0.021547, loss_ce: 0.010233
2021-12-13 00:32:22,252 iteration 3480 : loss : 0.019053, loss_ce: 0.009561
2021-12-13 00:32:23,693 iteration 3481 : loss : 0.026809, loss_ce: 0.010005
2021-12-13 00:32:25,163 iteration 3482 : loss : 0.020535, loss_ce: 0.008073
2021-12-13 00:32:26,703 iteration 3483 : loss : 0.023948, loss_ce: 0.010423
2021-12-13 00:32:28,181 iteration 3484 : loss : 0.023131, loss_ce: 0.006831
2021-12-13 00:32:28,181 Training Data Eval:
2021-12-13 00:32:35,695   Average segmentation loss on training set: 0.0201
2021-12-13 00:32:35,695 Validation Data Eval:
2021-12-13 00:32:38,297   Average segmentation loss on validation set: 0.1266
2021-12-13 00:32:39,758 iteration 3485 : loss : 0.017148, loss_ce: 0.006256
 51%|█████████████▊             | 205/400 [1:32:57<1:33:18, 28.71s/it]2021-12-13 00:32:41,289 iteration 3486 : loss : 0.019357, loss_ce: 0.005041
2021-12-13 00:32:42,765 iteration 3487 : loss : 0.022466, loss_ce: 0.009896
2021-12-13 00:32:44,236 iteration 3488 : loss : 0.026071, loss_ce: 0.008561
2021-12-13 00:32:45,597 iteration 3489 : loss : 0.020655, loss_ce: 0.009558
2021-12-13 00:32:47,104 iteration 3490 : loss : 0.028615, loss_ce: 0.011298
2021-12-13 00:32:48,667 iteration 3491 : loss : 0.027493, loss_ce: 0.012106
2021-12-13 00:32:50,144 iteration 3492 : loss : 0.024438, loss_ce: 0.010208
2021-12-13 00:32:51,590 iteration 3493 : loss : 0.030979, loss_ce: 0.011427
2021-12-13 00:32:53,060 iteration 3494 : loss : 0.019799, loss_ce: 0.007346
2021-12-13 00:32:54,544 iteration 3495 : loss : 0.026570, loss_ce: 0.008885
2021-12-13 00:32:56,108 iteration 3496 : loss : 0.027170, loss_ce: 0.010458
2021-12-13 00:32:57,570 iteration 3497 : loss : 0.018810, loss_ce: 0.007815
2021-12-13 00:32:59,079 iteration 3498 : loss : 0.023299, loss_ce: 0.008826
2021-12-13 00:33:00,507 iteration 3499 : loss : 0.020492, loss_ce: 0.009743
2021-12-13 00:33:01,979 iteration 3500 : loss : 0.024150, loss_ce: 0.012160
2021-12-13 00:33:03,538 iteration 3501 : loss : 0.029121, loss_ce: 0.013348
2021-12-13 00:33:04,998 iteration 3502 : loss : 0.020656, loss_ce: 0.010314
 52%|█████████████▉             | 206/400 [1:33:23<1:29:27, 27.67s/it]2021-12-13 00:33:06,524 iteration 3503 : loss : 0.036991, loss_ce: 0.009970
2021-12-13 00:33:07,994 iteration 3504 : loss : 0.017814, loss_ce: 0.006469
2021-12-13 00:33:09,463 iteration 3505 : loss : 0.017621, loss_ce: 0.008002
2021-12-13 00:33:10,967 iteration 3506 : loss : 0.032177, loss_ce: 0.010499
2021-12-13 00:33:12,366 iteration 3507 : loss : 0.031281, loss_ce: 0.012169
2021-12-13 00:33:13,823 iteration 3508 : loss : 0.038230, loss_ce: 0.014411
2021-12-13 00:33:15,327 iteration 3509 : loss : 0.023275, loss_ce: 0.008718
2021-12-13 00:33:16,794 iteration 3510 : loss : 0.022364, loss_ce: 0.008763
2021-12-13 00:33:18,441 iteration 3511 : loss : 0.025204, loss_ce: 0.010647
2021-12-13 00:33:19,846 iteration 3512 : loss : 0.019727, loss_ce: 0.007952
2021-12-13 00:33:21,236 iteration 3513 : loss : 0.022494, loss_ce: 0.009781
2021-12-13 00:33:22,704 iteration 3514 : loss : 0.019462, loss_ce: 0.007788
2021-12-13 00:33:24,161 iteration 3515 : loss : 0.032189, loss_ce: 0.014611
2021-12-13 00:33:25,608 iteration 3516 : loss : 0.018459, loss_ce: 0.008514
2021-12-13 00:33:27,070 iteration 3517 : loss : 0.019341, loss_ce: 0.008948
2021-12-13 00:33:28,620 iteration 3518 : loss : 0.049383, loss_ce: 0.017527
2021-12-13 00:33:30,128 iteration 3519 : loss : 0.021639, loss_ce: 0.009108
 52%|█████████████▉             | 207/400 [1:33:48<1:26:33, 26.91s/it]2021-12-13 00:33:31,567 iteration 3520 : loss : 0.020955, loss_ce: 0.007218
2021-12-13 00:33:33,013 iteration 3521 : loss : 0.024494, loss_ce: 0.005973
2021-12-13 00:33:34,426 iteration 3522 : loss : 0.024375, loss_ce: 0.006542
2021-12-13 00:33:35,905 iteration 3523 : loss : 0.019633, loss_ce: 0.009373
2021-12-13 00:33:37,440 iteration 3524 : loss : 0.021150, loss_ce: 0.008397
2021-12-13 00:33:38,879 iteration 3525 : loss : 0.022688, loss_ce: 0.006377
2021-12-13 00:33:40,372 iteration 3526 : loss : 0.020854, loss_ce: 0.010053
2021-12-13 00:33:41,928 iteration 3527 : loss : 0.031132, loss_ce: 0.012965
2021-12-13 00:33:43,387 iteration 3528 : loss : 0.035169, loss_ce: 0.007388
2021-12-13 00:33:44,851 iteration 3529 : loss : 0.020057, loss_ce: 0.006610
2021-12-13 00:33:46,318 iteration 3530 : loss : 0.027127, loss_ce: 0.010476
2021-12-13 00:33:47,781 iteration 3531 : loss : 0.024530, loss_ce: 0.008620
2021-12-13 00:33:49,251 iteration 3532 : loss : 0.020815, loss_ce: 0.008916
2021-12-13 00:33:50,730 iteration 3533 : loss : 0.025924, loss_ce: 0.009317
2021-12-13 00:33:52,134 iteration 3534 : loss : 0.029512, loss_ce: 0.009989
2021-12-13 00:33:53,614 iteration 3535 : loss : 0.021540, loss_ce: 0.007986
2021-12-13 00:33:55,071 iteration 3536 : loss : 0.025742, loss_ce: 0.010668
 52%|██████████████             | 208/400 [1:34:13<1:24:12, 26.32s/it]2021-12-13 00:33:56,660 iteration 3537 : loss : 0.024742, loss_ce: 0.010890
2021-12-13 00:33:58,089 iteration 3538 : loss : 0.021285, loss_ce: 0.007946
2021-12-13 00:33:59,532 iteration 3539 : loss : 0.024750, loss_ce: 0.009029
2021-12-13 00:34:01,030 iteration 3540 : loss : 0.022859, loss_ce: 0.010710
2021-12-13 00:34:02,536 iteration 3541 : loss : 0.020220, loss_ce: 0.007143
2021-12-13 00:34:04,011 iteration 3542 : loss : 0.022165, loss_ce: 0.008917
2021-12-13 00:34:05,538 iteration 3543 : loss : 0.024972, loss_ce: 0.009567
2021-12-13 00:34:07,050 iteration 3544 : loss : 0.042012, loss_ce: 0.007734
2021-12-13 00:34:08,577 iteration 3545 : loss : 0.023821, loss_ce: 0.007587
2021-12-13 00:34:10,102 iteration 3546 : loss : 0.024249, loss_ce: 0.007572
2021-12-13 00:34:11,643 iteration 3547 : loss : 0.022312, loss_ce: 0.010336
2021-12-13 00:34:13,076 iteration 3548 : loss : 0.016701, loss_ce: 0.004679
2021-12-13 00:34:14,635 iteration 3549 : loss : 0.033751, loss_ce: 0.015147
2021-12-13 00:34:16,083 iteration 3550 : loss : 0.018950, loss_ce: 0.006313
2021-12-13 00:34:17,517 iteration 3551 : loss : 0.019667, loss_ce: 0.008432
2021-12-13 00:34:18,955 iteration 3552 : loss : 0.028942, loss_ce: 0.013733
2021-12-13 00:34:20,407 iteration 3553 : loss : 0.017894, loss_ce: 0.006228
 52%|██████████████             | 209/400 [1:34:38<1:22:50, 26.03s/it]2021-12-13 00:34:21,913 iteration 3554 : loss : 0.023506, loss_ce: 0.008859
2021-12-13 00:34:23,371 iteration 3555 : loss : 0.029293, loss_ce: 0.012209
2021-12-13 00:34:24,902 iteration 3556 : loss : 0.020066, loss_ce: 0.007819
2021-12-13 00:34:26,444 iteration 3557 : loss : 0.022432, loss_ce: 0.009730
2021-12-13 00:34:27,905 iteration 3558 : loss : 0.019536, loss_ce: 0.005930
2021-12-13 00:34:29,381 iteration 3559 : loss : 0.030022, loss_ce: 0.007631
2021-12-13 00:34:30,827 iteration 3560 : loss : 0.019869, loss_ce: 0.007361
2021-12-13 00:34:32,209 iteration 3561 : loss : 0.015790, loss_ce: 0.007526
2021-12-13 00:34:33,683 iteration 3562 : loss : 0.023268, loss_ce: 0.008225
2021-12-13 00:34:35,142 iteration 3563 : loss : 0.028271, loss_ce: 0.010151
2021-12-13 00:34:36,652 iteration 3564 : loss : 0.071232, loss_ce: 0.023831
2021-12-13 00:34:38,079 iteration 3565 : loss : 0.022852, loss_ce: 0.005973
2021-12-13 00:34:39,511 iteration 3566 : loss : 0.021189, loss_ce: 0.008197
2021-12-13 00:34:41,057 iteration 3567 : loss : 0.026773, loss_ce: 0.014139
2021-12-13 00:34:42,518 iteration 3568 : loss : 0.028261, loss_ce: 0.012238
2021-12-13 00:34:43,946 iteration 3569 : loss : 0.029452, loss_ce: 0.012587
2021-12-13 00:34:43,947 Training Data Eval:
2021-12-13 00:34:51,461   Average segmentation loss on training set: 0.0674
2021-12-13 00:34:51,461 Validation Data Eval:
2021-12-13 00:34:54,062   Average segmentation loss on validation set: 0.1003
2021-12-13 00:34:55,572 iteration 3570 : loss : 0.077297, loss_ce: 0.037794
 52%|██████████████▏            | 210/400 [1:35:13<1:31:05, 28.77s/it]2021-12-13 00:34:57,108 iteration 3571 : loss : 0.033949, loss_ce: 0.017676
2021-12-13 00:34:58,526 iteration 3572 : loss : 0.025321, loss_ce: 0.011883
2021-12-13 00:35:00,024 iteration 3573 : loss : 0.027680, loss_ce: 0.009373
2021-12-13 00:35:01,484 iteration 3574 : loss : 0.028862, loss_ce: 0.008942
2021-12-13 00:35:02,894 iteration 3575 : loss : 0.020308, loss_ce: 0.007441
2021-12-13 00:35:04,397 iteration 3576 : loss : 0.021402, loss_ce: 0.006957
2021-12-13 00:35:05,872 iteration 3577 : loss : 0.026295, loss_ce: 0.011072
2021-12-13 00:35:07,256 iteration 3578 : loss : 0.029191, loss_ce: 0.011773
2021-12-13 00:35:08,695 iteration 3579 : loss : 0.038085, loss_ce: 0.018106
2021-12-13 00:35:10,113 iteration 3580 : loss : 0.023164, loss_ce: 0.010566
2021-12-13 00:35:11,523 iteration 3581 : loss : 0.027638, loss_ce: 0.015735
2021-12-13 00:35:12,977 iteration 3582 : loss : 0.031619, loss_ce: 0.013279
2021-12-13 00:35:14,471 iteration 3583 : loss : 0.028630, loss_ce: 0.009493
2021-12-13 00:35:15,942 iteration 3584 : loss : 0.022685, loss_ce: 0.008054
2021-12-13 00:35:17,363 iteration 3585 : loss : 0.029259, loss_ce: 0.012294
2021-12-13 00:35:18,885 iteration 3586 : loss : 0.033000, loss_ce: 0.015648
2021-12-13 00:35:20,334 iteration 3587 : loss : 0.024466, loss_ce: 0.009701
 53%|██████████████▏            | 211/400 [1:35:38<1:26:49, 27.57s/it]2021-12-13 00:35:21,898 iteration 3588 : loss : 0.017921, loss_ce: 0.007811
2021-12-13 00:35:23,307 iteration 3589 : loss : 0.034068, loss_ce: 0.013575
2021-12-13 00:35:24,747 iteration 3590 : loss : 0.018938, loss_ce: 0.007048
2021-12-13 00:35:26,221 iteration 3591 : loss : 0.022261, loss_ce: 0.007191
2021-12-13 00:35:27,832 iteration 3592 : loss : 0.044574, loss_ce: 0.018646
2021-12-13 00:35:29,252 iteration 3593 : loss : 0.031642, loss_ce: 0.011569
2021-12-13 00:35:30,706 iteration 3594 : loss : 0.026877, loss_ce: 0.009442
2021-12-13 00:35:32,188 iteration 3595 : loss : 0.031885, loss_ce: 0.013008
2021-12-13 00:35:33,629 iteration 3596 : loss : 0.016145, loss_ce: 0.005888
2021-12-13 00:35:35,113 iteration 3597 : loss : 0.027980, loss_ce: 0.012602
2021-12-13 00:35:36,514 iteration 3598 : loss : 0.014761, loss_ce: 0.006094
2021-12-13 00:35:38,015 iteration 3599 : loss : 0.029452, loss_ce: 0.010012
2021-12-13 00:35:39,380 iteration 3600 : loss : 0.018624, loss_ce: 0.007625
2021-12-13 00:35:40,840 iteration 3601 : loss : 0.027419, loss_ce: 0.012638
2021-12-13 00:35:42,257 iteration 3602 : loss : 0.020592, loss_ce: 0.006965
2021-12-13 00:35:43,734 iteration 3603 : loss : 0.025540, loss_ce: 0.013137
2021-12-13 00:35:45,125 iteration 3604 : loss : 0.018149, loss_ce: 0.007820
 53%|██████████████▎            | 212/400 [1:36:03<1:23:45, 26.73s/it]2021-12-13 00:35:46,629 iteration 3605 : loss : 0.034201, loss_ce: 0.012576
2021-12-13 00:35:48,082 iteration 3606 : loss : 0.025320, loss_ce: 0.013362
2021-12-13 00:35:49,563 iteration 3607 : loss : 0.022176, loss_ce: 0.008196
2021-12-13 00:35:50,997 iteration 3608 : loss : 0.017772, loss_ce: 0.006962
2021-12-13 00:35:52,432 iteration 3609 : loss : 0.018356, loss_ce: 0.008013
2021-12-13 00:35:53,911 iteration 3610 : loss : 0.017926, loss_ce: 0.007135
2021-12-13 00:35:55,306 iteration 3611 : loss : 0.021992, loss_ce: 0.006759
2021-12-13 00:35:56,707 iteration 3612 : loss : 0.020630, loss_ce: 0.007467
2021-12-13 00:35:58,268 iteration 3613 : loss : 0.026837, loss_ce: 0.011010
2021-12-13 00:35:59,670 iteration 3614 : loss : 0.016690, loss_ce: 0.006428
2021-12-13 00:36:01,041 iteration 3615 : loss : 0.016629, loss_ce: 0.006142
2021-12-13 00:36:02,528 iteration 3616 : loss : 0.022897, loss_ce: 0.008934
2021-12-13 00:36:04,018 iteration 3617 : loss : 0.038544, loss_ce: 0.015053
2021-12-13 00:36:05,479 iteration 3618 : loss : 0.017169, loss_ce: 0.007112
2021-12-13 00:36:06,944 iteration 3619 : loss : 0.027163, loss_ce: 0.007424
2021-12-13 00:36:08,371 iteration 3620 : loss : 0.022780, loss_ce: 0.006325
2021-12-13 00:36:09,851 iteration 3621 : loss : 0.025782, loss_ce: 0.010470
 53%|██████████████▍            | 213/400 [1:36:27<1:21:26, 26.13s/it]2021-12-13 00:36:11,347 iteration 3622 : loss : 0.023789, loss_ce: 0.013005
2021-12-13 00:36:12,851 iteration 3623 : loss : 0.020255, loss_ce: 0.004757
2021-12-13 00:36:14,302 iteration 3624 : loss : 0.013438, loss_ce: 0.005465
2021-12-13 00:36:15,758 iteration 3625 : loss : 0.018766, loss_ce: 0.007453
2021-12-13 00:36:17,181 iteration 3626 : loss : 0.022834, loss_ce: 0.010675
2021-12-13 00:36:18,586 iteration 3627 : loss : 0.016121, loss_ce: 0.006145
2021-12-13 00:36:20,112 iteration 3628 : loss : 0.043137, loss_ce: 0.012355
2021-12-13 00:36:21,719 iteration 3629 : loss : 0.024006, loss_ce: 0.008769
2021-12-13 00:36:23,088 iteration 3630 : loss : 0.019589, loss_ce: 0.007604
2021-12-13 00:36:24,554 iteration 3631 : loss : 0.022857, loss_ce: 0.006730
2021-12-13 00:36:26,145 iteration 3632 : loss : 0.020727, loss_ce: 0.006293
2021-12-13 00:36:27,589 iteration 3633 : loss : 0.017770, loss_ce: 0.006222
2021-12-13 00:36:29,030 iteration 3634 : loss : 0.023664, loss_ce: 0.010562
2021-12-13 00:36:30,583 iteration 3635 : loss : 0.037192, loss_ce: 0.016049
2021-12-13 00:36:32,103 iteration 3636 : loss : 0.026586, loss_ce: 0.008107
2021-12-13 00:36:33,569 iteration 3637 : loss : 0.025930, loss_ce: 0.008324
2021-12-13 00:36:35,017 iteration 3638 : loss : 0.022935, loss_ce: 0.011030
 54%|██████████████▍            | 214/400 [1:36:53<1:20:06, 25.84s/it]2021-12-13 00:36:36,460 iteration 3639 : loss : 0.018876, loss_ce: 0.007827
2021-12-13 00:36:37,868 iteration 3640 : loss : 0.021456, loss_ce: 0.008643
2021-12-13 00:36:39,269 iteration 3641 : loss : 0.017537, loss_ce: 0.005940
2021-12-13 00:36:40,730 iteration 3642 : loss : 0.023169, loss_ce: 0.006940
2021-12-13 00:36:42,144 iteration 3643 : loss : 0.022027, loss_ce: 0.008842
2021-12-13 00:36:43,578 iteration 3644 : loss : 0.013003, loss_ce: 0.004701
2021-12-13 00:36:45,027 iteration 3645 : loss : 0.020396, loss_ce: 0.006862
2021-12-13 00:36:46,493 iteration 3646 : loss : 0.025324, loss_ce: 0.008817
2021-12-13 00:36:47,964 iteration 3647 : loss : 0.025904, loss_ce: 0.007103
2021-12-13 00:36:49,445 iteration 3648 : loss : 0.024194, loss_ce: 0.008561
2021-12-13 00:36:50,877 iteration 3649 : loss : 0.018284, loss_ce: 0.004979
2021-12-13 00:36:52,349 iteration 3650 : loss : 0.018321, loss_ce: 0.009256
2021-12-13 00:36:53,830 iteration 3651 : loss : 0.026704, loss_ce: 0.009060
2021-12-13 00:36:55,399 iteration 3652 : loss : 0.031570, loss_ce: 0.009724
2021-12-13 00:36:56,804 iteration 3653 : loss : 0.019397, loss_ce: 0.010948
2021-12-13 00:36:58,195 iteration 3654 : loss : 0.018120, loss_ce: 0.009040
2021-12-13 00:36:58,195 Training Data Eval:
2021-12-13 00:37:05,718   Average segmentation loss on training set: 0.0143
2021-12-13 00:37:05,718 Validation Data Eval:
2021-12-13 00:37:08,323   Average segmentation loss on validation set: 0.0655
2021-12-13 00:37:09,813 iteration 3655 : loss : 0.022949, loss_ce: 0.010918
 54%|██████████████▌            | 215/400 [1:37:27<1:27:57, 28.53s/it]2021-12-13 00:37:11,364 iteration 3656 : loss : 0.021218, loss_ce: 0.010392
2021-12-13 00:37:12,769 iteration 3657 : loss : 0.017475, loss_ce: 0.008657
2021-12-13 00:37:14,272 iteration 3658 : loss : 0.018678, loss_ce: 0.008291
2021-12-13 00:37:15,829 iteration 3659 : loss : 0.026522, loss_ce: 0.008544
2021-12-13 00:37:17,285 iteration 3660 : loss : 0.021474, loss_ce: 0.004631
2021-12-13 00:37:18,680 iteration 3661 : loss : 0.018892, loss_ce: 0.007957
2021-12-13 00:37:20,137 iteration 3662 : loss : 0.017537, loss_ce: 0.006201
2021-12-13 00:37:21,573 iteration 3663 : loss : 0.021343, loss_ce: 0.006313
2021-12-13 00:37:23,054 iteration 3664 : loss : 0.017151, loss_ce: 0.007034
2021-12-13 00:37:24,510 iteration 3665 : loss : 0.018214, loss_ce: 0.009081
2021-12-13 00:37:25,954 iteration 3666 : loss : 0.026984, loss_ce: 0.009853
2021-12-13 00:37:27,390 iteration 3667 : loss : 0.023808, loss_ce: 0.010474
2021-12-13 00:37:28,768 iteration 3668 : loss : 0.016500, loss_ce: 0.003484
2021-12-13 00:37:30,279 iteration 3669 : loss : 0.029720, loss_ce: 0.016468
2021-12-13 00:37:31,695 iteration 3670 : loss : 0.014332, loss_ce: 0.005419
2021-12-13 00:37:33,135 iteration 3671 : loss : 0.016278, loss_ce: 0.007268
2021-12-13 00:37:34,716 iteration 3672 : loss : 0.031422, loss_ce: 0.008512
 54%|██████████████▌            | 216/400 [1:37:52<1:24:09, 27.44s/it]2021-12-13 00:37:36,219 iteration 3673 : loss : 0.021363, loss_ce: 0.009756
2021-12-13 00:37:37,730 iteration 3674 : loss : 0.023773, loss_ce: 0.005863
2021-12-13 00:37:39,267 iteration 3675 : loss : 0.022651, loss_ce: 0.007965
2021-12-13 00:37:40,638 iteration 3676 : loss : 0.016239, loss_ce: 0.006495
2021-12-13 00:37:42,100 iteration 3677 : loss : 0.021905, loss_ce: 0.007477
2021-12-13 00:37:43,618 iteration 3678 : loss : 0.023285, loss_ce: 0.007277
2021-12-13 00:37:45,063 iteration 3679 : loss : 0.016334, loss_ce: 0.005929
2021-12-13 00:37:46,519 iteration 3680 : loss : 0.036454, loss_ce: 0.016726
2021-12-13 00:37:47,959 iteration 3681 : loss : 0.025277, loss_ce: 0.010798
2021-12-13 00:37:49,335 iteration 3682 : loss : 0.018411, loss_ce: 0.007120
2021-12-13 00:37:50,702 iteration 3683 : loss : 0.016817, loss_ce: 0.005948
2021-12-13 00:37:52,213 iteration 3684 : loss : 0.015817, loss_ce: 0.006944
2021-12-13 00:37:53,642 iteration 3685 : loss : 0.018575, loss_ce: 0.005937
2021-12-13 00:37:55,116 iteration 3686 : loss : 0.029946, loss_ce: 0.012515
2021-12-13 00:37:56,547 iteration 3687 : loss : 0.017771, loss_ce: 0.006054
2021-12-13 00:37:57,994 iteration 3688 : loss : 0.020826, loss_ce: 0.011062
2021-12-13 00:37:59,472 iteration 3689 : loss : 0.025599, loss_ce: 0.006818
 54%|██████████████▋            | 217/400 [1:38:17<1:21:14, 26.63s/it]2021-12-13 00:38:00,970 iteration 3690 : loss : 0.031092, loss_ce: 0.006068
2021-12-13 00:38:02,450 iteration 3691 : loss : 0.029175, loss_ce: 0.007875
2021-12-13 00:38:03,925 iteration 3692 : loss : 0.023239, loss_ce: 0.011444
2021-12-13 00:38:05,329 iteration 3693 : loss : 0.026719, loss_ce: 0.013809
2021-12-13 00:38:06,792 iteration 3694 : loss : 0.028631, loss_ce: 0.011327
2021-12-13 00:38:08,263 iteration 3695 : loss : 0.023571, loss_ce: 0.012842
2021-12-13 00:38:09,701 iteration 3696 : loss : 0.024934, loss_ce: 0.008817
2021-12-13 00:38:11,178 iteration 3697 : loss : 0.029740, loss_ce: 0.010134
2021-12-13 00:38:12,714 iteration 3698 : loss : 0.026456, loss_ce: 0.010506
2021-12-13 00:38:14,122 iteration 3699 : loss : 0.016365, loss_ce: 0.006506
2021-12-13 00:38:15,598 iteration 3700 : loss : 0.018678, loss_ce: 0.005963
2021-12-13 00:38:16,973 iteration 3701 : loss : 0.016102, loss_ce: 0.007669
2021-12-13 00:38:18,449 iteration 3702 : loss : 0.019794, loss_ce: 0.006541
2021-12-13 00:38:19,906 iteration 3703 : loss : 0.019818, loss_ce: 0.009135
2021-12-13 00:38:21,270 iteration 3704 : loss : 0.021293, loss_ce: 0.008935
2021-12-13 00:38:22,787 iteration 3705 : loss : 0.028010, loss_ce: 0.009835
2021-12-13 00:38:24,162 iteration 3706 : loss : 0.017382, loss_ce: 0.005624
 55%|██████████████▋            | 218/400 [1:38:42<1:19:01, 26.05s/it]2021-12-13 00:38:25,688 iteration 3707 : loss : 0.028750, loss_ce: 0.015990
2021-12-13 00:38:27,067 iteration 3708 : loss : 0.020906, loss_ce: 0.006892
2021-12-13 00:38:28,616 iteration 3709 : loss : 0.031986, loss_ce: 0.009419
2021-12-13 00:38:30,064 iteration 3710 : loss : 0.020949, loss_ce: 0.007932
2021-12-13 00:38:31,472 iteration 3711 : loss : 0.016231, loss_ce: 0.005840
2021-12-13 00:38:32,859 iteration 3712 : loss : 0.018716, loss_ce: 0.008746
2021-12-13 00:38:34,394 iteration 3713 : loss : 0.023947, loss_ce: 0.008945
2021-12-13 00:38:35,868 iteration 3714 : loss : 0.023047, loss_ce: 0.008734
2021-12-13 00:38:37,316 iteration 3715 : loss : 0.016460, loss_ce: 0.007110
2021-12-13 00:38:38,774 iteration 3716 : loss : 0.021105, loss_ce: 0.010894
2021-12-13 00:38:40,259 iteration 3717 : loss : 0.017843, loss_ce: 0.006333
2021-12-13 00:38:41,669 iteration 3718 : loss : 0.018371, loss_ce: 0.006344
2021-12-13 00:38:43,111 iteration 3719 : loss : 0.021155, loss_ce: 0.007819
2021-12-13 00:38:44,642 iteration 3720 : loss : 0.027905, loss_ce: 0.008443
2021-12-13 00:38:46,071 iteration 3721 : loss : 0.017143, loss_ce: 0.006034
2021-12-13 00:38:47,501 iteration 3722 : loss : 0.022401, loss_ce: 0.011177
2021-12-13 00:38:49,007 iteration 3723 : loss : 0.042793, loss_ce: 0.010797
 55%|██████████████▊            | 219/400 [1:39:07<1:17:29, 25.69s/it]2021-12-13 00:38:50,541 iteration 3724 : loss : 0.025663, loss_ce: 0.010360
2021-12-13 00:38:51,991 iteration 3725 : loss : 0.022210, loss_ce: 0.009853
2021-12-13 00:38:53,573 iteration 3726 : loss : 0.019430, loss_ce: 0.006053
2021-12-13 00:38:54,968 iteration 3727 : loss : 0.014666, loss_ce: 0.004859
2021-12-13 00:38:56,401 iteration 3728 : loss : 0.020250, loss_ce: 0.010536
2021-12-13 00:38:57,899 iteration 3729 : loss : 0.029305, loss_ce: 0.010157
2021-12-13 00:38:59,319 iteration 3730 : loss : 0.023203, loss_ce: 0.006840
2021-12-13 00:39:00,714 iteration 3731 : loss : 0.019004, loss_ce: 0.006275
2021-12-13 00:39:02,165 iteration 3732 : loss : 0.026592, loss_ce: 0.010758
2021-12-13 00:39:03,601 iteration 3733 : loss : 0.026125, loss_ce: 0.007902
2021-12-13 00:39:05,070 iteration 3734 : loss : 0.018527, loss_ce: 0.007122
2021-12-13 00:39:06,559 iteration 3735 : loss : 0.027749, loss_ce: 0.012572
2021-12-13 00:39:08,055 iteration 3736 : loss : 0.026140, loss_ce: 0.009418
2021-12-13 00:39:09,516 iteration 3737 : loss : 0.024280, loss_ce: 0.008415
2021-12-13 00:39:10,966 iteration 3738 : loss : 0.029358, loss_ce: 0.010708
2021-12-13 00:39:12,415 iteration 3739 : loss : 0.020567, loss_ce: 0.007126
2021-12-13 00:39:12,415 Training Data Eval:
2021-12-13 00:39:19,919   Average segmentation loss on training set: 0.0131
2021-12-13 00:39:19,920 Validation Data Eval:
2021-12-13 00:39:22,526   Average segmentation loss on validation set: 0.0832
2021-12-13 00:39:24,057 iteration 3740 : loss : 0.016870, loss_ce: 0.005911
 55%|██████████████▊            | 220/400 [1:39:42<1:25:29, 28.50s/it]2021-12-13 00:39:25,588 iteration 3741 : loss : 0.021313, loss_ce: 0.008006
2021-12-13 00:39:27,009 iteration 3742 : loss : 0.022599, loss_ce: 0.010979
2021-12-13 00:39:28,444 iteration 3743 : loss : 0.024272, loss_ce: 0.008397
2021-12-13 00:39:29,926 iteration 3744 : loss : 0.021670, loss_ce: 0.011406
2021-12-13 00:39:31,344 iteration 3745 : loss : 0.019223, loss_ce: 0.006714
2021-12-13 00:39:32,860 iteration 3746 : loss : 0.017025, loss_ce: 0.006260
2021-12-13 00:39:34,362 iteration 3747 : loss : 0.043685, loss_ce: 0.008116
2021-12-13 00:39:35,825 iteration 3748 : loss : 0.061535, loss_ce: 0.045280
2021-12-13 00:39:37,267 iteration 3749 : loss : 0.029263, loss_ce: 0.015544
2021-12-13 00:39:38,748 iteration 3750 : loss : 0.027627, loss_ce: 0.010638
2021-12-13 00:39:40,235 iteration 3751 : loss : 0.030751, loss_ce: 0.008054
2021-12-13 00:39:41,690 iteration 3752 : loss : 0.025938, loss_ce: 0.011171
2021-12-13 00:39:43,095 iteration 3753 : loss : 0.025981, loss_ce: 0.006931
2021-12-13 00:39:44,491 iteration 3754 : loss : 0.017180, loss_ce: 0.006604
2021-12-13 00:39:45,927 iteration 3755 : loss : 0.022993, loss_ce: 0.010498
2021-12-13 00:39:47,393 iteration 3756 : loss : 0.060446, loss_ce: 0.028575
2021-12-13 00:39:48,839 iteration 3757 : loss : 0.025735, loss_ce: 0.010116
 55%|██████████████▉            | 221/400 [1:40:06<1:21:41, 27.38s/it]2021-12-13 00:39:50,343 iteration 3758 : loss : 0.033209, loss_ce: 0.013439
2021-12-13 00:39:51,795 iteration 3759 : loss : 0.020920, loss_ce: 0.008284
2021-12-13 00:39:53,171 iteration 3760 : loss : 0.024813, loss_ce: 0.008392
2021-12-13 00:39:54,678 iteration 3761 : loss : 0.031940, loss_ce: 0.013171
2021-12-13 00:39:56,143 iteration 3762 : loss : 0.031981, loss_ce: 0.010685
2021-12-13 00:39:57,656 iteration 3763 : loss : 0.030150, loss_ce: 0.013240
2021-12-13 00:39:59,165 iteration 3764 : loss : 0.029436, loss_ce: 0.012401
2021-12-13 00:40:00,640 iteration 3765 : loss : 0.023011, loss_ce: 0.009397
2021-12-13 00:40:02,096 iteration 3766 : loss : 0.022679, loss_ce: 0.009075
2021-12-13 00:40:03,625 iteration 3767 : loss : 0.034793, loss_ce: 0.011812
2021-12-13 00:40:05,101 iteration 3768 : loss : 0.024746, loss_ce: 0.010425
2021-12-13 00:40:06,546 iteration 3769 : loss : 0.021762, loss_ce: 0.009768
2021-12-13 00:40:07,965 iteration 3770 : loss : 0.021990, loss_ce: 0.007467
2021-12-13 00:40:09,400 iteration 3771 : loss : 0.019153, loss_ce: 0.007721
2021-12-13 00:40:10,848 iteration 3772 : loss : 0.023599, loss_ce: 0.007797
2021-12-13 00:40:12,229 iteration 3773 : loss : 0.016041, loss_ce: 0.005716
2021-12-13 00:40:13,629 iteration 3774 : loss : 0.020632, loss_ce: 0.008308
 56%|██████████████▉            | 222/400 [1:40:31<1:18:55, 26.60s/it]2021-12-13 00:40:15,085 iteration 3775 : loss : 0.023762, loss_ce: 0.006429
2021-12-13 00:40:16,575 iteration 3776 : loss : 0.028159, loss_ce: 0.011898
2021-12-13 00:40:18,134 iteration 3777 : loss : 0.028014, loss_ce: 0.010042
2021-12-13 00:40:19,547 iteration 3778 : loss : 0.017221, loss_ce: 0.009130
2021-12-13 00:40:21,015 iteration 3779 : loss : 0.020129, loss_ce: 0.007206
2021-12-13 00:40:22,429 iteration 3780 : loss : 0.018733, loss_ce: 0.009183
2021-12-13 00:40:23,870 iteration 3781 : loss : 0.024555, loss_ce: 0.010567
2021-12-13 00:40:25,345 iteration 3782 : loss : 0.021072, loss_ce: 0.007785
2021-12-13 00:40:26,835 iteration 3783 : loss : 0.019172, loss_ce: 0.005794
2021-12-13 00:40:28,341 iteration 3784 : loss : 0.050327, loss_ce: 0.021869
2021-12-13 00:40:29,765 iteration 3785 : loss : 0.018644, loss_ce: 0.006449
2021-12-13 00:40:31,236 iteration 3786 : loss : 0.021635, loss_ce: 0.007379
2021-12-13 00:40:32,746 iteration 3787 : loss : 0.031346, loss_ce: 0.014334
2021-12-13 00:40:34,269 iteration 3788 : loss : 0.024630, loss_ce: 0.008751
2021-12-13 00:40:35,686 iteration 3789 : loss : 0.023160, loss_ce: 0.006580
2021-12-13 00:40:37,161 iteration 3790 : loss : 0.022291, loss_ce: 0.007938
2021-12-13 00:40:38,533 iteration 3791 : loss : 0.017335, loss_ce: 0.006907
 56%|███████████████            | 223/400 [1:40:56<1:16:58, 26.09s/it]2021-12-13 00:40:40,027 iteration 3792 : loss : 0.015211, loss_ce: 0.006170
2021-12-13 00:40:41,490 iteration 3793 : loss : 0.015992, loss_ce: 0.006614
2021-12-13 00:40:42,897 iteration 3794 : loss : 0.018966, loss_ce: 0.007515
2021-12-13 00:40:44,445 iteration 3795 : loss : 0.033911, loss_ce: 0.016240
2021-12-13 00:40:45,926 iteration 3796 : loss : 0.030689, loss_ce: 0.009611
2021-12-13 00:40:47,354 iteration 3797 : loss : 0.022643, loss_ce: 0.007806
2021-12-13 00:40:48,897 iteration 3798 : loss : 0.024594, loss_ce: 0.008941
2021-12-13 00:40:50,314 iteration 3799 : loss : 0.018791, loss_ce: 0.010140
2021-12-13 00:40:51,812 iteration 3800 : loss : 0.023725, loss_ce: 0.007849
2021-12-13 00:40:53,219 iteration 3801 : loss : 0.015780, loss_ce: 0.005680
2021-12-13 00:40:54,673 iteration 3802 : loss : 0.019238, loss_ce: 0.006053
2021-12-13 00:40:56,117 iteration 3803 : loss : 0.017699, loss_ce: 0.006385
2021-12-13 00:40:57,483 iteration 3804 : loss : 0.019126, loss_ce: 0.006895
2021-12-13 00:40:58,965 iteration 3805 : loss : 0.018427, loss_ce: 0.007624
2021-12-13 00:41:00,378 iteration 3806 : loss : 0.024941, loss_ce: 0.006773
2021-12-13 00:41:01,816 iteration 3807 : loss : 0.023016, loss_ce: 0.008907
2021-12-13 00:41:03,308 iteration 3808 : loss : 0.019813, loss_ce: 0.007349
 56%|███████████████            | 224/400 [1:41:21<1:15:23, 25.70s/it]2021-12-13 00:41:04,802 iteration 3809 : loss : 0.018193, loss_ce: 0.007087
2021-12-13 00:41:06,242 iteration 3810 : loss : 0.024665, loss_ce: 0.012107
2021-12-13 00:41:07,795 iteration 3811 : loss : 0.024630, loss_ce: 0.007865
2021-12-13 00:41:09,225 iteration 3812 : loss : 0.026839, loss_ce: 0.009773
2021-12-13 00:41:10,705 iteration 3813 : loss : 0.027454, loss_ce: 0.007105
2021-12-13 00:41:12,092 iteration 3814 : loss : 0.014633, loss_ce: 0.004874
2021-12-13 00:41:13,606 iteration 3815 : loss : 0.054070, loss_ce: 0.015315
2021-12-13 00:41:15,170 iteration 3816 : loss : 0.021968, loss_ce: 0.008040
2021-12-13 00:41:16,641 iteration 3817 : loss : 0.021530, loss_ce: 0.009035
2021-12-13 00:41:18,190 iteration 3818 : loss : 0.022636, loss_ce: 0.009805
2021-12-13 00:41:19,582 iteration 3819 : loss : 0.021634, loss_ce: 0.009490
2021-12-13 00:41:21,063 iteration 3820 : loss : 0.024129, loss_ce: 0.009214
2021-12-13 00:41:22,512 iteration 3821 : loss : 0.022748, loss_ce: 0.010891
2021-12-13 00:41:23,884 iteration 3822 : loss : 0.016809, loss_ce: 0.006900
2021-12-13 00:41:25,308 iteration 3823 : loss : 0.020879, loss_ce: 0.007154
2021-12-13 00:41:26,748 iteration 3824 : loss : 0.026516, loss_ce: 0.009245
2021-12-13 00:41:26,748 Training Data Eval:
2021-12-13 00:41:34,233   Average segmentation loss on training set: 0.0138
2021-12-13 00:41:34,233 Validation Data Eval:
2021-12-13 00:41:36,840   Average segmentation loss on validation set: 0.0662
2021-12-13 00:41:38,270 iteration 3825 : loss : 0.023067, loss_ce: 0.008828
 56%|███████████████▏           | 225/400 [1:41:56<1:23:03, 28.48s/it]2021-12-13 00:41:39,688 iteration 3826 : loss : 0.018329, loss_ce: 0.007338
2021-12-13 00:41:41,160 iteration 3827 : loss : 0.021512, loss_ce: 0.008246
2021-12-13 00:41:42,656 iteration 3828 : loss : 0.025741, loss_ce: 0.010436
2021-12-13 00:41:44,113 iteration 3829 : loss : 0.022674, loss_ce: 0.010609
2021-12-13 00:41:45,573 iteration 3830 : loss : 0.024523, loss_ce: 0.009937
2021-12-13 00:41:47,093 iteration 3831 : loss : 0.054405, loss_ce: 0.012640
2021-12-13 00:41:48,470 iteration 3832 : loss : 0.016215, loss_ce: 0.005403
2021-12-13 00:41:49,937 iteration 3833 : loss : 0.021104, loss_ce: 0.007103
2021-12-13 00:41:51,370 iteration 3834 : loss : 0.016591, loss_ce: 0.007572
2021-12-13 00:41:52,866 iteration 3835 : loss : 0.020169, loss_ce: 0.009372
2021-12-13 00:41:54,377 iteration 3836 : loss : 0.023465, loss_ce: 0.007703
2021-12-13 00:41:55,767 iteration 3837 : loss : 0.018896, loss_ce: 0.007028
2021-12-13 00:41:57,187 iteration 3838 : loss : 0.026154, loss_ce: 0.008530
2021-12-13 00:41:58,608 iteration 3839 : loss : 0.017949, loss_ce: 0.006848
2021-12-13 00:41:59,967 iteration 3840 : loss : 0.020635, loss_ce: 0.005501
2021-12-13 00:42:01,373 iteration 3841 : loss : 0.017946, loss_ce: 0.005721
2021-12-13 00:42:02,800 iteration 3842 : loss : 0.020688, loss_ce: 0.004929
 56%|███████████████▎           | 226/400 [1:42:20<1:19:08, 27.29s/it]2021-12-13 00:42:04,320 iteration 3843 : loss : 0.017734, loss_ce: 0.006779
2021-12-13 00:42:05,789 iteration 3844 : loss : 0.025134, loss_ce: 0.011867
2021-12-13 00:42:07,226 iteration 3845 : loss : 0.033071, loss_ce: 0.012260
2021-12-13 00:42:08,675 iteration 3846 : loss : 0.016301, loss_ce: 0.004215
2021-12-13 00:42:10,169 iteration 3847 : loss : 0.019575, loss_ce: 0.008267
2021-12-13 00:42:11,594 iteration 3848 : loss : 0.018768, loss_ce: 0.007589
2021-12-13 00:42:12,981 iteration 3849 : loss : 0.016284, loss_ce: 0.005911
2021-12-13 00:42:14,465 iteration 3850 : loss : 0.033154, loss_ce: 0.009869
2021-12-13 00:42:15,957 iteration 3851 : loss : 0.024666, loss_ce: 0.012407
2021-12-13 00:42:17,389 iteration 3852 : loss : 0.020591, loss_ce: 0.007518
2021-12-13 00:42:18,806 iteration 3853 : loss : 0.017916, loss_ce: 0.009655
2021-12-13 00:42:20,301 iteration 3854 : loss : 0.020991, loss_ce: 0.008213
2021-12-13 00:42:21,774 iteration 3855 : loss : 0.028299, loss_ce: 0.013394
2021-12-13 00:42:23,250 iteration 3856 : loss : 0.025672, loss_ce: 0.008797
2021-12-13 00:42:24,664 iteration 3857 : loss : 0.018666, loss_ce: 0.007645
2021-12-13 00:42:26,131 iteration 3858 : loss : 0.016548, loss_ce: 0.006367
2021-12-13 00:42:27,598 iteration 3859 : loss : 0.021604, loss_ce: 0.005341
 57%|███████████████▎           | 227/400 [1:42:45<1:16:32, 26.54s/it]2021-12-13 00:42:29,099 iteration 3860 : loss : 0.015031, loss_ce: 0.006508
2021-12-13 00:42:30,621 iteration 3861 : loss : 0.021311, loss_ce: 0.008797
2021-12-13 00:42:32,015 iteration 3862 : loss : 0.021309, loss_ce: 0.011027
2021-12-13 00:42:33,509 iteration 3863 : loss : 0.019472, loss_ce: 0.009284
2021-12-13 00:42:35,008 iteration 3864 : loss : 0.021615, loss_ce: 0.008145
2021-12-13 00:42:36,588 iteration 3865 : loss : 0.026812, loss_ce: 0.012540
2021-12-13 00:42:38,141 iteration 3866 : loss : 0.040809, loss_ce: 0.026794
2021-12-13 00:42:39,568 iteration 3867 : loss : 0.017813, loss_ce: 0.008159
2021-12-13 00:42:41,064 iteration 3868 : loss : 0.019955, loss_ce: 0.008504
2021-12-13 00:42:42,545 iteration 3869 : loss : 0.025907, loss_ce: 0.010075
2021-12-13 00:42:44,061 iteration 3870 : loss : 0.023299, loss_ce: 0.007972
2021-12-13 00:42:45,525 iteration 3871 : loss : 0.026095, loss_ce: 0.007651
2021-12-13 00:42:46,975 iteration 3872 : loss : 0.019487, loss_ce: 0.008542
2021-12-13 00:42:48,428 iteration 3873 : loss : 0.020629, loss_ce: 0.008187
2021-12-13 00:42:49,944 iteration 3874 : loss : 0.018139, loss_ce: 0.006909
2021-12-13 00:42:51,445 iteration 3875 : loss : 0.017816, loss_ce: 0.006788
2021-12-13 00:42:52,894 iteration 3876 : loss : 0.028342, loss_ce: 0.006434
 57%|███████████████▍           | 228/400 [1:43:10<1:15:01, 26.17s/it]2021-12-13 00:42:54,354 iteration 3877 : loss : 0.018258, loss_ce: 0.007511
2021-12-13 00:42:55,856 iteration 3878 : loss : 0.030036, loss_ce: 0.020142
2021-12-13 00:42:57,340 iteration 3879 : loss : 0.020279, loss_ce: 0.009099
2021-12-13 00:42:58,793 iteration 3880 : loss : 0.017902, loss_ce: 0.008051
2021-12-13 00:43:00,225 iteration 3881 : loss : 0.017333, loss_ce: 0.008529
2021-12-13 00:43:01,766 iteration 3882 : loss : 0.029264, loss_ce: 0.010825
2021-12-13 00:43:03,270 iteration 3883 : loss : 0.031235, loss_ce: 0.014132
2021-12-13 00:43:04,687 iteration 3884 : loss : 0.032050, loss_ce: 0.004659
2021-12-13 00:43:06,095 iteration 3885 : loss : 0.018423, loss_ce: 0.006076
2021-12-13 00:43:07,512 iteration 3886 : loss : 0.024211, loss_ce: 0.008500
2021-12-13 00:43:09,038 iteration 3887 : loss : 0.026347, loss_ce: 0.010711
2021-12-13 00:43:10,525 iteration 3888 : loss : 0.027995, loss_ce: 0.009161
2021-12-13 00:43:12,002 iteration 3889 : loss : 0.026802, loss_ce: 0.012355
2021-12-13 00:43:13,376 iteration 3890 : loss : 0.023055, loss_ce: 0.008461
2021-12-13 00:43:14,864 iteration 3891 : loss : 0.018199, loss_ce: 0.006701
2021-12-13 00:43:16,347 iteration 3892 : loss : 0.036148, loss_ce: 0.007121
2021-12-13 00:43:17,890 iteration 3893 : loss : 0.029075, loss_ce: 0.014435
 57%|███████████████▍           | 229/400 [1:43:35<1:13:34, 25.82s/it]2021-12-13 00:43:19,318 iteration 3894 : loss : 0.019798, loss_ce: 0.008617
2021-12-13 00:43:20,823 iteration 3895 : loss : 0.028427, loss_ce: 0.009883
2021-12-13 00:43:22,266 iteration 3896 : loss : 0.031701, loss_ce: 0.008841
2021-12-13 00:43:23,758 iteration 3897 : loss : 0.038020, loss_ce: 0.015450
2021-12-13 00:43:25,198 iteration 3898 : loss : 0.024466, loss_ce: 0.009909
2021-12-13 00:43:26,706 iteration 3899 : loss : 0.030629, loss_ce: 0.011441
2021-12-13 00:43:28,240 iteration 3900 : loss : 0.035115, loss_ce: 0.011341
2021-12-13 00:43:29,639 iteration 3901 : loss : 0.017282, loss_ce: 0.005801
2021-12-13 00:43:31,059 iteration 3902 : loss : 0.021661, loss_ce: 0.008112
2021-12-13 00:43:32,516 iteration 3903 : loss : 0.023425, loss_ce: 0.009309
2021-12-13 00:43:34,046 iteration 3904 : loss : 0.025107, loss_ce: 0.009402
2021-12-13 00:43:35,514 iteration 3905 : loss : 0.018938, loss_ce: 0.008771
2021-12-13 00:43:36,944 iteration 3906 : loss : 0.020279, loss_ce: 0.009619
2021-12-13 00:43:38,432 iteration 3907 : loss : 0.020919, loss_ce: 0.006738
2021-12-13 00:43:39,964 iteration 3908 : loss : 0.024625, loss_ce: 0.008709
2021-12-13 00:43:41,450 iteration 3909 : loss : 0.021750, loss_ce: 0.008383
2021-12-13 00:43:41,450 Training Data Eval:
2021-12-13 00:43:48,957   Average segmentation loss on training set: 0.0167
2021-12-13 00:43:48,958 Validation Data Eval:
2021-12-13 00:43:51,568   Average segmentation loss on validation set: 0.0799
2021-12-13 00:43:52,974 iteration 3910 : loss : 0.016169, loss_ce: 0.005590
 57%|███████████████▌           | 230/400 [1:44:11<1:21:01, 28.60s/it]2021-12-13 00:43:54,433 iteration 3911 : loss : 0.017495, loss_ce: 0.005494
2021-12-13 00:43:55,952 iteration 3912 : loss : 0.030535, loss_ce: 0.012608
2021-12-13 00:43:57,348 iteration 3913 : loss : 0.018979, loss_ce: 0.005990
2021-12-13 00:43:58,740 iteration 3914 : loss : 0.016721, loss_ce: 0.005884
2021-12-13 00:44:00,118 iteration 3915 : loss : 0.016504, loss_ce: 0.005808
2021-12-13 00:44:01,629 iteration 3916 : loss : 0.025268, loss_ce: 0.008298
2021-12-13 00:44:03,139 iteration 3917 : loss : 0.042597, loss_ce: 0.012191
2021-12-13 00:44:04,637 iteration 3918 : loss : 0.022182, loss_ce: 0.009116
2021-12-13 00:44:06,093 iteration 3919 : loss : 0.021708, loss_ce: 0.007946
2021-12-13 00:44:07,575 iteration 3920 : loss : 0.036525, loss_ce: 0.020131
2021-12-13 00:44:09,049 iteration 3921 : loss : 0.038089, loss_ce: 0.013165
2021-12-13 00:44:10,474 iteration 3922 : loss : 0.014660, loss_ce: 0.005916
2021-12-13 00:44:11,942 iteration 3923 : loss : 0.021825, loss_ce: 0.008916
2021-12-13 00:44:13,405 iteration 3924 : loss : 0.030253, loss_ce: 0.011626
2021-12-13 00:44:15,002 iteration 3925 : loss : 0.027424, loss_ce: 0.014694
2021-12-13 00:44:16,463 iteration 3926 : loss : 0.024785, loss_ce: 0.009798
2021-12-13 00:44:17,945 iteration 3927 : loss : 0.029880, loss_ce: 0.012371
 58%|███████████████▌           | 231/400 [1:44:36<1:17:29, 27.51s/it]2021-12-13 00:44:19,454 iteration 3928 : loss : 0.020152, loss_ce: 0.008437
2021-12-13 00:44:20,977 iteration 3929 : loss : 0.020956, loss_ce: 0.008785
2021-12-13 00:44:22,563 iteration 3930 : loss : 0.028285, loss_ce: 0.009663
2021-12-13 00:44:24,043 iteration 3931 : loss : 0.020272, loss_ce: 0.009494
2021-12-13 00:44:25,557 iteration 3932 : loss : 0.023754, loss_ce: 0.008245
2021-12-13 00:44:26,985 iteration 3933 : loss : 0.028533, loss_ce: 0.007106
2021-12-13 00:44:28,440 iteration 3934 : loss : 0.018034, loss_ce: 0.005886
2021-12-13 00:44:29,947 iteration 3935 : loss : 0.023062, loss_ce: 0.008546
2021-12-13 00:44:31,394 iteration 3936 : loss : 0.018372, loss_ce: 0.007354
2021-12-13 00:44:32,864 iteration 3937 : loss : 0.016769, loss_ce: 0.005707
2021-12-13 00:44:34,290 iteration 3938 : loss : 0.020911, loss_ce: 0.009088
2021-12-13 00:44:35,834 iteration 3939 : loss : 0.030440, loss_ce: 0.010835
2021-12-13 00:44:37,264 iteration 3940 : loss : 0.027052, loss_ce: 0.007517
2021-12-13 00:44:38,730 iteration 3941 : loss : 0.019648, loss_ce: 0.009205
2021-12-13 00:44:40,196 iteration 3942 : loss : 0.018986, loss_ce: 0.009534
2021-12-13 00:44:41,690 iteration 3943 : loss : 0.019981, loss_ce: 0.008980
2021-12-13 00:44:43,150 iteration 3944 : loss : 0.026742, loss_ce: 0.008549
 58%|███████████████▋           | 232/400 [1:45:01<1:15:05, 26.82s/it]2021-12-13 00:44:44,624 iteration 3945 : loss : 0.016617, loss_ce: 0.007729
2021-12-13 00:44:46,001 iteration 3946 : loss : 0.013946, loss_ce: 0.005926
2021-12-13 00:44:47,461 iteration 3947 : loss : 0.023253, loss_ce: 0.008984
2021-12-13 00:44:48,911 iteration 3948 : loss : 0.017765, loss_ce: 0.007844
2021-12-13 00:44:50,392 iteration 3949 : loss : 0.029363, loss_ce: 0.013364
2021-12-13 00:44:51,873 iteration 3950 : loss : 0.017567, loss_ce: 0.006403
2021-12-13 00:44:53,389 iteration 3951 : loss : 0.023788, loss_ce: 0.009219
2021-12-13 00:44:54,839 iteration 3952 : loss : 0.023608, loss_ce: 0.013617
2021-12-13 00:44:56,296 iteration 3953 : loss : 0.018523, loss_ce: 0.006230
2021-12-13 00:44:57,800 iteration 3954 : loss : 0.028173, loss_ce: 0.012050
2021-12-13 00:44:59,291 iteration 3955 : loss : 0.018969, loss_ce: 0.006934
2021-12-13 00:45:00,730 iteration 3956 : loss : 0.034472, loss_ce: 0.013930
2021-12-13 00:45:02,184 iteration 3957 : loss : 0.022371, loss_ce: 0.009440
2021-12-13 00:45:03,729 iteration 3958 : loss : 0.024344, loss_ce: 0.009965
2021-12-13 00:45:05,161 iteration 3959 : loss : 0.016067, loss_ce: 0.005191
2021-12-13 00:45:06,634 iteration 3960 : loss : 0.027173, loss_ce: 0.006548
2021-12-13 00:45:08,128 iteration 3961 : loss : 0.014518, loss_ce: 0.005405
 58%|███████████████▋           | 233/400 [1:45:26<1:13:06, 26.27s/it]2021-12-13 00:45:09,742 iteration 3962 : loss : 0.026096, loss_ce: 0.009734
2021-12-13 00:45:11,138 iteration 3963 : loss : 0.015566, loss_ce: 0.005952
2021-12-13 00:45:12,635 iteration 3964 : loss : 0.046975, loss_ce: 0.022828
2021-12-13 00:45:14,179 iteration 3965 : loss : 0.022429, loss_ce: 0.006629
2021-12-13 00:45:15,625 iteration 3966 : loss : 0.025490, loss_ce: 0.009467
2021-12-13 00:45:17,064 iteration 3967 : loss : 0.031617, loss_ce: 0.009650
2021-12-13 00:45:18,615 iteration 3968 : loss : 0.030816, loss_ce: 0.011493
2021-12-13 00:45:20,126 iteration 3969 : loss : 0.020437, loss_ce: 0.008083
2021-12-13 00:45:21,666 iteration 3970 : loss : 0.027454, loss_ce: 0.013562
2021-12-13 00:45:23,077 iteration 3971 : loss : 0.020595, loss_ce: 0.007129
2021-12-13 00:45:24,508 iteration 3972 : loss : 0.021369, loss_ce: 0.009778
2021-12-13 00:45:25,989 iteration 3973 : loss : 0.025933, loss_ce: 0.010235
2021-12-13 00:45:27,528 iteration 3974 : loss : 0.031837, loss_ce: 0.012954
2021-12-13 00:45:29,057 iteration 3975 : loss : 0.020222, loss_ce: 0.007060
2021-12-13 00:45:30,608 iteration 3976 : loss : 0.025103, loss_ce: 0.010502
2021-12-13 00:45:32,075 iteration 3977 : loss : 0.026652, loss_ce: 0.010100
2021-12-13 00:45:33,535 iteration 3978 : loss : 0.027810, loss_ce: 0.011805
 58%|███████████████▊           | 234/400 [1:45:51<1:11:57, 26.01s/it]2021-12-13 00:45:35,048 iteration 3979 : loss : 0.021756, loss_ce: 0.007579
2021-12-13 00:45:36,547 iteration 3980 : loss : 0.026011, loss_ce: 0.012732
2021-12-13 00:45:37,983 iteration 3981 : loss : 0.030466, loss_ce: 0.011889
2021-12-13 00:45:39,582 iteration 3982 : loss : 0.019603, loss_ce: 0.007269
2021-12-13 00:45:41,049 iteration 3983 : loss : 0.018089, loss_ce: 0.004939
2021-12-13 00:45:42,560 iteration 3984 : loss : 0.022462, loss_ce: 0.007717
2021-12-13 00:45:44,034 iteration 3985 : loss : 0.017982, loss_ce: 0.005737
2021-12-13 00:45:45,470 iteration 3986 : loss : 0.023724, loss_ce: 0.010003
2021-12-13 00:45:46,918 iteration 3987 : loss : 0.018906, loss_ce: 0.008250
2021-12-13 00:45:48,452 iteration 3988 : loss : 0.022507, loss_ce: 0.009564
2021-12-13 00:45:49,920 iteration 3989 : loss : 0.025191, loss_ce: 0.009454
2021-12-13 00:45:51,365 iteration 3990 : loss : 0.019698, loss_ce: 0.006530
2021-12-13 00:45:52,821 iteration 3991 : loss : 0.021803, loss_ce: 0.008082
2021-12-13 00:45:54,395 iteration 3992 : loss : 0.038320, loss_ce: 0.012595
2021-12-13 00:45:55,843 iteration 3993 : loss : 0.022343, loss_ce: 0.011229
2021-12-13 00:45:57,303 iteration 3994 : loss : 0.022926, loss_ce: 0.009138
2021-12-13 00:45:57,303 Training Data Eval:
2021-12-13 00:46:04,825   Average segmentation loss on training set: 0.0151
2021-12-13 00:46:04,825 Validation Data Eval:
2021-12-13 00:46:07,421   Average segmentation loss on validation set: 0.0815
2021-12-13 00:46:08,888 iteration 3995 : loss : 0.023957, loss_ce: 0.007117
 59%|███████████████▊           | 235/400 [1:46:26<1:19:13, 28.81s/it]2021-12-13 00:46:10,476 iteration 3996 : loss : 0.024934, loss_ce: 0.012599
2021-12-13 00:46:11,988 iteration 3997 : loss : 0.022479, loss_ce: 0.008251
2021-12-13 00:46:13,451 iteration 3998 : loss : 0.019763, loss_ce: 0.007206
2021-12-13 00:46:14,965 iteration 3999 : loss : 0.018554, loss_ce: 0.005750
2021-12-13 00:46:16,431 iteration 4000 : loss : 0.018807, loss_ce: 0.007311
2021-12-13 00:46:18,004 iteration 4001 : loss : 0.024704, loss_ce: 0.006637
2021-12-13 00:46:19,469 iteration 4002 : loss : 0.019270, loss_ce: 0.008700
2021-12-13 00:46:20,938 iteration 4003 : loss : 0.028781, loss_ce: 0.010122
2021-12-13 00:46:22,406 iteration 4004 : loss : 0.026668, loss_ce: 0.009827
2021-12-13 00:46:23,894 iteration 4005 : loss : 0.021856, loss_ce: 0.009684
2021-12-13 00:46:25,457 iteration 4006 : loss : 0.031640, loss_ce: 0.009029
2021-12-13 00:46:26,905 iteration 4007 : loss : 0.017455, loss_ce: 0.006677
2021-12-13 00:46:28,377 iteration 4008 : loss : 0.029107, loss_ce: 0.009979
2021-12-13 00:46:29,829 iteration 4009 : loss : 0.026684, loss_ce: 0.010449
2021-12-13 00:46:31,234 iteration 4010 : loss : 0.013944, loss_ce: 0.005187
2021-12-13 00:46:32,748 iteration 4011 : loss : 0.023605, loss_ce: 0.007633
2021-12-13 00:46:34,252 iteration 4012 : loss : 0.027171, loss_ce: 0.011813
 59%|███████████████▉           | 236/400 [1:46:52<1:15:55, 27.78s/it]2021-12-13 00:46:35,742 iteration 4013 : loss : 0.022918, loss_ce: 0.006383
2021-12-13 00:46:37,249 iteration 4014 : loss : 0.027938, loss_ce: 0.009510
2021-12-13 00:46:38,680 iteration 4015 : loss : 0.021835, loss_ce: 0.011705
2021-12-13 00:46:40,182 iteration 4016 : loss : 0.022257, loss_ce: 0.007794
2021-12-13 00:46:41,619 iteration 4017 : loss : 0.015684, loss_ce: 0.005750
2021-12-13 00:46:43,161 iteration 4018 : loss : 0.023683, loss_ce: 0.009077
2021-12-13 00:46:44,691 iteration 4019 : loss : 0.027633, loss_ce: 0.012896
2021-12-13 00:46:46,151 iteration 4020 : loss : 0.018610, loss_ce: 0.006130
2021-12-13 00:46:47,636 iteration 4021 : loss : 0.018186, loss_ce: 0.006249
2021-12-13 00:46:49,101 iteration 4022 : loss : 0.027967, loss_ce: 0.008506
2021-12-13 00:46:50,566 iteration 4023 : loss : 0.023026, loss_ce: 0.010956
2021-12-13 00:46:52,046 iteration 4024 : loss : 0.043055, loss_ce: 0.019024
2021-12-13 00:46:53,497 iteration 4025 : loss : 0.019159, loss_ce: 0.007615
2021-12-13 00:46:54,950 iteration 4026 : loss : 0.014735, loss_ce: 0.006327
2021-12-13 00:46:56,405 iteration 4027 : loss : 0.031954, loss_ce: 0.014316
2021-12-13 00:46:57,881 iteration 4028 : loss : 0.021854, loss_ce: 0.005791
2021-12-13 00:46:59,367 iteration 4029 : loss : 0.021330, loss_ce: 0.008016
 59%|███████████████▉           | 237/400 [1:47:17<1:13:17, 26.98s/it]2021-12-13 00:47:00,885 iteration 4030 : loss : 0.025920, loss_ce: 0.010799
2021-12-13 00:47:02,342 iteration 4031 : loss : 0.017128, loss_ce: 0.006394
2021-12-13 00:47:03,852 iteration 4032 : loss : 0.021046, loss_ce: 0.007687
2021-12-13 00:47:05,405 iteration 4033 : loss : 0.029852, loss_ce: 0.009764
2021-12-13 00:47:06,854 iteration 4034 : loss : 0.024089, loss_ce: 0.007971
2021-12-13 00:47:08,342 iteration 4035 : loss : 0.017952, loss_ce: 0.006762
2021-12-13 00:47:09,804 iteration 4036 : loss : 0.015021, loss_ce: 0.005291
2021-12-13 00:47:11,327 iteration 4037 : loss : 0.019365, loss_ce: 0.006369
2021-12-13 00:47:12,810 iteration 4038 : loss : 0.022029, loss_ce: 0.012284
2021-12-13 00:47:14,183 iteration 4039 : loss : 0.017251, loss_ce: 0.008610
2021-12-13 00:47:15,669 iteration 4040 : loss : 0.024919, loss_ce: 0.005904
2021-12-13 00:47:17,251 iteration 4041 : loss : 0.034010, loss_ce: 0.016798
2021-12-13 00:47:18,645 iteration 4042 : loss : 0.019967, loss_ce: 0.008843
2021-12-13 00:47:20,133 iteration 4043 : loss : 0.020686, loss_ce: 0.007655
2021-12-13 00:47:21,625 iteration 4044 : loss : 0.023310, loss_ce: 0.009555
2021-12-13 00:47:23,063 iteration 4045 : loss : 0.021318, loss_ce: 0.008540
2021-12-13 00:47:24,562 iteration 4046 : loss : 0.015879, loss_ce: 0.005285
 60%|████████████████           | 238/400 [1:47:42<1:11:23, 26.44s/it]2021-12-13 00:47:25,991 iteration 4047 : loss : 0.016965, loss_ce: 0.007054
2021-12-13 00:47:27,439 iteration 4048 : loss : 0.017129, loss_ce: 0.004485
2021-12-13 00:47:28,977 iteration 4049 : loss : 0.031355, loss_ce: 0.012262
2021-12-13 00:47:30,445 iteration 4050 : loss : 0.019484, loss_ce: 0.004985
2021-12-13 00:47:31,911 iteration 4051 : loss : 0.014015, loss_ce: 0.004569
2021-12-13 00:47:33,362 iteration 4052 : loss : 0.018318, loss_ce: 0.005409
2021-12-13 00:47:34,794 iteration 4053 : loss : 0.019514, loss_ce: 0.009856
2021-12-13 00:47:36,213 iteration 4054 : loss : 0.019096, loss_ce: 0.007610
2021-12-13 00:47:37,767 iteration 4055 : loss : 0.023615, loss_ce: 0.007693
2021-12-13 00:47:39,268 iteration 4056 : loss : 0.033641, loss_ce: 0.011034
2021-12-13 00:47:40,802 iteration 4057 : loss : 0.025502, loss_ce: 0.010267
2021-12-13 00:47:42,207 iteration 4058 : loss : 0.021940, loss_ce: 0.008960
2021-12-13 00:47:43,728 iteration 4059 : loss : 0.018855, loss_ce: 0.008197
2021-12-13 00:47:45,215 iteration 4060 : loss : 0.025987, loss_ce: 0.010419
2021-12-13 00:47:46,661 iteration 4061 : loss : 0.023843, loss_ce: 0.005511
2021-12-13 00:47:48,106 iteration 4062 : loss : 0.031931, loss_ce: 0.015185
2021-12-13 00:47:49,678 iteration 4063 : loss : 0.031464, loss_ce: 0.012331
 60%|████████████████▏          | 239/400 [1:48:07<1:09:53, 26.05s/it]2021-12-13 00:47:51,175 iteration 4064 : loss : 0.021356, loss_ce: 0.006826
2021-12-13 00:47:52,627 iteration 4065 : loss : 0.018875, loss_ce: 0.007136
2021-12-13 00:47:54,020 iteration 4066 : loss : 0.016546, loss_ce: 0.005084
2021-12-13 00:47:55,445 iteration 4067 : loss : 0.042514, loss_ce: 0.009181
2021-12-13 00:47:56,920 iteration 4068 : loss : 0.023401, loss_ce: 0.009203
2021-12-13 00:47:58,421 iteration 4069 : loss : 0.021255, loss_ce: 0.007007
2021-12-13 00:47:59,913 iteration 4070 : loss : 0.021900, loss_ce: 0.011161
2021-12-13 00:48:01,332 iteration 4071 : loss : 0.017517, loss_ce: 0.007728
2021-12-13 00:48:02,802 iteration 4072 : loss : 0.017175, loss_ce: 0.006893
2021-12-13 00:48:04,275 iteration 4073 : loss : 0.023372, loss_ce: 0.011607
2021-12-13 00:48:05,703 iteration 4074 : loss : 0.023561, loss_ce: 0.008431
2021-12-13 00:48:07,217 iteration 4075 : loss : 0.026410, loss_ce: 0.010455
2021-12-13 00:48:08,698 iteration 4076 : loss : 0.018215, loss_ce: 0.005773
2021-12-13 00:48:10,189 iteration 4077 : loss : 0.017244, loss_ce: 0.007277
2021-12-13 00:48:11,721 iteration 4078 : loss : 0.028978, loss_ce: 0.008205
2021-12-13 00:48:13,205 iteration 4079 : loss : 0.018514, loss_ce: 0.006400
2021-12-13 00:48:13,205 Training Data Eval:
2021-12-13 00:48:20,697   Average segmentation loss on training set: 0.0135
2021-12-13 00:48:20,698 Validation Data Eval:
2021-12-13 00:48:23,309   Average segmentation loss on validation set: 0.0797
2021-12-13 00:48:24,792 iteration 4080 : loss : 0.020821, loss_ce: 0.005950
 60%|████████████████▏          | 240/400 [1:48:42<1:16:42, 28.77s/it]2021-12-13 00:48:26,290 iteration 4081 : loss : 0.030168, loss_ce: 0.014377
2021-12-13 00:48:27,836 iteration 4082 : loss : 0.024978, loss_ce: 0.009888
2021-12-13 00:48:29,244 iteration 4083 : loss : 0.019349, loss_ce: 0.008005
2021-12-13 00:48:30,685 iteration 4084 : loss : 0.020583, loss_ce: 0.006944
2021-12-13 00:48:32,153 iteration 4085 : loss : 0.022376, loss_ce: 0.004883
2021-12-13 00:48:33,593 iteration 4086 : loss : 0.016006, loss_ce: 0.005550
2021-12-13 00:48:35,060 iteration 4087 : loss : 0.018284, loss_ce: 0.006093
2021-12-13 00:48:36,549 iteration 4088 : loss : 0.019813, loss_ce: 0.009020
2021-12-13 00:48:38,043 iteration 4089 : loss : 0.024729, loss_ce: 0.009536
2021-12-13 00:48:39,511 iteration 4090 : loss : 0.022645, loss_ce: 0.009916
2021-12-13 00:48:41,023 iteration 4091 : loss : 0.022767, loss_ce: 0.007683
2021-12-13 00:48:42,446 iteration 4092 : loss : 0.019600, loss_ce: 0.005665
2021-12-13 00:48:43,895 iteration 4093 : loss : 0.017766, loss_ce: 0.008277
2021-12-13 00:48:45,432 iteration 4094 : loss : 0.017877, loss_ce: 0.007303
2021-12-13 00:48:46,899 iteration 4095 : loss : 0.024499, loss_ce: 0.007474
2021-12-13 00:48:48,401 iteration 4096 : loss : 0.018820, loss_ce: 0.007716
2021-12-13 00:48:49,915 iteration 4097 : loss : 0.021913, loss_ce: 0.008774
 60%|████████████████▎          | 241/400 [1:49:08<1:13:19, 27.67s/it]2021-12-13 00:48:51,416 iteration 4098 : loss : 0.019504, loss_ce: 0.008151
2021-12-13 00:48:52,864 iteration 4099 : loss : 0.016006, loss_ce: 0.004804
2021-12-13 00:48:54,279 iteration 4100 : loss : 0.019312, loss_ce: 0.008175
2021-12-13 00:48:55,768 iteration 4101 : loss : 0.017020, loss_ce: 0.007311
2021-12-13 00:48:57,325 iteration 4102 : loss : 0.024598, loss_ce: 0.009053
2021-12-13 00:48:58,709 iteration 4103 : loss : 0.015394, loss_ce: 0.006568
2021-12-13 00:49:00,188 iteration 4104 : loss : 0.024055, loss_ce: 0.007688
2021-12-13 00:49:01,696 iteration 4105 : loss : 0.027877, loss_ce: 0.010066
2021-12-13 00:49:03,243 iteration 4106 : loss : 0.027534, loss_ce: 0.010794
2021-12-13 00:49:04,737 iteration 4107 : loss : 0.021930, loss_ce: 0.008339
2021-12-13 00:49:06,242 iteration 4108 : loss : 0.021035, loss_ce: 0.008774
2021-12-13 00:49:07,730 iteration 4109 : loss : 0.027884, loss_ce: 0.007334
2021-12-13 00:49:09,248 iteration 4110 : loss : 0.016861, loss_ce: 0.004980
2021-12-13 00:49:10,719 iteration 4111 : loss : 0.021266, loss_ce: 0.006032
2021-12-13 00:49:12,090 iteration 4112 : loss : 0.013842, loss_ce: 0.005161
2021-12-13 00:49:13,613 iteration 4113 : loss : 0.023663, loss_ce: 0.007534
2021-12-13 00:49:15,085 iteration 4114 : loss : 0.026729, loss_ce: 0.011500
 60%|████████████████▎          | 242/400 [1:49:33<1:10:54, 26.93s/it]2021-12-13 00:49:16,595 iteration 4115 : loss : 0.019547, loss_ce: 0.005580
2021-12-13 00:49:18,024 iteration 4116 : loss : 0.018296, loss_ce: 0.007286
2021-12-13 00:49:19,438 iteration 4117 : loss : 0.014921, loss_ce: 0.007400
2021-12-13 00:49:20,882 iteration 4118 : loss : 0.026046, loss_ce: 0.008476
2021-12-13 00:49:22,257 iteration 4119 : loss : 0.014557, loss_ce: 0.005366
2021-12-13 00:49:23,830 iteration 4120 : loss : 0.017709, loss_ce: 0.004713
2021-12-13 00:49:25,301 iteration 4121 : loss : 0.023802, loss_ce: 0.008920
2021-12-13 00:49:26,792 iteration 4122 : loss : 0.019815, loss_ce: 0.006422
2021-12-13 00:49:28,279 iteration 4123 : loss : 0.025497, loss_ce: 0.009939
2021-12-13 00:49:29,667 iteration 4124 : loss : 0.016721, loss_ce: 0.007219
2021-12-13 00:49:31,146 iteration 4125 : loss : 0.021530, loss_ce: 0.006962
2021-12-13 00:49:32,709 iteration 4126 : loss : 0.027726, loss_ce: 0.012878
2021-12-13 00:49:34,222 iteration 4127 : loss : 0.022711, loss_ce: 0.010938
2021-12-13 00:49:35,655 iteration 4128 : loss : 0.017954, loss_ce: 0.008038
2021-12-13 00:49:37,228 iteration 4129 : loss : 0.022637, loss_ce: 0.005709
2021-12-13 00:49:38,741 iteration 4130 : loss : 0.024860, loss_ce: 0.008318
2021-12-13 00:49:40,193 iteration 4131 : loss : 0.016846, loss_ce: 0.007129
 61%|████████████████▍          | 243/400 [1:49:58<1:09:01, 26.38s/it]2021-12-13 00:49:41,732 iteration 4132 : loss : 0.027483, loss_ce: 0.011528
2021-12-13 00:49:43,139 iteration 4133 : loss : 0.022377, loss_ce: 0.011158
2021-12-13 00:49:44,653 iteration 4134 : loss : 0.016294, loss_ce: 0.007044
2021-12-13 00:49:46,120 iteration 4135 : loss : 0.030652, loss_ce: 0.011407
2021-12-13 00:49:47,577 iteration 4136 : loss : 0.014682, loss_ce: 0.004306
2021-12-13 00:49:49,066 iteration 4137 : loss : 0.019296, loss_ce: 0.009787
2021-12-13 00:49:50,544 iteration 4138 : loss : 0.014861, loss_ce: 0.007230
2021-12-13 00:49:52,016 iteration 4139 : loss : 0.026678, loss_ce: 0.006717
2021-12-13 00:49:53,523 iteration 4140 : loss : 0.020305, loss_ce: 0.006074
2021-12-13 00:49:54,986 iteration 4141 : loss : 0.019078, loss_ce: 0.004994
2021-12-13 00:49:56,428 iteration 4142 : loss : 0.018227, loss_ce: 0.008045
2021-12-13 00:49:57,866 iteration 4143 : loss : 0.018774, loss_ce: 0.006546
2021-12-13 00:49:59,351 iteration 4144 : loss : 0.017043, loss_ce: 0.005437
2021-12-13 00:50:00,798 iteration 4145 : loss : 0.020900, loss_ce: 0.007101
2021-12-13 00:50:02,160 iteration 4146 : loss : 0.016437, loss_ce: 0.004632
2021-12-13 00:50:03,606 iteration 4147 : loss : 0.016423, loss_ce: 0.006351
2021-12-13 00:50:05,059 iteration 4148 : loss : 0.021651, loss_ce: 0.008609
 61%|████████████████▍          | 244/400 [1:50:23<1:07:24, 25.92s/it]2021-12-13 00:50:06,562 iteration 4149 : loss : 0.026754, loss_ce: 0.009904
2021-12-13 00:50:08,000 iteration 4150 : loss : 0.016109, loss_ce: 0.005792
2021-12-13 00:50:09,444 iteration 4151 : loss : 0.015762, loss_ce: 0.006443
2021-12-13 00:50:10,974 iteration 4152 : loss : 0.024426, loss_ce: 0.010236
2021-12-13 00:50:12,472 iteration 4153 : loss : 0.020736, loss_ce: 0.008768
2021-12-13 00:50:13,886 iteration 4154 : loss : 0.014334, loss_ce: 0.005660
2021-12-13 00:50:15,304 iteration 4155 : loss : 0.015075, loss_ce: 0.007153
2021-12-13 00:50:16,768 iteration 4156 : loss : 0.022561, loss_ce: 0.007286
2021-12-13 00:50:18,249 iteration 4157 : loss : 0.020167, loss_ce: 0.007389
2021-12-13 00:50:19,693 iteration 4158 : loss : 0.013909, loss_ce: 0.005302
2021-12-13 00:50:21,212 iteration 4159 : loss : 0.016642, loss_ce: 0.007554
2021-12-13 00:50:22,688 iteration 4160 : loss : 0.021917, loss_ce: 0.008823
2021-12-13 00:50:24,124 iteration 4161 : loss : 0.021245, loss_ce: 0.006672
2021-12-13 00:50:25,613 iteration 4162 : loss : 0.024187, loss_ce: 0.008947
2021-12-13 00:50:27,096 iteration 4163 : loss : 0.018308, loss_ce: 0.006788
2021-12-13 00:50:28,560 iteration 4164 : loss : 0.017104, loss_ce: 0.004816
2021-12-13 00:50:28,560 Training Data Eval:
2021-12-13 00:50:36,045   Average segmentation loss on training set: 0.0112
2021-12-13 00:50:36,046 Validation Data Eval:
2021-12-13 00:50:38,641   Average segmentation loss on validation set: 0.0804
2021-12-13 00:50:40,141 iteration 4165 : loss : 0.021481, loss_ce: 0.007039
 61%|████████████████▌          | 245/400 [1:50:58<1:14:04, 28.67s/it]2021-12-13 00:50:41,643 iteration 4166 : loss : 0.027602, loss_ce: 0.007243
2021-12-13 00:50:43,091 iteration 4167 : loss : 0.014272, loss_ce: 0.006043
2021-12-13 00:50:44,492 iteration 4168 : loss : 0.016589, loss_ce: 0.004953
2021-12-13 00:50:45,929 iteration 4169 : loss : 0.019067, loss_ce: 0.007920
2021-12-13 00:50:47,487 iteration 4170 : loss : 0.023124, loss_ce: 0.007652
2021-12-13 00:50:49,053 iteration 4171 : loss : 0.018269, loss_ce: 0.006492
2021-12-13 00:50:50,452 iteration 4172 : loss : 0.015638, loss_ce: 0.003570
2021-12-13 00:50:51,928 iteration 4173 : loss : 0.016946, loss_ce: 0.005813
2021-12-13 00:50:53,407 iteration 4174 : loss : 0.018686, loss_ce: 0.008297
2021-12-13 00:50:54,903 iteration 4175 : loss : 0.020046, loss_ce: 0.006888
2021-12-13 00:50:56,377 iteration 4176 : loss : 0.027056, loss_ce: 0.011319
2021-12-13 00:50:57,867 iteration 4177 : loss : 0.023317, loss_ce: 0.008140
2021-12-13 00:50:59,331 iteration 4178 : loss : 0.017792, loss_ce: 0.007509
2021-12-13 00:51:00,860 iteration 4179 : loss : 0.021531, loss_ce: 0.007479
2021-12-13 00:51:02,322 iteration 4180 : loss : 0.042424, loss_ce: 0.014944
2021-12-13 00:51:03,687 iteration 4181 : loss : 0.022884, loss_ce: 0.007104
2021-12-13 00:51:05,175 iteration 4182 : loss : 0.019848, loss_ce: 0.010124
 62%|████████████████▌          | 246/400 [1:51:23<1:10:47, 27.58s/it]2021-12-13 00:51:06,680 iteration 4183 : loss : 0.018347, loss_ce: 0.005881
2021-12-13 00:51:08,154 iteration 4184 : loss : 0.022630, loss_ce: 0.008118
2021-12-13 00:51:09,597 iteration 4185 : loss : 0.019632, loss_ce: 0.006982
2021-12-13 00:51:11,028 iteration 4186 : loss : 0.017102, loss_ce: 0.006553
2021-12-13 00:51:12,546 iteration 4187 : loss : 0.030752, loss_ce: 0.011189
2021-12-13 00:51:14,053 iteration 4188 : loss : 0.022290, loss_ce: 0.009859
2021-12-13 00:51:15,524 iteration 4189 : loss : 0.015910, loss_ce: 0.004116
2021-12-13 00:51:17,037 iteration 4190 : loss : 0.023472, loss_ce: 0.008907
2021-12-13 00:51:18,468 iteration 4191 : loss : 0.022698, loss_ce: 0.007145
2021-12-13 00:51:19,941 iteration 4192 : loss : 0.027284, loss_ce: 0.007912
2021-12-13 00:51:21,423 iteration 4193 : loss : 0.015685, loss_ce: 0.005355
2021-12-13 00:51:22,908 iteration 4194 : loss : 0.022005, loss_ce: 0.008557
2021-12-13 00:51:24,498 iteration 4195 : loss : 0.030296, loss_ce: 0.009022
2021-12-13 00:51:25,915 iteration 4196 : loss : 0.015592, loss_ce: 0.008060
2021-12-13 00:51:27,426 iteration 4197 : loss : 0.019362, loss_ce: 0.006454
2021-12-13 00:51:28,883 iteration 4198 : loss : 0.018978, loss_ce: 0.007019
2021-12-13 00:51:30,266 iteration 4199 : loss : 0.017570, loss_ce: 0.006567
 62%|████████████████▋          | 247/400 [1:51:48<1:08:25, 26.83s/it]2021-12-13 00:51:31,726 iteration 4200 : loss : 0.019658, loss_ce: 0.006744
2021-12-13 00:51:33,214 iteration 4201 : loss : 0.018368, loss_ce: 0.007538
2021-12-13 00:51:34,607 iteration 4202 : loss : 0.012897, loss_ce: 0.005943
2021-12-13 00:51:36,029 iteration 4203 : loss : 0.017035, loss_ce: 0.007437
2021-12-13 00:51:37,474 iteration 4204 : loss : 0.019636, loss_ce: 0.006993
2021-12-13 00:51:38,893 iteration 4205 : loss : 0.014981, loss_ce: 0.005546
2021-12-13 00:51:40,275 iteration 4206 : loss : 0.018632, loss_ce: 0.006343
2021-12-13 00:51:41,717 iteration 4207 : loss : 0.016260, loss_ce: 0.007171
2021-12-13 00:51:43,173 iteration 4208 : loss : 0.022974, loss_ce: 0.009583
2021-12-13 00:51:44,726 iteration 4209 : loss : 0.040056, loss_ce: 0.012346
2021-12-13 00:51:46,240 iteration 4210 : loss : 0.021564, loss_ce: 0.008222
2021-12-13 00:51:47,566 iteration 4211 : loss : 0.014075, loss_ce: 0.005445
2021-12-13 00:51:49,032 iteration 4212 : loss : 0.018868, loss_ce: 0.007611
2021-12-13 00:51:50,491 iteration 4213 : loss : 0.021159, loss_ce: 0.010399
2021-12-13 00:51:51,988 iteration 4214 : loss : 0.024172, loss_ce: 0.007885
2021-12-13 00:51:53,413 iteration 4215 : loss : 0.018056, loss_ce: 0.006935
2021-12-13 00:51:54,959 iteration 4216 : loss : 0.019814, loss_ce: 0.006683
 62%|████████████████▋          | 248/400 [1:52:13<1:06:21, 26.19s/it]2021-12-13 00:51:56,551 iteration 4217 : loss : 0.016618, loss_ce: 0.006635
2021-12-13 00:51:57,932 iteration 4218 : loss : 0.015352, loss_ce: 0.008211
2021-12-13 00:51:59,338 iteration 4219 : loss : 0.029871, loss_ce: 0.012182
2021-12-13 00:52:00,905 iteration 4220 : loss : 0.024065, loss_ce: 0.008833
2021-12-13 00:52:02,389 iteration 4221 : loss : 0.022742, loss_ce: 0.006110
2021-12-13 00:52:03,886 iteration 4222 : loss : 0.023051, loss_ce: 0.009696
2021-12-13 00:52:05,352 iteration 4223 : loss : 0.022995, loss_ce: 0.008317
2021-12-13 00:52:06,805 iteration 4224 : loss : 0.018504, loss_ce: 0.005789
2021-12-13 00:52:08,242 iteration 4225 : loss : 0.018974, loss_ce: 0.006094
2021-12-13 00:52:09,675 iteration 4226 : loss : 0.017531, loss_ce: 0.004637
2021-12-13 00:52:11,277 iteration 4227 : loss : 0.022380, loss_ce: 0.007655
2021-12-13 00:52:12,702 iteration 4228 : loss : 0.024133, loss_ce: 0.009090
2021-12-13 00:52:14,186 iteration 4229 : loss : 0.020715, loss_ce: 0.007643
2021-12-13 00:52:15,654 iteration 4230 : loss : 0.016399, loss_ce: 0.007906
2021-12-13 00:52:17,097 iteration 4231 : loss : 0.026380, loss_ce: 0.007861
2021-12-13 00:52:18,543 iteration 4232 : loss : 0.016751, loss_ce: 0.007187
2021-12-13 00:52:20,007 iteration 4233 : loss : 0.019600, loss_ce: 0.009481
 62%|████████████████▊          | 249/400 [1:52:38<1:05:03, 25.85s/it]2021-12-13 00:52:21,573 iteration 4234 : loss : 0.019062, loss_ce: 0.009028
2021-12-13 00:52:23,028 iteration 4235 : loss : 0.021939, loss_ce: 0.008061
2021-12-13 00:52:24,430 iteration 4236 : loss : 0.013470, loss_ce: 0.005495
2021-12-13 00:52:25,836 iteration 4237 : loss : 0.016819, loss_ce: 0.006300
2021-12-13 00:52:27,285 iteration 4238 : loss : 0.015542, loss_ce: 0.004918
2021-12-13 00:52:28,799 iteration 4239 : loss : 0.018580, loss_ce: 0.006714
2021-12-13 00:52:30,282 iteration 4240 : loss : 0.022119, loss_ce: 0.007116
2021-12-13 00:52:31,738 iteration 4241 : loss : 0.016814, loss_ce: 0.006890
2021-12-13 00:52:33,092 iteration 4242 : loss : 0.012555, loss_ce: 0.004769
2021-12-13 00:52:34,581 iteration 4243 : loss : 0.027547, loss_ce: 0.012888
2021-12-13 00:52:35,998 iteration 4244 : loss : 0.017941, loss_ce: 0.005797
2021-12-13 00:52:37,441 iteration 4245 : loss : 0.016254, loss_ce: 0.006249
2021-12-13 00:52:38,875 iteration 4246 : loss : 0.020219, loss_ce: 0.006684
2021-12-13 00:52:40,320 iteration 4247 : loss : 0.017824, loss_ce: 0.004530
2021-12-13 00:52:41,710 iteration 4248 : loss : 0.018625, loss_ce: 0.007215
2021-12-13 00:52:43,240 iteration 4249 : loss : 0.022545, loss_ce: 0.009806
2021-12-13 00:52:43,240 Training Data Eval:
2021-12-13 00:52:50,712   Average segmentation loss on training set: 0.0113
2021-12-13 00:52:50,712 Validation Data Eval:
2021-12-13 00:52:53,312   Average segmentation loss on validation set: 0.0746
2021-12-13 00:52:54,794 iteration 4250 : loss : 0.015835, loss_ce: 0.006071
 62%|████████████████▉          | 250/400 [1:53:12<1:11:19, 28.53s/it]2021-12-13 00:52:56,313 iteration 4251 : loss : 0.021770, loss_ce: 0.006700
2021-12-13 00:52:57,766 iteration 4252 : loss : 0.015326, loss_ce: 0.004155
2021-12-13 00:52:59,249 iteration 4253 : loss : 0.014360, loss_ce: 0.007090
2021-12-13 00:53:00,743 iteration 4254 : loss : 0.019304, loss_ce: 0.007398
2021-12-13 00:53:02,220 iteration 4255 : loss : 0.022475, loss_ce: 0.006853
2021-12-13 00:53:03,651 iteration 4256 : loss : 0.027099, loss_ce: 0.011911
2021-12-13 00:53:05,113 iteration 4257 : loss : 0.019312, loss_ce: 0.008505
2021-12-13 00:53:06,623 iteration 4258 : loss : 0.025760, loss_ce: 0.011564
2021-12-13 00:53:07,991 iteration 4259 : loss : 0.016125, loss_ce: 0.005498
2021-12-13 00:53:09,474 iteration 4260 : loss : 0.018649, loss_ce: 0.006342
2021-12-13 00:53:10,871 iteration 4261 : loss : 0.014528, loss_ce: 0.004896
2021-12-13 00:53:12,308 iteration 4262 : loss : 0.015227, loss_ce: 0.006980
2021-12-13 00:53:13,801 iteration 4263 : loss : 0.018433, loss_ce: 0.007080
2021-12-13 00:53:15,257 iteration 4264 : loss : 0.021430, loss_ce: 0.010037
2021-12-13 00:53:16,625 iteration 4265 : loss : 0.015664, loss_ce: 0.006696
2021-12-13 00:53:18,113 iteration 4266 : loss : 0.016454, loss_ce: 0.005448
2021-12-13 00:53:19,594 iteration 4267 : loss : 0.019716, loss_ce: 0.008025
 63%|████████████████▉          | 251/400 [1:53:37<1:08:04, 27.41s/it]2021-12-13 00:53:21,021 iteration 4268 : loss : 0.013251, loss_ce: 0.004840
2021-12-13 00:53:22,418 iteration 4269 : loss : 0.015270, loss_ce: 0.004261
2021-12-13 00:53:23,865 iteration 4270 : loss : 0.020052, loss_ce: 0.005776
2021-12-13 00:53:25,306 iteration 4271 : loss : 0.019737, loss_ce: 0.007192
2021-12-13 00:53:26,751 iteration 4272 : loss : 0.021259, loss_ce: 0.009217
2021-12-13 00:53:28,180 iteration 4273 : loss : 0.021607, loss_ce: 0.008966
2021-12-13 00:53:29,630 iteration 4274 : loss : 0.025640, loss_ce: 0.010089
2021-12-13 00:53:31,071 iteration 4275 : loss : 0.016267, loss_ce: 0.006371
2021-12-13 00:53:32,501 iteration 4276 : loss : 0.019566, loss_ce: 0.007831
2021-12-13 00:53:33,954 iteration 4277 : loss : 0.017283, loss_ce: 0.007422
2021-12-13 00:53:35,385 iteration 4278 : loss : 0.013312, loss_ce: 0.002924
2021-12-13 00:53:36,791 iteration 4279 : loss : 0.016727, loss_ce: 0.006808
2021-12-13 00:53:38,260 iteration 4280 : loss : 0.019224, loss_ce: 0.005728
2021-12-13 00:53:39,722 iteration 4281 : loss : 0.017596, loss_ce: 0.006682
2021-12-13 00:53:41,203 iteration 4282 : loss : 0.023463, loss_ce: 0.007735
2021-12-13 00:53:42,721 iteration 4283 : loss : 0.020543, loss_ce: 0.008086
2021-12-13 00:53:44,230 iteration 4284 : loss : 0.022633, loss_ce: 0.009711
 63%|█████████████████          | 252/400 [1:54:02<1:05:33, 26.58s/it]2021-12-13 00:53:45,658 iteration 4285 : loss : 0.019944, loss_ce: 0.010341
2021-12-13 00:53:47,070 iteration 4286 : loss : 0.016471, loss_ce: 0.005841
2021-12-13 00:53:48,523 iteration 4287 : loss : 0.019980, loss_ce: 0.008020
2021-12-13 00:53:49,931 iteration 4288 : loss : 0.014735, loss_ce: 0.004507
2021-12-13 00:53:51,358 iteration 4289 : loss : 0.016211, loss_ce: 0.006969
2021-12-13 00:53:52,829 iteration 4290 : loss : 0.014062, loss_ce: 0.004982
2021-12-13 00:53:54,356 iteration 4291 : loss : 0.017173, loss_ce: 0.007360
2021-12-13 00:53:55,836 iteration 4292 : loss : 0.025929, loss_ce: 0.015708
2021-12-13 00:53:57,199 iteration 4293 : loss : 0.017027, loss_ce: 0.006435
2021-12-13 00:53:58,616 iteration 4294 : loss : 0.018578, loss_ce: 0.008478
2021-12-13 00:54:00,197 iteration 4295 : loss : 0.024490, loss_ce: 0.009084
2021-12-13 00:54:01,628 iteration 4296 : loss : 0.014844, loss_ce: 0.005581
2021-12-13 00:54:03,048 iteration 4297 : loss : 0.013997, loss_ce: 0.004434
2021-12-13 00:54:04,564 iteration 4298 : loss : 0.017923, loss_ce: 0.006124
2021-12-13 00:54:06,045 iteration 4299 : loss : 0.017236, loss_ce: 0.005170
2021-12-13 00:54:07,594 iteration 4300 : loss : 0.017535, loss_ce: 0.005483
2021-12-13 00:54:09,038 iteration 4301 : loss : 0.021752, loss_ce: 0.008233
 63%|█████████████████          | 253/400 [1:54:27<1:03:48, 26.05s/it]2021-12-13 00:54:10,588 iteration 4302 : loss : 0.032080, loss_ce: 0.011489
2021-12-13 00:54:11,974 iteration 4303 : loss : 0.014259, loss_ce: 0.006950
2021-12-13 00:54:13,440 iteration 4304 : loss : 0.017038, loss_ce: 0.007704
2021-12-13 00:54:14,910 iteration 4305 : loss : 0.025936, loss_ce: 0.006983
2021-12-13 00:54:16,351 iteration 4306 : loss : 0.016671, loss_ce: 0.005349
2021-12-13 00:54:17,873 iteration 4307 : loss : 0.018323, loss_ce: 0.005908
2021-12-13 00:54:19,312 iteration 4308 : loss : 0.019231, loss_ce: 0.007189
2021-12-13 00:54:20,807 iteration 4309 : loss : 0.015538, loss_ce: 0.005177
2021-12-13 00:54:22,212 iteration 4310 : loss : 0.015944, loss_ce: 0.005269
2021-12-13 00:54:23,757 iteration 4311 : loss : 0.020359, loss_ce: 0.007807
2021-12-13 00:54:25,188 iteration 4312 : loss : 0.015803, loss_ce: 0.007506
2021-12-13 00:54:26,693 iteration 4313 : loss : 0.017716, loss_ce: 0.008070
2021-12-13 00:54:28,162 iteration 4314 : loss : 0.015790, loss_ce: 0.005031
2021-12-13 00:54:29,590 iteration 4315 : loss : 0.017261, loss_ce: 0.006832
2021-12-13 00:54:31,030 iteration 4316 : loss : 0.020452, loss_ce: 0.007622
2021-12-13 00:54:32,491 iteration 4317 : loss : 0.021289, loss_ce: 0.008735
2021-12-13 00:54:34,036 iteration 4318 : loss : 0.019548, loss_ce: 0.007136
 64%|█████████████████▏         | 254/400 [1:54:52<1:02:37, 25.73s/it]2021-12-13 00:54:35,499 iteration 4319 : loss : 0.014385, loss_ce: 0.005034
2021-12-13 00:54:36,875 iteration 4320 : loss : 0.016384, loss_ce: 0.007308
2021-12-13 00:54:38,469 iteration 4321 : loss : 0.021958, loss_ce: 0.011079
2021-12-13 00:54:39,909 iteration 4322 : loss : 0.017932, loss_ce: 0.006172
2021-12-13 00:54:41,354 iteration 4323 : loss : 0.021042, loss_ce: 0.007073
2021-12-13 00:54:42,784 iteration 4324 : loss : 0.012418, loss_ce: 0.005314
2021-12-13 00:54:44,217 iteration 4325 : loss : 0.028920, loss_ce: 0.011526
2021-12-13 00:54:45,721 iteration 4326 : loss : 0.024485, loss_ce: 0.007560
2021-12-13 00:54:47,252 iteration 4327 : loss : 0.015703, loss_ce: 0.006258
2021-12-13 00:54:48,744 iteration 4328 : loss : 0.016189, loss_ce: 0.007472
2021-12-13 00:54:50,175 iteration 4329 : loss : 0.014569, loss_ce: 0.005394
2021-12-13 00:54:51,578 iteration 4330 : loss : 0.018306, loss_ce: 0.007981
2021-12-13 00:54:53,021 iteration 4331 : loss : 0.018194, loss_ce: 0.008574
2021-12-13 00:54:54,435 iteration 4332 : loss : 0.015237, loss_ce: 0.005362
2021-12-13 00:54:55,808 iteration 4333 : loss : 0.013011, loss_ce: 0.005318
2021-12-13 00:54:57,297 iteration 4334 : loss : 0.015912, loss_ce: 0.004913
2021-12-13 00:54:57,297 Training Data Eval:
2021-12-13 00:55:04,784   Average segmentation loss on training set: 0.0113
2021-12-13 00:55:04,784 Validation Data Eval:
2021-12-13 00:55:07,380   Average segmentation loss on validation set: 0.0625
2021-12-13 00:55:08,877 iteration 4335 : loss : 0.032626, loss_ce: 0.008202
 64%|█████████████████▏         | 255/400 [1:55:26<1:08:47, 28.46s/it]2021-12-13 00:55:10,308 iteration 4336 : loss : 0.017836, loss_ce: 0.007373
2021-12-13 00:55:11,798 iteration 4337 : loss : 0.015712, loss_ce: 0.006608
2021-12-13 00:55:13,285 iteration 4338 : loss : 0.019681, loss_ce: 0.007382
2021-12-13 00:55:14,669 iteration 4339 : loss : 0.019374, loss_ce: 0.004609
2021-12-13 00:55:16,158 iteration 4340 : loss : 0.017995, loss_ce: 0.003246
2021-12-13 00:55:17,599 iteration 4341 : loss : 0.020121, loss_ce: 0.008212
2021-12-13 00:55:19,024 iteration 4342 : loss : 0.014924, loss_ce: 0.005653
2021-12-13 00:55:20,525 iteration 4343 : loss : 0.042741, loss_ce: 0.012377
2021-12-13 00:55:21,932 iteration 4344 : loss : 0.015475, loss_ce: 0.006113
2021-12-13 00:55:23,355 iteration 4345 : loss : 0.016165, loss_ce: 0.006676
2021-12-13 00:55:24,715 iteration 4346 : loss : 0.012700, loss_ce: 0.004419
2021-12-13 00:55:26,225 iteration 4347 : loss : 0.021010, loss_ce: 0.007434
2021-12-13 00:55:27,724 iteration 4348 : loss : 0.021115, loss_ce: 0.010469
2021-12-13 00:55:29,109 iteration 4349 : loss : 0.018933, loss_ce: 0.007790
2021-12-13 00:55:30,498 iteration 4350 : loss : 0.018453, loss_ce: 0.007682
2021-12-13 00:55:32,017 iteration 4351 : loss : 0.020304, loss_ce: 0.009568
2021-12-13 00:55:33,514 iteration 4352 : loss : 0.020620, loss_ce: 0.008206
 64%|█████████████████▎         | 256/400 [1:55:51<1:05:33, 27.32s/it]2021-12-13 00:55:34,982 iteration 4353 : loss : 0.015706, loss_ce: 0.005739
2021-12-13 00:55:36,514 iteration 4354 : loss : 0.017892, loss_ce: 0.005187
2021-12-13 00:55:37,994 iteration 4355 : loss : 0.015813, loss_ce: 0.004776
2021-12-13 00:55:39,406 iteration 4356 : loss : 0.014162, loss_ce: 0.005532
2021-12-13 00:55:40,936 iteration 4357 : loss : 0.021788, loss_ce: 0.009379
2021-12-13 00:55:42,373 iteration 4358 : loss : 0.020155, loss_ce: 0.008015
2021-12-13 00:55:43,853 iteration 4359 : loss : 0.020166, loss_ce: 0.006407
2021-12-13 00:55:45,235 iteration 4360 : loss : 0.013888, loss_ce: 0.005540
2021-12-13 00:55:46,734 iteration 4361 : loss : 0.021421, loss_ce: 0.008097
2021-12-13 00:55:48,134 iteration 4362 : loss : 0.018136, loss_ce: 0.006512
2021-12-13 00:55:49,632 iteration 4363 : loss : 0.018183, loss_ce: 0.007072
2021-12-13 00:55:51,093 iteration 4364 : loss : 0.016592, loss_ce: 0.007135
2021-12-13 00:55:52,611 iteration 4365 : loss : 0.019267, loss_ce: 0.006049
2021-12-13 00:55:54,028 iteration 4366 : loss : 0.013746, loss_ce: 0.005726
2021-12-13 00:55:55,411 iteration 4367 : loss : 0.016735, loss_ce: 0.007013
2021-12-13 00:55:56,844 iteration 4368 : loss : 0.011553, loss_ce: 0.004037
2021-12-13 00:55:58,354 iteration 4369 : loss : 0.025007, loss_ce: 0.009575
 64%|█████████████████▎         | 257/400 [1:56:16<1:03:19, 26.57s/it]2021-12-13 00:55:59,810 iteration 4370 : loss : 0.016430, loss_ce: 0.005842
2021-12-13 00:56:01,414 iteration 4371 : loss : 0.021618, loss_ce: 0.008343
2021-12-13 00:56:02,904 iteration 4372 : loss : 0.036014, loss_ce: 0.011006
2021-12-13 00:56:04,385 iteration 4373 : loss : 0.020068, loss_ce: 0.006812
2021-12-13 00:56:05,797 iteration 4374 : loss : 0.016737, loss_ce: 0.006093
2021-12-13 00:56:07,257 iteration 4375 : loss : 0.013606, loss_ce: 0.005583
2021-12-13 00:56:08,752 iteration 4376 : loss : 0.016266, loss_ce: 0.005762
2021-12-13 00:56:10,179 iteration 4377 : loss : 0.015755, loss_ce: 0.005428
2021-12-13 00:56:11,689 iteration 4378 : loss : 0.019640, loss_ce: 0.009884
2021-12-13 00:56:13,114 iteration 4379 : loss : 0.017372, loss_ce: 0.006675
2021-12-13 00:56:14,573 iteration 4380 : loss : 0.021288, loss_ce: 0.006630
2021-12-13 00:56:16,052 iteration 4381 : loss : 0.018283, loss_ce: 0.005284
2021-12-13 00:56:17,605 iteration 4382 : loss : 0.027985, loss_ce: 0.009825
2021-12-13 00:56:19,063 iteration 4383 : loss : 0.022677, loss_ce: 0.007861
2021-12-13 00:56:20,568 iteration 4384 : loss : 0.016748, loss_ce: 0.006084
2021-12-13 00:56:22,089 iteration 4385 : loss : 0.021276, loss_ce: 0.009871
2021-12-13 00:56:23,531 iteration 4386 : loss : 0.017404, loss_ce: 0.004789
 64%|█████████████████▍         | 258/400 [1:56:41<1:01:53, 26.15s/it]2021-12-13 00:56:25,099 iteration 4387 : loss : 0.025735, loss_ce: 0.007125
2021-12-13 00:56:26,584 iteration 4388 : loss : 0.019121, loss_ce: 0.008440
2021-12-13 00:56:28,062 iteration 4389 : loss : 0.020502, loss_ce: 0.008117
2021-12-13 00:56:29,553 iteration 4390 : loss : 0.019597, loss_ce: 0.009364
2021-12-13 00:56:31,079 iteration 4391 : loss : 0.032668, loss_ce: 0.013512
2021-12-13 00:56:32,564 iteration 4392 : loss : 0.021533, loss_ce: 0.008961
2021-12-13 00:56:34,124 iteration 4393 : loss : 0.019457, loss_ce: 0.008078
2021-12-13 00:56:35,527 iteration 4394 : loss : 0.014692, loss_ce: 0.005722
2021-12-13 00:56:36,995 iteration 4395 : loss : 0.014865, loss_ce: 0.006363
2021-12-13 00:56:38,472 iteration 4396 : loss : 0.018107, loss_ce: 0.006995
2021-12-13 00:56:39,884 iteration 4397 : loss : 0.014606, loss_ce: 0.004678
2021-12-13 00:56:41,352 iteration 4398 : loss : 0.017202, loss_ce: 0.006258
2021-12-13 00:56:42,816 iteration 4399 : loss : 0.020128, loss_ce: 0.006581
2021-12-13 00:56:44,235 iteration 4400 : loss : 0.015561, loss_ce: 0.004928
2021-12-13 00:56:45,738 iteration 4401 : loss : 0.017362, loss_ce: 0.008461
2021-12-13 00:56:47,119 iteration 4402 : loss : 0.016206, loss_ce: 0.005317
2021-12-13 00:56:48,592 iteration 4403 : loss : 0.015855, loss_ce: 0.004535
 65%|█████████████████▍         | 259/400 [1:57:06<1:00:41, 25.83s/it]2021-12-13 00:56:50,156 iteration 4404 : loss : 0.021878, loss_ce: 0.008970
2021-12-13 00:56:51,616 iteration 4405 : loss : 0.022907, loss_ce: 0.008465
2021-12-13 00:56:53,107 iteration 4406 : loss : 0.018200, loss_ce: 0.007812
2021-12-13 00:56:54,591 iteration 4407 : loss : 0.022396, loss_ce: 0.005121
2021-12-13 00:56:56,035 iteration 4408 : loss : 0.015232, loss_ce: 0.007386
2021-12-13 00:56:57,451 iteration 4409 : loss : 0.022518, loss_ce: 0.008049
2021-12-13 00:56:59,007 iteration 4410 : loss : 0.022408, loss_ce: 0.008932
2021-12-13 00:57:00,489 iteration 4411 : loss : 0.019903, loss_ce: 0.008389
2021-12-13 00:57:01,964 iteration 4412 : loss : 0.019110, loss_ce: 0.006289
2021-12-13 00:57:03,461 iteration 4413 : loss : 0.014069, loss_ce: 0.005711
2021-12-13 00:57:04,907 iteration 4414 : loss : 0.019482, loss_ce: 0.005684
2021-12-13 00:57:06,328 iteration 4415 : loss : 0.015108, loss_ce: 0.006917
2021-12-13 00:57:07,812 iteration 4416 : loss : 0.026317, loss_ce: 0.009071
2021-12-13 00:57:09,286 iteration 4417 : loss : 0.020537, loss_ce: 0.010745
2021-12-13 00:57:10,762 iteration 4418 : loss : 0.015457, loss_ce: 0.006221
2021-12-13 00:57:12,217 iteration 4419 : loss : 0.017251, loss_ce: 0.006098
2021-12-13 00:57:12,217 Training Data Eval:
2021-12-13 00:57:19,707   Average segmentation loss on training set: 0.0112
2021-12-13 00:57:19,707 Validation Data Eval:
2021-12-13 00:57:22,310   Average segmentation loss on validation set: 0.0636
2021-12-13 00:57:23,776 iteration 4420 : loss : 0.014078, loss_ce: 0.004470
 65%|█████████████████▌         | 260/400 [1:57:41<1:06:48, 28.63s/it]2021-12-13 00:57:25,302 iteration 4421 : loss : 0.028386, loss_ce: 0.009136
2021-12-13 00:57:26,750 iteration 4422 : loss : 0.014074, loss_ce: 0.004518
2021-12-13 00:57:28,201 iteration 4423 : loss : 0.011427, loss_ce: 0.004022
2021-12-13 00:57:29,709 iteration 4424 : loss : 0.020697, loss_ce: 0.008573
2021-12-13 00:57:31,161 iteration 4425 : loss : 0.026005, loss_ce: 0.008379
2021-12-13 00:57:32,600 iteration 4426 : loss : 0.026291, loss_ce: 0.006548
2021-12-13 00:57:34,070 iteration 4427 : loss : 0.017855, loss_ce: 0.007306
2021-12-13 00:57:35,567 iteration 4428 : loss : 0.018818, loss_ce: 0.007071
2021-12-13 00:57:36,947 iteration 4429 : loss : 0.021879, loss_ce: 0.009950
2021-12-13 00:57:38,430 iteration 4430 : loss : 0.026068, loss_ce: 0.011786
2021-12-13 00:57:39,953 iteration 4431 : loss : 0.026825, loss_ce: 0.008536
2021-12-13 00:57:41,480 iteration 4432 : loss : 0.024963, loss_ce: 0.011021
2021-12-13 00:57:42,961 iteration 4433 : loss : 0.017476, loss_ce: 0.004309
2021-12-13 00:57:44,458 iteration 4434 : loss : 0.018998, loss_ce: 0.007867
2021-12-13 00:57:45,871 iteration 4435 : loss : 0.013873, loss_ce: 0.004414
2021-12-13 00:57:47,319 iteration 4436 : loss : 0.016069, loss_ce: 0.008022
2021-12-13 00:57:48,774 iteration 4437 : loss : 0.015581, loss_ce: 0.005727
 65%|█████████████████▌         | 261/400 [1:58:06<1:03:48, 27.54s/it]2021-12-13 00:57:50,358 iteration 4438 : loss : 0.026792, loss_ce: 0.010615
2021-12-13 00:57:51,740 iteration 4439 : loss : 0.016562, loss_ce: 0.007540
2021-12-13 00:57:53,269 iteration 4440 : loss : 0.019928, loss_ce: 0.009046
2021-12-13 00:57:54,733 iteration 4441 : loss : 0.015204, loss_ce: 0.005842
2021-12-13 00:57:56,278 iteration 4442 : loss : 0.019108, loss_ce: 0.007262
2021-12-13 00:57:57,807 iteration 4443 : loss : 0.019337, loss_ce: 0.007288
2021-12-13 00:57:59,290 iteration 4444 : loss : 0.014796, loss_ce: 0.004937
2021-12-13 00:58:00,720 iteration 4445 : loss : 0.016279, loss_ce: 0.005388
2021-12-13 00:58:02,242 iteration 4446 : loss : 0.034814, loss_ce: 0.006501
2021-12-13 00:58:03,796 iteration 4447 : loss : 0.019988, loss_ce: 0.006034
2021-12-13 00:58:05,242 iteration 4448 : loss : 0.018492, loss_ce: 0.005929
2021-12-13 00:58:06,785 iteration 4449 : loss : 0.023151, loss_ce: 0.009594
2021-12-13 00:58:08,221 iteration 4450 : loss : 0.018624, loss_ce: 0.009462
2021-12-13 00:58:09,713 iteration 4451 : loss : 0.017875, loss_ce: 0.006253
2021-12-13 00:58:11,155 iteration 4452 : loss : 0.020401, loss_ce: 0.006255
2021-12-13 00:58:12,577 iteration 4453 : loss : 0.016604, loss_ce: 0.006118
2021-12-13 00:58:14,011 iteration 4454 : loss : 0.016906, loss_ce: 0.005951
 66%|█████████████████▋         | 262/400 [1:58:32<1:01:45, 26.85s/it]2021-12-13 00:58:15,493 iteration 4455 : loss : 0.021170, loss_ce: 0.006862
2021-12-13 00:58:16,895 iteration 4456 : loss : 0.016921, loss_ce: 0.006179
2021-12-13 00:58:18,353 iteration 4457 : loss : 0.016797, loss_ce: 0.006577
2021-12-13 00:58:19,794 iteration 4458 : loss : 0.018284, loss_ce: 0.007127
2021-12-13 00:58:21,304 iteration 4459 : loss : 0.033501, loss_ce: 0.007881
2021-12-13 00:58:22,731 iteration 4460 : loss : 0.014610, loss_ce: 0.005716
2021-12-13 00:58:24,176 iteration 4461 : loss : 0.015596, loss_ce: 0.006946
2021-12-13 00:58:25,720 iteration 4462 : loss : 0.034052, loss_ce: 0.015536
2021-12-13 00:58:27,119 iteration 4463 : loss : 0.017677, loss_ce: 0.007339
2021-12-13 00:58:28,555 iteration 4464 : loss : 0.014690, loss_ce: 0.006491
2021-12-13 00:58:30,106 iteration 4465 : loss : 0.084417, loss_ce: 0.011606
2021-12-13 00:58:31,488 iteration 4466 : loss : 0.013928, loss_ce: 0.004902
2021-12-13 00:58:32,974 iteration 4467 : loss : 0.022046, loss_ce: 0.010283
2021-12-13 00:58:34,437 iteration 4468 : loss : 0.029678, loss_ce: 0.009211
2021-12-13 00:58:35,887 iteration 4469 : loss : 0.014514, loss_ce: 0.004140
2021-12-13 00:58:37,323 iteration 4470 : loss : 0.022551, loss_ce: 0.009534
2021-12-13 00:58:38,828 iteration 4471 : loss : 0.028026, loss_ce: 0.007380
 66%|███████████████████          | 263/400 [1:58:56<59:54, 26.24s/it]2021-12-13 00:58:40,290 iteration 4472 : loss : 0.019036, loss_ce: 0.007587
2021-12-13 00:58:41,801 iteration 4473 : loss : 0.020733, loss_ce: 0.008656
2021-12-13 00:58:43,360 iteration 4474 : loss : 0.025668, loss_ce: 0.012803
2021-12-13 00:58:44,838 iteration 4475 : loss : 0.025876, loss_ce: 0.009972
2021-12-13 00:58:46,272 iteration 4476 : loss : 0.028521, loss_ce: 0.009881
2021-12-13 00:58:47,708 iteration 4477 : loss : 0.024526, loss_ce: 0.012230
2021-12-13 00:58:49,255 iteration 4478 : loss : 0.029354, loss_ce: 0.014610
2021-12-13 00:58:50,695 iteration 4479 : loss : 0.020538, loss_ce: 0.009492
2021-12-13 00:58:52,087 iteration 4480 : loss : 0.016248, loss_ce: 0.006567
2021-12-13 00:58:53,598 iteration 4481 : loss : 0.023228, loss_ce: 0.005626
2021-12-13 00:58:55,056 iteration 4482 : loss : 0.017117, loss_ce: 0.005617
2021-12-13 00:58:56,472 iteration 4483 : loss : 0.028121, loss_ce: 0.008452
2021-12-13 00:58:58,017 iteration 4484 : loss : 0.023917, loss_ce: 0.007531
2021-12-13 00:58:59,546 iteration 4485 : loss : 0.033196, loss_ce: 0.013256
2021-12-13 00:59:01,079 iteration 4486 : loss : 0.021646, loss_ce: 0.006717
2021-12-13 00:59:02,500 iteration 4487 : loss : 0.018591, loss_ce: 0.005293
2021-12-13 00:59:03,935 iteration 4488 : loss : 0.020608, loss_ce: 0.007193
 66%|███████████████████▏         | 264/400 [1:59:22<58:42, 25.90s/it]2021-12-13 00:59:05,476 iteration 4489 : loss : 0.023778, loss_ce: 0.010962
2021-12-13 00:59:06,897 iteration 4490 : loss : 0.014773, loss_ce: 0.008015
2021-12-13 00:59:08,419 iteration 4491 : loss : 0.022548, loss_ce: 0.007428
2021-12-13 00:59:09,969 iteration 4492 : loss : 0.019290, loss_ce: 0.008241
2021-12-13 00:59:11,417 iteration 4493 : loss : 0.024474, loss_ce: 0.011021
2021-12-13 00:59:12,889 iteration 4494 : loss : 0.018201, loss_ce: 0.005528
2021-12-13 00:59:14,359 iteration 4495 : loss : 0.032365, loss_ce: 0.011469
2021-12-13 00:59:15,793 iteration 4496 : loss : 0.019996, loss_ce: 0.009344
2021-12-13 00:59:17,334 iteration 4497 : loss : 0.021226, loss_ce: 0.009350
2021-12-13 00:59:18,798 iteration 4498 : loss : 0.033600, loss_ce: 0.009660
2021-12-13 00:59:20,294 iteration 4499 : loss : 0.027007, loss_ce: 0.010545
2021-12-13 00:59:21,694 iteration 4500 : loss : 0.014942, loss_ce: 0.005148
2021-12-13 00:59:23,122 iteration 4501 : loss : 0.018426, loss_ce: 0.006308
2021-12-13 00:59:24,570 iteration 4502 : loss : 0.024779, loss_ce: 0.007829
2021-12-13 00:59:26,118 iteration 4503 : loss : 0.021480, loss_ce: 0.008815
2021-12-13 00:59:27,562 iteration 4504 : loss : 0.015505, loss_ce: 0.006032
2021-12-13 00:59:27,563 Training Data Eval:
2021-12-13 00:59:35,071   Average segmentation loss on training set: 0.0805
2021-12-13 00:59:35,072 Validation Data Eval:
2021-12-13 00:59:37,679   Average segmentation loss on validation set: 0.1064
2021-12-13 00:59:39,182 iteration 4505 : loss : 0.020663, loss_ce: 0.007913
 66%|█████████████████▉         | 265/400 [1:59:57<1:04:35, 28.70s/it]2021-12-13 00:59:40,661 iteration 4506 : loss : 0.021748, loss_ce: 0.009349
2021-12-13 00:59:42,147 iteration 4507 : loss : 0.015498, loss_ce: 0.006854
2021-12-13 00:59:43,594 iteration 4508 : loss : 0.019899, loss_ce: 0.008298
2021-12-13 00:59:45,032 iteration 4509 : loss : 0.035939, loss_ce: 0.008793
2021-12-13 00:59:46,554 iteration 4510 : loss : 0.021779, loss_ce: 0.007553
2021-12-13 00:59:47,983 iteration 4511 : loss : 0.018684, loss_ce: 0.004712
2021-12-13 00:59:49,503 iteration 4512 : loss : 0.024068, loss_ce: 0.014971
2021-12-13 00:59:51,051 iteration 4513 : loss : 0.027960, loss_ce: 0.010301
2021-12-13 00:59:52,433 iteration 4514 : loss : 0.017624, loss_ce: 0.005035
2021-12-13 00:59:53,893 iteration 4515 : loss : 0.028782, loss_ce: 0.012854
2021-12-13 00:59:55,305 iteration 4516 : loss : 0.013508, loss_ce: 0.005543
2021-12-13 00:59:56,726 iteration 4517 : loss : 0.017419, loss_ce: 0.007025
2021-12-13 00:59:58,206 iteration 4518 : loss : 0.030350, loss_ce: 0.009760
2021-12-13 00:59:59,590 iteration 4519 : loss : 0.017218, loss_ce: 0.006304
2021-12-13 01:00:01,079 iteration 4520 : loss : 0.029058, loss_ce: 0.010783
2021-12-13 01:00:02,505 iteration 4521 : loss : 0.013988, loss_ce: 0.005802
2021-12-13 01:00:03,968 iteration 4522 : loss : 0.020605, loss_ce: 0.007815
 66%|█████████████████▉         | 266/400 [2:00:22<1:01:29, 27.53s/it]2021-12-13 01:00:05,529 iteration 4523 : loss : 0.016975, loss_ce: 0.006417
2021-12-13 01:00:06,960 iteration 4524 : loss : 0.022411, loss_ce: 0.007765
2021-12-13 01:00:08,357 iteration 4525 : loss : 0.013371, loss_ce: 0.006243
2021-12-13 01:00:09,789 iteration 4526 : loss : 0.016992, loss_ce: 0.004781
2021-12-13 01:00:11,223 iteration 4527 : loss : 0.012223, loss_ce: 0.005060
2021-12-13 01:00:12,690 iteration 4528 : loss : 0.016362, loss_ce: 0.006431
2021-12-13 01:00:14,089 iteration 4529 : loss : 0.016617, loss_ce: 0.005398
2021-12-13 01:00:15,561 iteration 4530 : loss : 0.018591, loss_ce: 0.007689
2021-12-13 01:00:17,109 iteration 4531 : loss : 0.023399, loss_ce: 0.007891
2021-12-13 01:00:18,479 iteration 4532 : loss : 0.014490, loss_ce: 0.005101
2021-12-13 01:00:20,055 iteration 4533 : loss : 0.026328, loss_ce: 0.010792
2021-12-13 01:00:21,473 iteration 4534 : loss : 0.014336, loss_ce: 0.006727
2021-12-13 01:00:22,977 iteration 4535 : loss : 0.032373, loss_ce: 0.016330
2021-12-13 01:00:24,450 iteration 4536 : loss : 0.015414, loss_ce: 0.004286
2021-12-13 01:00:25,873 iteration 4537 : loss : 0.021547, loss_ce: 0.005631
2021-12-13 01:00:27,315 iteration 4538 : loss : 0.015137, loss_ce: 0.006256
2021-12-13 01:00:28,686 iteration 4539 : loss : 0.013509, loss_ce: 0.004819
 67%|███████████████████▎         | 267/400 [2:00:46<59:09, 26.69s/it]2021-12-13 01:00:30,149 iteration 4540 : loss : 0.016289, loss_ce: 0.007097
2021-12-13 01:00:31,606 iteration 4541 : loss : 0.020023, loss_ce: 0.006968
2021-12-13 01:00:33,057 iteration 4542 : loss : 0.019378, loss_ce: 0.005328
2021-12-13 01:00:34,660 iteration 4543 : loss : 0.021589, loss_ce: 0.009916
2021-12-13 01:00:36,063 iteration 4544 : loss : 0.017258, loss_ce: 0.007094
2021-12-13 01:00:37,476 iteration 4545 : loss : 0.017422, loss_ce: 0.008023
2021-12-13 01:00:38,937 iteration 4546 : loss : 0.018961, loss_ce: 0.007586
2021-12-13 01:00:40,419 iteration 4547 : loss : 0.017716, loss_ce: 0.006093
2021-12-13 01:00:41,845 iteration 4548 : loss : 0.018681, loss_ce: 0.008254
2021-12-13 01:00:43,213 iteration 4549 : loss : 0.021402, loss_ce: 0.007670
2021-12-13 01:00:44,740 iteration 4550 : loss : 0.025129, loss_ce: 0.010072
2021-12-13 01:00:46,272 iteration 4551 : loss : 0.024580, loss_ce: 0.009671
2021-12-13 01:00:47,731 iteration 4552 : loss : 0.019363, loss_ce: 0.006050
2021-12-13 01:00:49,170 iteration 4553 : loss : 0.014992, loss_ce: 0.005013
2021-12-13 01:00:50,666 iteration 4554 : loss : 0.025456, loss_ce: 0.008095
2021-12-13 01:00:52,065 iteration 4555 : loss : 0.020705, loss_ce: 0.007104
2021-12-13 01:00:53,517 iteration 4556 : loss : 0.018921, loss_ce: 0.007664
 67%|███████████████████▍         | 268/400 [2:01:11<57:29, 26.13s/it]2021-12-13 01:00:55,008 iteration 4557 : loss : 0.012204, loss_ce: 0.005933
2021-12-13 01:00:56,495 iteration 4558 : loss : 0.023261, loss_ce: 0.011074
2021-12-13 01:00:57,988 iteration 4559 : loss : 0.017592, loss_ce: 0.005533
2021-12-13 01:00:59,430 iteration 4560 : loss : 0.031493, loss_ce: 0.009746
2021-12-13 01:01:00,917 iteration 4561 : loss : 0.022220, loss_ce: 0.006342
2021-12-13 01:01:02,334 iteration 4562 : loss : 0.020617, loss_ce: 0.005962
2021-12-13 01:01:03,816 iteration 4563 : loss : 0.017822, loss_ce: 0.007999
2021-12-13 01:01:05,330 iteration 4564 : loss : 0.017722, loss_ce: 0.006423
2021-12-13 01:01:06,874 iteration 4565 : loss : 0.025155, loss_ce: 0.007283
2021-12-13 01:01:08,376 iteration 4566 : loss : 0.029658, loss_ce: 0.011557
2021-12-13 01:01:09,821 iteration 4567 : loss : 0.019337, loss_ce: 0.007258
2021-12-13 01:01:11,271 iteration 4568 : loss : 0.017941, loss_ce: 0.005420
2021-12-13 01:01:12,809 iteration 4569 : loss : 0.041047, loss_ce: 0.008454
2021-12-13 01:01:14,352 iteration 4570 : loss : 0.027738, loss_ce: 0.014864
2021-12-13 01:01:15,788 iteration 4571 : loss : 0.024059, loss_ce: 0.008940
2021-12-13 01:01:17,191 iteration 4572 : loss : 0.015603, loss_ce: 0.006590
2021-12-13 01:01:18,692 iteration 4573 : loss : 0.016700, loss_ce: 0.007388
 67%|███████████████████▌         | 269/400 [2:01:36<56:25, 25.84s/it]2021-12-13 01:01:20,107 iteration 4574 : loss : 0.016998, loss_ce: 0.008043
2021-12-13 01:01:21,610 iteration 4575 : loss : 0.022015, loss_ce: 0.007168
2021-12-13 01:01:23,178 iteration 4576 : loss : 0.022919, loss_ce: 0.008385
2021-12-13 01:01:24,655 iteration 4577 : loss : 0.016687, loss_ce: 0.005749
2021-12-13 01:01:26,040 iteration 4578 : loss : 0.018453, loss_ce: 0.007420
2021-12-13 01:01:27,568 iteration 4579 : loss : 0.014518, loss_ce: 0.004514
2021-12-13 01:01:29,048 iteration 4580 : loss : 0.015763, loss_ce: 0.006090
2021-12-13 01:01:30,524 iteration 4581 : loss : 0.016250, loss_ce: 0.005903
2021-12-13 01:01:31,976 iteration 4582 : loss : 0.016781, loss_ce: 0.006542
2021-12-13 01:01:33,535 iteration 4583 : loss : 0.027161, loss_ce: 0.006169
2021-12-13 01:01:34,999 iteration 4584 : loss : 0.025685, loss_ce: 0.007578
2021-12-13 01:01:36,419 iteration 4585 : loss : 0.013991, loss_ce: 0.004597
2021-12-13 01:01:37,874 iteration 4586 : loss : 0.018361, loss_ce: 0.008571
2021-12-13 01:01:39,331 iteration 4587 : loss : 0.015903, loss_ce: 0.006036
2021-12-13 01:01:40,861 iteration 4588 : loss : 0.021532, loss_ce: 0.009416
2021-12-13 01:01:42,324 iteration 4589 : loss : 0.020212, loss_ce: 0.008606
2021-12-13 01:01:42,324 Training Data Eval:
2021-12-13 01:01:49,820   Average segmentation loss on training set: 0.0108
2021-12-13 01:01:49,821 Validation Data Eval:
2021-12-13 01:01:52,423   Average segmentation loss on validation set: 0.0642
2021-12-13 01:01:53,943 iteration 4590 : loss : 0.018584, loss_ce: 0.010288
 68%|██████████████████▏        | 270/400 [2:02:12<1:02:06, 28.67s/it]2021-12-13 01:01:55,589 iteration 4591 : loss : 0.022859, loss_ce: 0.007310
2021-12-13 01:01:57,037 iteration 4592 : loss : 0.020442, loss_ce: 0.010185
2021-12-13 01:01:58,490 iteration 4593 : loss : 0.019222, loss_ce: 0.007067
2021-12-13 01:01:59,961 iteration 4594 : loss : 0.015013, loss_ce: 0.005681
2021-12-13 01:02:01,434 iteration 4595 : loss : 0.013791, loss_ce: 0.005502
2021-12-13 01:02:03,009 iteration 4596 : loss : 0.016942, loss_ce: 0.006796
2021-12-13 01:02:04,423 iteration 4597 : loss : 0.033747, loss_ce: 0.010320
2021-12-13 01:02:05,791 iteration 4598 : loss : 0.014700, loss_ce: 0.004270
2021-12-13 01:02:07,221 iteration 4599 : loss : 0.019119, loss_ce: 0.007385
2021-12-13 01:02:08,695 iteration 4600 : loss : 0.018012, loss_ce: 0.006310
2021-12-13 01:02:10,184 iteration 4601 : loss : 0.017058, loss_ce: 0.008074
2021-12-13 01:02:11,719 iteration 4602 : loss : 0.022105, loss_ce: 0.009681
2021-12-13 01:02:13,246 iteration 4603 : loss : 0.019578, loss_ce: 0.006013
2021-12-13 01:02:14,663 iteration 4604 : loss : 0.017736, loss_ce: 0.006280
2021-12-13 01:02:16,130 iteration 4605 : loss : 0.020018, loss_ce: 0.005932
2021-12-13 01:02:17,592 iteration 4606 : loss : 0.032258, loss_ce: 0.011112
2021-12-13 01:02:19,043 iteration 4607 : loss : 0.015878, loss_ce: 0.006557
 68%|███████████████████▋         | 271/400 [2:02:37<59:19, 27.59s/it]2021-12-13 01:02:20,571 iteration 4608 : loss : 0.016060, loss_ce: 0.005761
2021-12-13 01:02:22,048 iteration 4609 : loss : 0.015530, loss_ce: 0.004630
2021-12-13 01:02:23,529 iteration 4610 : loss : 0.019283, loss_ce: 0.004246
2021-12-13 01:02:25,032 iteration 4611 : loss : 0.021470, loss_ce: 0.008850
2021-12-13 01:02:26,492 iteration 4612 : loss : 0.022404, loss_ce: 0.010098
2021-12-13 01:02:27,958 iteration 4613 : loss : 0.022454, loss_ce: 0.007601
2021-12-13 01:02:29,424 iteration 4614 : loss : 0.015670, loss_ce: 0.004739
2021-12-13 01:02:31,003 iteration 4615 : loss : 0.024059, loss_ce: 0.010298
2021-12-13 01:02:32,402 iteration 4616 : loss : 0.017467, loss_ce: 0.008209
2021-12-13 01:02:33,879 iteration 4617 : loss : 0.019742, loss_ce: 0.006514
2021-12-13 01:02:35,310 iteration 4618 : loss : 0.011825, loss_ce: 0.004369
2021-12-13 01:02:36,787 iteration 4619 : loss : 0.020633, loss_ce: 0.009485
2021-12-13 01:02:38,220 iteration 4620 : loss : 0.018896, loss_ce: 0.008227
2021-12-13 01:02:39,666 iteration 4621 : loss : 0.014639, loss_ce: 0.004812
2021-12-13 01:02:41,153 iteration 4622 : loss : 0.018263, loss_ce: 0.007159
2021-12-13 01:02:42,631 iteration 4623 : loss : 0.016208, loss_ce: 0.006883
2021-12-13 01:02:44,058 iteration 4624 : loss : 0.016519, loss_ce: 0.005401
 68%|███████████████████▋         | 272/400 [2:03:02<57:13, 26.82s/it]2021-12-13 01:02:45,607 iteration 4625 : loss : 0.030293, loss_ce: 0.008414
2021-12-13 01:02:47,113 iteration 4626 : loss : 0.021700, loss_ce: 0.007211
2021-12-13 01:02:48,572 iteration 4627 : loss : 0.015439, loss_ce: 0.006803
2021-12-13 01:02:50,033 iteration 4628 : loss : 0.020761, loss_ce: 0.006920
2021-12-13 01:02:51,444 iteration 4629 : loss : 0.026811, loss_ce: 0.004663
2021-12-13 01:02:52,920 iteration 4630 : loss : 0.016540, loss_ce: 0.010014
2021-12-13 01:02:54,351 iteration 4631 : loss : 0.017860, loss_ce: 0.007288
2021-12-13 01:02:55,823 iteration 4632 : loss : 0.018053, loss_ce: 0.005318
2021-12-13 01:02:57,316 iteration 4633 : loss : 0.026633, loss_ce: 0.009087
2021-12-13 01:02:58,865 iteration 4634 : loss : 0.022659, loss_ce: 0.009800
2021-12-13 01:03:00,211 iteration 4635 : loss : 0.013611, loss_ce: 0.004412
2021-12-13 01:03:01,611 iteration 4636 : loss : 0.012194, loss_ce: 0.004599
2021-12-13 01:03:03,079 iteration 4637 : loss : 0.025412, loss_ce: 0.010201
2021-12-13 01:03:04,552 iteration 4638 : loss : 0.016428, loss_ce: 0.008138
2021-12-13 01:03:06,053 iteration 4639 : loss : 0.021989, loss_ce: 0.007086
2021-12-13 01:03:07,552 iteration 4640 : loss : 0.023667, loss_ce: 0.010464
2021-12-13 01:03:09,026 iteration 4641 : loss : 0.022720, loss_ce: 0.009288
 68%|███████████████████▊         | 273/400 [2:03:27<55:35, 26.26s/it]2021-12-13 01:03:10,523 iteration 4642 : loss : 0.022958, loss_ce: 0.008739
2021-12-13 01:03:11,994 iteration 4643 : loss : 0.021955, loss_ce: 0.008797
2021-12-13 01:03:13,487 iteration 4644 : loss : 0.023601, loss_ce: 0.010215
2021-12-13 01:03:14,936 iteration 4645 : loss : 0.023593, loss_ce: 0.007957
2021-12-13 01:03:16,405 iteration 4646 : loss : 0.018201, loss_ce: 0.007710
2021-12-13 01:03:17,880 iteration 4647 : loss : 0.017539, loss_ce: 0.007208
2021-12-13 01:03:19,299 iteration 4648 : loss : 0.016443, loss_ce: 0.006959
2021-12-13 01:03:20,881 iteration 4649 : loss : 0.019211, loss_ce: 0.007100
2021-12-13 01:03:22,230 iteration 4650 : loss : 0.016484, loss_ce: 0.007213
2021-12-13 01:03:23,707 iteration 4651 : loss : 0.019606, loss_ce: 0.006901
2021-12-13 01:03:25,169 iteration 4652 : loss : 0.020732, loss_ce: 0.007663
2021-12-13 01:03:26,558 iteration 4653 : loss : 0.015039, loss_ce: 0.005834
2021-12-13 01:03:27,966 iteration 4654 : loss : 0.017197, loss_ce: 0.004899
2021-12-13 01:03:29,501 iteration 4655 : loss : 0.027250, loss_ce: 0.010185
2021-12-13 01:03:30,962 iteration 4656 : loss : 0.018484, loss_ce: 0.006320
2021-12-13 01:03:32,432 iteration 4657 : loss : 0.017108, loss_ce: 0.007594
2021-12-13 01:03:33,877 iteration 4658 : loss : 0.017824, loss_ce: 0.007919
 68%|███████████████████▊         | 274/400 [2:03:51<54:15, 25.84s/it]2021-12-13 01:03:35,393 iteration 4659 : loss : 0.019265, loss_ce: 0.007254
2021-12-13 01:03:36,833 iteration 4660 : loss : 0.012661, loss_ce: 0.005056
2021-12-13 01:03:38,351 iteration 4661 : loss : 0.022470, loss_ce: 0.011384
2021-12-13 01:03:39,714 iteration 4662 : loss : 0.013084, loss_ce: 0.006203
2021-12-13 01:03:41,276 iteration 4663 : loss : 0.023767, loss_ce: 0.009861
2021-12-13 01:03:42,732 iteration 4664 : loss : 0.017704, loss_ce: 0.007177
2021-12-13 01:03:44,190 iteration 4665 : loss : 0.025157, loss_ce: 0.010529
2021-12-13 01:03:45,696 iteration 4666 : loss : 0.019922, loss_ce: 0.008418
2021-12-13 01:03:47,197 iteration 4667 : loss : 0.020038, loss_ce: 0.006744
2021-12-13 01:03:48,633 iteration 4668 : loss : 0.013429, loss_ce: 0.005698
2021-12-13 01:03:50,136 iteration 4669 : loss : 0.016869, loss_ce: 0.005512
2021-12-13 01:03:51,618 iteration 4670 : loss : 0.025945, loss_ce: 0.006757
2021-12-13 01:03:53,062 iteration 4671 : loss : 0.013800, loss_ce: 0.004690
2021-12-13 01:03:54,500 iteration 4672 : loss : 0.012584, loss_ce: 0.004409
2021-12-13 01:03:55,879 iteration 4673 : loss : 0.013918, loss_ce: 0.004590
2021-12-13 01:03:57,370 iteration 4674 : loss : 0.014444, loss_ce: 0.003035
2021-12-13 01:03:57,370 Training Data Eval:
2021-12-13 01:04:04,856   Average segmentation loss on training set: 0.0167
2021-12-13 01:04:04,857 Validation Data Eval:
2021-12-13 01:04:07,450   Average segmentation loss on validation set: 0.1136
2021-12-13 01:04:08,857 iteration 4675 : loss : 0.013152, loss_ce: 0.004971
 69%|███████████████████▉         | 275/400 [2:04:26<59:32, 28.58s/it]2021-12-13 01:04:10,384 iteration 4676 : loss : 0.014351, loss_ce: 0.006200
2021-12-13 01:04:11,804 iteration 4677 : loss : 0.016250, loss_ce: 0.006350
2021-12-13 01:04:13,312 iteration 4678 : loss : 0.019751, loss_ce: 0.006736
2021-12-13 01:04:14,851 iteration 4679 : loss : 0.019876, loss_ce: 0.008400
2021-12-13 01:04:16,236 iteration 4680 : loss : 0.013984, loss_ce: 0.005612
2021-12-13 01:04:17,686 iteration 4681 : loss : 0.016164, loss_ce: 0.006792
2021-12-13 01:04:19,115 iteration 4682 : loss : 0.017368, loss_ce: 0.006530
2021-12-13 01:04:20,539 iteration 4683 : loss : 0.019163, loss_ce: 0.005837
2021-12-13 01:04:21,995 iteration 4684 : loss : 0.017725, loss_ce: 0.006191
2021-12-13 01:04:23,497 iteration 4685 : loss : 0.013329, loss_ce: 0.005314
2021-12-13 01:04:24,918 iteration 4686 : loss : 0.016471, loss_ce: 0.005743
2021-12-13 01:04:26,386 iteration 4687 : loss : 0.025140, loss_ce: 0.006949
2021-12-13 01:04:27,763 iteration 4688 : loss : 0.011888, loss_ce: 0.005064
2021-12-13 01:04:29,256 iteration 4689 : loss : 0.020646, loss_ce: 0.006744
2021-12-13 01:04:30,628 iteration 4690 : loss : 0.014667, loss_ce: 0.005451
2021-12-13 01:04:32,091 iteration 4691 : loss : 0.028564, loss_ce: 0.007080
2021-12-13 01:04:33,661 iteration 4692 : loss : 0.016172, loss_ce: 0.005567
 69%|████████████████████         | 276/400 [2:04:51<56:43, 27.45s/it]2021-12-13 01:04:35,144 iteration 4693 : loss : 0.016998, loss_ce: 0.006367
2021-12-13 01:04:36,589 iteration 4694 : loss : 0.018246, loss_ce: 0.005812
2021-12-13 01:04:38,070 iteration 4695 : loss : 0.023257, loss_ce: 0.008087
2021-12-13 01:04:39,563 iteration 4696 : loss : 0.015207, loss_ce: 0.005472
2021-12-13 01:04:40,989 iteration 4697 : loss : 0.024420, loss_ce: 0.009257
2021-12-13 01:04:42,419 iteration 4698 : loss : 0.015074, loss_ce: 0.005060
2021-12-13 01:04:43,880 iteration 4699 : loss : 0.021146, loss_ce: 0.005872
2021-12-13 01:04:45,354 iteration 4700 : loss : 0.024547, loss_ce: 0.008507
2021-12-13 01:04:46,796 iteration 4701 : loss : 0.014694, loss_ce: 0.003965
2021-12-13 01:04:48,315 iteration 4702 : loss : 0.018878, loss_ce: 0.005946
2021-12-13 01:04:49,805 iteration 4703 : loss : 0.026637, loss_ce: 0.014025
2021-12-13 01:04:51,290 iteration 4704 : loss : 0.027941, loss_ce: 0.006410
2021-12-13 01:04:52,772 iteration 4705 : loss : 0.028549, loss_ce: 0.007912
2021-12-13 01:04:54,154 iteration 4706 : loss : 0.012892, loss_ce: 0.005129
2021-12-13 01:04:55,577 iteration 4707 : loss : 0.021410, loss_ce: 0.007061
2021-12-13 01:04:57,027 iteration 4708 : loss : 0.019515, loss_ce: 0.009131
2021-12-13 01:04:58,459 iteration 4709 : loss : 0.018971, loss_ce: 0.007727
 69%|████████████████████         | 277/400 [2:05:16<54:38, 26.65s/it]2021-12-13 01:04:59,918 iteration 4710 : loss : 0.020688, loss_ce: 0.007302
2021-12-13 01:05:01,322 iteration 4711 : loss : 0.014816, loss_ce: 0.004733
2021-12-13 01:05:02,704 iteration 4712 : loss : 0.017076, loss_ce: 0.005484
2021-12-13 01:05:04,172 iteration 4713 : loss : 0.024516, loss_ce: 0.007537
2021-12-13 01:05:05,564 iteration 4714 : loss : 0.014879, loss_ce: 0.004369
2021-12-13 01:05:07,046 iteration 4715 : loss : 0.022895, loss_ce: 0.011506
2021-12-13 01:05:08,552 iteration 4716 : loss : 0.023160, loss_ce: 0.008769
2021-12-13 01:05:10,001 iteration 4717 : loss : 0.021397, loss_ce: 0.006701
2021-12-13 01:05:11,477 iteration 4718 : loss : 0.017372, loss_ce: 0.006539
2021-12-13 01:05:12,920 iteration 4719 : loss : 0.015490, loss_ce: 0.005029
2021-12-13 01:05:14,374 iteration 4720 : loss : 0.019339, loss_ce: 0.009465
2021-12-13 01:05:15,822 iteration 4721 : loss : 0.020742, loss_ce: 0.006773
2021-12-13 01:05:17,361 iteration 4722 : loss : 0.016484, loss_ce: 0.006756
2021-12-13 01:05:18,903 iteration 4723 : loss : 0.016905, loss_ce: 0.005652
2021-12-13 01:05:20,449 iteration 4724 : loss : 0.021439, loss_ce: 0.010996
2021-12-13 01:05:21,870 iteration 4725 : loss : 0.022963, loss_ce: 0.008491
2021-12-13 01:05:23,370 iteration 4726 : loss : 0.017726, loss_ce: 0.004796
 70%|████████████████████▏        | 278/400 [2:05:41<53:08, 26.13s/it]2021-12-13 01:05:24,887 iteration 4727 : loss : 0.029808, loss_ce: 0.012801
2021-12-13 01:05:26,357 iteration 4728 : loss : 0.013375, loss_ce: 0.004659
2021-12-13 01:05:27,774 iteration 4729 : loss : 0.015073, loss_ce: 0.004387
2021-12-13 01:05:29,235 iteration 4730 : loss : 0.020443, loss_ce: 0.009528
2021-12-13 01:05:30,704 iteration 4731 : loss : 0.037898, loss_ce: 0.011718
2021-12-13 01:05:32,183 iteration 4732 : loss : 0.014919, loss_ce: 0.005696
2021-12-13 01:05:33,598 iteration 4733 : loss : 0.013720, loss_ce: 0.004935
2021-12-13 01:05:34,997 iteration 4734 : loss : 0.011584, loss_ce: 0.003754
2021-12-13 01:05:36,527 iteration 4735 : loss : 0.023183, loss_ce: 0.011128
2021-12-13 01:05:38,001 iteration 4736 : loss : 0.019542, loss_ce: 0.007431
2021-12-13 01:05:39,533 iteration 4737 : loss : 0.029827, loss_ce: 0.009452
2021-12-13 01:05:41,037 iteration 4738 : loss : 0.043344, loss_ce: 0.005881
2021-12-13 01:05:42,456 iteration 4739 : loss : 0.014564, loss_ce: 0.005283
2021-12-13 01:05:43,859 iteration 4740 : loss : 0.014179, loss_ce: 0.006023
2021-12-13 01:05:45,318 iteration 4741 : loss : 0.019913, loss_ce: 0.011164
2021-12-13 01:05:46,704 iteration 4742 : loss : 0.016290, loss_ce: 0.005797
2021-12-13 01:05:48,179 iteration 4743 : loss : 0.013215, loss_ce: 0.004276
 70%|████████████████████▏        | 279/400 [2:06:06<51:54, 25.74s/it]2021-12-13 01:05:49,682 iteration 4744 : loss : 0.019718, loss_ce: 0.008827
2021-12-13 01:05:51,132 iteration 4745 : loss : 0.016697, loss_ce: 0.007046
2021-12-13 01:05:52,572 iteration 4746 : loss : 0.025902, loss_ce: 0.013770
2021-12-13 01:05:54,072 iteration 4747 : loss : 0.016926, loss_ce: 0.006793
2021-12-13 01:05:55,625 iteration 4748 : loss : 0.021667, loss_ce: 0.008585
2021-12-13 01:05:57,132 iteration 4749 : loss : 0.018784, loss_ce: 0.004957
2021-12-13 01:05:58,586 iteration 4750 : loss : 0.017259, loss_ce: 0.006547
2021-12-13 01:05:59,999 iteration 4751 : loss : 0.016785, loss_ce: 0.006085
2021-12-13 01:06:01,479 iteration 4752 : loss : 0.018402, loss_ce: 0.004404
2021-12-13 01:06:02,976 iteration 4753 : loss : 0.017101, loss_ce: 0.007791
2021-12-13 01:06:04,436 iteration 4754 : loss : 0.017107, loss_ce: 0.004707
2021-12-13 01:06:05,908 iteration 4755 : loss : 0.021955, loss_ce: 0.008580
2021-12-13 01:06:07,373 iteration 4756 : loss : 0.016699, loss_ce: 0.007086
2021-12-13 01:06:08,848 iteration 4757 : loss : 0.014192, loss_ce: 0.005564
2021-12-13 01:06:10,402 iteration 4758 : loss : 0.018934, loss_ce: 0.005396
2021-12-13 01:06:11,807 iteration 4759 : loss : 0.012723, loss_ce: 0.004727
2021-12-13 01:06:11,808 Training Data Eval:
2021-12-13 01:06:19,308   Average segmentation loss on training set: 0.0114
2021-12-13 01:06:19,309 Validation Data Eval:
2021-12-13 01:06:21,913   Average segmentation loss on validation set: 0.0691
2021-12-13 01:06:23,386 iteration 4760 : loss : 0.032760, loss_ce: 0.008666
 70%|████████████████████▎        | 280/400 [2:06:41<57:09, 28.58s/it]2021-12-13 01:06:24,903 iteration 4761 : loss : 0.016290, loss_ce: 0.006986
2021-12-13 01:06:26,392 iteration 4762 : loss : 0.015823, loss_ce: 0.004678
2021-12-13 01:06:27,867 iteration 4763 : loss : 0.019081, loss_ce: 0.006263
2021-12-13 01:06:29,384 iteration 4764 : loss : 0.015145, loss_ce: 0.004213
2021-12-13 01:06:30,872 iteration 4765 : loss : 0.014245, loss_ce: 0.005459
2021-12-13 01:06:32,433 iteration 4766 : loss : 0.019002, loss_ce: 0.005164
2021-12-13 01:06:34,003 iteration 4767 : loss : 0.017205, loss_ce: 0.008435
2021-12-13 01:06:35,493 iteration 4768 : loss : 0.017046, loss_ce: 0.007262
2021-12-13 01:06:36,901 iteration 4769 : loss : 0.014867, loss_ce: 0.005000
2021-12-13 01:06:38,421 iteration 4770 : loss : 0.018590, loss_ce: 0.009427
2021-12-13 01:06:39,872 iteration 4771 : loss : 0.021975, loss_ce: 0.007487
2021-12-13 01:06:41,284 iteration 4772 : loss : 0.017813, loss_ce: 0.006377
2021-12-13 01:06:42,674 iteration 4773 : loss : 0.013573, loss_ce: 0.006399
2021-12-13 01:06:44,173 iteration 4774 : loss : 0.022263, loss_ce: 0.008005
2021-12-13 01:06:45,572 iteration 4775 : loss : 0.013391, loss_ce: 0.004987
2021-12-13 01:06:47,037 iteration 4776 : loss : 0.025944, loss_ce: 0.013411
2021-12-13 01:06:48,492 iteration 4777 : loss : 0.020599, loss_ce: 0.007383
 70%|████████████████████▎        | 281/400 [2:07:06<54:36, 27.53s/it]2021-12-13 01:06:50,008 iteration 4778 : loss : 0.016046, loss_ce: 0.007723
2021-12-13 01:06:51,429 iteration 4779 : loss : 0.017769, loss_ce: 0.008263
2021-12-13 01:06:52,854 iteration 4780 : loss : 0.015919, loss_ce: 0.006514
2021-12-13 01:06:54,343 iteration 4781 : loss : 0.019043, loss_ce: 0.006511
2021-12-13 01:06:55,839 iteration 4782 : loss : 0.020763, loss_ce: 0.007764
2021-12-13 01:06:57,278 iteration 4783 : loss : 0.016968, loss_ce: 0.007786
2021-12-13 01:06:58,790 iteration 4784 : loss : 0.023875, loss_ce: 0.008977
2021-12-13 01:07:00,260 iteration 4785 : loss : 0.014989, loss_ce: 0.004917
2021-12-13 01:07:01,708 iteration 4786 : loss : 0.011778, loss_ce: 0.004739
2021-12-13 01:07:03,161 iteration 4787 : loss : 0.035766, loss_ce: 0.012331
2021-12-13 01:07:04,641 iteration 4788 : loss : 0.024474, loss_ce: 0.007106
2021-12-13 01:07:06,005 iteration 4789 : loss : 0.014618, loss_ce: 0.005522
2021-12-13 01:07:07,369 iteration 4790 : loss : 0.012479, loss_ce: 0.004788
2021-12-13 01:07:08,862 iteration 4791 : loss : 0.023328, loss_ce: 0.009715
2021-12-13 01:07:10,326 iteration 4792 : loss : 0.014889, loss_ce: 0.006023
2021-12-13 01:07:11,838 iteration 4793 : loss : 0.016142, loss_ce: 0.004807
2021-12-13 01:07:13,289 iteration 4794 : loss : 0.018831, loss_ce: 0.005053
 70%|████████████████████▍        | 282/400 [2:07:31<52:32, 26.71s/it]2021-12-13 01:07:14,826 iteration 4795 : loss : 0.024598, loss_ce: 0.008170
2021-12-13 01:07:16,311 iteration 4796 : loss : 0.022176, loss_ce: 0.007944
2021-12-13 01:07:17,772 iteration 4797 : loss : 0.014597, loss_ce: 0.005525
2021-12-13 01:07:19,264 iteration 4798 : loss : 0.017851, loss_ce: 0.006999
2021-12-13 01:07:20,707 iteration 4799 : loss : 0.016866, loss_ce: 0.003953
2021-12-13 01:07:22,185 iteration 4800 : loss : 0.018826, loss_ce: 0.006979
2021-12-13 01:07:23,623 iteration 4801 : loss : 0.017001, loss_ce: 0.007490
2021-12-13 01:07:25,129 iteration 4802 : loss : 0.015780, loss_ce: 0.006100
2021-12-13 01:07:26,591 iteration 4803 : loss : 0.019619, loss_ce: 0.007091
2021-12-13 01:07:28,078 iteration 4804 : loss : 0.012965, loss_ce: 0.004880
2021-12-13 01:07:29,613 iteration 4805 : loss : 0.018007, loss_ce: 0.007645
2021-12-13 01:07:31,105 iteration 4806 : loss : 0.016490, loss_ce: 0.004103
2021-12-13 01:07:32,515 iteration 4807 : loss : 0.016495, loss_ce: 0.005006
2021-12-13 01:07:34,023 iteration 4808 : loss : 0.019016, loss_ce: 0.007226
2021-12-13 01:07:35,442 iteration 4809 : loss : 0.013166, loss_ce: 0.006132
2021-12-13 01:07:36,910 iteration 4810 : loss : 0.016650, loss_ce: 0.006024
2021-12-13 01:07:38,406 iteration 4811 : loss : 0.022741, loss_ce: 0.008348
 71%|████████████████████▌        | 283/400 [2:07:56<51:09, 26.23s/it]2021-12-13 01:07:39,899 iteration 4812 : loss : 0.016940, loss_ce: 0.005064
2021-12-13 01:07:41,333 iteration 4813 : loss : 0.013643, loss_ce: 0.005716
2021-12-13 01:07:42,921 iteration 4814 : loss : 0.029468, loss_ce: 0.011631
2021-12-13 01:07:44,360 iteration 4815 : loss : 0.014832, loss_ce: 0.005079
2021-12-13 01:07:45,783 iteration 4816 : loss : 0.017958, loss_ce: 0.006398
2021-12-13 01:07:47,203 iteration 4817 : loss : 0.012559, loss_ce: 0.004982
2021-12-13 01:07:48,644 iteration 4818 : loss : 0.017879, loss_ce: 0.006065
2021-12-13 01:07:50,136 iteration 4819 : loss : 0.018769, loss_ce: 0.006315
2021-12-13 01:07:51,562 iteration 4820 : loss : 0.018844, loss_ce: 0.008369
2021-12-13 01:07:53,030 iteration 4821 : loss : 0.017468, loss_ce: 0.006544
2021-12-13 01:07:54,553 iteration 4822 : loss : 0.017293, loss_ce: 0.006250
2021-12-13 01:07:56,025 iteration 4823 : loss : 0.023590, loss_ce: 0.004950
2021-12-13 01:07:57,452 iteration 4824 : loss : 0.021277, loss_ce: 0.005695
2021-12-13 01:07:58,968 iteration 4825 : loss : 0.018591, loss_ce: 0.009409
2021-12-13 01:08:00,617 iteration 4826 : loss : 0.036287, loss_ce: 0.018226
2021-12-13 01:08:02,051 iteration 4827 : loss : 0.015423, loss_ce: 0.007318
2021-12-13 01:08:03,469 iteration 4828 : loss : 0.013862, loss_ce: 0.005013
 71%|████████████████████▌        | 284/400 [2:08:21<50:02, 25.88s/it]2021-12-13 01:08:04,961 iteration 4829 : loss : 0.013887, loss_ce: 0.006657
2021-12-13 01:08:06,485 iteration 4830 : loss : 0.022494, loss_ce: 0.009041
2021-12-13 01:08:07,979 iteration 4831 : loss : 0.018706, loss_ce: 0.009700
2021-12-13 01:08:09,484 iteration 4832 : loss : 0.017136, loss_ce: 0.006249
2021-12-13 01:08:10,928 iteration 4833 : loss : 0.015563, loss_ce: 0.007234
2021-12-13 01:08:12,458 iteration 4834 : loss : 0.017866, loss_ce: 0.006430
2021-12-13 01:08:13,906 iteration 4835 : loss : 0.023491, loss_ce: 0.009931
2021-12-13 01:08:15,336 iteration 4836 : loss : 0.017154, loss_ce: 0.004747
2021-12-13 01:08:16,816 iteration 4837 : loss : 0.013826, loss_ce: 0.003454
2021-12-13 01:08:18,292 iteration 4838 : loss : 0.016076, loss_ce: 0.006982
2021-12-13 01:08:19,657 iteration 4839 : loss : 0.017582, loss_ce: 0.006762
2021-12-13 01:08:21,112 iteration 4840 : loss : 0.018721, loss_ce: 0.008266
2021-12-13 01:08:22,616 iteration 4841 : loss : 0.027343, loss_ce: 0.010021
2021-12-13 01:08:24,087 iteration 4842 : loss : 0.023522, loss_ce: 0.009415
2021-12-13 01:08:25,522 iteration 4843 : loss : 0.019671, loss_ce: 0.007173
2021-12-13 01:08:27,024 iteration 4844 : loss : 0.030473, loss_ce: 0.007568
2021-12-13 01:08:27,024 Training Data Eval:
2021-12-13 01:08:34,547   Average segmentation loss on training set: 0.0116
2021-12-13 01:08:34,547 Validation Data Eval:
2021-12-13 01:08:37,152   Average segmentation loss on validation set: 0.0723
2021-12-13 01:08:38,581 iteration 4845 : loss : 0.018591, loss_ce: 0.005974
 71%|████████████████████▋        | 285/400 [2:08:56<54:55, 28.65s/it]2021-12-13 01:08:40,095 iteration 4846 : loss : 0.016045, loss_ce: 0.005937
2021-12-13 01:08:41,505 iteration 4847 : loss : 0.012821, loss_ce: 0.004136
2021-12-13 01:08:43,056 iteration 4848 : loss : 0.020439, loss_ce: 0.007796
2021-12-13 01:08:44,497 iteration 4849 : loss : 0.014414, loss_ce: 0.005438
2021-12-13 01:08:45,879 iteration 4850 : loss : 0.012502, loss_ce: 0.005767
2021-12-13 01:08:47,435 iteration 4851 : loss : 0.022123, loss_ce: 0.007169
2021-12-13 01:08:48,875 iteration 4852 : loss : 0.017506, loss_ce: 0.008771
2021-12-13 01:08:50,356 iteration 4853 : loss : 0.017561, loss_ce: 0.004509
2021-12-13 01:08:51,956 iteration 4854 : loss : 0.019426, loss_ce: 0.007380
2021-12-13 01:08:53,434 iteration 4855 : loss : 0.022062, loss_ce: 0.007363
2021-12-13 01:08:54,828 iteration 4856 : loss : 0.014769, loss_ce: 0.004438
2021-12-13 01:08:56,335 iteration 4857 : loss : 0.016221, loss_ce: 0.007639
2021-12-13 01:08:57,829 iteration 4858 : loss : 0.016702, loss_ce: 0.005752
2021-12-13 01:08:59,298 iteration 4859 : loss : 0.013719, loss_ce: 0.006004
2021-12-13 01:09:00,789 iteration 4860 : loss : 0.020203, loss_ce: 0.007517
2021-12-13 01:09:02,247 iteration 4861 : loss : 0.017550, loss_ce: 0.006706
2021-12-13 01:09:03,664 iteration 4862 : loss : 0.013599, loss_ce: 0.005647
 72%|████████████████████▋        | 286/400 [2:09:21<52:24, 27.58s/it]2021-12-13 01:09:05,117 iteration 4863 : loss : 0.014945, loss_ce: 0.005282
2021-12-13 01:09:06,637 iteration 4864 : loss : 0.019488, loss_ce: 0.006567
2021-12-13 01:09:08,180 iteration 4865 : loss : 0.024159, loss_ce: 0.007133
2021-12-13 01:09:09,625 iteration 4866 : loss : 0.014399, loss_ce: 0.005988
2021-12-13 01:09:11,105 iteration 4867 : loss : 0.016986, loss_ce: 0.006290
2021-12-13 01:09:12,538 iteration 4868 : loss : 0.014189, loss_ce: 0.006306
2021-12-13 01:09:13,974 iteration 4869 : loss : 0.016885, loss_ce: 0.006328
2021-12-13 01:09:15,514 iteration 4870 : loss : 0.018117, loss_ce: 0.005663
2021-12-13 01:09:16,984 iteration 4871 : loss : 0.013464, loss_ce: 0.005092
2021-12-13 01:09:18,388 iteration 4872 : loss : 0.017703, loss_ce: 0.007069
2021-12-13 01:09:19,777 iteration 4873 : loss : 0.014778, loss_ce: 0.005051
2021-12-13 01:09:21,155 iteration 4874 : loss : 0.011606, loss_ce: 0.004984
2021-12-13 01:09:22,622 iteration 4875 : loss : 0.012594, loss_ce: 0.003849
2021-12-13 01:09:24,028 iteration 4876 : loss : 0.017075, loss_ce: 0.005422
2021-12-13 01:09:25,582 iteration 4877 : loss : 0.017763, loss_ce: 0.007535
2021-12-13 01:09:27,040 iteration 4878 : loss : 0.015705, loss_ce: 0.005641
2021-12-13 01:09:28,501 iteration 4879 : loss : 0.014859, loss_ce: 0.005835
 72%|████████████████████▊        | 287/400 [2:09:46<50:23, 26.76s/it]2021-12-13 01:09:30,064 iteration 4880 : loss : 0.018239, loss_ce: 0.009949
2021-12-13 01:09:31,484 iteration 4881 : loss : 0.024399, loss_ce: 0.007874
2021-12-13 01:09:32,914 iteration 4882 : loss : 0.014808, loss_ce: 0.004032
2021-12-13 01:09:34,370 iteration 4883 : loss : 0.017515, loss_ce: 0.005145
2021-12-13 01:09:35,832 iteration 4884 : loss : 0.011258, loss_ce: 0.005884
2021-12-13 01:09:37,424 iteration 4885 : loss : 0.031187, loss_ce: 0.009813
2021-12-13 01:09:38,928 iteration 4886 : loss : 0.016822, loss_ce: 0.005686
2021-12-13 01:09:40,456 iteration 4887 : loss : 0.022941, loss_ce: 0.008841
2021-12-13 01:09:41,900 iteration 4888 : loss : 0.016741, loss_ce: 0.003936
2021-12-13 01:09:43,354 iteration 4889 : loss : 0.013877, loss_ce: 0.005265
2021-12-13 01:09:44,892 iteration 4890 : loss : 0.018302, loss_ce: 0.006032
2021-12-13 01:09:46,423 iteration 4891 : loss : 0.026870, loss_ce: 0.016567
2021-12-13 01:09:47,819 iteration 4892 : loss : 0.014319, loss_ce: 0.005848
2021-12-13 01:09:49,247 iteration 4893 : loss : 0.012582, loss_ce: 0.005714
2021-12-13 01:09:50,690 iteration 4894 : loss : 0.017953, loss_ce: 0.004374
2021-12-13 01:09:52,114 iteration 4895 : loss : 0.016176, loss_ce: 0.005913
2021-12-13 01:09:53,586 iteration 4896 : loss : 0.015497, loss_ce: 0.004998
 72%|████████████████████▉        | 288/400 [2:10:11<49:00, 26.26s/it]2021-12-13 01:09:55,076 iteration 4897 : loss : 0.016756, loss_ce: 0.005684
2021-12-13 01:09:56,588 iteration 4898 : loss : 0.032487, loss_ce: 0.021435
2021-12-13 01:09:57,925 iteration 4899 : loss : 0.012876, loss_ce: 0.005769
2021-12-13 01:09:59,470 iteration 4900 : loss : 0.018811, loss_ce: 0.005823
2021-12-13 01:10:00,908 iteration 4901 : loss : 0.018458, loss_ce: 0.004125
2021-12-13 01:10:02,422 iteration 4902 : loss : 0.022733, loss_ce: 0.009259
2021-12-13 01:10:03,967 iteration 4903 : loss : 0.018192, loss_ce: 0.007538
2021-12-13 01:10:05,494 iteration 4904 : loss : 0.023067, loss_ce: 0.011279
2021-12-13 01:10:06,985 iteration 4905 : loss : 0.019295, loss_ce: 0.006324
2021-12-13 01:10:08,482 iteration 4906 : loss : 0.022278, loss_ce: 0.009485
2021-12-13 01:10:09,868 iteration 4907 : loss : 0.011881, loss_ce: 0.004878
2021-12-13 01:10:11,305 iteration 4908 : loss : 0.018477, loss_ce: 0.007278
2021-12-13 01:10:12,777 iteration 4909 : loss : 0.016705, loss_ce: 0.006120
2021-12-13 01:10:14,236 iteration 4910 : loss : 0.014558, loss_ce: 0.005163
2021-12-13 01:10:15,652 iteration 4911 : loss : 0.016069, loss_ce: 0.005042
2021-12-13 01:10:17,140 iteration 4912 : loss : 0.025977, loss_ce: 0.007846
2021-12-13 01:10:18,587 iteration 4913 : loss : 0.017250, loss_ce: 0.005522
 72%|████████████████████▉        | 289/400 [2:10:36<47:52, 25.88s/it]2021-12-13 01:10:20,019 iteration 4914 : loss : 0.015852, loss_ce: 0.006265
2021-12-13 01:10:21,483 iteration 4915 : loss : 0.018447, loss_ce: 0.008425
2021-12-13 01:10:23,002 iteration 4916 : loss : 0.023266, loss_ce: 0.006851
2021-12-13 01:10:24,463 iteration 4917 : loss : 0.013604, loss_ce: 0.004437
2021-12-13 01:10:25,927 iteration 4918 : loss : 0.023562, loss_ce: 0.016338
2021-12-13 01:10:27,362 iteration 4919 : loss : 0.027988, loss_ce: 0.015516
2021-12-13 01:10:28,878 iteration 4920 : loss : 0.020444, loss_ce: 0.006911
2021-12-13 01:10:30,276 iteration 4921 : loss : 0.015603, loss_ce: 0.005536
2021-12-13 01:10:31,765 iteration 4922 : loss : 0.013045, loss_ce: 0.004319
2021-12-13 01:10:33,233 iteration 4923 : loss : 0.018351, loss_ce: 0.006688
2021-12-13 01:10:34,714 iteration 4924 : loss : 0.017527, loss_ce: 0.006926
2021-12-13 01:10:36,146 iteration 4925 : loss : 0.020882, loss_ce: 0.008169
2021-12-13 01:10:37,512 iteration 4926 : loss : 0.012639, loss_ce: 0.006081
2021-12-13 01:10:38,983 iteration 4927 : loss : 0.015996, loss_ce: 0.006359
2021-12-13 01:10:40,468 iteration 4928 : loss : 0.016425, loss_ce: 0.008173
2021-12-13 01:10:41,889 iteration 4929 : loss : 0.019960, loss_ce: 0.006091
2021-12-13 01:10:41,889 Training Data Eval:
2021-12-13 01:10:49,365   Average segmentation loss on training set: 0.0430
2021-12-13 01:10:49,366 Validation Data Eval:
2021-12-13 01:10:51,972   Average segmentation loss on validation set: 0.0867
2021-12-13 01:10:53,453 iteration 4930 : loss : 0.020908, loss_ce: 0.007690
 72%|█████████████████████        | 290/400 [2:11:11<52:23, 28.58s/it]2021-12-13 01:10:55,003 iteration 4931 : loss : 0.018418, loss_ce: 0.008682
2021-12-13 01:10:56,491 iteration 4932 : loss : 0.020203, loss_ce: 0.007301
2021-12-13 01:10:57,875 iteration 4933 : loss : 0.015677, loss_ce: 0.006465
2021-12-13 01:10:59,340 iteration 4934 : loss : 0.018311, loss_ce: 0.007566
2021-12-13 01:11:00,790 iteration 4935 : loss : 0.016135, loss_ce: 0.004579
2021-12-13 01:11:02,277 iteration 4936 : loss : 0.015278, loss_ce: 0.005467
2021-12-13 01:11:03,713 iteration 4937 : loss : 0.015004, loss_ce: 0.005131
2021-12-13 01:11:05,141 iteration 4938 : loss : 0.015497, loss_ce: 0.006353
2021-12-13 01:11:06,702 iteration 4939 : loss : 0.020608, loss_ce: 0.007939
2021-12-13 01:11:08,105 iteration 4940 : loss : 0.017407, loss_ce: 0.007587
2021-12-13 01:11:09,565 iteration 4941 : loss : 0.014725, loss_ce: 0.005878
2021-12-13 01:11:11,190 iteration 4942 : loss : 0.021278, loss_ce: 0.007995
2021-12-13 01:11:12,619 iteration 4943 : loss : 0.040397, loss_ce: 0.016635
2021-12-13 01:11:14,051 iteration 4944 : loss : 0.019244, loss_ce: 0.009488
2021-12-13 01:11:15,504 iteration 4945 : loss : 0.013213, loss_ce: 0.004995
2021-12-13 01:11:16,897 iteration 4946 : loss : 0.015766, loss_ce: 0.005986
2021-12-13 01:11:18,423 iteration 4947 : loss : 0.019875, loss_ce: 0.007587
 73%|█████████████████████        | 291/400 [2:11:36<49:56, 27.49s/it]2021-12-13 01:11:19,946 iteration 4948 : loss : 0.027236, loss_ce: 0.010062
2021-12-13 01:11:21,506 iteration 4949 : loss : 0.025924, loss_ce: 0.012931
2021-12-13 01:11:22,933 iteration 4950 : loss : 0.020508, loss_ce: 0.009636
2021-12-13 01:11:24,386 iteration 4951 : loss : 0.022240, loss_ce: 0.008610
2021-12-13 01:11:25,846 iteration 4952 : loss : 0.020041, loss_ce: 0.007647
2021-12-13 01:11:27,376 iteration 4953 : loss : 0.019106, loss_ce: 0.005278
2021-12-13 01:11:28,736 iteration 4954 : loss : 0.021548, loss_ce: 0.008570
2021-12-13 01:11:30,157 iteration 4955 : loss : 0.015464, loss_ce: 0.007499
2021-12-13 01:11:31,663 iteration 4956 : loss : 0.018471, loss_ce: 0.005217
2021-12-13 01:11:33,126 iteration 4957 : loss : 0.020479, loss_ce: 0.008318
2021-12-13 01:11:34,733 iteration 4958 : loss : 0.019276, loss_ce: 0.008120
2021-12-13 01:11:36,271 iteration 4959 : loss : 0.028983, loss_ce: 0.012269
2021-12-13 01:11:37,836 iteration 4960 : loss : 0.018652, loss_ce: 0.007156
2021-12-13 01:11:39,255 iteration 4961 : loss : 0.016778, loss_ce: 0.003763
2021-12-13 01:11:40,696 iteration 4962 : loss : 0.015020, loss_ce: 0.006907
2021-12-13 01:11:42,182 iteration 4963 : loss : 0.022992, loss_ce: 0.009770
2021-12-13 01:11:43,689 iteration 4964 : loss : 0.013712, loss_ce: 0.004477
 73%|█████████████████████▏       | 292/400 [2:12:01<48:17, 26.83s/it]2021-12-13 01:11:45,189 iteration 4965 : loss : 0.016182, loss_ce: 0.005026
2021-12-13 01:11:46,667 iteration 4966 : loss : 0.024873, loss_ce: 0.007707
2021-12-13 01:11:48,135 iteration 4967 : loss : 0.023328, loss_ce: 0.006853
2021-12-13 01:11:49,591 iteration 4968 : loss : 0.021932, loss_ce: 0.005016
2021-12-13 01:11:51,071 iteration 4969 : loss : 0.037068, loss_ce: 0.016756
2021-12-13 01:11:52,573 iteration 4970 : loss : 0.016558, loss_ce: 0.008185
2021-12-13 01:11:54,012 iteration 4971 : loss : 0.018517, loss_ce: 0.008309
2021-12-13 01:11:55,419 iteration 4972 : loss : 0.015385, loss_ce: 0.004996
2021-12-13 01:11:56,864 iteration 4973 : loss : 0.014270, loss_ce: 0.004758
2021-12-13 01:11:58,354 iteration 4974 : loss : 0.015723, loss_ce: 0.008407
2021-12-13 01:11:59,895 iteration 4975 : loss : 0.014947, loss_ce: 0.005170
2021-12-13 01:12:01,315 iteration 4976 : loss : 0.014443, loss_ce: 0.005664
2021-12-13 01:12:02,763 iteration 4977 : loss : 0.013974, loss_ce: 0.006114
2021-12-13 01:12:04,229 iteration 4978 : loss : 0.017192, loss_ce: 0.007948
2021-12-13 01:12:05,649 iteration 4979 : loss : 0.013175, loss_ce: 0.004725
2021-12-13 01:12:07,043 iteration 4980 : loss : 0.012835, loss_ce: 0.004689
2021-12-13 01:12:08,504 iteration 4981 : loss : 0.016313, loss_ce: 0.005752
 73%|█████████████████████▏       | 293/400 [2:12:26<46:45, 26.22s/it]2021-12-13 01:12:10,034 iteration 4982 : loss : 0.021751, loss_ce: 0.004538
2021-12-13 01:12:11,422 iteration 4983 : loss : 0.014938, loss_ce: 0.004765
2021-12-13 01:12:12,897 iteration 4984 : loss : 0.023644, loss_ce: 0.007379
2021-12-13 01:12:14,280 iteration 4985 : loss : 0.012076, loss_ce: 0.003835
2021-12-13 01:12:15,696 iteration 4986 : loss : 0.020069, loss_ce: 0.006280
2021-12-13 01:12:17,165 iteration 4987 : loss : 0.014061, loss_ce: 0.006446
2021-12-13 01:12:18,644 iteration 4988 : loss : 0.016325, loss_ce: 0.008436
2021-12-13 01:12:20,081 iteration 4989 : loss : 0.017732, loss_ce: 0.007695
2021-12-13 01:12:21,557 iteration 4990 : loss : 0.016079, loss_ce: 0.007095
2021-12-13 01:12:22,984 iteration 4991 : loss : 0.016186, loss_ce: 0.005662
2021-12-13 01:12:24,464 iteration 4992 : loss : 0.019298, loss_ce: 0.006298
2021-12-13 01:12:25,917 iteration 4993 : loss : 0.021664, loss_ce: 0.009522
2021-12-13 01:12:27,488 iteration 4994 : loss : 0.021119, loss_ce: 0.008799
2021-12-13 01:12:28,989 iteration 4995 : loss : 0.028633, loss_ce: 0.013578
2021-12-13 01:12:30,407 iteration 4996 : loss : 0.013955, loss_ce: 0.003809
2021-12-13 01:12:31,876 iteration 4997 : loss : 0.017925, loss_ce: 0.007076
2021-12-13 01:12:33,340 iteration 4998 : loss : 0.014781, loss_ce: 0.005687
 74%|█████████████████████▎       | 294/400 [2:12:51<45:35, 25.81s/it]2021-12-13 01:12:34,830 iteration 4999 : loss : 0.018794, loss_ce: 0.010340
2021-12-13 01:12:36,227 iteration 5000 : loss : 0.016682, loss_ce: 0.004922
2021-12-13 01:12:37,727 iteration 5001 : loss : 0.018233, loss_ce: 0.005206
2021-12-13 01:12:39,266 iteration 5002 : loss : 0.017991, loss_ce: 0.005771
2021-12-13 01:12:40,815 iteration 5003 : loss : 0.019449, loss_ce: 0.009296
2021-12-13 01:12:42,263 iteration 5004 : loss : 0.012851, loss_ce: 0.005372
2021-12-13 01:12:43,744 iteration 5005 : loss : 0.014599, loss_ce: 0.005779
2021-12-13 01:12:45,150 iteration 5006 : loss : 0.016130, loss_ce: 0.005755
2021-12-13 01:12:46,634 iteration 5007 : loss : 0.028541, loss_ce: 0.007044
2021-12-13 01:12:48,051 iteration 5008 : loss : 0.013397, loss_ce: 0.004412
2021-12-13 01:12:49,465 iteration 5009 : loss : 0.016709, loss_ce: 0.009583
2021-12-13 01:12:50,954 iteration 5010 : loss : 0.017904, loss_ce: 0.007766
2021-12-13 01:12:52,354 iteration 5011 : loss : 0.012527, loss_ce: 0.004902
2021-12-13 01:12:53,789 iteration 5012 : loss : 0.023809, loss_ce: 0.005899
2021-12-13 01:12:55,334 iteration 5013 : loss : 0.014477, loss_ce: 0.005788
2021-12-13 01:12:56,735 iteration 5014 : loss : 0.015792, loss_ce: 0.005959
2021-12-13 01:12:56,735 Training Data Eval:
2021-12-13 01:13:04,226   Average segmentation loss on training set: 0.0104
2021-12-13 01:13:04,227 Validation Data Eval:
2021-12-13 01:13:06,817   Average segmentation loss on validation set: 0.0707
2021-12-13 01:13:08,269 iteration 5015 : loss : 0.019381, loss_ce: 0.005952
 74%|█████████████████████▍       | 295/400 [2:13:26<49:56, 28.54s/it]2021-12-13 01:13:09,792 iteration 5016 : loss : 0.016572, loss_ce: 0.006624
2021-12-13 01:13:11,165 iteration 5017 : loss : 0.011819, loss_ce: 0.004555
2021-12-13 01:13:12,723 iteration 5018 : loss : 0.016594, loss_ce: 0.007292
2021-12-13 01:13:14,123 iteration 5019 : loss : 0.013180, loss_ce: 0.004639
2021-12-13 01:13:15,630 iteration 5020 : loss : 0.020424, loss_ce: 0.006406
2021-12-13 01:13:17,084 iteration 5021 : loss : 0.026488, loss_ce: 0.009454
2021-12-13 01:13:18,529 iteration 5022 : loss : 0.016777, loss_ce: 0.005364
2021-12-13 01:13:19,972 iteration 5023 : loss : 0.013728, loss_ce: 0.005959
2021-12-13 01:13:21,491 iteration 5024 : loss : 0.025390, loss_ce: 0.009377
2021-12-13 01:13:22,955 iteration 5025 : loss : 0.017708, loss_ce: 0.005954
2021-12-13 01:13:24,472 iteration 5026 : loss : 0.018440, loss_ce: 0.006615
2021-12-13 01:13:25,891 iteration 5027 : loss : 0.012609, loss_ce: 0.004661
2021-12-13 01:13:27,291 iteration 5028 : loss : 0.012406, loss_ce: 0.005352
2021-12-13 01:13:28,806 iteration 5029 : loss : 0.019048, loss_ce: 0.008247
2021-12-13 01:13:30,228 iteration 5030 : loss : 0.012861, loss_ce: 0.005379
2021-12-13 01:13:31,717 iteration 5031 : loss : 0.028981, loss_ce: 0.009429
2021-12-13 01:13:33,108 iteration 5032 : loss : 0.011355, loss_ce: 0.004114
 74%|█████████████████████▍       | 296/400 [2:13:51<47:32, 27.43s/it]2021-12-13 01:13:34,551 iteration 5033 : loss : 0.018778, loss_ce: 0.006796
2021-12-13 01:13:35,973 iteration 5034 : loss : 0.017728, loss_ce: 0.005179
2021-12-13 01:13:37,430 iteration 5035 : loss : 0.015630, loss_ce: 0.005269
2021-12-13 01:13:38,841 iteration 5036 : loss : 0.016371, loss_ce: 0.005966
2021-12-13 01:13:40,288 iteration 5037 : loss : 0.014911, loss_ce: 0.004631
2021-12-13 01:13:41,712 iteration 5038 : loss : 0.013803, loss_ce: 0.004324
2021-12-13 01:13:43,189 iteration 5039 : loss : 0.017894, loss_ce: 0.006905
2021-12-13 01:13:44,702 iteration 5040 : loss : 0.013524, loss_ce: 0.005092
2021-12-13 01:13:46,160 iteration 5041 : loss : 0.014947, loss_ce: 0.005909
2021-12-13 01:13:47,715 iteration 5042 : loss : 0.018644, loss_ce: 0.007231
2021-12-13 01:13:49,077 iteration 5043 : loss : 0.014442, loss_ce: 0.004568
2021-12-13 01:13:50,579 iteration 5044 : loss : 0.014041, loss_ce: 0.004924
2021-12-13 01:13:52,060 iteration 5045 : loss : 0.018450, loss_ce: 0.007827
2021-12-13 01:13:53,531 iteration 5046 : loss : 0.019047, loss_ce: 0.005101
2021-12-13 01:13:54,938 iteration 5047 : loss : 0.010313, loss_ce: 0.002686
2021-12-13 01:13:56,320 iteration 5048 : loss : 0.011068, loss_ce: 0.005601
2021-12-13 01:13:57,690 iteration 5049 : loss : 0.011952, loss_ce: 0.005345
 74%|█████████████████████▌       | 297/400 [2:14:15<45:37, 26.58s/it]2021-12-13 01:13:59,212 iteration 5050 : loss : 0.014059, loss_ce: 0.004510
2021-12-13 01:14:00,739 iteration 5051 : loss : 0.021072, loss_ce: 0.007952
2021-12-13 01:14:02,279 iteration 5052 : loss : 0.018375, loss_ce: 0.006638
2021-12-13 01:14:03,811 iteration 5053 : loss : 0.023429, loss_ce: 0.007469
2021-12-13 01:14:05,236 iteration 5054 : loss : 0.016525, loss_ce: 0.004935
2021-12-13 01:14:06,704 iteration 5055 : loss : 0.016234, loss_ce: 0.005420
2021-12-13 01:14:08,173 iteration 5056 : loss : 0.012679, loss_ce: 0.005439
2021-12-13 01:14:09,718 iteration 5057 : loss : 0.021212, loss_ce: 0.008583
2021-12-13 01:14:11,253 iteration 5058 : loss : 0.018838, loss_ce: 0.006456
2021-12-13 01:14:12,690 iteration 5059 : loss : 0.015657, loss_ce: 0.006073
2021-12-13 01:14:14,187 iteration 5060 : loss : 0.014220, loss_ce: 0.006147
2021-12-13 01:14:15,711 iteration 5061 : loss : 0.022088, loss_ce: 0.007485
2021-12-13 01:14:17,266 iteration 5062 : loss : 0.022764, loss_ce: 0.007371
2021-12-13 01:14:18,803 iteration 5063 : loss : 0.018977, loss_ce: 0.007764
2021-12-13 01:14:20,241 iteration 5064 : loss : 0.018050, loss_ce: 0.006270
2021-12-13 01:14:21,754 iteration 5065 : loss : 0.015943, loss_ce: 0.008038
2021-12-13 01:14:23,154 iteration 5066 : loss : 0.014155, loss_ce: 0.005450
 74%|█████████████████████▌       | 298/400 [2:14:41<44:36, 26.24s/it]2021-12-13 01:14:24,548 iteration 5067 : loss : 0.014897, loss_ce: 0.005116
2021-12-13 01:14:26,058 iteration 5068 : loss : 0.020861, loss_ce: 0.004811
2021-12-13 01:14:27,534 iteration 5069 : loss : 0.015346, loss_ce: 0.007603
2021-12-13 01:14:28,936 iteration 5070 : loss : 0.017413, loss_ce: 0.005602
2021-12-13 01:14:30,438 iteration 5071 : loss : 0.018602, loss_ce: 0.008238
2021-12-13 01:14:31,824 iteration 5072 : loss : 0.012972, loss_ce: 0.004722
2021-12-13 01:14:33,335 iteration 5073 : loss : 0.018911, loss_ce: 0.007345
2021-12-13 01:14:34,759 iteration 5074 : loss : 0.012551, loss_ce: 0.004954
2021-12-13 01:14:36,189 iteration 5075 : loss : 0.018452, loss_ce: 0.006590
2021-12-13 01:14:37,650 iteration 5076 : loss : 0.028250, loss_ce: 0.004387
2021-12-13 01:14:39,111 iteration 5077 : loss : 0.016381, loss_ce: 0.004947
2021-12-13 01:14:40,523 iteration 5078 : loss : 0.016395, loss_ce: 0.007916
2021-12-13 01:14:41,926 iteration 5079 : loss : 0.012555, loss_ce: 0.005311
2021-12-13 01:14:43,353 iteration 5080 : loss : 0.017213, loss_ce: 0.007386
2021-12-13 01:14:44,854 iteration 5081 : loss : 0.020714, loss_ce: 0.006151
2021-12-13 01:14:46,292 iteration 5082 : loss : 0.015100, loss_ce: 0.006033
2021-12-13 01:14:47,764 iteration 5083 : loss : 0.022970, loss_ce: 0.005282
 75%|█████████████████████▋       | 299/400 [2:15:05<43:21, 25.75s/it]2021-12-13 01:14:49,293 iteration 5084 : loss : 0.015858, loss_ce: 0.008637
2021-12-13 01:14:50,825 iteration 5085 : loss : 0.022921, loss_ce: 0.008394
2021-12-13 01:14:52,325 iteration 5086 : loss : 0.013197, loss_ce: 0.004330
2021-12-13 01:14:53,733 iteration 5087 : loss : 0.015642, loss_ce: 0.006769
2021-12-13 01:14:55,153 iteration 5088 : loss : 0.016779, loss_ce: 0.006953
2021-12-13 01:14:56,645 iteration 5089 : loss : 0.018443, loss_ce: 0.005245
2021-12-13 01:14:58,111 iteration 5090 : loss : 0.017386, loss_ce: 0.004138
2021-12-13 01:14:59,633 iteration 5091 : loss : 0.019155, loss_ce: 0.006971
2021-12-13 01:15:01,109 iteration 5092 : loss : 0.020665, loss_ce: 0.007687
2021-12-13 01:15:02,517 iteration 5093 : loss : 0.017385, loss_ce: 0.005354
2021-12-13 01:15:04,010 iteration 5094 : loss : 0.019055, loss_ce: 0.007320
2021-12-13 01:15:05,414 iteration 5095 : loss : 0.014301, loss_ce: 0.005540
2021-12-13 01:15:06,872 iteration 5096 : loss : 0.016922, loss_ce: 0.007796
2021-12-13 01:15:08,278 iteration 5097 : loss : 0.018317, loss_ce: 0.008289
2021-12-13 01:15:09,820 iteration 5098 : loss : 0.021242, loss_ce: 0.006555
2021-12-13 01:15:11,297 iteration 5099 : loss : 0.021173, loss_ce: 0.008323
2021-12-13 01:15:11,298 Training Data Eval:
2021-12-13 01:15:18,774   Average segmentation loss on training set: 0.0093
2021-12-13 01:15:18,774 Validation Data Eval:
2021-12-13 01:15:21,374   Average segmentation loss on validation set: 0.0692
2021-12-13 01:15:22,907 iteration 5100 : loss : 0.017109, loss_ce: 0.003442
 75%|█████████████████████▊       | 300/400 [2:15:41<47:37, 28.57s/it]2021-12-13 01:15:24,485 iteration 5101 : loss : 0.017995, loss_ce: 0.008641
2021-12-13 01:15:25,926 iteration 5102 : loss : 0.017943, loss_ce: 0.005995
2021-12-13 01:15:27,383 iteration 5103 : loss : 0.015498, loss_ce: 0.007756
2021-12-13 01:15:28,901 iteration 5104 : loss : 0.015083, loss_ce: 0.004083
2021-12-13 01:15:30,336 iteration 5105 : loss : 0.013120, loss_ce: 0.004841
2021-12-13 01:15:31,778 iteration 5106 : loss : 0.011987, loss_ce: 0.004622
2021-12-13 01:15:33,295 iteration 5107 : loss : 0.024783, loss_ce: 0.007846
2021-12-13 01:15:34,760 iteration 5108 : loss : 0.017184, loss_ce: 0.006795
2021-12-13 01:15:36,206 iteration 5109 : loss : 0.018940, loss_ce: 0.007155
2021-12-13 01:15:37,613 iteration 5110 : loss : 0.012322, loss_ce: 0.003776
2021-12-13 01:15:39,101 iteration 5111 : loss : 0.018767, loss_ce: 0.005790
2021-12-13 01:15:40,648 iteration 5112 : loss : 0.025976, loss_ce: 0.009401
2021-12-13 01:15:42,123 iteration 5113 : loss : 0.016744, loss_ce: 0.005165
2021-12-13 01:15:43,660 iteration 5114 : loss : 0.022798, loss_ce: 0.008116
2021-12-13 01:15:45,122 iteration 5115 : loss : 0.022146, loss_ce: 0.007307
2021-12-13 01:15:46,569 iteration 5116 : loss : 0.014617, loss_ce: 0.006166
2021-12-13 01:15:48,049 iteration 5117 : loss : 0.025002, loss_ce: 0.010800
 75%|█████████████████████▊       | 301/400 [2:16:06<45:26, 27.54s/it]2021-12-13 01:15:49,567 iteration 5118 : loss : 0.023927, loss_ce: 0.006581
2021-12-13 01:15:51,000 iteration 5119 : loss : 0.015681, loss_ce: 0.007268
2021-12-13 01:15:52,403 iteration 5120 : loss : 0.011015, loss_ce: 0.004391
2021-12-13 01:15:53,906 iteration 5121 : loss : 0.016592, loss_ce: 0.004688
2021-12-13 01:15:55,450 iteration 5122 : loss : 0.016115, loss_ce: 0.006454
2021-12-13 01:15:56,984 iteration 5123 : loss : 0.045976, loss_ce: 0.014420
2021-12-13 01:15:58,398 iteration 5124 : loss : 0.011191, loss_ce: 0.005212
2021-12-13 01:15:59,814 iteration 5125 : loss : 0.014046, loss_ce: 0.005121
2021-12-13 01:16:01,282 iteration 5126 : loss : 0.016219, loss_ce: 0.005944
2021-12-13 01:16:02,741 iteration 5127 : loss : 0.021776, loss_ce: 0.010065
2021-12-13 01:16:04,170 iteration 5128 : loss : 0.029194, loss_ce: 0.007087
2021-12-13 01:16:05,649 iteration 5129 : loss : 0.016202, loss_ce: 0.005960
2021-12-13 01:16:07,096 iteration 5130 : loss : 0.015804, loss_ce: 0.006715
2021-12-13 01:16:08,563 iteration 5131 : loss : 0.013779, loss_ce: 0.005034
2021-12-13 01:16:10,012 iteration 5132 : loss : 0.018544, loss_ce: 0.007321
2021-12-13 01:16:11,542 iteration 5133 : loss : 0.039596, loss_ce: 0.014553
2021-12-13 01:16:13,004 iteration 5134 : loss : 0.024189, loss_ce: 0.006193
 76%|█████████████████████▉       | 302/400 [2:16:31<43:42, 26.76s/it]2021-12-13 01:16:14,481 iteration 5135 : loss : 0.016765, loss_ce: 0.008824
2021-12-13 01:16:15,916 iteration 5136 : loss : 0.011652, loss_ce: 0.003959
2021-12-13 01:16:17,304 iteration 5137 : loss : 0.016588, loss_ce: 0.005593
2021-12-13 01:16:18,787 iteration 5138 : loss : 0.019179, loss_ce: 0.007745
2021-12-13 01:16:20,346 iteration 5139 : loss : 0.021336, loss_ce: 0.008239
2021-12-13 01:16:21,875 iteration 5140 : loss : 0.022330, loss_ce: 0.008705
2021-12-13 01:16:23,288 iteration 5141 : loss : 0.018095, loss_ce: 0.006219
2021-12-13 01:16:24,772 iteration 5142 : loss : 0.018347, loss_ce: 0.005805
2021-12-13 01:16:26,220 iteration 5143 : loss : 0.013438, loss_ce: 0.006541
2021-12-13 01:16:27,763 iteration 5144 : loss : 0.014052, loss_ce: 0.005609
2021-12-13 01:16:29,356 iteration 5145 : loss : 0.013279, loss_ce: 0.003897
2021-12-13 01:16:30,851 iteration 5146 : loss : 0.015431, loss_ce: 0.005125
2021-12-13 01:16:32,252 iteration 5147 : loss : 0.020909, loss_ce: 0.005457
2021-12-13 01:16:33,709 iteration 5148 : loss : 0.019555, loss_ce: 0.007740
2021-12-13 01:16:35,156 iteration 5149 : loss : 0.020907, loss_ce: 0.007191
2021-12-13 01:16:36,606 iteration 5150 : loss : 0.016815, loss_ce: 0.009545
2021-12-13 01:16:38,119 iteration 5151 : loss : 0.017173, loss_ce: 0.007354
 76%|█████████████████████▉       | 303/400 [2:16:56<42:28, 26.27s/it]2021-12-13 01:16:39,594 iteration 5152 : loss : 0.020851, loss_ce: 0.008703
2021-12-13 01:16:41,069 iteration 5153 : loss : 0.016729, loss_ce: 0.005833
2021-12-13 01:16:42,476 iteration 5154 : loss : 0.014873, loss_ce: 0.005180
2021-12-13 01:16:43,892 iteration 5155 : loss : 0.013749, loss_ce: 0.005337
2021-12-13 01:16:45,350 iteration 5156 : loss : 0.019152, loss_ce: 0.004323
2021-12-13 01:16:46,764 iteration 5157 : loss : 0.011837, loss_ce: 0.004427
2021-12-13 01:16:48,191 iteration 5158 : loss : 0.016234, loss_ce: 0.005648
2021-12-13 01:16:49,688 iteration 5159 : loss : 0.015312, loss_ce: 0.005551
2021-12-13 01:16:51,154 iteration 5160 : loss : 0.017961, loss_ce: 0.008033
2021-12-13 01:16:52,622 iteration 5161 : loss : 0.023282, loss_ce: 0.009779
2021-12-13 01:16:54,137 iteration 5162 : loss : 0.014046, loss_ce: 0.003671
2021-12-13 01:16:55,621 iteration 5163 : loss : 0.016844, loss_ce: 0.008031
2021-12-13 01:16:57,036 iteration 5164 : loss : 0.012472, loss_ce: 0.004800
2021-12-13 01:16:58,558 iteration 5165 : loss : 0.018644, loss_ce: 0.005673
2021-12-13 01:17:00,017 iteration 5166 : loss : 0.015306, loss_ce: 0.005868
2021-12-13 01:17:01,521 iteration 5167 : loss : 0.016580, loss_ce: 0.003928
2021-12-13 01:17:02,895 iteration 5168 : loss : 0.013838, loss_ce: 0.007205
 76%|██████████████████████       | 304/400 [2:17:20<41:18, 25.82s/it]2021-12-13 01:17:04,434 iteration 5169 : loss : 0.013908, loss_ce: 0.003605
2021-12-13 01:17:05,871 iteration 5170 : loss : 0.012341, loss_ce: 0.005925
2021-12-13 01:17:07,329 iteration 5171 : loss : 0.018639, loss_ce: 0.005840
2021-12-13 01:17:08,795 iteration 5172 : loss : 0.019732, loss_ce: 0.006363
2021-12-13 01:17:10,331 iteration 5173 : loss : 0.018683, loss_ce: 0.006975
2021-12-13 01:17:11,804 iteration 5174 : loss : 0.008685, loss_ce: 0.002500
2021-12-13 01:17:13,306 iteration 5175 : loss : 0.013280, loss_ce: 0.004430
2021-12-13 01:17:14,835 iteration 5176 : loss : 0.014972, loss_ce: 0.005094
2021-12-13 01:17:16,301 iteration 5177 : loss : 0.017853, loss_ce: 0.007402
2021-12-13 01:17:17,777 iteration 5178 : loss : 0.012571, loss_ce: 0.005756
2021-12-13 01:17:19,207 iteration 5179 : loss : 0.016861, loss_ce: 0.009191
2021-12-13 01:17:20,598 iteration 5180 : loss : 0.014202, loss_ce: 0.005868
2021-12-13 01:17:22,033 iteration 5181 : loss : 0.015019, loss_ce: 0.004601
2021-12-13 01:17:23,489 iteration 5182 : loss : 0.018407, loss_ce: 0.007900
2021-12-13 01:17:24,931 iteration 5183 : loss : 0.013665, loss_ce: 0.005116
2021-12-13 01:17:26,335 iteration 5184 : loss : 0.013950, loss_ce: 0.006478
2021-12-13 01:17:26,335 Training Data Eval:
2021-12-13 01:17:33,811   Average segmentation loss on training set: 0.0091
2021-12-13 01:17:33,812 Validation Data Eval:
2021-12-13 01:17:36,412   Average segmentation loss on validation set: 0.0832
2021-12-13 01:17:37,865 iteration 5185 : loss : 0.011588, loss_ce: 0.004617
 76%|██████████████████████       | 305/400 [2:17:55<45:13, 28.57s/it]2021-12-13 01:17:39,412 iteration 5186 : loss : 0.028016, loss_ce: 0.009440
2021-12-13 01:17:40,821 iteration 5187 : loss : 0.013900, loss_ce: 0.005003
2021-12-13 01:17:42,292 iteration 5188 : loss : 0.012034, loss_ce: 0.003829
2021-12-13 01:17:43,774 iteration 5189 : loss : 0.027231, loss_ce: 0.008322
2021-12-13 01:17:45,320 iteration 5190 : loss : 0.020250, loss_ce: 0.006281
2021-12-13 01:17:46,746 iteration 5191 : loss : 0.016829, loss_ce: 0.006406
2021-12-13 01:17:48,192 iteration 5192 : loss : 0.017478, loss_ce: 0.006053
2021-12-13 01:17:49,700 iteration 5193 : loss : 0.019642, loss_ce: 0.009889
2021-12-13 01:17:51,175 iteration 5194 : loss : 0.015968, loss_ce: 0.004234
2021-12-13 01:17:52,609 iteration 5195 : loss : 0.017214, loss_ce: 0.004828
2021-12-13 01:17:54,155 iteration 5196 : loss : 0.018100, loss_ce: 0.007053
2021-12-13 01:17:55,604 iteration 5197 : loss : 0.017876, loss_ce: 0.005025
2021-12-13 01:17:57,028 iteration 5198 : loss : 0.012870, loss_ce: 0.007090
2021-12-13 01:17:58,599 iteration 5199 : loss : 0.016762, loss_ce: 0.006799
2021-12-13 01:17:59,962 iteration 5200 : loss : 0.015607, loss_ce: 0.006795
2021-12-13 01:18:01,350 iteration 5201 : loss : 0.013894, loss_ce: 0.006038
2021-12-13 01:18:02,802 iteration 5202 : loss : 0.018560, loss_ce: 0.006572
 76%|██████████████████████▏      | 306/400 [2:18:20<43:02, 27.48s/it]2021-12-13 01:18:04,285 iteration 5203 : loss : 0.015933, loss_ce: 0.006482
2021-12-13 01:18:05,799 iteration 5204 : loss : 0.014512, loss_ce: 0.005615
2021-12-13 01:18:07,295 iteration 5205 : loss : 0.019884, loss_ce: 0.004971
2021-12-13 01:18:08,872 iteration 5206 : loss : 0.027458, loss_ce: 0.010190
2021-12-13 01:18:10,373 iteration 5207 : loss : 0.030448, loss_ce: 0.007019
2021-12-13 01:18:11,834 iteration 5208 : loss : 0.013930, loss_ce: 0.006085
2021-12-13 01:18:13,343 iteration 5209 : loss : 0.015550, loss_ce: 0.005910
2021-12-13 01:18:14,854 iteration 5210 : loss : 0.016637, loss_ce: 0.008321
2021-12-13 01:18:16,315 iteration 5211 : loss : 0.015231, loss_ce: 0.005187
2021-12-13 01:18:17,828 iteration 5212 : loss : 0.025186, loss_ce: 0.008148
2021-12-13 01:18:19,269 iteration 5213 : loss : 0.021090, loss_ce: 0.009261
2021-12-13 01:18:20,715 iteration 5214 : loss : 0.013801, loss_ce: 0.006099
2021-12-13 01:18:22,107 iteration 5215 : loss : 0.013379, loss_ce: 0.004652
2021-12-13 01:18:23,556 iteration 5216 : loss : 0.013462, loss_ce: 0.004205
2021-12-13 01:18:25,095 iteration 5217 : loss : 0.019530, loss_ce: 0.008485
2021-12-13 01:18:26,505 iteration 5218 : loss : 0.012184, loss_ce: 0.003944
2021-12-13 01:18:27,981 iteration 5219 : loss : 0.016771, loss_ce: 0.006632
 77%|██████████████████████▎      | 307/400 [2:18:46<41:31, 26.79s/it]2021-12-13 01:18:29,407 iteration 5220 : loss : 0.012510, loss_ce: 0.005508
2021-12-13 01:18:30,817 iteration 5221 : loss : 0.015825, loss_ce: 0.004286
2021-12-13 01:18:32,326 iteration 5222 : loss : 0.022496, loss_ce: 0.006306
2021-12-13 01:18:33,769 iteration 5223 : loss : 0.012064, loss_ce: 0.005586
2021-12-13 01:18:35,288 iteration 5224 : loss : 0.019572, loss_ce: 0.004702
2021-12-13 01:18:36,719 iteration 5225 : loss : 0.012128, loss_ce: 0.004979
2021-12-13 01:18:38,206 iteration 5226 : loss : 0.013192, loss_ce: 0.005204
2021-12-13 01:18:39,692 iteration 5227 : loss : 0.027897, loss_ce: 0.010092
2021-12-13 01:18:41,078 iteration 5228 : loss : 0.010088, loss_ce: 0.003161
2021-12-13 01:18:42,573 iteration 5229 : loss : 0.018206, loss_ce: 0.006987
2021-12-13 01:18:43,988 iteration 5230 : loss : 0.011602, loss_ce: 0.004402
2021-12-13 01:18:45,457 iteration 5231 : loss : 0.018534, loss_ce: 0.006146
2021-12-13 01:18:46,997 iteration 5232 : loss : 0.017891, loss_ce: 0.006385
2021-12-13 01:18:48,352 iteration 5233 : loss : 0.014312, loss_ce: 0.005858
2021-12-13 01:18:49,814 iteration 5234 : loss : 0.020693, loss_ce: 0.008414
2021-12-13 01:18:51,316 iteration 5235 : loss : 0.016090, loss_ce: 0.007140
2021-12-13 01:18:52,850 iteration 5236 : loss : 0.023320, loss_ce: 0.010188
 77%|██████████████████████▎      | 308/400 [2:19:10<40:11, 26.21s/it]2021-12-13 01:18:54,260 iteration 5237 : loss : 0.011235, loss_ce: 0.005017
2021-12-13 01:18:55,695 iteration 5238 : loss : 0.014236, loss_ce: 0.005600
2021-12-13 01:18:57,125 iteration 5239 : loss : 0.013852, loss_ce: 0.004518
2021-12-13 01:18:58,639 iteration 5240 : loss : 0.031758, loss_ce: 0.005449
2021-12-13 01:19:00,124 iteration 5241 : loss : 0.017789, loss_ce: 0.006219
2021-12-13 01:19:01,690 iteration 5242 : loss : 0.018258, loss_ce: 0.007625
2021-12-13 01:19:03,174 iteration 5243 : loss : 0.019074, loss_ce: 0.008258
2021-12-13 01:19:04,623 iteration 5244 : loss : 0.016903, loss_ce: 0.006162
2021-12-13 01:19:06,143 iteration 5245 : loss : 0.025343, loss_ce: 0.010138
2021-12-13 01:19:07,618 iteration 5246 : loss : 0.021187, loss_ce: 0.007750
2021-12-13 01:19:09,057 iteration 5247 : loss : 0.018845, loss_ce: 0.005731
2021-12-13 01:19:10,573 iteration 5248 : loss : 0.018182, loss_ce: 0.008478
2021-12-13 01:19:12,014 iteration 5249 : loss : 0.013248, loss_ce: 0.004827
2021-12-13 01:19:13,485 iteration 5250 : loss : 0.015867, loss_ce: 0.005984
2021-12-13 01:19:15,009 iteration 5251 : loss : 0.014774, loss_ce: 0.006051
2021-12-13 01:19:16,455 iteration 5252 : loss : 0.016164, loss_ce: 0.008432
2021-12-13 01:19:17,904 iteration 5253 : loss : 0.012698, loss_ce: 0.004709
 77%|██████████████████████▍      | 309/400 [2:19:36<39:13, 25.86s/it]2021-12-13 01:19:19,391 iteration 5254 : loss : 0.018592, loss_ce: 0.009103
2021-12-13 01:19:20,912 iteration 5255 : loss : 0.015203, loss_ce: 0.004432
2021-12-13 01:19:22,391 iteration 5256 : loss : 0.021971, loss_ce: 0.008470
2021-12-13 01:19:23,901 iteration 5257 : loss : 0.019341, loss_ce: 0.007046
2021-12-13 01:19:25,296 iteration 5258 : loss : 0.013465, loss_ce: 0.005675
2021-12-13 01:19:26,740 iteration 5259 : loss : 0.020699, loss_ce: 0.006670
2021-12-13 01:19:28,294 iteration 5260 : loss : 0.013806, loss_ce: 0.004681
2021-12-13 01:19:29,734 iteration 5261 : loss : 0.015696, loss_ce: 0.006715
2021-12-13 01:19:31,163 iteration 5262 : loss : 0.017292, loss_ce: 0.007377
2021-12-13 01:19:32,662 iteration 5263 : loss : 0.018291, loss_ce: 0.007083
2021-12-13 01:19:34,168 iteration 5264 : loss : 0.016508, loss_ce: 0.006013
2021-12-13 01:19:35,673 iteration 5265 : loss : 0.015444, loss_ce: 0.006068
2021-12-13 01:19:37,109 iteration 5266 : loss : 0.013961, loss_ce: 0.005396
2021-12-13 01:19:38,656 iteration 5267 : loss : 0.020584, loss_ce: 0.009052
2021-12-13 01:19:40,001 iteration 5268 : loss : 0.010987, loss_ce: 0.002290
2021-12-13 01:19:41,375 iteration 5269 : loss : 0.012877, loss_ce: 0.004720
2021-12-13 01:19:41,375 Training Data Eval:
2021-12-13 01:19:48,874   Average segmentation loss on training set: 0.0089
2021-12-13 01:19:48,874 Validation Data Eval:
2021-12-13 01:19:51,471   Average segmentation loss on validation set: 0.0766
2021-12-13 01:19:52,934 iteration 5270 : loss : 0.018499, loss_ce: 0.002689
 78%|██████████████████████▍      | 310/400 [2:20:11<42:55, 28.62s/it]2021-12-13 01:19:54,567 iteration 5271 : loss : 0.021289, loss_ce: 0.006874
2021-12-13 01:19:56,114 iteration 5272 : loss : 0.023646, loss_ce: 0.008757
2021-12-13 01:19:57,568 iteration 5273 : loss : 0.018011, loss_ce: 0.008063
2021-12-13 01:19:59,028 iteration 5274 : loss : 0.017749, loss_ce: 0.007324
2021-12-13 01:20:00,457 iteration 5275 : loss : 0.013777, loss_ce: 0.005535
2021-12-13 01:20:01,890 iteration 5276 : loss : 0.018455, loss_ce: 0.006174
2021-12-13 01:20:03,452 iteration 5277 : loss : 0.021047, loss_ce: 0.009241
2021-12-13 01:20:04,895 iteration 5278 : loss : 0.016636, loss_ce: 0.003985
2021-12-13 01:20:06,390 iteration 5279 : loss : 0.025667, loss_ce: 0.008800
2021-12-13 01:20:07,804 iteration 5280 : loss : 0.011855, loss_ce: 0.003608
2021-12-13 01:20:09,253 iteration 5281 : loss : 0.012323, loss_ce: 0.005634
2021-12-13 01:20:10,695 iteration 5282 : loss : 0.015768, loss_ce: 0.006412
2021-12-13 01:20:12,119 iteration 5283 : loss : 0.014905, loss_ce: 0.006208
2021-12-13 01:20:13,605 iteration 5284 : loss : 0.014014, loss_ce: 0.005266
2021-12-13 01:20:15,071 iteration 5285 : loss : 0.014672, loss_ce: 0.005274
2021-12-13 01:20:16,502 iteration 5286 : loss : 0.013641, loss_ce: 0.006591
2021-12-13 01:20:17,991 iteration 5287 : loss : 0.014738, loss_ce: 0.005096
 78%|██████████████████████▌      | 311/400 [2:20:36<40:51, 27.55s/it]2021-12-13 01:20:19,504 iteration 5288 : loss : 0.016558, loss_ce: 0.007839
2021-12-13 01:20:20,917 iteration 5289 : loss : 0.024743, loss_ce: 0.008757
2021-12-13 01:20:22,501 iteration 5290 : loss : 0.029795, loss_ce: 0.008460
2021-12-13 01:20:23,957 iteration 5291 : loss : 0.016922, loss_ce: 0.007453
2021-12-13 01:20:25,434 iteration 5292 : loss : 0.034858, loss_ce: 0.006400
2021-12-13 01:20:26,841 iteration 5293 : loss : 0.018844, loss_ce: 0.006819
2021-12-13 01:20:28,346 iteration 5294 : loss : 0.020100, loss_ce: 0.005803
2021-12-13 01:20:29,825 iteration 5295 : loss : 0.016526, loss_ce: 0.004940
2021-12-13 01:20:31,231 iteration 5296 : loss : 0.017070, loss_ce: 0.004906
2021-12-13 01:20:32,679 iteration 5297 : loss : 0.019106, loss_ce: 0.005582
2021-12-13 01:20:34,105 iteration 5298 : loss : 0.012703, loss_ce: 0.005574
2021-12-13 01:20:35,541 iteration 5299 : loss : 0.015429, loss_ce: 0.002731
2021-12-13 01:20:36,972 iteration 5300 : loss : 0.015857, loss_ce: 0.006727
2021-12-13 01:20:38,430 iteration 5301 : loss : 0.021643, loss_ce: 0.004768
2021-12-13 01:20:39,952 iteration 5302 : loss : 0.019831, loss_ce: 0.007985
2021-12-13 01:20:41,438 iteration 5303 : loss : 0.013455, loss_ce: 0.006231
2021-12-13 01:20:42,892 iteration 5304 : loss : 0.017534, loss_ce: 0.008800
 78%|██████████████████████▌      | 312/400 [2:21:00<39:14, 26.75s/it]2021-12-13 01:20:44,334 iteration 5305 : loss : 0.008656, loss_ce: 0.002981
2021-12-13 01:20:45,837 iteration 5306 : loss : 0.024281, loss_ce: 0.012062
2021-12-13 01:20:47,304 iteration 5307 : loss : 0.020556, loss_ce: 0.008550
2021-12-13 01:20:48,739 iteration 5308 : loss : 0.012672, loss_ce: 0.003922
2021-12-13 01:20:50,214 iteration 5309 : loss : 0.014522, loss_ce: 0.007171
2021-12-13 01:20:51,768 iteration 5310 : loss : 0.014546, loss_ce: 0.004872
2021-12-13 01:20:53,210 iteration 5311 : loss : 0.017378, loss_ce: 0.006001
2021-12-13 01:20:54,736 iteration 5312 : loss : 0.022115, loss_ce: 0.008759
2021-12-13 01:20:56,173 iteration 5313 : loss : 0.015616, loss_ce: 0.008294
2021-12-13 01:20:57,623 iteration 5314 : loss : 0.015805, loss_ce: 0.005641
2021-12-13 01:20:59,061 iteration 5315 : loss : 0.017430, loss_ce: 0.005692
2021-12-13 01:21:00,512 iteration 5316 : loss : 0.014444, loss_ce: 0.004394
2021-12-13 01:21:01,963 iteration 5317 : loss : 0.013212, loss_ce: 0.004145
2021-12-13 01:21:03,469 iteration 5318 : loss : 0.015800, loss_ce: 0.005684
2021-12-13 01:21:04,907 iteration 5319 : loss : 0.022386, loss_ce: 0.007834
2021-12-13 01:21:06,331 iteration 5320 : loss : 0.014417, loss_ce: 0.004914
2021-12-13 01:21:07,775 iteration 5321 : loss : 0.020202, loss_ce: 0.007516
 78%|██████████████████████▋      | 313/400 [2:21:25<37:58, 26.19s/it]2021-12-13 01:21:09,224 iteration 5322 : loss : 0.017104, loss_ce: 0.006059
2021-12-13 01:21:10,710 iteration 5323 : loss : 0.032045, loss_ce: 0.012199
2021-12-13 01:21:12,145 iteration 5324 : loss : 0.016462, loss_ce: 0.005704
2021-12-13 01:21:13,648 iteration 5325 : loss : 0.014871, loss_ce: 0.006040
2021-12-13 01:21:15,139 iteration 5326 : loss : 0.014645, loss_ce: 0.004983
2021-12-13 01:21:16,597 iteration 5327 : loss : 0.019796, loss_ce: 0.008393
2021-12-13 01:21:18,078 iteration 5328 : loss : 0.011825, loss_ce: 0.004367
2021-12-13 01:21:19,567 iteration 5329 : loss : 0.019274, loss_ce: 0.010526
2021-12-13 01:21:21,079 iteration 5330 : loss : 0.015320, loss_ce: 0.005815
2021-12-13 01:21:22,483 iteration 5331 : loss : 0.016648, loss_ce: 0.006360
2021-12-13 01:21:23,909 iteration 5332 : loss : 0.015329, loss_ce: 0.006343
2021-12-13 01:21:25,353 iteration 5333 : loss : 0.028633, loss_ce: 0.010572
2021-12-13 01:21:26,789 iteration 5334 : loss : 0.014748, loss_ce: 0.004622
2021-12-13 01:21:28,337 iteration 5335 : loss : 0.026172, loss_ce: 0.008408
2021-12-13 01:21:29,810 iteration 5336 : loss : 0.032417, loss_ce: 0.015852
2021-12-13 01:21:31,277 iteration 5337 : loss : 0.014334, loss_ce: 0.004874
2021-12-13 01:21:32,648 iteration 5338 : loss : 0.012779, loss_ce: 0.005044
 78%|██████████████████████▊      | 314/400 [2:21:50<36:58, 25.80s/it]2021-12-13 01:21:34,129 iteration 5339 : loss : 0.016825, loss_ce: 0.006360
2021-12-13 01:21:35,592 iteration 5340 : loss : 0.014603, loss_ce: 0.008647
2021-12-13 01:21:37,064 iteration 5341 : loss : 0.015350, loss_ce: 0.006072
2021-12-13 01:21:38,555 iteration 5342 : loss : 0.018550, loss_ce: 0.005089
2021-12-13 01:21:39,974 iteration 5343 : loss : 0.017492, loss_ce: 0.005666
2021-12-13 01:21:41,396 iteration 5344 : loss : 0.016533, loss_ce: 0.007654
2021-12-13 01:21:42,810 iteration 5345 : loss : 0.027937, loss_ce: 0.006844
2021-12-13 01:21:44,260 iteration 5346 : loss : 0.020257, loss_ce: 0.007389
2021-12-13 01:21:45,800 iteration 5347 : loss : 0.016979, loss_ce: 0.007538
2021-12-13 01:21:47,280 iteration 5348 : loss : 0.022324, loss_ce: 0.011128
2021-12-13 01:21:48,728 iteration 5349 : loss : 0.024009, loss_ce: 0.010005
2021-12-13 01:21:50,131 iteration 5350 : loss : 0.014217, loss_ce: 0.005722
2021-12-13 01:21:51,650 iteration 5351 : loss : 0.045650, loss_ce: 0.014420
2021-12-13 01:21:53,120 iteration 5352 : loss : 0.016800, loss_ce: 0.006194
2021-12-13 01:21:54,637 iteration 5353 : loss : 0.019685, loss_ce: 0.009465
2021-12-13 01:21:56,051 iteration 5354 : loss : 0.014026, loss_ce: 0.005660
2021-12-13 01:21:56,051 Training Data Eval:
2021-12-13 01:22:03,550   Average segmentation loss on training set: 0.0113
2021-12-13 01:22:03,551 Validation Data Eval:
2021-12-13 01:22:06,144   Average segmentation loss on validation set: 0.0752
2021-12-13 01:22:07,566 iteration 5355 : loss : 0.012964, loss_ce: 0.005150
 79%|██████████████████████▊      | 315/400 [2:22:25<40:25, 28.53s/it]2021-12-13 01:22:09,137 iteration 5356 : loss : 0.031975, loss_ce: 0.015643
2021-12-13 01:22:10,534 iteration 5357 : loss : 0.011991, loss_ce: 0.003613
2021-12-13 01:22:11,997 iteration 5358 : loss : 0.017748, loss_ce: 0.005389
2021-12-13 01:22:13,428 iteration 5359 : loss : 0.017454, loss_ce: 0.009942
2021-12-13 01:22:14,882 iteration 5360 : loss : 0.016329, loss_ce: 0.005677
2021-12-13 01:22:16,415 iteration 5361 : loss : 0.017218, loss_ce: 0.005572
2021-12-13 01:22:17,931 iteration 5362 : loss : 0.016982, loss_ce: 0.009711
2021-12-13 01:22:19,403 iteration 5363 : loss : 0.016998, loss_ce: 0.007279
2021-12-13 01:22:20,770 iteration 5364 : loss : 0.017910, loss_ce: 0.002799
2021-12-13 01:22:22,286 iteration 5365 : loss : 0.018442, loss_ce: 0.006606
2021-12-13 01:22:23,678 iteration 5366 : loss : 0.019413, loss_ce: 0.006235
2021-12-13 01:22:25,163 iteration 5367 : loss : 0.026395, loss_ce: 0.008943
2021-12-13 01:22:26,702 iteration 5368 : loss : 0.014220, loss_ce: 0.005657
2021-12-13 01:22:28,165 iteration 5369 : loss : 0.023046, loss_ce: 0.009588
2021-12-13 01:22:29,640 iteration 5370 : loss : 0.018827, loss_ce: 0.006059
2021-12-13 01:22:31,172 iteration 5371 : loss : 0.016541, loss_ce: 0.005168
2021-12-13 01:22:32,602 iteration 5372 : loss : 0.035335, loss_ce: 0.020433
 79%|██████████████████████▉      | 316/400 [2:22:50<38:28, 27.48s/it]2021-12-13 01:22:34,015 iteration 5373 : loss : 0.012551, loss_ce: 0.005804
2021-12-13 01:22:35,497 iteration 5374 : loss : 0.020260, loss_ce: 0.005995
2021-12-13 01:22:36,912 iteration 5375 : loss : 0.018972, loss_ce: 0.006268
2021-12-13 01:22:38,310 iteration 5376 : loss : 0.014074, loss_ce: 0.004164
2021-12-13 01:22:39,680 iteration 5377 : loss : 0.018603, loss_ce: 0.002496
2021-12-13 01:22:41,051 iteration 5378 : loss : 0.012556, loss_ce: 0.004567
2021-12-13 01:22:42,534 iteration 5379 : loss : 0.015651, loss_ce: 0.004633
2021-12-13 01:22:43,963 iteration 5380 : loss : 0.014393, loss_ce: 0.005946
2021-12-13 01:22:45,427 iteration 5381 : loss : 0.018980, loss_ce: 0.007863
2021-12-13 01:22:46,933 iteration 5382 : loss : 0.023187, loss_ce: 0.006550
2021-12-13 01:22:48,433 iteration 5383 : loss : 0.023260, loss_ce: 0.010474
2021-12-13 01:22:49,876 iteration 5384 : loss : 0.017506, loss_ce: 0.007860
2021-12-13 01:22:51,329 iteration 5385 : loss : 0.016148, loss_ce: 0.006733
2021-12-13 01:22:52,823 iteration 5386 : loss : 0.014365, loss_ce: 0.005349
2021-12-13 01:22:54,286 iteration 5387 : loss : 0.021312, loss_ce: 0.009338
2021-12-13 01:22:55,659 iteration 5388 : loss : 0.013242, loss_ce: 0.005403
2021-12-13 01:22:57,093 iteration 5389 : loss : 0.013003, loss_ce: 0.004723
 79%|██████████████████████▉      | 317/400 [2:23:15<36:46, 26.58s/it]2021-12-13 01:22:58,674 iteration 5390 : loss : 0.022060, loss_ce: 0.006086
2021-12-13 01:23:00,049 iteration 5391 : loss : 0.014378, loss_ce: 0.004770
2021-12-13 01:23:01,547 iteration 5392 : loss : 0.014730, loss_ce: 0.006169
2021-12-13 01:23:03,053 iteration 5393 : loss : 0.026091, loss_ce: 0.007529
2021-12-13 01:23:04,493 iteration 5394 : loss : 0.013198, loss_ce: 0.005295
2021-12-13 01:23:05,891 iteration 5395 : loss : 0.016315, loss_ce: 0.007482
2021-12-13 01:23:07,395 iteration 5396 : loss : 0.023240, loss_ce: 0.006851
2021-12-13 01:23:08,861 iteration 5397 : loss : 0.033191, loss_ce: 0.012925
2021-12-13 01:23:10,223 iteration 5398 : loss : 0.010688, loss_ce: 0.005286
2021-12-13 01:23:11,660 iteration 5399 : loss : 0.015141, loss_ce: 0.007608
2021-12-13 01:23:13,201 iteration 5400 : loss : 0.020475, loss_ce: 0.006825
2021-12-13 01:23:14,701 iteration 5401 : loss : 0.017610, loss_ce: 0.006160
2021-12-13 01:23:16,145 iteration 5402 : loss : 0.015712, loss_ce: 0.006092
2021-12-13 01:23:17,631 iteration 5403 : loss : 0.030105, loss_ce: 0.010707
2021-12-13 01:23:19,039 iteration 5404 : loss : 0.015215, loss_ce: 0.007594
2021-12-13 01:23:20,434 iteration 5405 : loss : 0.010166, loss_ce: 0.003565
2021-12-13 01:23:21,809 iteration 5406 : loss : 0.015595, loss_ce: 0.003942
 80%|███████████████████████      | 318/400 [2:23:39<35:34, 26.03s/it]2021-12-13 01:23:23,378 iteration 5407 : loss : 0.014769, loss_ce: 0.004878
2021-12-13 01:23:24,800 iteration 5408 : loss : 0.015264, loss_ce: 0.004041
2021-12-13 01:23:26,205 iteration 5409 : loss : 0.012281, loss_ce: 0.005787
2021-12-13 01:23:27,631 iteration 5410 : loss : 0.013630, loss_ce: 0.004365
2021-12-13 01:23:29,108 iteration 5411 : loss : 0.014953, loss_ce: 0.005127
2021-12-13 01:23:30,586 iteration 5412 : loss : 0.015143, loss_ce: 0.006915
2021-12-13 01:23:31,995 iteration 5413 : loss : 0.014187, loss_ce: 0.005344
2021-12-13 01:23:33,504 iteration 5414 : loss : 0.019769, loss_ce: 0.007044
2021-12-13 01:23:34,962 iteration 5415 : loss : 0.014772, loss_ce: 0.005296
2021-12-13 01:23:36,476 iteration 5416 : loss : 0.019096, loss_ce: 0.009171
2021-12-13 01:23:37,893 iteration 5417 : loss : 0.023455, loss_ce: 0.008025
2021-12-13 01:23:39,336 iteration 5418 : loss : 0.015977, loss_ce: 0.006606
2021-12-13 01:23:40,765 iteration 5419 : loss : 0.012280, loss_ce: 0.006009
2021-12-13 01:23:42,230 iteration 5420 : loss : 0.012461, loss_ce: 0.005274
2021-12-13 01:23:43,709 iteration 5421 : loss : 0.017531, loss_ce: 0.005319
2021-12-13 01:23:45,175 iteration 5422 : loss : 0.022157, loss_ce: 0.007770
2021-12-13 01:23:46,683 iteration 5423 : loss : 0.020102, loss_ce: 0.006664
 80%|███████████████████████▏     | 319/400 [2:24:04<34:39, 25.68s/it]2021-12-13 01:23:48,197 iteration 5424 : loss : 0.018525, loss_ce: 0.007847
2021-12-13 01:23:49,675 iteration 5425 : loss : 0.029727, loss_ce: 0.014228
2021-12-13 01:23:51,168 iteration 5426 : loss : 0.016657, loss_ce: 0.005566
2021-12-13 01:23:52,727 iteration 5427 : loss : 0.025781, loss_ce: 0.008163
2021-12-13 01:23:54,236 iteration 5428 : loss : 0.024699, loss_ce: 0.008941
2021-12-13 01:23:55,657 iteration 5429 : loss : 0.014145, loss_ce: 0.005668
2021-12-13 01:23:57,042 iteration 5430 : loss : 0.016356, loss_ce: 0.006947
2021-12-13 01:23:58,562 iteration 5431 : loss : 0.018715, loss_ce: 0.006201
2021-12-13 01:23:59,987 iteration 5432 : loss : 0.016215, loss_ce: 0.005916
2021-12-13 01:24:01,558 iteration 5433 : loss : 0.022818, loss_ce: 0.008153
2021-12-13 01:24:03,093 iteration 5434 : loss : 0.042094, loss_ce: 0.012182
2021-12-13 01:24:04,566 iteration 5435 : loss : 0.016015, loss_ce: 0.006301
2021-12-13 01:24:06,067 iteration 5436 : loss : 0.016908, loss_ce: 0.007589
2021-12-13 01:24:07,490 iteration 5437 : loss : 0.018224, loss_ce: 0.004829
2021-12-13 01:24:08,967 iteration 5438 : loss : 0.017473, loss_ce: 0.007664
2021-12-13 01:24:10,466 iteration 5439 : loss : 0.020769, loss_ce: 0.006580
2021-12-13 01:24:10,467 Training Data Eval:
2021-12-13 01:24:17,932   Average segmentation loss on training set: 0.0103
2021-12-13 01:24:17,932 Validation Data Eval:
2021-12-13 01:24:20,542   Average segmentation loss on validation set: 0.0899
2021-12-13 01:24:22,025 iteration 5440 : loss : 0.016512, loss_ce: 0.005775
 80%|███████████████████████▏     | 320/400 [2:24:40<38:06, 28.58s/it]2021-12-13 01:24:23,480 iteration 5441 : loss : 0.012977, loss_ce: 0.005670
2021-12-13 01:24:25,083 iteration 5442 : loss : 0.025502, loss_ce: 0.009672
2021-12-13 01:24:26,577 iteration 5443 : loss : 0.017684, loss_ce: 0.006145
2021-12-13 01:24:28,030 iteration 5444 : loss : 0.016231, loss_ce: 0.007747
2021-12-13 01:24:29,469 iteration 5445 : loss : 0.018059, loss_ce: 0.007388
2021-12-13 01:24:30,922 iteration 5446 : loss : 0.016669, loss_ce: 0.006707
2021-12-13 01:24:32,314 iteration 5447 : loss : 0.015684, loss_ce: 0.002948
2021-12-13 01:24:33,805 iteration 5448 : loss : 0.017408, loss_ce: 0.005756
2021-12-13 01:24:35,240 iteration 5449 : loss : 0.013546, loss_ce: 0.003909
2021-12-13 01:24:36,668 iteration 5450 : loss : 0.018975, loss_ce: 0.005471
2021-12-13 01:24:38,149 iteration 5451 : loss : 0.010881, loss_ce: 0.002770
2021-12-13 01:24:39,633 iteration 5452 : loss : 0.012243, loss_ce: 0.004597
2021-12-13 01:24:41,146 iteration 5453 : loss : 0.020244, loss_ce: 0.008988
2021-12-13 01:24:42,617 iteration 5454 : loss : 0.022327, loss_ce: 0.009799
2021-12-13 01:24:44,083 iteration 5455 : loss : 0.015193, loss_ce: 0.007682
2021-12-13 01:24:45,574 iteration 5456 : loss : 0.016840, loss_ce: 0.004589
2021-12-13 01:24:47,057 iteration 5457 : loss : 0.016387, loss_ce: 0.006176
 80%|███████████████████████▎     | 321/400 [2:25:05<36:13, 27.51s/it]2021-12-13 01:24:48,620 iteration 5458 : loss : 0.023232, loss_ce: 0.005386
2021-12-13 01:24:50,037 iteration 5459 : loss : 0.014555, loss_ce: 0.005324
2021-12-13 01:24:51,497 iteration 5460 : loss : 0.023280, loss_ce: 0.009186
2021-12-13 01:24:52,983 iteration 5461 : loss : 0.019250, loss_ce: 0.006778
2021-12-13 01:24:54,478 iteration 5462 : loss : 0.021947, loss_ce: 0.011851
2021-12-13 01:24:55,890 iteration 5463 : loss : 0.010669, loss_ce: 0.003446
2021-12-13 01:24:57,459 iteration 5464 : loss : 0.024577, loss_ce: 0.008179
2021-12-13 01:24:58,879 iteration 5465 : loss : 0.016675, loss_ce: 0.005917
2021-12-13 01:25:00,311 iteration 5466 : loss : 0.015026, loss_ce: 0.005626
2021-12-13 01:25:01,848 iteration 5467 : loss : 0.012923, loss_ce: 0.004406
2021-12-13 01:25:03,358 iteration 5468 : loss : 0.015035, loss_ce: 0.007172
2021-12-13 01:25:04,871 iteration 5469 : loss : 0.019010, loss_ce: 0.007046
2021-12-13 01:25:06,311 iteration 5470 : loss : 0.016317, loss_ce: 0.007261
2021-12-13 01:25:07,745 iteration 5471 : loss : 0.013810, loss_ce: 0.006281
2021-12-13 01:25:09,267 iteration 5472 : loss : 0.023586, loss_ce: 0.010584
2021-12-13 01:25:10,690 iteration 5473 : loss : 0.015096, loss_ce: 0.003980
2021-12-13 01:25:12,185 iteration 5474 : loss : 0.014326, loss_ce: 0.004466
 80%|███████████████████████▎     | 322/400 [2:25:30<34:50, 26.80s/it]2021-12-13 01:25:13,649 iteration 5475 : loss : 0.015102, loss_ce: 0.005873
2021-12-13 01:25:15,095 iteration 5476 : loss : 0.012031, loss_ce: 0.005183
2021-12-13 01:25:16,588 iteration 5477 : loss : 0.011074, loss_ce: 0.003848
2021-12-13 01:25:18,099 iteration 5478 : loss : 0.014059, loss_ce: 0.006257
2021-12-13 01:25:19,520 iteration 5479 : loss : 0.016925, loss_ce: 0.004343
2021-12-13 01:25:20,978 iteration 5480 : loss : 0.016060, loss_ce: 0.003445
2021-12-13 01:25:22,448 iteration 5481 : loss : 0.017159, loss_ce: 0.006717
2021-12-13 01:25:23,916 iteration 5482 : loss : 0.018835, loss_ce: 0.006954
2021-12-13 01:25:25,337 iteration 5483 : loss : 0.016691, loss_ce: 0.006766
2021-12-13 01:25:26,868 iteration 5484 : loss : 0.016369, loss_ce: 0.006842
2021-12-13 01:25:28,260 iteration 5485 : loss : 0.012125, loss_ce: 0.005714
2021-12-13 01:25:29,825 iteration 5486 : loss : 0.015162, loss_ce: 0.004359
2021-12-13 01:25:31,212 iteration 5487 : loss : 0.012373, loss_ce: 0.006307
2021-12-13 01:25:32,691 iteration 5488 : loss : 0.021700, loss_ce: 0.006030
2021-12-13 01:25:34,102 iteration 5489 : loss : 0.014148, loss_ce: 0.003631
2021-12-13 01:25:35,611 iteration 5490 : loss : 0.014859, loss_ce: 0.005465
2021-12-13 01:25:37,040 iteration 5491 : loss : 0.014070, loss_ce: 0.004961
 81%|███████████████████████▍     | 323/400 [2:25:55<33:38, 26.21s/it]2021-12-13 01:25:38,564 iteration 5492 : loss : 0.013468, loss_ce: 0.006389
2021-12-13 01:25:39,964 iteration 5493 : loss : 0.012426, loss_ce: 0.004144
2021-12-13 01:25:41,394 iteration 5494 : loss : 0.016241, loss_ce: 0.006953
2021-12-13 01:25:42,916 iteration 5495 : loss : 0.022807, loss_ce: 0.005480
2021-12-13 01:25:44,327 iteration 5496 : loss : 0.012667, loss_ce: 0.003821
2021-12-13 01:25:45,796 iteration 5497 : loss : 0.015334, loss_ce: 0.006634
2021-12-13 01:25:47,302 iteration 5498 : loss : 0.015619, loss_ce: 0.006151
2021-12-13 01:25:48,753 iteration 5499 : loss : 0.015760, loss_ce: 0.004197
2021-12-13 01:25:50,195 iteration 5500 : loss : 0.011307, loss_ce: 0.003512
2021-12-13 01:25:51,615 iteration 5501 : loss : 0.012271, loss_ce: 0.004140
2021-12-13 01:25:53,040 iteration 5502 : loss : 0.014155, loss_ce: 0.006938
2021-12-13 01:25:54,623 iteration 5503 : loss : 0.021787, loss_ce: 0.006097
2021-12-13 01:25:56,099 iteration 5504 : loss : 0.014862, loss_ce: 0.005916
2021-12-13 01:25:57,491 iteration 5505 : loss : 0.013552, loss_ce: 0.004975
2021-12-13 01:25:58,923 iteration 5506 : loss : 0.015316, loss_ce: 0.006279
2021-12-13 01:26:00,479 iteration 5507 : loss : 0.014669, loss_ce: 0.004830
2021-12-13 01:26:01,976 iteration 5508 : loss : 0.025699, loss_ce: 0.010741
 81%|███████████████████████▍     | 324/400 [2:26:20<32:43, 25.83s/it]2021-12-13 01:26:03,516 iteration 5509 : loss : 0.017645, loss_ce: 0.007483
2021-12-13 01:26:04,953 iteration 5510 : loss : 0.016145, loss_ce: 0.006155
2021-12-13 01:26:06,430 iteration 5511 : loss : 0.016475, loss_ce: 0.005734
2021-12-13 01:26:07,892 iteration 5512 : loss : 0.013376, loss_ce: 0.005697
2021-12-13 01:26:09,351 iteration 5513 : loss : 0.012589, loss_ce: 0.007132
2021-12-13 01:26:10,876 iteration 5514 : loss : 0.022830, loss_ce: 0.010157
2021-12-13 01:26:12,318 iteration 5515 : loss : 0.011489, loss_ce: 0.004198
2021-12-13 01:26:13,759 iteration 5516 : loss : 0.013374, loss_ce: 0.006590
2021-12-13 01:26:15,235 iteration 5517 : loss : 0.022781, loss_ce: 0.007047
2021-12-13 01:26:16,629 iteration 5518 : loss : 0.012320, loss_ce: 0.004172
2021-12-13 01:26:18,175 iteration 5519 : loss : 0.019502, loss_ce: 0.005805
2021-12-13 01:26:19,631 iteration 5520 : loss : 0.011932, loss_ce: 0.001705
2021-12-13 01:26:21,184 iteration 5521 : loss : 0.014278, loss_ce: 0.005143
2021-12-13 01:26:22,648 iteration 5522 : loss : 0.012457, loss_ce: 0.004596
2021-12-13 01:26:24,170 iteration 5523 : loss : 0.023028, loss_ce: 0.009203
2021-12-13 01:26:25,692 iteration 5524 : loss : 0.015494, loss_ce: 0.005998
2021-12-13 01:26:25,692 Training Data Eval:
2021-12-13 01:26:33,171   Average segmentation loss on training set: 0.0085
2021-12-13 01:26:33,172 Validation Data Eval:
2021-12-13 01:26:35,766   Average segmentation loss on validation set: 0.0757
2021-12-13 01:26:37,328 iteration 5525 : loss : 0.016650, loss_ce: 0.007443
 81%|███████████████████████▌     | 325/400 [2:26:55<35:51, 28.69s/it]2021-12-13 01:26:38,825 iteration 5526 : loss : 0.020183, loss_ce: 0.006603
2021-12-13 01:26:40,229 iteration 5527 : loss : 0.012679, loss_ce: 0.004926
2021-12-13 01:26:41,757 iteration 5528 : loss : 0.017826, loss_ce: 0.005928
2021-12-13 01:26:43,185 iteration 5529 : loss : 0.012404, loss_ce: 0.004571
2021-12-13 01:26:44,593 iteration 5530 : loss : 0.010468, loss_ce: 0.004191
2021-12-13 01:26:45,964 iteration 5531 : loss : 0.010214, loss_ce: 0.003141
2021-12-13 01:26:47,366 iteration 5532 : loss : 0.012505, loss_ce: 0.004846
2021-12-13 01:26:48,866 iteration 5533 : loss : 0.014535, loss_ce: 0.006442
2021-12-13 01:26:50,259 iteration 5534 : loss : 0.011268, loss_ce: 0.003844
2021-12-13 01:26:51,688 iteration 5535 : loss : 0.014648, loss_ce: 0.007015
2021-12-13 01:26:53,191 iteration 5536 : loss : 0.014798, loss_ce: 0.005238
2021-12-13 01:26:54,688 iteration 5537 : loss : 0.017481, loss_ce: 0.007307
2021-12-13 01:26:56,223 iteration 5538 : loss : 0.016227, loss_ce: 0.004375
2021-12-13 01:26:57,694 iteration 5539 : loss : 0.013355, loss_ce: 0.005209
2021-12-13 01:26:59,101 iteration 5540 : loss : 0.016590, loss_ce: 0.006164
2021-12-13 01:27:00,657 iteration 5541 : loss : 0.029114, loss_ce: 0.013875
2021-12-13 01:27:02,109 iteration 5542 : loss : 0.019695, loss_ce: 0.007812
 82%|███████████████████████▋     | 326/400 [2:27:20<33:56, 27.52s/it]2021-12-13 01:27:03,653 iteration 5543 : loss : 0.026341, loss_ce: 0.012283
2021-12-13 01:27:05,074 iteration 5544 : loss : 0.010775, loss_ce: 0.003718
2021-12-13 01:27:06,561 iteration 5545 : loss : 0.013728, loss_ce: 0.006062
2021-12-13 01:27:08,108 iteration 5546 : loss : 0.026182, loss_ce: 0.005972
2021-12-13 01:27:09,603 iteration 5547 : loss : 0.012965, loss_ce: 0.005342
2021-12-13 01:27:11,033 iteration 5548 : loss : 0.015911, loss_ce: 0.003936
2021-12-13 01:27:12,472 iteration 5549 : loss : 0.014168, loss_ce: 0.004391
2021-12-13 01:27:13,954 iteration 5550 : loss : 0.014853, loss_ce: 0.005607
2021-12-13 01:27:15,376 iteration 5551 : loss : 0.021705, loss_ce: 0.010052
2021-12-13 01:27:16,736 iteration 5552 : loss : 0.009931, loss_ce: 0.003584
2021-12-13 01:27:18,225 iteration 5553 : loss : 0.014243, loss_ce: 0.005693
2021-12-13 01:27:19,673 iteration 5554 : loss : 0.012886, loss_ce: 0.005619
2021-12-13 01:27:21,057 iteration 5555 : loss : 0.012678, loss_ce: 0.005608
2021-12-13 01:27:22,588 iteration 5556 : loss : 0.027752, loss_ce: 0.013523
2021-12-13 01:27:24,071 iteration 5557 : loss : 0.011076, loss_ce: 0.004504
2021-12-13 01:27:25,532 iteration 5558 : loss : 0.014678, loss_ce: 0.004562
2021-12-13 01:27:26,991 iteration 5559 : loss : 0.019142, loss_ce: 0.005410
 82%|███████████████████████▋     | 327/400 [2:27:45<32:31, 26.73s/it]2021-12-13 01:27:28,498 iteration 5560 : loss : 0.015662, loss_ce: 0.004924
2021-12-13 01:27:29,920 iteration 5561 : loss : 0.015862, loss_ce: 0.005774
2021-12-13 01:27:31,359 iteration 5562 : loss : 0.017025, loss_ce: 0.007777
2021-12-13 01:27:32,803 iteration 5563 : loss : 0.013464, loss_ce: 0.005634
2021-12-13 01:27:34,300 iteration 5564 : loss : 0.017836, loss_ce: 0.007784
2021-12-13 01:27:35,795 iteration 5565 : loss : 0.018314, loss_ce: 0.007613
2021-12-13 01:27:37,276 iteration 5566 : loss : 0.015300, loss_ce: 0.006289
2021-12-13 01:27:38,768 iteration 5567 : loss : 0.015505, loss_ce: 0.007538
2021-12-13 01:27:40,187 iteration 5568 : loss : 0.016751, loss_ce: 0.006047
2021-12-13 01:27:41,634 iteration 5569 : loss : 0.014659, loss_ce: 0.005030
2021-12-13 01:27:43,030 iteration 5570 : loss : 0.010342, loss_ce: 0.002996
2021-12-13 01:27:44,394 iteration 5571 : loss : 0.009647, loss_ce: 0.003628
2021-12-13 01:27:45,823 iteration 5572 : loss : 0.014984, loss_ce: 0.004850
2021-12-13 01:27:47,219 iteration 5573 : loss : 0.010051, loss_ce: 0.002953
2021-12-13 01:27:48,677 iteration 5574 : loss : 0.012402, loss_ce: 0.003832
2021-12-13 01:27:50,222 iteration 5575 : loss : 0.020281, loss_ce: 0.006959
2021-12-13 01:27:51,687 iteration 5576 : loss : 0.016562, loss_ce: 0.005922
 82%|███████████████████████▊     | 328/400 [2:28:09<31:20, 26.12s/it]2021-12-13 01:27:53,193 iteration 5577 : loss : 0.015778, loss_ce: 0.006954
2021-12-13 01:27:54,692 iteration 5578 : loss : 0.019161, loss_ce: 0.006902
2021-12-13 01:27:56,213 iteration 5579 : loss : 0.016456, loss_ce: 0.007414
2021-12-13 01:27:57,646 iteration 5580 : loss : 0.015624, loss_ce: 0.006249
2021-12-13 01:27:59,047 iteration 5581 : loss : 0.010295, loss_ce: 0.004028
2021-12-13 01:28:00,508 iteration 5582 : loss : 0.013045, loss_ce: 0.003686
2021-12-13 01:28:01,960 iteration 5583 : loss : 0.012309, loss_ce: 0.004836
2021-12-13 01:28:03,489 iteration 5584 : loss : 0.015021, loss_ce: 0.006084
2021-12-13 01:28:04,934 iteration 5585 : loss : 0.012576, loss_ce: 0.003737
2021-12-13 01:28:06,451 iteration 5586 : loss : 0.033280, loss_ce: 0.009658
2021-12-13 01:28:07,848 iteration 5587 : loss : 0.014877, loss_ce: 0.005630
2021-12-13 01:28:09,282 iteration 5588 : loss : 0.013459, loss_ce: 0.005010
2021-12-13 01:28:10,676 iteration 5589 : loss : 0.010051, loss_ce: 0.002816
2021-12-13 01:28:12,110 iteration 5590 : loss : 0.012192, loss_ce: 0.003241
2021-12-13 01:28:13,556 iteration 5591 : loss : 0.014037, loss_ce: 0.006251
2021-12-13 01:28:15,077 iteration 5592 : loss : 0.017812, loss_ce: 0.005753
2021-12-13 01:28:16,557 iteration 5593 : loss : 0.023477, loss_ce: 0.010083
 82%|███████████████████████▊     | 329/400 [2:28:34<30:27, 25.74s/it]2021-12-13 01:28:18,012 iteration 5594 : loss : 0.016406, loss_ce: 0.004867
2021-12-13 01:28:19,507 iteration 5595 : loss : 0.017062, loss_ce: 0.007500
2021-12-13 01:28:20,934 iteration 5596 : loss : 0.015096, loss_ce: 0.005677
2021-12-13 01:28:22,444 iteration 5597 : loss : 0.011357, loss_ce: 0.004267
2021-12-13 01:28:23,850 iteration 5598 : loss : 0.011998, loss_ce: 0.005143
2021-12-13 01:28:25,303 iteration 5599 : loss : 0.019623, loss_ce: 0.007879
2021-12-13 01:28:26,739 iteration 5600 : loss : 0.011532, loss_ce: 0.004689
2021-12-13 01:28:28,146 iteration 5601 : loss : 0.011285, loss_ce: 0.004507
2021-12-13 01:28:29,614 iteration 5602 : loss : 0.014060, loss_ce: 0.005604
2021-12-13 01:28:31,032 iteration 5603 : loss : 0.010742, loss_ce: 0.004247
2021-12-13 01:28:32,512 iteration 5604 : loss : 0.018483, loss_ce: 0.004310
2021-12-13 01:28:34,005 iteration 5605 : loss : 0.015910, loss_ce: 0.006641
2021-12-13 01:28:35,478 iteration 5606 : loss : 0.014022, loss_ce: 0.004666
2021-12-13 01:28:36,926 iteration 5607 : loss : 0.013983, loss_ce: 0.004233
2021-12-13 01:28:38,365 iteration 5608 : loss : 0.014403, loss_ce: 0.004620
2021-12-13 01:28:39,857 iteration 5609 : loss : 0.012829, loss_ce: 0.005421
2021-12-13 01:28:39,858 Training Data Eval:
2021-12-13 01:28:47,349   Average segmentation loss on training set: 0.0083
2021-12-13 01:28:47,350 Validation Data Eval:
2021-12-13 01:28:49,948   Average segmentation loss on validation set: 0.0851
2021-12-13 01:28:51,381 iteration 5610 : loss : 0.011878, loss_ce: 0.004248
 82%|███████████████████████▉     | 330/400 [2:29:09<33:12, 28.46s/it]2021-12-13 01:28:52,870 iteration 5611 : loss : 0.020799, loss_ce: 0.007619
2021-12-13 01:28:54,344 iteration 5612 : loss : 0.020817, loss_ce: 0.004592
2021-12-13 01:28:55,819 iteration 5613 : loss : 0.013810, loss_ce: 0.005042
2021-12-13 01:28:57,290 iteration 5614 : loss : 0.018832, loss_ce: 0.006031
2021-12-13 01:28:58,676 iteration 5615 : loss : 0.009163, loss_ce: 0.003955
2021-12-13 01:29:00,163 iteration 5616 : loss : 0.012445, loss_ce: 0.005386
2021-12-13 01:29:01,679 iteration 5617 : loss : 0.012347, loss_ce: 0.004681
2021-12-13 01:29:03,154 iteration 5618 : loss : 0.014013, loss_ce: 0.005855
2021-12-13 01:29:04,577 iteration 5619 : loss : 0.017880, loss_ce: 0.006216
2021-12-13 01:29:06,093 iteration 5620 : loss : 0.013599, loss_ce: 0.005299
2021-12-13 01:29:07,496 iteration 5621 : loss : 0.014502, loss_ce: 0.004822
2021-12-13 01:29:08,979 iteration 5622 : loss : 0.013156, loss_ce: 0.004791
2021-12-13 01:29:10,515 iteration 5623 : loss : 0.017368, loss_ce: 0.005993
2021-12-13 01:29:11,923 iteration 5624 : loss : 0.013724, loss_ce: 0.003881
2021-12-13 01:29:13,322 iteration 5625 : loss : 0.012852, loss_ce: 0.005555
2021-12-13 01:29:14,757 iteration 5626 : loss : 0.015094, loss_ce: 0.004040
2021-12-13 01:29:16,227 iteration 5627 : loss : 0.014958, loss_ce: 0.005936
 83%|███████████████████████▉     | 331/400 [2:29:34<31:29, 27.38s/it]2021-12-13 01:29:17,816 iteration 5628 : loss : 0.017359, loss_ce: 0.008298
2021-12-13 01:29:19,230 iteration 5629 : loss : 0.012646, loss_ce: 0.005570
2021-12-13 01:29:20,731 iteration 5630 : loss : 0.022469, loss_ce: 0.009397
2021-12-13 01:29:22,182 iteration 5631 : loss : 0.013743, loss_ce: 0.005050
2021-12-13 01:29:23,674 iteration 5632 : loss : 0.016888, loss_ce: 0.007351
2021-12-13 01:29:25,194 iteration 5633 : loss : 0.023652, loss_ce: 0.007132
2021-12-13 01:29:26,659 iteration 5634 : loss : 0.008916, loss_ce: 0.003596
2021-12-13 01:29:28,108 iteration 5635 : loss : 0.016259, loss_ce: 0.005688
2021-12-13 01:29:29,575 iteration 5636 : loss : 0.020187, loss_ce: 0.006070
2021-12-13 01:29:31,020 iteration 5637 : loss : 0.015917, loss_ce: 0.004632
2021-12-13 01:29:32,479 iteration 5638 : loss : 0.013838, loss_ce: 0.005550
2021-12-13 01:29:33,967 iteration 5639 : loss : 0.015150, loss_ce: 0.006586
2021-12-13 01:29:35,458 iteration 5640 : loss : 0.012812, loss_ce: 0.005005
2021-12-13 01:29:36,864 iteration 5641 : loss : 0.012996, loss_ce: 0.003768
2021-12-13 01:29:38,288 iteration 5642 : loss : 0.013839, loss_ce: 0.005079
2021-12-13 01:29:39,742 iteration 5643 : loss : 0.014909, loss_ce: 0.005255
2021-12-13 01:29:41,185 iteration 5644 : loss : 0.013667, loss_ce: 0.005164
 83%|████████████████████████     | 332/400 [2:29:59<30:12, 26.66s/it]2021-12-13 01:29:42,661 iteration 5645 : loss : 0.013293, loss_ce: 0.004076
2021-12-13 01:29:44,112 iteration 5646 : loss : 0.015178, loss_ce: 0.006385
2021-12-13 01:29:45,604 iteration 5647 : loss : 0.014133, loss_ce: 0.004304
2021-12-13 01:29:47,092 iteration 5648 : loss : 0.020022, loss_ce: 0.005946
2021-12-13 01:29:48,552 iteration 5649 : loss : 0.011009, loss_ce: 0.004298
2021-12-13 01:29:50,068 iteration 5650 : loss : 0.023167, loss_ce: 0.006555
2021-12-13 01:29:51,519 iteration 5651 : loss : 0.012433, loss_ce: 0.005784
2021-12-13 01:29:52,943 iteration 5652 : loss : 0.014291, loss_ce: 0.005885
2021-12-13 01:29:54,371 iteration 5653 : loss : 0.017742, loss_ce: 0.005679
2021-12-13 01:29:55,897 iteration 5654 : loss : 0.013534, loss_ce: 0.005066
2021-12-13 01:29:57,351 iteration 5655 : loss : 0.022502, loss_ce: 0.007916
2021-12-13 01:29:58,846 iteration 5656 : loss : 0.015197, loss_ce: 0.006480
2021-12-13 01:30:00,287 iteration 5657 : loss : 0.016145, loss_ce: 0.008080
2021-12-13 01:30:01,814 iteration 5658 : loss : 0.023797, loss_ce: 0.006315
2021-12-13 01:30:03,367 iteration 5659 : loss : 0.018476, loss_ce: 0.008951
2021-12-13 01:30:04,746 iteration 5660 : loss : 0.010143, loss_ce: 0.003843
2021-12-13 01:30:06,247 iteration 5661 : loss : 0.017143, loss_ce: 0.006322
 83%|████████████████████████▏    | 333/400 [2:30:24<29:13, 26.18s/it]2021-12-13 01:30:07,704 iteration 5662 : loss : 0.011844, loss_ce: 0.004738
2021-12-13 01:30:09,226 iteration 5663 : loss : 0.012940, loss_ce: 0.005989
2021-12-13 01:30:10,752 iteration 5664 : loss : 0.017533, loss_ce: 0.006915
2021-12-13 01:30:12,184 iteration 5665 : loss : 0.010095, loss_ce: 0.002260
2021-12-13 01:30:13,706 iteration 5666 : loss : 0.014912, loss_ce: 0.005267
2021-12-13 01:30:15,191 iteration 5667 : loss : 0.014569, loss_ce: 0.004039
2021-12-13 01:30:16,671 iteration 5668 : loss : 0.016162, loss_ce: 0.005028
2021-12-13 01:30:18,200 iteration 5669 : loss : 0.019246, loss_ce: 0.009818
2021-12-13 01:30:19,678 iteration 5670 : loss : 0.013740, loss_ce: 0.004310
2021-12-13 01:30:21,206 iteration 5671 : loss : 0.021565, loss_ce: 0.005919
2021-12-13 01:30:22,584 iteration 5672 : loss : 0.013011, loss_ce: 0.003508
2021-12-13 01:30:24,020 iteration 5673 : loss : 0.012678, loss_ce: 0.005398
2021-12-13 01:30:25,420 iteration 5674 : loss : 0.016789, loss_ce: 0.005888
2021-12-13 01:30:26,995 iteration 5675 : loss : 0.024914, loss_ce: 0.010015
2021-12-13 01:30:28,459 iteration 5676 : loss : 0.024121, loss_ce: 0.012572
2021-12-13 01:30:29,881 iteration 5677 : loss : 0.014127, loss_ce: 0.004806
2021-12-13 01:30:31,329 iteration 5678 : loss : 0.013736, loss_ce: 0.005529
 84%|████████████████████████▏    | 334/400 [2:30:49<28:25, 25.85s/it]2021-12-13 01:30:32,855 iteration 5679 : loss : 0.017683, loss_ce: 0.005799
2021-12-13 01:30:34,311 iteration 5680 : loss : 0.013399, loss_ce: 0.005788
2021-12-13 01:30:35,805 iteration 5681 : loss : 0.014000, loss_ce: 0.003721
2021-12-13 01:30:37,197 iteration 5682 : loss : 0.012034, loss_ce: 0.003911
2021-12-13 01:30:38,571 iteration 5683 : loss : 0.009449, loss_ce: 0.004136
2021-12-13 01:30:40,091 iteration 5684 : loss : 0.013583, loss_ce: 0.006958
2021-12-13 01:30:41,580 iteration 5685 : loss : 0.018975, loss_ce: 0.006435
2021-12-13 01:30:43,038 iteration 5686 : loss : 0.016282, loss_ce: 0.005554
2021-12-13 01:30:44,521 iteration 5687 : loss : 0.011923, loss_ce: 0.003550
2021-12-13 01:30:46,046 iteration 5688 : loss : 0.018661, loss_ce: 0.006729
2021-12-13 01:30:47,496 iteration 5689 : loss : 0.015299, loss_ce: 0.006558
2021-12-13 01:30:48,909 iteration 5690 : loss : 0.012290, loss_ce: 0.004273
2021-12-13 01:30:50,406 iteration 5691 : loss : 0.012260, loss_ce: 0.005348
2021-12-13 01:30:51,858 iteration 5692 : loss : 0.008894, loss_ce: 0.002633
2021-12-13 01:30:53,200 iteration 5693 : loss : 0.011319, loss_ce: 0.004471
2021-12-13 01:30:54,690 iteration 5694 : loss : 0.013773, loss_ce: 0.005205
2021-12-13 01:30:54,690 Training Data Eval:
2021-12-13 01:31:02,177   Average segmentation loss on training set: 0.0080
2021-12-13 01:31:02,178 Validation Data Eval:
2021-12-13 01:31:04,771   Average segmentation loss on validation set: 0.0788
2021-12-13 01:31:06,231 iteration 5695 : loss : 0.013944, loss_ce: 0.005428
 84%|████████████████████████▎    | 335/400 [2:31:24<30:56, 28.56s/it]2021-12-13 01:31:07,741 iteration 5696 : loss : 0.018998, loss_ce: 0.005427
2021-12-13 01:31:09,159 iteration 5697 : loss : 0.010955, loss_ce: 0.003182
2021-12-13 01:31:10,672 iteration 5698 : loss : 0.014683, loss_ce: 0.004915
2021-12-13 01:31:12,199 iteration 5699 : loss : 0.018848, loss_ce: 0.005307
2021-12-13 01:31:13,593 iteration 5700 : loss : 0.012391, loss_ce: 0.005423
2021-12-13 01:31:15,159 iteration 5701 : loss : 0.018146, loss_ce: 0.003383
2021-12-13 01:31:16,640 iteration 5702 : loss : 0.014358, loss_ce: 0.005222
2021-12-13 01:31:18,169 iteration 5703 : loss : 0.012518, loss_ce: 0.005817
2021-12-13 01:31:19,602 iteration 5704 : loss : 0.013777, loss_ce: 0.006124
2021-12-13 01:31:21,042 iteration 5705 : loss : 0.013040, loss_ce: 0.005738
2021-12-13 01:31:22,476 iteration 5706 : loss : 0.013476, loss_ce: 0.005346
2021-12-13 01:31:23,977 iteration 5707 : loss : 0.023116, loss_ce: 0.005675
2021-12-13 01:31:25,432 iteration 5708 : loss : 0.011952, loss_ce: 0.005929
2021-12-13 01:31:26,843 iteration 5709 : loss : 0.014380, loss_ce: 0.004879
2021-12-13 01:31:28,289 iteration 5710 : loss : 0.014303, loss_ce: 0.006404
2021-12-13 01:31:29,755 iteration 5711 : loss : 0.011113, loss_ce: 0.005209
2021-12-13 01:31:31,215 iteration 5712 : loss : 0.019791, loss_ce: 0.007952
 84%|████████████████████████▎    | 336/400 [2:31:49<29:19, 27.49s/it]2021-12-13 01:31:32,725 iteration 5713 : loss : 0.010425, loss_ce: 0.004689
2021-12-13 01:31:34,229 iteration 5714 : loss : 0.015788, loss_ce: 0.004823
2021-12-13 01:31:35,652 iteration 5715 : loss : 0.012093, loss_ce: 0.004572
2021-12-13 01:31:37,152 iteration 5716 : loss : 0.015014, loss_ce: 0.004929
2021-12-13 01:31:38,547 iteration 5717 : loss : 0.009597, loss_ce: 0.003417
2021-12-13 01:31:39,968 iteration 5718 : loss : 0.013856, loss_ce: 0.006066
2021-12-13 01:31:41,462 iteration 5719 : loss : 0.015956, loss_ce: 0.004379
2021-12-13 01:31:42,966 iteration 5720 : loss : 0.019544, loss_ce: 0.009103
2021-12-13 01:31:44,374 iteration 5721 : loss : 0.014159, loss_ce: 0.003849
2021-12-13 01:31:45,871 iteration 5722 : loss : 0.015906, loss_ce: 0.005602
2021-12-13 01:31:47,400 iteration 5723 : loss : 0.025413, loss_ce: 0.008563
2021-12-13 01:31:48,874 iteration 5724 : loss : 0.015146, loss_ce: 0.007599
2021-12-13 01:31:50,318 iteration 5725 : loss : 0.015403, loss_ce: 0.007019
2021-12-13 01:31:51,829 iteration 5726 : loss : 0.009847, loss_ce: 0.003731
2021-12-13 01:31:53,305 iteration 5727 : loss : 0.015904, loss_ce: 0.008119
2021-12-13 01:31:54,727 iteration 5728 : loss : 0.015886, loss_ce: 0.005266
2021-12-13 01:31:56,117 iteration 5729 : loss : 0.011812, loss_ce: 0.003361
 84%|████████████████████████▍    | 337/400 [2:32:14<28:02, 26.71s/it]2021-12-13 01:31:57,714 iteration 5730 : loss : 0.019735, loss_ce: 0.007465
2021-12-13 01:31:59,226 iteration 5731 : loss : 0.022055, loss_ce: 0.007338
2021-12-13 01:32:00,710 iteration 5732 : loss : 0.022150, loss_ce: 0.004993
2021-12-13 01:32:02,212 iteration 5733 : loss : 0.014301, loss_ce: 0.005616
2021-12-13 01:32:03,651 iteration 5734 : loss : 0.008878, loss_ce: 0.003106
2021-12-13 01:32:05,199 iteration 5735 : loss : 0.019444, loss_ce: 0.006751
2021-12-13 01:32:06,712 iteration 5736 : loss : 0.014357, loss_ce: 0.005855
2021-12-13 01:32:08,177 iteration 5737 : loss : 0.013581, loss_ce: 0.005277
2021-12-13 01:32:09,623 iteration 5738 : loss : 0.014011, loss_ce: 0.006237
2021-12-13 01:32:11,109 iteration 5739 : loss : 0.012308, loss_ce: 0.003864
2021-12-13 01:32:12,619 iteration 5740 : loss : 0.016049, loss_ce: 0.006653
2021-12-13 01:32:14,090 iteration 5741 : loss : 0.011348, loss_ce: 0.004613
2021-12-13 01:32:15,538 iteration 5742 : loss : 0.022158, loss_ce: 0.004148
2021-12-13 01:32:17,021 iteration 5743 : loss : 0.017793, loss_ce: 0.005660
2021-12-13 01:32:18,454 iteration 5744 : loss : 0.012698, loss_ce: 0.005384
2021-12-13 01:32:19,932 iteration 5745 : loss : 0.010749, loss_ce: 0.003796
2021-12-13 01:32:21,358 iteration 5746 : loss : 0.015038, loss_ce: 0.006864
 84%|████████████████████████▌    | 338/400 [2:32:39<27:08, 26.27s/it]2021-12-13 01:32:22,884 iteration 5747 : loss : 0.019783, loss_ce: 0.007148
2021-12-13 01:32:24,319 iteration 5748 : loss : 0.013688, loss_ce: 0.005563
2021-12-13 01:32:25,833 iteration 5749 : loss : 0.019881, loss_ce: 0.008491
2021-12-13 01:32:27,304 iteration 5750 : loss : 0.017888, loss_ce: 0.004105
2021-12-13 01:32:28,820 iteration 5751 : loss : 0.016573, loss_ce: 0.007273
2021-12-13 01:32:30,289 iteration 5752 : loss : 0.014790, loss_ce: 0.005021
2021-12-13 01:32:31,801 iteration 5753 : loss : 0.018346, loss_ce: 0.009510
2021-12-13 01:32:33,246 iteration 5754 : loss : 0.015246, loss_ce: 0.005268
2021-12-13 01:32:34,685 iteration 5755 : loss : 0.016946, loss_ce: 0.005037
2021-12-13 01:32:36,114 iteration 5756 : loss : 0.016847, loss_ce: 0.008556
2021-12-13 01:32:37,589 iteration 5757 : loss : 0.016765, loss_ce: 0.005250
2021-12-13 01:32:38,997 iteration 5758 : loss : 0.007875, loss_ce: 0.002358
2021-12-13 01:32:40,527 iteration 5759 : loss : 0.017235, loss_ce: 0.004470
2021-12-13 01:32:41,974 iteration 5760 : loss : 0.013698, loss_ce: 0.004814
2021-12-13 01:32:43,455 iteration 5761 : loss : 0.012687, loss_ce: 0.004247
2021-12-13 01:32:44,969 iteration 5762 : loss : 0.016911, loss_ce: 0.007150
2021-12-13 01:32:46,455 iteration 5763 : loss : 0.016418, loss_ce: 0.006309
 85%|████████████████████████▌    | 339/400 [2:33:04<26:20, 25.92s/it]2021-12-13 01:32:48,029 iteration 5764 : loss : 0.017012, loss_ce: 0.008216
2021-12-13 01:32:49,503 iteration 5765 : loss : 0.025256, loss_ce: 0.010866
2021-12-13 01:32:50,925 iteration 5766 : loss : 0.018436, loss_ce: 0.006144
2021-12-13 01:32:52,426 iteration 5767 : loss : 0.014714, loss_ce: 0.006317
2021-12-13 01:32:53,932 iteration 5768 : loss : 0.020387, loss_ce: 0.007455
2021-12-13 01:32:55,415 iteration 5769 : loss : 0.015223, loss_ce: 0.003936
2021-12-13 01:32:56,907 iteration 5770 : loss : 0.017346, loss_ce: 0.007710
2021-12-13 01:32:58,311 iteration 5771 : loss : 0.010543, loss_ce: 0.004511
2021-12-13 01:32:59,793 iteration 5772 : loss : 0.012754, loss_ce: 0.004609
2021-12-13 01:33:01,188 iteration 5773 : loss : 0.011868, loss_ce: 0.004124
2021-12-13 01:33:02,623 iteration 5774 : loss : 0.010301, loss_ce: 0.003904
2021-12-13 01:33:04,106 iteration 5775 : loss : 0.025260, loss_ce: 0.009230
2021-12-13 01:33:05,474 iteration 5776 : loss : 0.011793, loss_ce: 0.004726
2021-12-13 01:33:06,912 iteration 5777 : loss : 0.012776, loss_ce: 0.004385
2021-12-13 01:33:08,403 iteration 5778 : loss : 0.011555, loss_ce: 0.003786
2021-12-13 01:33:09,866 iteration 5779 : loss : 0.010520, loss_ce: 0.004487
2021-12-13 01:33:09,866 Training Data Eval:
2021-12-13 01:33:17,355   Average segmentation loss on training set: 0.0078
2021-12-13 01:33:17,355 Validation Data Eval:
2021-12-13 01:33:19,955   Average segmentation loss on validation set: 0.0840
2021-12-13 01:33:21,414 iteration 5780 : loss : 0.019382, loss_ce: 0.007322
 85%|████████████████████████▋    | 340/400 [2:33:39<28:37, 28.63s/it]2021-12-13 01:33:22,923 iteration 5781 : loss : 0.016122, loss_ce: 0.005481
2021-12-13 01:33:24,308 iteration 5782 : loss : 0.009062, loss_ce: 0.003305
2021-12-13 01:33:25,791 iteration 5783 : loss : 0.014726, loss_ce: 0.005157
2021-12-13 01:33:27,300 iteration 5784 : loss : 0.013136, loss_ce: 0.004418
2021-12-13 01:33:28,785 iteration 5785 : loss : 0.013285, loss_ce: 0.006394
2021-12-13 01:33:30,295 iteration 5786 : loss : 0.012870, loss_ce: 0.005521
2021-12-13 01:33:31,756 iteration 5787 : loss : 0.017312, loss_ce: 0.005303
2021-12-13 01:33:33,226 iteration 5788 : loss : 0.016195, loss_ce: 0.006752
2021-12-13 01:33:34,678 iteration 5789 : loss : 0.013103, loss_ce: 0.004078
2021-12-13 01:33:36,158 iteration 5790 : loss : 0.017956, loss_ce: 0.008071
2021-12-13 01:33:37,655 iteration 5791 : loss : 0.012371, loss_ce: 0.004694
2021-12-13 01:33:39,185 iteration 5792 : loss : 0.014124, loss_ce: 0.003858
2021-12-13 01:33:40,610 iteration 5793 : loss : 0.012798, loss_ce: 0.004554
2021-12-13 01:33:42,040 iteration 5794 : loss : 0.014148, loss_ce: 0.004450
2021-12-13 01:33:43,482 iteration 5795 : loss : 0.013744, loss_ce: 0.006408
2021-12-13 01:33:44,932 iteration 5796 : loss : 0.015116, loss_ce: 0.005905
2021-12-13 01:33:46,376 iteration 5797 : loss : 0.016773, loss_ce: 0.005078
 85%|████████████████████████▋    | 341/400 [2:34:04<27:04, 27.53s/it]2021-12-13 01:33:47,836 iteration 5798 : loss : 0.012038, loss_ce: 0.003690
2021-12-13 01:33:49,246 iteration 5799 : loss : 0.013138, loss_ce: 0.005113
2021-12-13 01:33:50,613 iteration 5800 : loss : 0.008736, loss_ce: 0.003632
2021-12-13 01:33:52,085 iteration 5801 : loss : 0.012030, loss_ce: 0.005375
2021-12-13 01:33:53,505 iteration 5802 : loss : 0.013043, loss_ce: 0.005355
2021-12-13 01:33:55,005 iteration 5803 : loss : 0.014756, loss_ce: 0.004910
2021-12-13 01:33:56,415 iteration 5804 : loss : 0.017661, loss_ce: 0.005074
2021-12-13 01:33:57,829 iteration 5805 : loss : 0.011501, loss_ce: 0.003875
2021-12-13 01:33:59,236 iteration 5806 : loss : 0.010837, loss_ce: 0.004659
2021-12-13 01:34:00,714 iteration 5807 : loss : 0.014544, loss_ce: 0.005281
2021-12-13 01:34:02,221 iteration 5808 : loss : 0.014229, loss_ce: 0.004527
2021-12-13 01:34:03,719 iteration 5809 : loss : 0.019105, loss_ce: 0.007739
2021-12-13 01:34:05,253 iteration 5810 : loss : 0.018659, loss_ce: 0.005209
2021-12-13 01:34:06,740 iteration 5811 : loss : 0.014042, loss_ce: 0.005371
2021-12-13 01:34:08,166 iteration 5812 : loss : 0.015248, loss_ce: 0.006358
2021-12-13 01:34:09,601 iteration 5813 : loss : 0.012949, loss_ce: 0.004056
2021-12-13 01:34:11,058 iteration 5814 : loss : 0.019284, loss_ce: 0.007035
 86%|████████████████████████▊    | 342/400 [2:34:29<25:47, 26.68s/it]2021-12-13 01:34:12,620 iteration 5815 : loss : 0.020829, loss_ce: 0.008009
2021-12-13 01:34:14,052 iteration 5816 : loss : 0.011971, loss_ce: 0.004356
2021-12-13 01:34:15,573 iteration 5817 : loss : 0.016336, loss_ce: 0.008047
2021-12-13 01:34:17,069 iteration 5818 : loss : 0.017003, loss_ce: 0.006184
2021-12-13 01:34:18,512 iteration 5819 : loss : 0.011069, loss_ce: 0.002872
2021-12-13 01:34:19,937 iteration 5820 : loss : 0.015866, loss_ce: 0.005409
2021-12-13 01:34:21,404 iteration 5821 : loss : 0.014769, loss_ce: 0.005334
2021-12-13 01:34:22,929 iteration 5822 : loss : 0.015532, loss_ce: 0.004667
2021-12-13 01:34:24,326 iteration 5823 : loss : 0.011300, loss_ce: 0.005596
2021-12-13 01:34:25,866 iteration 5824 : loss : 0.023235, loss_ce: 0.004775
2021-12-13 01:34:27,329 iteration 5825 : loss : 0.010819, loss_ce: 0.003799
2021-12-13 01:34:28,782 iteration 5826 : loss : 0.013982, loss_ce: 0.006632
2021-12-13 01:34:30,183 iteration 5827 : loss : 0.018438, loss_ce: 0.006802
2021-12-13 01:34:31,724 iteration 5828 : loss : 0.024245, loss_ce: 0.005472
2021-12-13 01:34:33,197 iteration 5829 : loss : 0.012123, loss_ce: 0.004536
2021-12-13 01:34:34,615 iteration 5830 : loss : 0.012083, loss_ce: 0.004011
2021-12-13 01:34:36,132 iteration 5831 : loss : 0.018154, loss_ce: 0.006469
 86%|████████████████████████▊    | 343/400 [2:34:54<24:53, 26.20s/it]2021-12-13 01:34:37,662 iteration 5832 : loss : 0.015815, loss_ce: 0.007491
2021-12-13 01:34:39,183 iteration 5833 : loss : 0.013309, loss_ce: 0.004422
2021-12-13 01:34:40,634 iteration 5834 : loss : 0.017918, loss_ce: 0.007911
2021-12-13 01:34:42,076 iteration 5835 : loss : 0.016048, loss_ce: 0.006769
2021-12-13 01:34:43,522 iteration 5836 : loss : 0.016580, loss_ce: 0.004920
2021-12-13 01:34:45,044 iteration 5837 : loss : 0.014136, loss_ce: 0.005908
2021-12-13 01:34:46,510 iteration 5838 : loss : 0.018575, loss_ce: 0.005237
2021-12-13 01:34:47,971 iteration 5839 : loss : 0.017583, loss_ce: 0.005814
2021-12-13 01:34:49,424 iteration 5840 : loss : 0.009704, loss_ce: 0.003220
2021-12-13 01:34:50,934 iteration 5841 : loss : 0.019535, loss_ce: 0.007453
2021-12-13 01:34:52,336 iteration 5842 : loss : 0.015607, loss_ce: 0.004347
2021-12-13 01:34:53,752 iteration 5843 : loss : 0.011198, loss_ce: 0.004128
2021-12-13 01:34:55,210 iteration 5844 : loss : 0.020982, loss_ce: 0.007322
2021-12-13 01:34:56,616 iteration 5845 : loss : 0.010510, loss_ce: 0.003832
2021-12-13 01:34:58,031 iteration 5846 : loss : 0.017636, loss_ce: 0.006921
2021-12-13 01:34:59,465 iteration 5847 : loss : 0.014566, loss_ce: 0.004968
2021-12-13 01:35:00,907 iteration 5848 : loss : 0.013402, loss_ce: 0.004885
 86%|████████████████████████▉    | 344/400 [2:35:19<24:03, 25.77s/it]2021-12-13 01:35:02,407 iteration 5849 : loss : 0.013528, loss_ce: 0.004170
2021-12-13 01:35:03,923 iteration 5850 : loss : 0.019508, loss_ce: 0.009602
2021-12-13 01:35:05,417 iteration 5851 : loss : 0.011936, loss_ce: 0.002862
2021-12-13 01:35:06,884 iteration 5852 : loss : 0.013073, loss_ce: 0.006105
2021-12-13 01:35:08,292 iteration 5853 : loss : 0.013581, loss_ce: 0.004690
2021-12-13 01:35:09,792 iteration 5854 : loss : 0.016984, loss_ce: 0.005594
2021-12-13 01:35:11,253 iteration 5855 : loss : 0.014389, loss_ce: 0.006683
2021-12-13 01:35:12,726 iteration 5856 : loss : 0.014589, loss_ce: 0.005776
2021-12-13 01:35:14,210 iteration 5857 : loss : 0.011278, loss_ce: 0.004196
2021-12-13 01:35:15,697 iteration 5858 : loss : 0.014071, loss_ce: 0.004488
2021-12-13 01:35:17,248 iteration 5859 : loss : 0.014838, loss_ce: 0.005301
2021-12-13 01:35:18,730 iteration 5860 : loss : 0.013540, loss_ce: 0.004578
2021-12-13 01:35:20,170 iteration 5861 : loss : 0.016357, loss_ce: 0.006562
2021-12-13 01:35:21,645 iteration 5862 : loss : 0.017753, loss_ce: 0.007360
2021-12-13 01:35:23,117 iteration 5863 : loss : 0.022148, loss_ce: 0.006427
2021-12-13 01:35:24,675 iteration 5864 : loss : 0.015860, loss_ce: 0.008704
2021-12-13 01:35:24,675 Training Data Eval:
2021-12-13 01:35:32,177   Average segmentation loss on training set: 0.0074
2021-12-13 01:35:32,177 Validation Data Eval:
2021-12-13 01:35:34,777   Average segmentation loss on validation set: 0.0935
2021-12-13 01:35:36,342 iteration 5865 : loss : 0.023189, loss_ce: 0.006892
 86%|█████████████████████████    | 345/400 [2:35:54<26:16, 28.67s/it]2021-12-13 01:35:37,792 iteration 5866 : loss : 0.012634, loss_ce: 0.002943
2021-12-13 01:35:39,231 iteration 5867 : loss : 0.010700, loss_ce: 0.004366
2021-12-13 01:35:40,711 iteration 5868 : loss : 0.013836, loss_ce: 0.005576
2021-12-13 01:35:42,148 iteration 5869 : loss : 0.012824, loss_ce: 0.003733
2021-12-13 01:35:43,698 iteration 5870 : loss : 0.024360, loss_ce: 0.009700
2021-12-13 01:35:45,137 iteration 5871 : loss : 0.011352, loss_ce: 0.004106
2021-12-13 01:35:46,568 iteration 5872 : loss : 0.014711, loss_ce: 0.004835
2021-12-13 01:35:48,047 iteration 5873 : loss : 0.015472, loss_ce: 0.008791
2021-12-13 01:35:49,526 iteration 5874 : loss : 0.016253, loss_ce: 0.005961
2021-12-13 01:35:51,013 iteration 5875 : loss : 0.010544, loss_ce: 0.004773
2021-12-13 01:35:52,559 iteration 5876 : loss : 0.014439, loss_ce: 0.005740
2021-12-13 01:35:54,068 iteration 5877 : loss : 0.013942, loss_ce: 0.005492
2021-12-13 01:35:55,482 iteration 5878 : loss : 0.015046, loss_ce: 0.004537
2021-12-13 01:35:56,950 iteration 5879 : loss : 0.017733, loss_ce: 0.006104
2021-12-13 01:35:58,448 iteration 5880 : loss : 0.017581, loss_ce: 0.004682
2021-12-13 01:35:59,875 iteration 5881 : loss : 0.010542, loss_ce: 0.004280
2021-12-13 01:36:01,283 iteration 5882 : loss : 0.010827, loss_ce: 0.003736
 86%|█████████████████████████    | 346/400 [2:36:19<24:47, 27.55s/it]2021-12-13 01:36:02,749 iteration 5883 : loss : 0.017645, loss_ce: 0.006099
2021-12-13 01:36:04,123 iteration 5884 : loss : 0.009306, loss_ce: 0.003377
2021-12-13 01:36:05,643 iteration 5885 : loss : 0.013045, loss_ce: 0.003549
2021-12-13 01:36:07,087 iteration 5886 : loss : 0.016843, loss_ce: 0.004884
2021-12-13 01:36:08,595 iteration 5887 : loss : 0.013470, loss_ce: 0.004900
2021-12-13 01:36:10,070 iteration 5888 : loss : 0.009538, loss_ce: 0.003892
2021-12-13 01:36:11,594 iteration 5889 : loss : 0.013262, loss_ce: 0.004724
2021-12-13 01:36:13,026 iteration 5890 : loss : 0.014496, loss_ce: 0.006797
2021-12-13 01:36:14,483 iteration 5891 : loss : 0.015126, loss_ce: 0.004040
2021-12-13 01:36:15,983 iteration 5892 : loss : 0.017877, loss_ce: 0.004309
2021-12-13 01:36:17,434 iteration 5893 : loss : 0.011795, loss_ce: 0.005382
2021-12-13 01:36:18,836 iteration 5894 : loss : 0.016615, loss_ce: 0.007074
2021-12-13 01:36:20,246 iteration 5895 : loss : 0.010858, loss_ce: 0.004107
2021-12-13 01:36:21,666 iteration 5896 : loss : 0.015046, loss_ce: 0.006109
2021-12-13 01:36:23,115 iteration 5897 : loss : 0.019953, loss_ce: 0.007864
2021-12-13 01:36:24,532 iteration 5898 : loss : 0.017640, loss_ce: 0.005752
2021-12-13 01:36:26,027 iteration 5899 : loss : 0.017316, loss_ce: 0.007455
 87%|█████████████████████████▏   | 347/400 [2:36:44<23:35, 26.71s/it]2021-12-13 01:36:27,461 iteration 5900 : loss : 0.013576, loss_ce: 0.004364
2021-12-13 01:36:29,018 iteration 5901 : loss : 0.013723, loss_ce: 0.005774
2021-12-13 01:36:30,548 iteration 5902 : loss : 0.015739, loss_ce: 0.007293
2021-12-13 01:36:31,984 iteration 5903 : loss : 0.016896, loss_ce: 0.005485
2021-12-13 01:36:33,453 iteration 5904 : loss : 0.012775, loss_ce: 0.005632
2021-12-13 01:36:34,860 iteration 5905 : loss : 0.012274, loss_ce: 0.004316
2021-12-13 01:36:36,315 iteration 5906 : loss : 0.013215, loss_ce: 0.005187
2021-12-13 01:36:37,789 iteration 5907 : loss : 0.015648, loss_ce: 0.004522
2021-12-13 01:36:39,237 iteration 5908 : loss : 0.013091, loss_ce: 0.004775
2021-12-13 01:36:40,643 iteration 5909 : loss : 0.009962, loss_ce: 0.004088
2021-12-13 01:36:42,075 iteration 5910 : loss : 0.012174, loss_ce: 0.005649
2021-12-13 01:36:43,526 iteration 5911 : loss : 0.011391, loss_ce: 0.004701
2021-12-13 01:36:45,091 iteration 5912 : loss : 0.038853, loss_ce: 0.006518
2021-12-13 01:36:46,479 iteration 5913 : loss : 0.012737, loss_ce: 0.004234
2021-12-13 01:36:48,006 iteration 5914 : loss : 0.011960, loss_ce: 0.004273
2021-12-13 01:36:49,505 iteration 5915 : loss : 0.017454, loss_ce: 0.007362
2021-12-13 01:36:50,959 iteration 5916 : loss : 0.017757, loss_ce: 0.006860
 87%|█████████████████████████▏   | 348/400 [2:37:09<22:41, 26.17s/it]2021-12-13 01:36:52,439 iteration 5917 : loss : 0.018712, loss_ce: 0.004270
2021-12-13 01:36:53,975 iteration 5918 : loss : 0.018131, loss_ce: 0.006944
2021-12-13 01:36:55,394 iteration 5919 : loss : 0.014238, loss_ce: 0.008007
2021-12-13 01:36:56,955 iteration 5920 : loss : 0.019213, loss_ce: 0.008481
2021-12-13 01:36:58,409 iteration 5921 : loss : 0.015252, loss_ce: 0.004130
2021-12-13 01:36:59,901 iteration 5922 : loss : 0.016814, loss_ce: 0.008552
2021-12-13 01:37:01,332 iteration 5923 : loss : 0.013834, loss_ce: 0.003322
2021-12-13 01:37:02,746 iteration 5924 : loss : 0.011952, loss_ce: 0.004607
2021-12-13 01:37:04,190 iteration 5925 : loss : 0.014210, loss_ce: 0.004133
2021-12-13 01:37:05,633 iteration 5926 : loss : 0.012559, loss_ce: 0.004242
2021-12-13 01:37:07,152 iteration 5927 : loss : 0.018822, loss_ce: 0.006652
2021-12-13 01:37:08,539 iteration 5928 : loss : 0.010690, loss_ce: 0.004824
2021-12-13 01:37:09,963 iteration 5929 : loss : 0.014643, loss_ce: 0.004058
2021-12-13 01:37:11,427 iteration 5930 : loss : 0.014358, loss_ce: 0.004928
2021-12-13 01:37:12,888 iteration 5931 : loss : 0.013323, loss_ce: 0.005938
2021-12-13 01:37:14,338 iteration 5932 : loss : 0.014236, loss_ce: 0.005222
2021-12-13 01:37:15,767 iteration 5933 : loss : 0.010401, loss_ce: 0.003947
 87%|█████████████████████████▎   | 349/400 [2:37:33<21:54, 25.77s/it]2021-12-13 01:37:17,216 iteration 5934 : loss : 0.011773, loss_ce: 0.003933
2021-12-13 01:37:18,613 iteration 5935 : loss : 0.016201, loss_ce: 0.007308
2021-12-13 01:37:19,997 iteration 5936 : loss : 0.010784, loss_ce: 0.004268
2021-12-13 01:37:21,484 iteration 5937 : loss : 0.019976, loss_ce: 0.009853
2021-12-13 01:37:22,961 iteration 5938 : loss : 0.012984, loss_ce: 0.005656
2021-12-13 01:37:24,467 iteration 5939 : loss : 0.031795, loss_ce: 0.011559
2021-12-13 01:37:25,892 iteration 5940 : loss : 0.010226, loss_ce: 0.003833
2021-12-13 01:37:27,391 iteration 5941 : loss : 0.011974, loss_ce: 0.004383
2021-12-13 01:37:28,859 iteration 5942 : loss : 0.012376, loss_ce: 0.004764
2021-12-13 01:37:30,362 iteration 5943 : loss : 0.012764, loss_ce: 0.005117
2021-12-13 01:37:31,744 iteration 5944 : loss : 0.012209, loss_ce: 0.004993
2021-12-13 01:37:33,310 iteration 5945 : loss : 0.015927, loss_ce: 0.005116
2021-12-13 01:37:34,768 iteration 5946 : loss : 0.010408, loss_ce: 0.004298
2021-12-13 01:37:36,315 iteration 5947 : loss : 0.027796, loss_ce: 0.008579
2021-12-13 01:37:37,819 iteration 5948 : loss : 0.015513, loss_ce: 0.004910
2021-12-13 01:37:39,259 iteration 5949 : loss : 0.014018, loss_ce: 0.003406
2021-12-13 01:37:39,259 Training Data Eval:
2021-12-13 01:37:46,750   Average segmentation loss on training set: 0.0083
2021-12-13 01:37:46,750 Validation Data Eval:
2021-12-13 01:37:49,355   Average segmentation loss on validation set: 0.1133
2021-12-13 01:37:50,776 iteration 5950 : loss : 0.009984, loss_ce: 0.003193
 88%|█████████████████████████▍   | 350/400 [2:38:08<23:47, 28.54s/it]2021-12-13 01:37:52,223 iteration 5951 : loss : 0.016104, loss_ce: 0.004882
2021-12-13 01:37:53,709 iteration 5952 : loss : 0.016998, loss_ce: 0.007523
2021-12-13 01:37:55,260 iteration 5953 : loss : 0.016424, loss_ce: 0.007807
2021-12-13 01:37:56,673 iteration 5954 : loss : 0.017711, loss_ce: 0.005142
2021-12-13 01:37:58,230 iteration 5955 : loss : 0.019500, loss_ce: 0.007515
2021-12-13 01:37:59,673 iteration 5956 : loss : 0.019039, loss_ce: 0.004544
2021-12-13 01:38:01,173 iteration 5957 : loss : 0.017896, loss_ce: 0.008060
2021-12-13 01:38:02,678 iteration 5958 : loss : 0.023366, loss_ce: 0.009258
2021-12-13 01:38:04,169 iteration 5959 : loss : 0.017835, loss_ce: 0.004413
2021-12-13 01:38:05,600 iteration 5960 : loss : 0.013151, loss_ce: 0.003764
2021-12-13 01:38:07,094 iteration 5961 : loss : 0.022451, loss_ce: 0.010162
2021-12-13 01:38:08,586 iteration 5962 : loss : 0.014408, loss_ce: 0.005426
2021-12-13 01:38:10,017 iteration 5963 : loss : 0.019543, loss_ce: 0.006932
2021-12-13 01:38:11,527 iteration 5964 : loss : 0.017847, loss_ce: 0.007457
2021-12-13 01:38:13,002 iteration 5965 : loss : 0.011823, loss_ce: 0.006049
2021-12-13 01:38:14,437 iteration 5966 : loss : 0.009875, loss_ce: 0.003503
2021-12-13 01:38:15,972 iteration 5967 : loss : 0.014017, loss_ce: 0.005234
 88%|█████████████████████████▍   | 351/400 [2:38:34<22:29, 27.53s/it]2021-12-13 01:38:17,454 iteration 5968 : loss : 0.012555, loss_ce: 0.004727
2021-12-13 01:38:18,903 iteration 5969 : loss : 0.013639, loss_ce: 0.006283
2021-12-13 01:38:20,402 iteration 5970 : loss : 0.013183, loss_ce: 0.005391
2021-12-13 01:38:21,823 iteration 5971 : loss : 0.009207, loss_ce: 0.004085
2021-12-13 01:38:23,236 iteration 5972 : loss : 0.012063, loss_ce: 0.003203
2021-12-13 01:38:24,659 iteration 5973 : loss : 0.011762, loss_ce: 0.005157
2021-12-13 01:38:26,122 iteration 5974 : loss : 0.019819, loss_ce: 0.005966
2021-12-13 01:38:27,591 iteration 5975 : loss : 0.013943, loss_ce: 0.007702
2021-12-13 01:38:29,080 iteration 5976 : loss : 0.014863, loss_ce: 0.005299
2021-12-13 01:38:30,495 iteration 5977 : loss : 0.010604, loss_ce: 0.003484
2021-12-13 01:38:31,936 iteration 5978 : loss : 0.012655, loss_ce: 0.004458
2021-12-13 01:38:33,394 iteration 5979 : loss : 0.011531, loss_ce: 0.003309
2021-12-13 01:38:34,917 iteration 5980 : loss : 0.018343, loss_ce: 0.003746
2021-12-13 01:38:36,442 iteration 5981 : loss : 0.017024, loss_ce: 0.007422
2021-12-13 01:38:37,923 iteration 5982 : loss : 0.019660, loss_ce: 0.010176
2021-12-13 01:38:39,406 iteration 5983 : loss : 0.014598, loss_ce: 0.003834
2021-12-13 01:38:40,933 iteration 5984 : loss : 0.012534, loss_ce: 0.004003
 88%|█████████████████████████▌   | 352/400 [2:38:59<21:24, 26.76s/it]2021-12-13 01:38:42,450 iteration 5985 : loss : 0.019705, loss_ce: 0.007327
2021-12-13 01:38:43,805 iteration 5986 : loss : 0.009804, loss_ce: 0.004739
2021-12-13 01:38:45,313 iteration 5987 : loss : 0.024470, loss_ce: 0.005321
2021-12-13 01:38:46,713 iteration 5988 : loss : 0.011818, loss_ce: 0.004598
2021-12-13 01:38:48,201 iteration 5989 : loss : 0.010851, loss_ce: 0.003971
2021-12-13 01:38:49,659 iteration 5990 : loss : 0.016800, loss_ce: 0.005631
2021-12-13 01:38:51,182 iteration 5991 : loss : 0.020968, loss_ce: 0.005668
2021-12-13 01:38:52,685 iteration 5992 : loss : 0.021713, loss_ce: 0.005365
2021-12-13 01:38:54,123 iteration 5993 : loss : 0.016388, loss_ce: 0.005906
2021-12-13 01:38:55,513 iteration 5994 : loss : 0.010059, loss_ce: 0.004256
2021-12-13 01:38:57,050 iteration 5995 : loss : 0.015146, loss_ce: 0.004740
2021-12-13 01:38:58,536 iteration 5996 : loss : 0.012258, loss_ce: 0.005848
2021-12-13 01:38:59,942 iteration 5997 : loss : 0.014072, loss_ce: 0.003921
2021-12-13 01:39:01,493 iteration 5998 : loss : 0.017455, loss_ce: 0.006615
2021-12-13 01:39:02,918 iteration 5999 : loss : 0.013235, loss_ce: 0.004234
2021-12-13 01:39:04,485 iteration 6000 : loss : 0.024689, loss_ce: 0.009931
2021-12-13 01:39:05,893 iteration 6001 : loss : 0.009211, loss_ce: 0.003512
 88%|█████████████████████████▌   | 353/400 [2:39:23<20:32, 26.22s/it]2021-12-13 01:39:07,331 iteration 6002 : loss : 0.012772, loss_ce: 0.004753
2021-12-13 01:39:08,808 iteration 6003 : loss : 0.011621, loss_ce: 0.005091
2021-12-13 01:39:10,259 iteration 6004 : loss : 0.010709, loss_ce: 0.003979
2021-12-13 01:39:11,703 iteration 6005 : loss : 0.015304, loss_ce: 0.006880
2021-12-13 01:39:13,208 iteration 6006 : loss : 0.016476, loss_ce: 0.005663
2021-12-13 01:39:14,629 iteration 6007 : loss : 0.012016, loss_ce: 0.004521
2021-12-13 01:39:16,092 iteration 6008 : loss : 0.013160, loss_ce: 0.004630
2021-12-13 01:39:17,599 iteration 6009 : loss : 0.015326, loss_ce: 0.004497
2021-12-13 01:39:19,009 iteration 6010 : loss : 0.015102, loss_ce: 0.003462
2021-12-13 01:39:20,503 iteration 6011 : loss : 0.019964, loss_ce: 0.005781
2021-12-13 01:39:22,024 iteration 6012 : loss : 0.016085, loss_ce: 0.006970
2021-12-13 01:39:23,462 iteration 6013 : loss : 0.014234, loss_ce: 0.004917
2021-12-13 01:39:24,875 iteration 6014 : loss : 0.014988, loss_ce: 0.005666
2021-12-13 01:39:26,257 iteration 6015 : loss : 0.010358, loss_ce: 0.004915
2021-12-13 01:39:27,695 iteration 6016 : loss : 0.011559, loss_ce: 0.003902
2021-12-13 01:39:29,164 iteration 6017 : loss : 0.011575, loss_ce: 0.004329
2021-12-13 01:39:30,551 iteration 6018 : loss : 0.014392, loss_ce: 0.005680
 88%|█████████████████████████▋   | 354/400 [2:39:48<19:44, 25.75s/it]2021-12-13 01:39:32,089 iteration 6019 : loss : 0.015189, loss_ce: 0.005766
2021-12-13 01:39:33,559 iteration 6020 : loss : 0.014526, loss_ce: 0.004562
2021-12-13 01:39:34,961 iteration 6021 : loss : 0.011499, loss_ce: 0.004598
2021-12-13 01:39:36,449 iteration 6022 : loss : 0.015161, loss_ce: 0.006127
2021-12-13 01:39:37,941 iteration 6023 : loss : 0.011149, loss_ce: 0.004965
2021-12-13 01:39:39,416 iteration 6024 : loss : 0.010910, loss_ce: 0.003884
2021-12-13 01:39:40,831 iteration 6025 : loss : 0.013798, loss_ce: 0.003017
2021-12-13 01:39:42,279 iteration 6026 : loss : 0.014676, loss_ce: 0.005555
2021-12-13 01:39:43,774 iteration 6027 : loss : 0.009948, loss_ce: 0.004318
2021-12-13 01:39:45,177 iteration 6028 : loss : 0.011663, loss_ce: 0.004994
2021-12-13 01:39:46,638 iteration 6029 : loss : 0.015348, loss_ce: 0.007061
2021-12-13 01:39:48,209 iteration 6030 : loss : 0.016503, loss_ce: 0.006253
2021-12-13 01:39:49,700 iteration 6031 : loss : 0.021670, loss_ce: 0.006254
2021-12-13 01:39:51,156 iteration 6032 : loss : 0.016942, loss_ce: 0.005018
2021-12-13 01:39:52,601 iteration 6033 : loss : 0.017345, loss_ce: 0.005698
2021-12-13 01:39:54,021 iteration 6034 : loss : 0.009883, loss_ce: 0.003505
2021-12-13 01:39:54,021 Training Data Eval:
2021-12-13 01:40:01,543   Average segmentation loss on training set: 0.0076
2021-12-13 01:40:01,543 Validation Data Eval:
2021-12-13 01:40:04,148   Average segmentation loss on validation set: 0.0908
2021-12-13 01:40:05,572 iteration 6035 : loss : 0.012382, loss_ce: 0.005294
 89%|█████████████████████████▋   | 355/400 [2:40:23<21:24, 28.53s/it]2021-12-13 01:40:07,091 iteration 6036 : loss : 0.011660, loss_ce: 0.005383
2021-12-13 01:40:08,500 iteration 6037 : loss : 0.010295, loss_ce: 0.004413
2021-12-13 01:40:09,928 iteration 6038 : loss : 0.011744, loss_ce: 0.004155
2021-12-13 01:40:11,307 iteration 6039 : loss : 0.010730, loss_ce: 0.003616
2021-12-13 01:40:12,740 iteration 6040 : loss : 0.015040, loss_ce: 0.004435
2021-12-13 01:40:14,246 iteration 6041 : loss : 0.025220, loss_ce: 0.009369
2021-12-13 01:40:15,648 iteration 6042 : loss : 0.011858, loss_ce: 0.002775
2021-12-13 01:40:17,036 iteration 6043 : loss : 0.008730, loss_ce: 0.002082
2021-12-13 01:40:18,531 iteration 6044 : loss : 0.013605, loss_ce: 0.004220
2021-12-13 01:40:19,962 iteration 6045 : loss : 0.010853, loss_ce: 0.004328
2021-12-13 01:40:21,431 iteration 6046 : loss : 0.012017, loss_ce: 0.004630
2021-12-13 01:40:22,865 iteration 6047 : loss : 0.010902, loss_ce: 0.003989
2021-12-13 01:40:24,353 iteration 6048 : loss : 0.014364, loss_ce: 0.006054
2021-12-13 01:40:25,791 iteration 6049 : loss : 0.012623, loss_ce: 0.006203
2021-12-13 01:40:27,243 iteration 6050 : loss : 0.015707, loss_ce: 0.006084
2021-12-13 01:40:28,797 iteration 6051 : loss : 0.014678, loss_ce: 0.004619
2021-12-13 01:40:30,227 iteration 6052 : loss : 0.012780, loss_ce: 0.005428
 89%|█████████████████████████▊   | 356/400 [2:40:48<20:04, 27.37s/it]2021-12-13 01:40:31,680 iteration 6053 : loss : 0.018246, loss_ce: 0.006809
2021-12-13 01:40:33,080 iteration 6054 : loss : 0.011766, loss_ce: 0.005743
2021-12-13 01:40:34,587 iteration 6055 : loss : 0.016094, loss_ce: 0.005774
2021-12-13 01:40:36,021 iteration 6056 : loss : 0.012578, loss_ce: 0.005560
2021-12-13 01:40:37,429 iteration 6057 : loss : 0.010071, loss_ce: 0.002981
2021-12-13 01:40:38,906 iteration 6058 : loss : 0.016680, loss_ce: 0.004923
2021-12-13 01:40:40,406 iteration 6059 : loss : 0.016056, loss_ce: 0.007173
2021-12-13 01:40:41,998 iteration 6060 : loss : 0.030103, loss_ce: 0.010481
2021-12-13 01:40:43,457 iteration 6061 : loss : 0.011867, loss_ce: 0.004955
2021-12-13 01:40:44,990 iteration 6062 : loss : 0.022371, loss_ce: 0.007225
2021-12-13 01:40:46,408 iteration 6063 : loss : 0.022679, loss_ce: 0.005052
2021-12-13 01:40:47,932 iteration 6064 : loss : 0.017749, loss_ce: 0.007452
2021-12-13 01:40:49,334 iteration 6065 : loss : 0.007702, loss_ce: 0.002892
2021-12-13 01:40:50,748 iteration 6066 : loss : 0.008233, loss_ce: 0.002503
2021-12-13 01:40:52,201 iteration 6067 : loss : 0.012017, loss_ce: 0.005480
2021-12-13 01:40:53,617 iteration 6068 : loss : 0.009575, loss_ce: 0.002609
2021-12-13 01:40:55,056 iteration 6069 : loss : 0.014367, loss_ce: 0.005625
 89%|█████████████████████████▉   | 357/400 [2:41:13<19:04, 26.61s/it]2021-12-13 01:40:56,576 iteration 6070 : loss : 0.009327, loss_ce: 0.004729
2021-12-13 01:40:57,985 iteration 6071 : loss : 0.008901, loss_ce: 0.002904
2021-12-13 01:40:59,420 iteration 6072 : loss : 0.011415, loss_ce: 0.005572
2021-12-13 01:41:00,882 iteration 6073 : loss : 0.019210, loss_ce: 0.004988
2021-12-13 01:41:02,365 iteration 6074 : loss : 0.013359, loss_ce: 0.004974
2021-12-13 01:41:03,735 iteration 6075 : loss : 0.009461, loss_ce: 0.004084
2021-12-13 01:41:05,186 iteration 6076 : loss : 0.012398, loss_ce: 0.002525
2021-12-13 01:41:06,675 iteration 6077 : loss : 0.013865, loss_ce: 0.005395
2021-12-13 01:41:08,190 iteration 6078 : loss : 0.016454, loss_ce: 0.005592
2021-12-13 01:41:09,738 iteration 6079 : loss : 0.013379, loss_ce: 0.004958
2021-12-13 01:41:11,187 iteration 6080 : loss : 0.012889, loss_ce: 0.004160
2021-12-13 01:41:12,658 iteration 6081 : loss : 0.019083, loss_ce: 0.007819
2021-12-13 01:41:14,036 iteration 6082 : loss : 0.011137, loss_ce: 0.003592
2021-12-13 01:41:15,458 iteration 6083 : loss : 0.010718, loss_ce: 0.002858
2021-12-13 01:41:16,925 iteration 6084 : loss : 0.015409, loss_ce: 0.003916
2021-12-13 01:41:18,372 iteration 6085 : loss : 0.018918, loss_ce: 0.007067
2021-12-13 01:41:19,793 iteration 6086 : loss : 0.011061, loss_ce: 0.003550
 90%|█████████████████████████▉   | 358/400 [2:41:37<18:13, 26.04s/it]2021-12-13 01:41:21,224 iteration 6087 : loss : 0.015451, loss_ce: 0.004959
2021-12-13 01:41:22,711 iteration 6088 : loss : 0.012825, loss_ce: 0.005010
2021-12-13 01:41:24,151 iteration 6089 : loss : 0.014281, loss_ce: 0.003964
2021-12-13 01:41:25,505 iteration 6090 : loss : 0.009076, loss_ce: 0.003867
2021-12-13 01:41:26,969 iteration 6091 : loss : 0.012632, loss_ce: 0.004242
2021-12-13 01:41:28,429 iteration 6092 : loss : 0.015727, loss_ce: 0.004920
2021-12-13 01:41:29,874 iteration 6093 : loss : 0.013571, loss_ce: 0.005673
2021-12-13 01:41:31,293 iteration 6094 : loss : 0.010393, loss_ce: 0.003713
2021-12-13 01:41:32,706 iteration 6095 : loss : 0.011750, loss_ce: 0.003600
2021-12-13 01:41:34,174 iteration 6096 : loss : 0.013989, loss_ce: 0.004237
2021-12-13 01:41:35,654 iteration 6097 : loss : 0.008709, loss_ce: 0.003121
2021-12-13 01:41:37,205 iteration 6098 : loss : 0.015778, loss_ce: 0.006458
2021-12-13 01:41:38,699 iteration 6099 : loss : 0.012600, loss_ce: 0.005251
2021-12-13 01:41:40,174 iteration 6100 : loss : 0.016058, loss_ce: 0.009285
2021-12-13 01:41:41,654 iteration 6101 : loss : 0.014070, loss_ce: 0.005467
2021-12-13 01:41:43,151 iteration 6102 : loss : 0.015031, loss_ce: 0.007404
2021-12-13 01:41:44,663 iteration 6103 : loss : 0.017799, loss_ce: 0.006799
 90%|██████████████████████████   | 359/400 [2:42:02<17:33, 25.70s/it]2021-12-13 01:41:46,212 iteration 6104 : loss : 0.016739, loss_ce: 0.007362
2021-12-13 01:41:47,713 iteration 6105 : loss : 0.015031, loss_ce: 0.006861
2021-12-13 01:41:49,190 iteration 6106 : loss : 0.017130, loss_ce: 0.007653
2021-12-13 01:41:50,660 iteration 6107 : loss : 0.014900, loss_ce: 0.005920
2021-12-13 01:41:52,085 iteration 6108 : loss : 0.011133, loss_ce: 0.004196
2021-12-13 01:41:53,532 iteration 6109 : loss : 0.012903, loss_ce: 0.002841
2021-12-13 01:41:54,966 iteration 6110 : loss : 0.012225, loss_ce: 0.004886
2021-12-13 01:41:56,417 iteration 6111 : loss : 0.010234, loss_ce: 0.003859
2021-12-13 01:41:57,865 iteration 6112 : loss : 0.014296, loss_ce: 0.003910
2021-12-13 01:41:59,319 iteration 6113 : loss : 0.013119, loss_ce: 0.005502
2021-12-13 01:42:00,820 iteration 6114 : loss : 0.014949, loss_ce: 0.004284
2021-12-13 01:42:02,276 iteration 6115 : loss : 0.012410, loss_ce: 0.004570
2021-12-13 01:42:03,753 iteration 6116 : loss : 0.016714, loss_ce: 0.005068
2021-12-13 01:42:05,179 iteration 6117 : loss : 0.014956, loss_ce: 0.005562
2021-12-13 01:42:06,594 iteration 6118 : loss : 0.011121, loss_ce: 0.003500
2021-12-13 01:42:08,157 iteration 6119 : loss : 0.016159, loss_ce: 0.007847
2021-12-13 01:42:08,157 Training Data Eval:
2021-12-13 01:42:15,650   Average segmentation loss on training set: 0.0068
2021-12-13 01:42:15,651 Validation Data Eval:
2021-12-13 01:42:18,248   Average segmentation loss on validation set: 0.0952
2021-12-13 01:42:19,724 iteration 6120 : loss : 0.016044, loss_ce: 0.004640
 90%|██████████████████████████   | 360/400 [2:42:37<19:00, 28.50s/it]2021-12-13 01:42:21,226 iteration 6121 : loss : 0.018961, loss_ce: 0.006473
2021-12-13 01:42:22,682 iteration 6122 : loss : 0.013468, loss_ce: 0.005816
2021-12-13 01:42:24,131 iteration 6123 : loss : 0.017506, loss_ce: 0.007745
2021-12-13 01:42:25,548 iteration 6124 : loss : 0.010475, loss_ce: 0.003494
2021-12-13 01:42:27,010 iteration 6125 : loss : 0.020985, loss_ce: 0.008078
2021-12-13 01:42:28,424 iteration 6126 : loss : 0.010675, loss_ce: 0.005107
2021-12-13 01:42:29,914 iteration 6127 : loss : 0.011024, loss_ce: 0.003416
2021-12-13 01:42:31,351 iteration 6128 : loss : 0.016656, loss_ce: 0.005157
2021-12-13 01:42:32,894 iteration 6129 : loss : 0.010857, loss_ce: 0.004000
2021-12-13 01:42:34,315 iteration 6130 : loss : 0.014132, loss_ce: 0.003561
2021-12-13 01:42:35,862 iteration 6131 : loss : 0.015165, loss_ce: 0.007675
2021-12-13 01:42:37,303 iteration 6132 : loss : 0.012978, loss_ce: 0.006901
2021-12-13 01:42:38,799 iteration 6133 : loss : 0.015372, loss_ce: 0.004311
2021-12-13 01:42:40,265 iteration 6134 : loss : 0.013274, loss_ce: 0.004613
2021-12-13 01:42:41,820 iteration 6135 : loss : 0.017229, loss_ce: 0.006124
2021-12-13 01:42:43,281 iteration 6136 : loss : 0.013985, loss_ce: 0.003841
2021-12-13 01:42:44,702 iteration 6137 : loss : 0.014500, loss_ce: 0.005745
 90%|██████████████████████████▏  | 361/400 [2:43:02<17:50, 27.45s/it]2021-12-13 01:42:46,173 iteration 6138 : loss : 0.018099, loss_ce: 0.006048
2021-12-13 01:42:47,628 iteration 6139 : loss : 0.012132, loss_ce: 0.004860
2021-12-13 01:42:49,073 iteration 6140 : loss : 0.014200, loss_ce: 0.007025
2021-12-13 01:42:50,457 iteration 6141 : loss : 0.009756, loss_ce: 0.003868
2021-12-13 01:42:51,834 iteration 6142 : loss : 0.008975, loss_ce: 0.003883
2021-12-13 01:42:53,346 iteration 6143 : loss : 0.014055, loss_ce: 0.003224
2021-12-13 01:42:54,784 iteration 6144 : loss : 0.012706, loss_ce: 0.004286
2021-12-13 01:42:56,222 iteration 6145 : loss : 0.013482, loss_ce: 0.006214
2021-12-13 01:42:57,643 iteration 6146 : loss : 0.011521, loss_ce: 0.003443
2021-12-13 01:42:59,085 iteration 6147 : loss : 0.013227, loss_ce: 0.005495
2021-12-13 01:43:00,565 iteration 6148 : loss : 0.015275, loss_ce: 0.005663
2021-12-13 01:43:02,029 iteration 6149 : loss : 0.016035, loss_ce: 0.006202
2021-12-13 01:43:03,553 iteration 6150 : loss : 0.020810, loss_ce: 0.007677
2021-12-13 01:43:05,077 iteration 6151 : loss : 0.017993, loss_ce: 0.003971
2021-12-13 01:43:06,487 iteration 6152 : loss : 0.013163, loss_ce: 0.005593
2021-12-13 01:43:07,950 iteration 6153 : loss : 0.011252, loss_ce: 0.003360
2021-12-13 01:43:09,423 iteration 6154 : loss : 0.016121, loss_ce: 0.007044
 90%|██████████████████████████▏  | 362/400 [2:43:27<16:51, 26.63s/it]2021-12-13 01:43:10,964 iteration 6155 : loss : 0.016269, loss_ce: 0.005461
2021-12-13 01:43:12,442 iteration 6156 : loss : 0.016678, loss_ce: 0.006658
2021-12-13 01:43:13,907 iteration 6157 : loss : 0.012874, loss_ce: 0.004716
2021-12-13 01:43:15,442 iteration 6158 : loss : 0.014318, loss_ce: 0.003907
2021-12-13 01:43:16,873 iteration 6159 : loss : 0.010429, loss_ce: 0.003464
2021-12-13 01:43:18,326 iteration 6160 : loss : 0.011166, loss_ce: 0.003919
2021-12-13 01:43:19,839 iteration 6161 : loss : 0.016772, loss_ce: 0.004676
2021-12-13 01:43:21,373 iteration 6162 : loss : 0.017680, loss_ce: 0.005182
2021-12-13 01:43:22,851 iteration 6163 : loss : 0.015819, loss_ce: 0.006581
2021-12-13 01:43:24,253 iteration 6164 : loss : 0.009829, loss_ce: 0.002662
2021-12-13 01:43:25,785 iteration 6165 : loss : 0.017372, loss_ce: 0.005738
2021-12-13 01:43:27,212 iteration 6166 : loss : 0.011617, loss_ce: 0.004260
2021-12-13 01:43:28,732 iteration 6167 : loss : 0.015837, loss_ce: 0.008068
2021-12-13 01:43:30,211 iteration 6168 : loss : 0.015878, loss_ce: 0.005594
2021-12-13 01:43:31,664 iteration 6169 : loss : 0.017272, loss_ce: 0.004352
2021-12-13 01:43:33,074 iteration 6170 : loss : 0.011262, loss_ce: 0.005252
2021-12-13 01:43:34,507 iteration 6171 : loss : 0.015591, loss_ce: 0.007963
 91%|██████████████████████████▎  | 363/400 [2:43:52<16:08, 26.17s/it]2021-12-13 01:43:35,988 iteration 6172 : loss : 0.023240, loss_ce: 0.007854
2021-12-13 01:43:37,537 iteration 6173 : loss : 0.025082, loss_ce: 0.005461
2021-12-13 01:43:39,028 iteration 6174 : loss : 0.014031, loss_ce: 0.006303
2021-12-13 01:43:40,584 iteration 6175 : loss : 0.015702, loss_ce: 0.005106
2021-12-13 01:43:42,048 iteration 6176 : loss : 0.011872, loss_ce: 0.004529
2021-12-13 01:43:43,503 iteration 6177 : loss : 0.010301, loss_ce: 0.004782
2021-12-13 01:43:44,969 iteration 6178 : loss : 0.015817, loss_ce: 0.005547
2021-12-13 01:43:46,384 iteration 6179 : loss : 0.017085, loss_ce: 0.005350
2021-12-13 01:43:47,881 iteration 6180 : loss : 0.015355, loss_ce: 0.006954
2021-12-13 01:43:49,312 iteration 6181 : loss : 0.010502, loss_ce: 0.003179
2021-12-13 01:43:50,747 iteration 6182 : loss : 0.011583, loss_ce: 0.003233
2021-12-13 01:43:52,248 iteration 6183 : loss : 0.013658, loss_ce: 0.005033
2021-12-13 01:43:53,726 iteration 6184 : loss : 0.012599, loss_ce: 0.005385
2021-12-13 01:43:55,241 iteration 6185 : loss : 0.025750, loss_ce: 0.005719
2021-12-13 01:43:56,680 iteration 6186 : loss : 0.009243, loss_ce: 0.003354
2021-12-13 01:43:58,140 iteration 6187 : loss : 0.014463, loss_ce: 0.007560
2021-12-13 01:43:59,664 iteration 6188 : loss : 0.019403, loss_ce: 0.010162
 91%|██████████████████████████▍  | 364/400 [2:44:17<15:31, 25.86s/it]2021-12-13 01:44:01,219 iteration 6189 : loss : 0.015461, loss_ce: 0.003432
2021-12-13 01:44:02,720 iteration 6190 : loss : 0.013950, loss_ce: 0.004189
2021-12-13 01:44:04,147 iteration 6191 : loss : 0.013086, loss_ce: 0.006820
2021-12-13 01:44:05,548 iteration 6192 : loss : 0.009896, loss_ce: 0.004119
2021-12-13 01:44:07,006 iteration 6193 : loss : 0.014192, loss_ce: 0.004410
2021-12-13 01:44:08,407 iteration 6194 : loss : 0.012697, loss_ce: 0.004668
2021-12-13 01:44:09,942 iteration 6195 : loss : 0.014181, loss_ce: 0.004645
2021-12-13 01:44:11,387 iteration 6196 : loss : 0.017391, loss_ce: 0.006085
2021-12-13 01:44:12,797 iteration 6197 : loss : 0.017236, loss_ce: 0.008659
2021-12-13 01:44:14,368 iteration 6198 : loss : 0.028186, loss_ce: 0.007542
2021-12-13 01:44:15,813 iteration 6199 : loss : 0.011654, loss_ce: 0.004913
2021-12-13 01:44:17,249 iteration 6200 : loss : 0.010639, loss_ce: 0.004650
2021-12-13 01:44:18,720 iteration 6201 : loss : 0.013169, loss_ce: 0.005000
2021-12-13 01:44:20,126 iteration 6202 : loss : 0.014300, loss_ce: 0.004833
2021-12-13 01:44:21,726 iteration 6203 : loss : 0.021098, loss_ce: 0.009758
2021-12-13 01:44:23,123 iteration 6204 : loss : 0.011369, loss_ce: 0.005283
2021-12-13 01:44:23,138 Training Data Eval:
2021-12-13 01:44:30,637   Average segmentation loss on training set: 0.0070
2021-12-13 01:44:30,637 Validation Data Eval:
2021-12-13 01:44:33,238   Average segmentation loss on validation set: 0.0779
2021-12-13 01:44:34,765 iteration 6205 : loss : 0.016769, loss_ce: 0.005517
 91%|██████████████████████████▍  | 365/400 [2:44:52<16:42, 28.64s/it]2021-12-13 01:44:36,284 iteration 6206 : loss : 0.016884, loss_ce: 0.006679
2021-12-13 01:44:37,757 iteration 6207 : loss : 0.014124, loss_ce: 0.005975
2021-12-13 01:44:39,246 iteration 6208 : loss : 0.018663, loss_ce: 0.005894
2021-12-13 01:44:40,718 iteration 6209 : loss : 0.017272, loss_ce: 0.006766
2021-12-13 01:44:42,204 iteration 6210 : loss : 0.008946, loss_ce: 0.003471
2021-12-13 01:44:43,645 iteration 6211 : loss : 0.015803, loss_ce: 0.008610
2021-12-13 01:44:45,069 iteration 6212 : loss : 0.010340, loss_ce: 0.004019
2021-12-13 01:44:46,446 iteration 6213 : loss : 0.010665, loss_ce: 0.003710
2021-12-13 01:44:47,986 iteration 6214 : loss : 0.025138, loss_ce: 0.009035
2021-12-13 01:44:49,444 iteration 6215 : loss : 0.011432, loss_ce: 0.003583
2021-12-13 01:44:50,914 iteration 6216 : loss : 0.015753, loss_ce: 0.005297
2021-12-13 01:44:52,388 iteration 6217 : loss : 0.014600, loss_ce: 0.005655
2021-12-13 01:44:53,780 iteration 6218 : loss : 0.010387, loss_ce: 0.003846
2021-12-13 01:44:55,255 iteration 6219 : loss : 0.020056, loss_ce: 0.006395
2021-12-13 01:44:56,639 iteration 6220 : loss : 0.010267, loss_ce: 0.002767
2021-12-13 01:44:58,167 iteration 6221 : loss : 0.014621, loss_ce: 0.004733
2021-12-13 01:44:59,611 iteration 6222 : loss : 0.011255, loss_ce: 0.005208
 92%|██████████████████████████▌  | 366/400 [2:45:17<15:34, 27.50s/it]2021-12-13 01:45:01,123 iteration 6223 : loss : 0.016142, loss_ce: 0.007116
2021-12-13 01:45:02,627 iteration 6224 : loss : 0.015279, loss_ce: 0.006242
2021-12-13 01:45:04,107 iteration 6225 : loss : 0.011713, loss_ce: 0.005763
2021-12-13 01:45:05,553 iteration 6226 : loss : 0.011059, loss_ce: 0.004040
2021-12-13 01:45:07,083 iteration 6227 : loss : 0.010734, loss_ce: 0.003537
2021-12-13 01:45:08,522 iteration 6228 : loss : 0.015902, loss_ce: 0.005836
2021-12-13 01:45:10,007 iteration 6229 : loss : 0.011756, loss_ce: 0.003499
2021-12-13 01:45:11,519 iteration 6230 : loss : 0.023127, loss_ce: 0.004084
2021-12-13 01:45:12,933 iteration 6231 : loss : 0.013374, loss_ce: 0.005615
2021-12-13 01:45:14,372 iteration 6232 : loss : 0.012990, loss_ce: 0.004446
2021-12-13 01:45:15,898 iteration 6233 : loss : 0.031095, loss_ce: 0.011973
2021-12-13 01:45:17,339 iteration 6234 : loss : 0.015213, loss_ce: 0.006311
2021-12-13 01:45:18,795 iteration 6235 : loss : 0.013115, loss_ce: 0.004206
2021-12-13 01:45:20,300 iteration 6236 : loss : 0.021012, loss_ce: 0.007211
2021-12-13 01:45:21,775 iteration 6237 : loss : 0.016036, loss_ce: 0.005658
2021-12-13 01:45:23,275 iteration 6238 : loss : 0.012280, loss_ce: 0.004762
2021-12-13 01:45:24,790 iteration 6239 : loss : 0.013113, loss_ce: 0.005330
 92%|██████████████████████████▌  | 367/400 [2:45:42<14:44, 26.80s/it]2021-12-13 01:45:26,230 iteration 6240 : loss : 0.018107, loss_ce: 0.006331
2021-12-13 01:45:27,630 iteration 6241 : loss : 0.013927, loss_ce: 0.005593
2021-12-13 01:45:29,106 iteration 6242 : loss : 0.014546, loss_ce: 0.006886
2021-12-13 01:45:30,573 iteration 6243 : loss : 0.012167, loss_ce: 0.004699
2021-12-13 01:45:32,054 iteration 6244 : loss : 0.012814, loss_ce: 0.004699
2021-12-13 01:45:33,541 iteration 6245 : loss : 0.010871, loss_ce: 0.004325
2021-12-13 01:45:34,982 iteration 6246 : loss : 0.012744, loss_ce: 0.005358
2021-12-13 01:45:36,417 iteration 6247 : loss : 0.015439, loss_ce: 0.004920
2021-12-13 01:45:37,904 iteration 6248 : loss : 0.018459, loss_ce: 0.004434
2021-12-13 01:45:39,406 iteration 6249 : loss : 0.017281, loss_ce: 0.005759
2021-12-13 01:45:40,777 iteration 6250 : loss : 0.011499, loss_ce: 0.002974
2021-12-13 01:45:42,294 iteration 6251 : loss : 0.020167, loss_ce: 0.012202
2021-12-13 01:45:43,690 iteration 6252 : loss : 0.008679, loss_ce: 0.002757
2021-12-13 01:45:45,248 iteration 6253 : loss : 0.015487, loss_ce: 0.005717
2021-12-13 01:45:46,628 iteration 6254 : loss : 0.007812, loss_ce: 0.003394
2021-12-13 01:45:48,232 iteration 6255 : loss : 0.024938, loss_ce: 0.009240
2021-12-13 01:45:49,657 iteration 6256 : loss : 0.014621, loss_ce: 0.005694
 92%|██████████████████████████▋  | 368/400 [2:46:07<13:59, 26.22s/it]2021-12-13 01:45:51,182 iteration 6257 : loss : 0.015835, loss_ce: 0.006997
2021-12-13 01:45:52,609 iteration 6258 : loss : 0.009429, loss_ce: 0.004535
2021-12-13 01:45:54,080 iteration 6259 : loss : 0.014835, loss_ce: 0.007155
2021-12-13 01:45:55,534 iteration 6260 : loss : 0.014997, loss_ce: 0.003800
2021-12-13 01:45:56,946 iteration 6261 : loss : 0.010620, loss_ce: 0.004456
2021-12-13 01:45:58,439 iteration 6262 : loss : 0.012661, loss_ce: 0.005063
2021-12-13 01:45:59,951 iteration 6263 : loss : 0.016640, loss_ce: 0.004400
2021-12-13 01:46:01,392 iteration 6264 : loss : 0.010830, loss_ce: 0.005084
2021-12-13 01:46:02,817 iteration 6265 : loss : 0.018016, loss_ce: 0.008539
2021-12-13 01:46:04,277 iteration 6266 : loss : 0.009984, loss_ce: 0.004081
2021-12-13 01:46:05,724 iteration 6267 : loss : 0.018863, loss_ce: 0.006685
2021-12-13 01:46:07,162 iteration 6268 : loss : 0.014362, loss_ce: 0.005439
2021-12-13 01:46:08,589 iteration 6269 : loss : 0.018572, loss_ce: 0.005873
2021-12-13 01:46:10,071 iteration 6270 : loss : 0.015535, loss_ce: 0.004661
2021-12-13 01:46:11,525 iteration 6271 : loss : 0.015448, loss_ce: 0.003610
2021-12-13 01:46:12,974 iteration 6272 : loss : 0.009375, loss_ce: 0.002379
2021-12-13 01:46:14,366 iteration 6273 : loss : 0.009480, loss_ce: 0.003988
 92%|██████████████████████████▊  | 369/400 [2:46:32<13:18, 25.77s/it]2021-12-13 01:46:15,848 iteration 6274 : loss : 0.014537, loss_ce: 0.005070
2021-12-13 01:46:17,309 iteration 6275 : loss : 0.016499, loss_ce: 0.007522
2021-12-13 01:46:18,757 iteration 6276 : loss : 0.013043, loss_ce: 0.004876
2021-12-13 01:46:20,256 iteration 6277 : loss : 0.014335, loss_ce: 0.003895
2021-12-13 01:46:21,768 iteration 6278 : loss : 0.015298, loss_ce: 0.005962
2021-12-13 01:46:23,330 iteration 6279 : loss : 0.019892, loss_ce: 0.005833
2021-12-13 01:46:24,780 iteration 6280 : loss : 0.012011, loss_ce: 0.005821
2021-12-13 01:46:26,206 iteration 6281 : loss : 0.011427, loss_ce: 0.003712
2021-12-13 01:46:27,631 iteration 6282 : loss : 0.011060, loss_ce: 0.004619
2021-12-13 01:46:29,142 iteration 6283 : loss : 0.016026, loss_ce: 0.004397
2021-12-13 01:46:30,675 iteration 6284 : loss : 0.013765, loss_ce: 0.006418
2021-12-13 01:46:32,131 iteration 6285 : loss : 0.013501, loss_ce: 0.005109
2021-12-13 01:46:33,579 iteration 6286 : loss : 0.013706, loss_ce: 0.007876
2021-12-13 01:46:35,077 iteration 6287 : loss : 0.012746, loss_ce: 0.004611
2021-12-13 01:46:36,601 iteration 6288 : loss : 0.016034, loss_ce: 0.005345
2021-12-13 01:46:38,040 iteration 6289 : loss : 0.011368, loss_ce: 0.003924
2021-12-13 01:46:38,041 Training Data Eval:
2021-12-13 01:46:45,547   Average segmentation loss on training set: 0.0070
2021-12-13 01:46:45,547 Validation Data Eval:
2021-12-13 01:46:48,156   Average segmentation loss on validation set: 0.0954
2021-12-13 01:46:49,594 iteration 6290 : loss : 0.010709, loss_ce: 0.003936
 92%|██████████████████████████▊  | 370/400 [2:47:07<14:18, 28.61s/it]2021-12-13 01:46:51,098 iteration 6291 : loss : 0.014563, loss_ce: 0.002884
2021-12-13 01:46:52,646 iteration 6292 : loss : 0.011010, loss_ce: 0.003797
2021-12-13 01:46:54,077 iteration 6293 : loss : 0.011985, loss_ce: 0.005341
2021-12-13 01:46:55,557 iteration 6294 : loss : 0.013829, loss_ce: 0.005553
2021-12-13 01:46:57,048 iteration 6295 : loss : 0.015488, loss_ce: 0.005453
2021-12-13 01:46:58,491 iteration 6296 : loss : 0.011514, loss_ce: 0.004256
2021-12-13 01:46:59,964 iteration 6297 : loss : 0.010275, loss_ce: 0.002573
2021-12-13 01:47:01,403 iteration 6298 : loss : 0.012800, loss_ce: 0.005081
2021-12-13 01:47:02,907 iteration 6299 : loss : 0.013399, loss_ce: 0.004957
2021-12-13 01:47:04,356 iteration 6300 : loss : 0.012914, loss_ce: 0.004736
2021-12-13 01:47:05,769 iteration 6301 : loss : 0.010732, loss_ce: 0.003970
2021-12-13 01:47:07,168 iteration 6302 : loss : 0.011483, loss_ce: 0.004606
2021-12-13 01:47:08,633 iteration 6303 : loss : 0.014071, loss_ce: 0.005980
2021-12-13 01:47:10,063 iteration 6304 : loss : 0.011457, loss_ce: 0.004343
2021-12-13 01:47:11,459 iteration 6305 : loss : 0.009539, loss_ce: 0.003984
2021-12-13 01:47:12,866 iteration 6306 : loss : 0.014736, loss_ce: 0.004672
2021-12-13 01:47:14,398 iteration 6307 : loss : 0.013419, loss_ce: 0.004142
 93%|██████████████████████████▉  | 371/400 [2:47:32<13:16, 27.47s/it]2021-12-13 01:47:15,860 iteration 6308 : loss : 0.011254, loss_ce: 0.004294
2021-12-13 01:47:17,353 iteration 6309 : loss : 0.013550, loss_ce: 0.004545
2021-12-13 01:47:18,824 iteration 6310 : loss : 0.013694, loss_ce: 0.006074
2021-12-13 01:47:20,250 iteration 6311 : loss : 0.012435, loss_ce: 0.003254
2021-12-13 01:47:21,735 iteration 6312 : loss : 0.011364, loss_ce: 0.003974
2021-12-13 01:47:23,161 iteration 6313 : loss : 0.010023, loss_ce: 0.001955
2021-12-13 01:47:24,660 iteration 6314 : loss : 0.020522, loss_ce: 0.007751
2021-12-13 01:47:26,172 iteration 6315 : loss : 0.017851, loss_ce: 0.006133
2021-12-13 01:47:27,612 iteration 6316 : loss : 0.011934, loss_ce: 0.005736
2021-12-13 01:47:29,091 iteration 6317 : loss : 0.010928, loss_ce: 0.003799
2021-12-13 01:47:30,611 iteration 6318 : loss : 0.016045, loss_ce: 0.006573
2021-12-13 01:47:32,163 iteration 6319 : loss : 0.014530, loss_ce: 0.004315
2021-12-13 01:47:33,707 iteration 6320 : loss : 0.014064, loss_ce: 0.005370
2021-12-13 01:47:35,198 iteration 6321 : loss : 0.018030, loss_ce: 0.006995
2021-12-13 01:47:36,722 iteration 6322 : loss : 0.013781, loss_ce: 0.005663
2021-12-13 01:47:38,070 iteration 6323 : loss : 0.009943, loss_ce: 0.004161
2021-12-13 01:47:39,547 iteration 6324 : loss : 0.013009, loss_ce: 0.003285
 93%|██████████████████████████▉  | 372/400 [2:47:57<12:29, 26.77s/it]2021-12-13 01:47:40,985 iteration 6325 : loss : 0.012453, loss_ce: 0.003898
2021-12-13 01:47:42,375 iteration 6326 : loss : 0.009664, loss_ce: 0.004572
2021-12-13 01:47:43,763 iteration 6327 : loss : 0.009213, loss_ce: 0.003340
2021-12-13 01:47:45,296 iteration 6328 : loss : 0.015043, loss_ce: 0.006218
2021-12-13 01:47:46,843 iteration 6329 : loss : 0.016335, loss_ce: 0.006775
2021-12-13 01:47:48,320 iteration 6330 : loss : 0.011780, loss_ce: 0.005205
2021-12-13 01:47:49,838 iteration 6331 : loss : 0.015049, loss_ce: 0.006339
2021-12-13 01:47:51,290 iteration 6332 : loss : 0.012672, loss_ce: 0.004196
2021-12-13 01:47:52,749 iteration 6333 : loss : 0.010912, loss_ce: 0.004328
2021-12-13 01:47:54,233 iteration 6334 : loss : 0.010717, loss_ce: 0.004500
2021-12-13 01:47:55,835 iteration 6335 : loss : 0.016444, loss_ce: 0.007256
2021-12-13 01:47:57,317 iteration 6336 : loss : 0.011615, loss_ce: 0.004071
2021-12-13 01:47:58,711 iteration 6337 : loss : 0.011801, loss_ce: 0.004675
2021-12-13 01:48:00,256 iteration 6338 : loss : 0.017797, loss_ce: 0.005553
2021-12-13 01:48:01,698 iteration 6339 : loss : 0.009328, loss_ce: 0.003171
2021-12-13 01:48:03,178 iteration 6340 : loss : 0.014170, loss_ce: 0.006343
2021-12-13 01:48:04,678 iteration 6341 : loss : 0.013478, loss_ce: 0.003529
 93%|███████████████████████████  | 373/400 [2:48:22<11:49, 26.28s/it]2021-12-13 01:48:06,279 iteration 6342 : loss : 0.011423, loss_ce: 0.003959
2021-12-13 01:48:07,734 iteration 6343 : loss : 0.012190, loss_ce: 0.003398
2021-12-13 01:48:09,195 iteration 6344 : loss : 0.014134, loss_ce: 0.006822
2021-12-13 01:48:10,657 iteration 6345 : loss : 0.020039, loss_ce: 0.011280
2021-12-13 01:48:12,085 iteration 6346 : loss : 0.011256, loss_ce: 0.002971
2021-12-13 01:48:13,540 iteration 6347 : loss : 0.019401, loss_ce: 0.008256
2021-12-13 01:48:15,087 iteration 6348 : loss : 0.016365, loss_ce: 0.005648
2021-12-13 01:48:16,501 iteration 6349 : loss : 0.010073, loss_ce: 0.004157
2021-12-13 01:48:17,945 iteration 6350 : loss : 0.012830, loss_ce: 0.003234
2021-12-13 01:48:19,386 iteration 6351 : loss : 0.010347, loss_ce: 0.003623
2021-12-13 01:48:20,895 iteration 6352 : loss : 0.010404, loss_ce: 0.004139
2021-12-13 01:48:22,402 iteration 6353 : loss : 0.014689, loss_ce: 0.006658
2021-12-13 01:48:23,956 iteration 6354 : loss : 0.013076, loss_ce: 0.004928
2021-12-13 01:48:25,371 iteration 6355 : loss : 0.011847, loss_ce: 0.005411
2021-12-13 01:48:26,843 iteration 6356 : loss : 0.018640, loss_ce: 0.008624
2021-12-13 01:48:28,278 iteration 6357 : loss : 0.014920, loss_ce: 0.005327
2021-12-13 01:48:29,806 iteration 6358 : loss : 0.014738, loss_ce: 0.006478
 94%|███████████████████████████  | 374/400 [2:48:47<11:14, 25.94s/it]2021-12-13 01:48:31,311 iteration 6359 : loss : 0.015250, loss_ce: 0.005023
2021-12-13 01:48:32,730 iteration 6360 : loss : 0.015729, loss_ce: 0.004257
2021-12-13 01:48:34,204 iteration 6361 : loss : 0.016277, loss_ce: 0.003641
2021-12-13 01:48:35,689 iteration 6362 : loss : 0.015121, loss_ce: 0.006833
2021-12-13 01:48:37,223 iteration 6363 : loss : 0.015416, loss_ce: 0.006394
2021-12-13 01:48:38,642 iteration 6364 : loss : 0.009810, loss_ce: 0.003987
2021-12-13 01:48:40,059 iteration 6365 : loss : 0.012418, loss_ce: 0.004414
2021-12-13 01:48:41,556 iteration 6366 : loss : 0.015764, loss_ce: 0.005872
2021-12-13 01:48:43,000 iteration 6367 : loss : 0.012108, loss_ce: 0.005543
2021-12-13 01:48:44,429 iteration 6368 : loss : 0.013436, loss_ce: 0.003993
2021-12-13 01:48:45,901 iteration 6369 : loss : 0.012354, loss_ce: 0.005135
2021-12-13 01:48:47,398 iteration 6370 : loss : 0.021872, loss_ce: 0.005304
2021-12-13 01:48:48,897 iteration 6371 : loss : 0.014855, loss_ce: 0.005416
2021-12-13 01:48:50,356 iteration 6372 : loss : 0.011416, loss_ce: 0.005450
2021-12-13 01:48:51,686 iteration 6373 : loss : 0.007752, loss_ce: 0.001994
2021-12-13 01:48:53,116 iteration 6374 : loss : 0.011278, loss_ce: 0.004546
2021-12-13 01:48:53,116 Training Data Eval:
2021-12-13 01:49:00,624   Average segmentation loss on training set: 0.0064
2021-12-13 01:49:00,624 Validation Data Eval:
2021-12-13 01:49:03,223   Average segmentation loss on validation set: 0.0758
2021-12-13 01:49:04,685 iteration 6375 : loss : 0.013441, loss_ce: 0.004278
 94%|███████████████████████████▏ | 375/400 [2:49:22<11:55, 28.62s/it]2021-12-13 01:49:06,376 iteration 6376 : loss : 0.019510, loss_ce: 0.007611
2021-12-13 01:49:07,837 iteration 6377 : loss : 0.012369, loss_ce: 0.004168
2021-12-13 01:49:09,260 iteration 6378 : loss : 0.012772, loss_ce: 0.004581
2021-12-13 01:49:10,750 iteration 6379 : loss : 0.013308, loss_ce: 0.003756
2021-12-13 01:49:12,143 iteration 6380 : loss : 0.010404, loss_ce: 0.004895
2021-12-13 01:49:13,540 iteration 6381 : loss : 0.012992, loss_ce: 0.004221
2021-12-13 01:49:15,026 iteration 6382 : loss : 0.019075, loss_ce: 0.009145
2021-12-13 01:49:16,531 iteration 6383 : loss : 0.011881, loss_ce: 0.004250
2021-12-13 01:49:17,990 iteration 6384 : loss : 0.011753, loss_ce: 0.004386
2021-12-13 01:49:19,537 iteration 6385 : loss : 0.025275, loss_ce: 0.010907
2021-12-13 01:49:21,006 iteration 6386 : loss : 0.016937, loss_ce: 0.005627
2021-12-13 01:49:22,574 iteration 6387 : loss : 0.023285, loss_ce: 0.011162
2021-12-13 01:49:23,990 iteration 6388 : loss : 0.008903, loss_ce: 0.003187
2021-12-13 01:49:25,352 iteration 6389 : loss : 0.009650, loss_ce: 0.003057
2021-12-13 01:49:26,803 iteration 6390 : loss : 0.014420, loss_ce: 0.004988
2021-12-13 01:49:28,353 iteration 6391 : loss : 0.023427, loss_ce: 0.005959
2021-12-13 01:49:29,744 iteration 6392 : loss : 0.007918, loss_ce: 0.003243
 94%|███████████████████████████▎ | 376/400 [2:49:47<11:01, 27.55s/it]2021-12-13 01:49:31,248 iteration 6393 : loss : 0.010349, loss_ce: 0.003266
2021-12-13 01:49:32,744 iteration 6394 : loss : 0.016682, loss_ce: 0.005918
2021-12-13 01:49:34,171 iteration 6395 : loss : 0.009485, loss_ce: 0.004254
2021-12-13 01:49:35,708 iteration 6396 : loss : 0.021640, loss_ce: 0.007657
2021-12-13 01:49:37,136 iteration 6397 : loss : 0.014615, loss_ce: 0.005304
2021-12-13 01:49:38,540 iteration 6398 : loss : 0.010670, loss_ce: 0.003177
2021-12-13 01:49:40,005 iteration 6399 : loss : 0.013714, loss_ce: 0.004206
2021-12-13 01:49:41,467 iteration 6400 : loss : 0.011399, loss_ce: 0.005301
2021-12-13 01:49:42,870 iteration 6401 : loss : 0.010880, loss_ce: 0.004048
2021-12-13 01:49:44,338 iteration 6402 : loss : 0.013018, loss_ce: 0.005163
2021-12-13 01:49:45,909 iteration 6403 : loss : 0.016720, loss_ce: 0.005551
2021-12-13 01:49:47,347 iteration 6404 : loss : 0.014061, loss_ce: 0.003989
2021-12-13 01:49:48,786 iteration 6405 : loss : 0.014202, loss_ce: 0.005380
2021-12-13 01:49:50,396 iteration 6406 : loss : 0.016750, loss_ce: 0.007874
2021-12-13 01:49:51,796 iteration 6407 : loss : 0.010211, loss_ce: 0.002985
2021-12-13 01:49:53,253 iteration 6408 : loss : 0.013939, loss_ce: 0.003312
2021-12-13 01:49:54,672 iteration 6409 : loss : 0.014609, loss_ce: 0.006077
 94%|███████████████████████████▎ | 377/400 [2:50:12<10:15, 26.76s/it]2021-12-13 01:49:56,294 iteration 6410 : loss : 0.018519, loss_ce: 0.006649
2021-12-13 01:49:57,844 iteration 6411 : loss : 0.017348, loss_ce: 0.006449
2021-12-13 01:49:59,334 iteration 6412 : loss : 0.012383, loss_ce: 0.005746
2021-12-13 01:50:00,791 iteration 6413 : loss : 0.007769, loss_ce: 0.002357
2021-12-13 01:50:02,287 iteration 6414 : loss : 0.016963, loss_ce: 0.006335
2021-12-13 01:50:03,723 iteration 6415 : loss : 0.014331, loss_ce: 0.004800
2021-12-13 01:50:05,171 iteration 6416 : loss : 0.016731, loss_ce: 0.004438
2021-12-13 01:50:06,661 iteration 6417 : loss : 0.015626, loss_ce: 0.007432
2021-12-13 01:50:08,154 iteration 6418 : loss : 0.020279, loss_ce: 0.008588
2021-12-13 01:50:09,616 iteration 6419 : loss : 0.014160, loss_ce: 0.004220
2021-12-13 01:50:11,115 iteration 6420 : loss : 0.016675, loss_ce: 0.005380
2021-12-13 01:50:12,580 iteration 6421 : loss : 0.009377, loss_ce: 0.003564
2021-12-13 01:50:13,991 iteration 6422 : loss : 0.011211, loss_ce: 0.004724
2021-12-13 01:50:15,504 iteration 6423 : loss : 0.014200, loss_ce: 0.005159
2021-12-13 01:50:17,018 iteration 6424 : loss : 0.013211, loss_ce: 0.005882
2021-12-13 01:50:18,409 iteration 6425 : loss : 0.011336, loss_ce: 0.003779
2021-12-13 01:50:19,915 iteration 6426 : loss : 0.015605, loss_ce: 0.006652
 94%|███████████████████████████▍ | 378/400 [2:50:38<09:38, 26.31s/it]2021-12-13 01:50:21,428 iteration 6427 : loss : 0.012127, loss_ce: 0.004751
2021-12-13 01:50:22,808 iteration 6428 : loss : 0.010227, loss_ce: 0.004842
2021-12-13 01:50:24,316 iteration 6429 : loss : 0.013852, loss_ce: 0.004968
2021-12-13 01:50:25,729 iteration 6430 : loss : 0.011271, loss_ce: 0.003269
2021-12-13 01:50:27,213 iteration 6431 : loss : 0.016470, loss_ce: 0.006275
2021-12-13 01:50:28,694 iteration 6432 : loss : 0.012974, loss_ce: 0.004861
2021-12-13 01:50:30,230 iteration 6433 : loss : 0.009799, loss_ce: 0.003417
2021-12-13 01:50:31,601 iteration 6434 : loss : 0.008075, loss_ce: 0.002898
2021-12-13 01:50:33,054 iteration 6435 : loss : 0.010227, loss_ce: 0.004988
2021-12-13 01:50:34,510 iteration 6436 : loss : 0.011164, loss_ce: 0.004148
2021-12-13 01:50:36,014 iteration 6437 : loss : 0.015608, loss_ce: 0.003805
2021-12-13 01:50:37,515 iteration 6438 : loss : 0.013083, loss_ce: 0.005146
2021-12-13 01:50:39,005 iteration 6439 : loss : 0.016032, loss_ce: 0.007266
2021-12-13 01:50:40,537 iteration 6440 : loss : 0.018070, loss_ce: 0.006634
2021-12-13 01:50:42,011 iteration 6441 : loss : 0.011471, loss_ce: 0.002869
2021-12-13 01:50:43,481 iteration 6442 : loss : 0.016400, loss_ce: 0.007508
2021-12-13 01:50:44,958 iteration 6443 : loss : 0.015902, loss_ce: 0.005804
 95%|███████████████████████████▍ | 379/400 [2:51:03<09:04, 25.93s/it]2021-12-13 01:50:46,498 iteration 6444 : loss : 0.017362, loss_ce: 0.008824
2021-12-13 01:50:48,027 iteration 6445 : loss : 0.015462, loss_ce: 0.006444
2021-12-13 01:50:49,503 iteration 6446 : loss : 0.012710, loss_ce: 0.003281
2021-12-13 01:50:50,972 iteration 6447 : loss : 0.013953, loss_ce: 0.007123
2021-12-13 01:50:52,436 iteration 6448 : loss : 0.011418, loss_ce: 0.004990
2021-12-13 01:50:53,947 iteration 6449 : loss : 0.012609, loss_ce: 0.004014
2021-12-13 01:50:55,369 iteration 6450 : loss : 0.010223, loss_ce: 0.004613
2021-12-13 01:50:56,786 iteration 6451 : loss : 0.012386, loss_ce: 0.004313
2021-12-13 01:50:58,279 iteration 6452 : loss : 0.012529, loss_ce: 0.005438
2021-12-13 01:50:59,747 iteration 6453 : loss : 0.013493, loss_ce: 0.005907
2021-12-13 01:51:01,186 iteration 6454 : loss : 0.012787, loss_ce: 0.004312
2021-12-13 01:51:02,630 iteration 6455 : loss : 0.011759, loss_ce: 0.003709
2021-12-13 01:51:04,193 iteration 6456 : loss : 0.019166, loss_ce: 0.007653
2021-12-13 01:51:05,672 iteration 6457 : loss : 0.012864, loss_ce: 0.003752
2021-12-13 01:51:07,108 iteration 6458 : loss : 0.011409, loss_ce: 0.003820
2021-12-13 01:51:08,520 iteration 6459 : loss : 0.010730, loss_ce: 0.003830
2021-12-13 01:51:08,520 Training Data Eval:
2021-12-13 01:51:15,989   Average segmentation loss on training set: 0.0065
2021-12-13 01:51:15,989 Validation Data Eval:
2021-12-13 01:51:18,587   Average segmentation loss on validation set: 0.0778
2021-12-13 01:51:20,090 iteration 6460 : loss : 0.014261, loss_ce: 0.003886
 95%|███████████████████████████▌ | 380/400 [2:51:38<09:33, 28.69s/it]2021-12-13 01:51:21,604 iteration 6461 : loss : 0.014893, loss_ce: 0.004390
2021-12-13 01:51:23,091 iteration 6462 : loss : 0.010574, loss_ce: 0.003772
2021-12-13 01:51:24,513 iteration 6463 : loss : 0.007728, loss_ce: 0.002192
2021-12-13 01:51:25,934 iteration 6464 : loss : 0.010414, loss_ce: 0.003384
2021-12-13 01:51:27,394 iteration 6465 : loss : 0.017897, loss_ce: 0.006199
2021-12-13 01:51:28,881 iteration 6466 : loss : 0.014328, loss_ce: 0.005877
2021-12-13 01:51:30,392 iteration 6467 : loss : 0.011524, loss_ce: 0.005309
2021-12-13 01:51:31,923 iteration 6468 : loss : 0.020456, loss_ce: 0.010136
2021-12-13 01:51:33,376 iteration 6469 : loss : 0.012394, loss_ce: 0.006016
2021-12-13 01:51:34,807 iteration 6470 : loss : 0.020235, loss_ce: 0.005672
2021-12-13 01:51:36,248 iteration 6471 : loss : 0.015659, loss_ce: 0.006181
2021-12-13 01:51:37,699 iteration 6472 : loss : 0.016710, loss_ce: 0.004808
2021-12-13 01:51:39,110 iteration 6473 : loss : 0.011953, loss_ce: 0.005759
2021-12-13 01:51:40,632 iteration 6474 : loss : 0.014793, loss_ce: 0.008069
2021-12-13 01:51:42,036 iteration 6475 : loss : 0.008910, loss_ce: 0.003199
2021-12-13 01:51:43,460 iteration 6476 : loss : 0.012114, loss_ce: 0.004380
2021-12-13 01:51:44,880 iteration 6477 : loss : 0.011766, loss_ce: 0.004509
 95%|███████████████████████████▌ | 381/400 [2:52:02<08:42, 27.52s/it]2021-12-13 01:51:46,424 iteration 6478 : loss : 0.010728, loss_ce: 0.004657
2021-12-13 01:51:48,034 iteration 6479 : loss : 0.020258, loss_ce: 0.011018
2021-12-13 01:51:49,527 iteration 6480 : loss : 0.020749, loss_ce: 0.004960
2021-12-13 01:51:51,007 iteration 6481 : loss : 0.014629, loss_ce: 0.007283
2021-12-13 01:51:52,472 iteration 6482 : loss : 0.014302, loss_ce: 0.005456
2021-12-13 01:51:53,888 iteration 6483 : loss : 0.012416, loss_ce: 0.004358
2021-12-13 01:51:55,323 iteration 6484 : loss : 0.022944, loss_ce: 0.005913
2021-12-13 01:51:56,803 iteration 6485 : loss : 0.013994, loss_ce: 0.006313
2021-12-13 01:51:58,356 iteration 6486 : loss : 0.014010, loss_ce: 0.004531
2021-12-13 01:51:59,844 iteration 6487 : loss : 0.016203, loss_ce: 0.005127
2021-12-13 01:52:01,216 iteration 6488 : loss : 0.010761, loss_ce: 0.004554
2021-12-13 01:52:02,731 iteration 6489 : loss : 0.038391, loss_ce: 0.013218
2021-12-13 01:52:04,116 iteration 6490 : loss : 0.010356, loss_ce: 0.004343
2021-12-13 01:52:05,625 iteration 6491 : loss : 0.015767, loss_ce: 0.004519
2021-12-13 01:52:07,072 iteration 6492 : loss : 0.010323, loss_ce: 0.003680
2021-12-13 01:52:08,564 iteration 6493 : loss : 0.014964, loss_ce: 0.004155
2021-12-13 01:52:10,019 iteration 6494 : loss : 0.013536, loss_ce: 0.005212
 96%|███████████████████████████▋ | 382/400 [2:52:28<08:02, 26.81s/it]2021-12-13 01:52:11,560 iteration 6495 : loss : 0.010456, loss_ce: 0.002764
2021-12-13 01:52:12,998 iteration 6496 : loss : 0.016681, loss_ce: 0.005663
2021-12-13 01:52:14,491 iteration 6497 : loss : 0.010136, loss_ce: 0.003568
2021-12-13 01:52:15,969 iteration 6498 : loss : 0.015399, loss_ce: 0.007239
2021-12-13 01:52:17,532 iteration 6499 : loss : 0.018689, loss_ce: 0.006726
2021-12-13 01:52:19,044 iteration 6500 : loss : 0.019160, loss_ce: 0.008299
2021-12-13 01:52:20,579 iteration 6501 : loss : 0.011927, loss_ce: 0.003453
2021-12-13 01:52:22,087 iteration 6502 : loss : 0.015852, loss_ce: 0.006380
2021-12-13 01:52:23,634 iteration 6503 : loss : 0.019201, loss_ce: 0.005951
2021-12-13 01:52:25,041 iteration 6504 : loss : 0.012022, loss_ce: 0.006491
2021-12-13 01:52:26,475 iteration 6505 : loss : 0.010189, loss_ce: 0.002826
2021-12-13 01:52:27,932 iteration 6506 : loss : 0.011424, loss_ce: 0.003344
2021-12-13 01:52:29,385 iteration 6507 : loss : 0.014198, loss_ce: 0.005436
2021-12-13 01:52:30,861 iteration 6508 : loss : 0.012888, loss_ce: 0.004022
2021-12-13 01:52:32,325 iteration 6509 : loss : 0.012003, loss_ce: 0.004694
2021-12-13 01:52:33,753 iteration 6510 : loss : 0.014318, loss_ce: 0.004672
2021-12-13 01:52:35,213 iteration 6511 : loss : 0.015824, loss_ce: 0.007186
 96%|███████████████████████████▊ | 383/400 [2:52:53<07:27, 26.32s/it]2021-12-13 01:52:36,704 iteration 6512 : loss : 0.012752, loss_ce: 0.005118
2021-12-13 01:52:38,107 iteration 6513 : loss : 0.011544, loss_ce: 0.004251
2021-12-13 01:52:39,544 iteration 6514 : loss : 0.010802, loss_ce: 0.002482
2021-12-13 01:52:41,002 iteration 6515 : loss : 0.011966, loss_ce: 0.003482
2021-12-13 01:52:42,450 iteration 6516 : loss : 0.012123, loss_ce: 0.003528
2021-12-13 01:52:43,975 iteration 6517 : loss : 0.013376, loss_ce: 0.005971
2021-12-13 01:52:45,385 iteration 6518 : loss : 0.013933, loss_ce: 0.005855
2021-12-13 01:52:46,934 iteration 6519 : loss : 0.017771, loss_ce: 0.006176
2021-12-13 01:52:48,340 iteration 6520 : loss : 0.011629, loss_ce: 0.005409
2021-12-13 01:52:49,843 iteration 6521 : loss : 0.013601, loss_ce: 0.005144
2021-12-13 01:52:51,285 iteration 6522 : loss : 0.018888, loss_ce: 0.008292
2021-12-13 01:52:52,694 iteration 6523 : loss : 0.011912, loss_ce: 0.003577
2021-12-13 01:52:54,166 iteration 6524 : loss : 0.017019, loss_ce: 0.005978
2021-12-13 01:52:55,615 iteration 6525 : loss : 0.010350, loss_ce: 0.003305
2021-12-13 01:52:57,105 iteration 6526 : loss : 0.010958, loss_ce: 0.004317
2021-12-13 01:52:58,616 iteration 6527 : loss : 0.015262, loss_ce: 0.005063
2021-12-13 01:53:00,099 iteration 6528 : loss : 0.012616, loss_ce: 0.004966
 96%|███████████████████████████▊ | 384/400 [2:53:18<06:54, 25.89s/it]2021-12-13 01:53:01,563 iteration 6529 : loss : 0.015192, loss_ce: 0.005872
2021-12-13 01:53:02,949 iteration 6530 : loss : 0.008747, loss_ce: 0.003800
2021-12-13 01:53:04,427 iteration 6531 : loss : 0.012804, loss_ce: 0.002801
2021-12-13 01:53:05,939 iteration 6532 : loss : 0.009687, loss_ce: 0.003039
2021-12-13 01:53:07,350 iteration 6533 : loss : 0.010452, loss_ce: 0.004304
2021-12-13 01:53:08,828 iteration 6534 : loss : 0.017516, loss_ce: 0.005329
2021-12-13 01:53:10,280 iteration 6535 : loss : 0.014763, loss_ce: 0.005752
2021-12-13 01:53:11,779 iteration 6536 : loss : 0.016563, loss_ce: 0.006673
2021-12-13 01:53:13,354 iteration 6537 : loss : 0.021336, loss_ce: 0.006669
2021-12-13 01:53:14,775 iteration 6538 : loss : 0.012027, loss_ce: 0.003912
2021-12-13 01:53:16,345 iteration 6539 : loss : 0.013836, loss_ce: 0.005500
2021-12-13 01:53:17,766 iteration 6540 : loss : 0.013380, loss_ce: 0.005910
2021-12-13 01:53:19,168 iteration 6541 : loss : 0.011547, loss_ce: 0.004885
2021-12-13 01:53:20,634 iteration 6542 : loss : 0.022322, loss_ce: 0.007926
2021-12-13 01:53:22,187 iteration 6543 : loss : 0.014395, loss_ce: 0.005441
2021-12-13 01:53:23,644 iteration 6544 : loss : 0.013811, loss_ce: 0.005933
2021-12-13 01:53:23,645 Training Data Eval:
2021-12-13 01:53:31,146   Average segmentation loss on training set: 0.0063
2021-12-13 01:53:31,147 Validation Data Eval:
2021-12-13 01:53:33,746   Average segmentation loss on validation set: 0.0813
2021-12-13 01:53:35,230 iteration 6545 : loss : 0.009769, loss_ce: 0.002803
 96%|███████████████████████████▉ | 385/400 [2:53:53<07:09, 28.66s/it]2021-12-13 01:53:36,807 iteration 6546 : loss : 0.016131, loss_ce: 0.005827
2021-12-13 01:53:38,221 iteration 6547 : loss : 0.013052, loss_ce: 0.002834
2021-12-13 01:53:39,717 iteration 6548 : loss : 0.029371, loss_ce: 0.006822
2021-12-13 01:53:41,279 iteration 6549 : loss : 0.018178, loss_ce: 0.004899
2021-12-13 01:53:42,753 iteration 6550 : loss : 0.014485, loss_ce: 0.006253
2021-12-13 01:53:44,277 iteration 6551 : loss : 0.015138, loss_ce: 0.006375
2021-12-13 01:53:45,830 iteration 6552 : loss : 0.019776, loss_ce: 0.007119
2021-12-13 01:53:47,286 iteration 6553 : loss : 0.012833, loss_ce: 0.004583
2021-12-13 01:53:48,865 iteration 6554 : loss : 0.025032, loss_ce: 0.007062
2021-12-13 01:53:50,287 iteration 6555 : loss : 0.011316, loss_ce: 0.004153
2021-12-13 01:53:51,782 iteration 6556 : loss : 0.016292, loss_ce: 0.005912
2021-12-13 01:53:53,187 iteration 6557 : loss : 0.007798, loss_ce: 0.002886
2021-12-13 01:53:54,715 iteration 6558 : loss : 0.020706, loss_ce: 0.007922
2021-12-13 01:53:56,122 iteration 6559 : loss : 0.009644, loss_ce: 0.003358
2021-12-13 01:53:57,548 iteration 6560 : loss : 0.009861, loss_ce: 0.004435
2021-12-13 01:53:59,025 iteration 6561 : loss : 0.012022, loss_ce: 0.004261
2021-12-13 01:54:00,487 iteration 6562 : loss : 0.014411, loss_ce: 0.006432
 96%|███████████████████████████▉ | 386/400 [2:54:18<06:26, 27.64s/it]2021-12-13 01:54:02,006 iteration 6563 : loss : 0.014690, loss_ce: 0.006572
2021-12-13 01:54:03,529 iteration 6564 : loss : 0.014342, loss_ce: 0.004794
2021-12-13 01:54:04,949 iteration 6565 : loss : 0.020254, loss_ce: 0.007236
2021-12-13 01:54:06,485 iteration 6566 : loss : 0.015258, loss_ce: 0.005497
2021-12-13 01:54:07,957 iteration 6567 : loss : 0.013303, loss_ce: 0.004631
2021-12-13 01:54:09,412 iteration 6568 : loss : 0.008970, loss_ce: 0.002975
2021-12-13 01:54:10,844 iteration 6569 : loss : 0.015159, loss_ce: 0.004397
2021-12-13 01:54:12,396 iteration 6570 : loss : 0.020548, loss_ce: 0.008452
2021-12-13 01:54:13,797 iteration 6571 : loss : 0.010659, loss_ce: 0.004388
2021-12-13 01:54:15,229 iteration 6572 : loss : 0.015384, loss_ce: 0.005084
2021-12-13 01:54:16,643 iteration 6573 : loss : 0.010146, loss_ce: 0.003051
2021-12-13 01:54:18,109 iteration 6574 : loss : 0.014992, loss_ce: 0.005972
2021-12-13 01:54:19,477 iteration 6575 : loss : 0.008617, loss_ce: 0.003490
2021-12-13 01:54:20,950 iteration 6576 : loss : 0.013538, loss_ce: 0.005639
2021-12-13 01:54:22,441 iteration 6577 : loss : 0.014705, loss_ce: 0.005601
2021-12-13 01:54:23,930 iteration 6578 : loss : 0.011312, loss_ce: 0.004955
2021-12-13 01:54:25,381 iteration 6579 : loss : 0.011795, loss_ce: 0.002722
 97%|████████████████████████████ | 387/400 [2:54:43<05:48, 26.82s/it]2021-12-13 01:54:26,921 iteration 6580 : loss : 0.013128, loss_ce: 0.004842
2021-12-13 01:54:28,424 iteration 6581 : loss : 0.019204, loss_ce: 0.005729
2021-12-13 01:54:29,930 iteration 6582 : loss : 0.013908, loss_ce: 0.006523
2021-12-13 01:54:31,381 iteration 6583 : loss : 0.009237, loss_ce: 0.003424
2021-12-13 01:54:32,860 iteration 6584 : loss : 0.014400, loss_ce: 0.004754
2021-12-13 01:54:34,284 iteration 6585 : loss : 0.010852, loss_ce: 0.003519
2021-12-13 01:54:35,767 iteration 6586 : loss : 0.011822, loss_ce: 0.004462
2021-12-13 01:54:37,180 iteration 6587 : loss : 0.011115, loss_ce: 0.004860
2021-12-13 01:54:38,714 iteration 6588 : loss : 0.015458, loss_ce: 0.005486
2021-12-13 01:54:40,175 iteration 6589 : loss : 0.015057, loss_ce: 0.004703
2021-12-13 01:54:41,613 iteration 6590 : loss : 0.011706, loss_ce: 0.004535
2021-12-13 01:54:43,030 iteration 6591 : loss : 0.011585, loss_ce: 0.004848
2021-12-13 01:54:44,482 iteration 6592 : loss : 0.008569, loss_ce: 0.002735
2021-12-13 01:54:45,992 iteration 6593 : loss : 0.021596, loss_ce: 0.010881
2021-12-13 01:54:47,442 iteration 6594 : loss : 0.010059, loss_ce: 0.003456
2021-12-13 01:54:48,850 iteration 6595 : loss : 0.016085, loss_ce: 0.004790
2021-12-13 01:54:50,269 iteration 6596 : loss : 0.007618, loss_ce: 0.002968
 97%|████████████████████████████▏| 388/400 [2:55:08<05:14, 26.24s/it]2021-12-13 01:54:51,820 iteration 6597 : loss : 0.016035, loss_ce: 0.007610
2021-12-13 01:54:53,328 iteration 6598 : loss : 0.014573, loss_ce: 0.003658
2021-12-13 01:54:54,746 iteration 6599 : loss : 0.011858, loss_ce: 0.004407
2021-12-13 01:54:56,263 iteration 6600 : loss : 0.016641, loss_ce: 0.005751
2021-12-13 01:54:57,687 iteration 6601 : loss : 0.009353, loss_ce: 0.004013
2021-12-13 01:54:59,057 iteration 6602 : loss : 0.007075, loss_ce: 0.002455
2021-12-13 01:55:00,541 iteration 6603 : loss : 0.019791, loss_ce: 0.005951
2021-12-13 01:55:02,071 iteration 6604 : loss : 0.015552, loss_ce: 0.006433
2021-12-13 01:55:03,541 iteration 6605 : loss : 0.016081, loss_ce: 0.006764
2021-12-13 01:55:05,003 iteration 6606 : loss : 0.012633, loss_ce: 0.006690
2021-12-13 01:55:06,425 iteration 6607 : loss : 0.015332, loss_ce: 0.004603
2021-12-13 01:55:07,923 iteration 6608 : loss : 0.013203, loss_ce: 0.004522
2021-12-13 01:55:09,443 iteration 6609 : loss : 0.014701, loss_ce: 0.005722
2021-12-13 01:55:10,887 iteration 6610 : loss : 0.016761, loss_ce: 0.004121
2021-12-13 01:55:12,270 iteration 6611 : loss : 0.010144, loss_ce: 0.004326
2021-12-13 01:55:13,755 iteration 6612 : loss : 0.013316, loss_ce: 0.004976
2021-12-13 01:55:15,275 iteration 6613 : loss : 0.018781, loss_ce: 0.005191
 97%|████████████████████████████▏| 389/400 [2:55:33<04:44, 25.87s/it]2021-12-13 01:55:16,685 iteration 6614 : loss : 0.008816, loss_ce: 0.003425
2021-12-13 01:55:18,166 iteration 6615 : loss : 0.017494, loss_ce: 0.006736
2021-12-13 01:55:19,655 iteration 6616 : loss : 0.014507, loss_ce: 0.006041
2021-12-13 01:55:21,082 iteration 6617 : loss : 0.009377, loss_ce: 0.001793
2021-12-13 01:55:22,552 iteration 6618 : loss : 0.013323, loss_ce: 0.004270
2021-12-13 01:55:24,048 iteration 6619 : loss : 0.011338, loss_ce: 0.004225
2021-12-13 01:55:25,514 iteration 6620 : loss : 0.012923, loss_ce: 0.004610
2021-12-13 01:55:26,926 iteration 6621 : loss : 0.011361, loss_ce: 0.004868
2021-12-13 01:55:28,295 iteration 6622 : loss : 0.007979, loss_ce: 0.002552
2021-12-13 01:55:29,770 iteration 6623 : loss : 0.012960, loss_ce: 0.005609
2021-12-13 01:55:31,130 iteration 6624 : loss : 0.010507, loss_ce: 0.003721
2021-12-13 01:55:32,506 iteration 6625 : loss : 0.007560, loss_ce: 0.003128
2021-12-13 01:55:33,972 iteration 6626 : loss : 0.013799, loss_ce: 0.005351
2021-12-13 01:55:35,383 iteration 6627 : loss : 0.008351, loss_ce: 0.002731
2021-12-13 01:55:36,872 iteration 6628 : loss : 0.011603, loss_ce: 0.004160
2021-12-13 01:55:38,286 iteration 6629 : loss : 0.009310, loss_ce: 0.003821
2021-12-13 01:55:38,287 Training Data Eval:
2021-12-13 01:55:45,807   Average segmentation loss on training set: 0.0062
2021-12-13 01:55:45,807 Validation Data Eval:
2021-12-13 01:55:48,409   Average segmentation loss on validation set: 0.0768
2021-12-13 01:55:49,891 iteration 6630 : loss : 0.015507, loss_ce: 0.006455
 98%|████████████████████████████▎| 390/400 [2:56:07<04:44, 28.49s/it]2021-12-13 01:55:51,312 iteration 6631 : loss : 0.009814, loss_ce: 0.003649
2021-12-13 01:55:52,799 iteration 6632 : loss : 0.018099, loss_ce: 0.004138
2021-12-13 01:55:54,244 iteration 6633 : loss : 0.010984, loss_ce: 0.004885
2021-12-13 01:55:55,672 iteration 6634 : loss : 0.016655, loss_ce: 0.008866
2021-12-13 01:55:57,171 iteration 6635 : loss : 0.008097, loss_ce: 0.002987
2021-12-13 01:55:58,590 iteration 6636 : loss : 0.011240, loss_ce: 0.006087
2021-12-13 01:56:00,074 iteration 6637 : loss : 0.015139, loss_ce: 0.004392
2021-12-13 01:56:01,550 iteration 6638 : loss : 0.008863, loss_ce: 0.002620
2021-12-13 01:56:03,025 iteration 6639 : loss : 0.015153, loss_ce: 0.005013
2021-12-13 01:56:04,517 iteration 6640 : loss : 0.013719, loss_ce: 0.004102
2021-12-13 01:56:05,964 iteration 6641 : loss : 0.013214, loss_ce: 0.004989
2021-12-13 01:56:07,426 iteration 6642 : loss : 0.011815, loss_ce: 0.003454
2021-12-13 01:56:08,956 iteration 6643 : loss : 0.015761, loss_ce: 0.006352
2021-12-13 01:56:10,501 iteration 6644 : loss : 0.014294, loss_ce: 0.005939
2021-12-13 01:56:11,951 iteration 6645 : loss : 0.019940, loss_ce: 0.008013
2021-12-13 01:56:13,422 iteration 6646 : loss : 0.011653, loss_ce: 0.005274
2021-12-13 01:56:14,914 iteration 6647 : loss : 0.023628, loss_ce: 0.004344
 98%|████████████████████████████▎| 391/400 [2:56:33<04:07, 27.45s/it]2021-12-13 01:56:16,464 iteration 6648 : loss : 0.014322, loss_ce: 0.005009
2021-12-13 01:56:17,961 iteration 6649 : loss : 0.019368, loss_ce: 0.005555
2021-12-13 01:56:19,378 iteration 6650 : loss : 0.013752, loss_ce: 0.004716
2021-12-13 01:56:20,829 iteration 6651 : loss : 0.013826, loss_ce: 0.005795
2021-12-13 01:56:22,324 iteration 6652 : loss : 0.011477, loss_ce: 0.004237
2021-12-13 01:56:23,832 iteration 6653 : loss : 0.011877, loss_ce: 0.003901
2021-12-13 01:56:25,389 iteration 6654 : loss : 0.017534, loss_ce: 0.005837
2021-12-13 01:56:26,824 iteration 6655 : loss : 0.013211, loss_ce: 0.006422
2021-12-13 01:56:28,368 iteration 6656 : loss : 0.015986, loss_ce: 0.006028
2021-12-13 01:56:29,855 iteration 6657 : loss : 0.018739, loss_ce: 0.006180
2021-12-13 01:56:31,380 iteration 6658 : loss : 0.019084, loss_ce: 0.007248
2021-12-13 01:56:32,849 iteration 6659 : loss : 0.019878, loss_ce: 0.006073
2021-12-13 01:56:34,296 iteration 6660 : loss : 0.010456, loss_ce: 0.004263
2021-12-13 01:56:35,705 iteration 6661 : loss : 0.010217, loss_ce: 0.003688
2021-12-13 01:56:37,198 iteration 6662 : loss : 0.019985, loss_ce: 0.008169
2021-12-13 01:56:38,648 iteration 6663 : loss : 0.009301, loss_ce: 0.003700
2021-12-13 01:56:40,156 iteration 6664 : loss : 0.010488, loss_ce: 0.004754
 98%|████████████████████████████▍| 392/400 [2:56:58<03:34, 26.79s/it]2021-12-13 01:56:41,667 iteration 6665 : loss : 0.016034, loss_ce: 0.005725
2021-12-13 01:56:43,165 iteration 6666 : loss : 0.010471, loss_ce: 0.003346
2021-12-13 01:56:44,640 iteration 6667 : loss : 0.013965, loss_ce: 0.005831
2021-12-13 01:56:46,229 iteration 6668 : loss : 0.016136, loss_ce: 0.008652
2021-12-13 01:56:47,634 iteration 6669 : loss : 0.014124, loss_ce: 0.005220
2021-12-13 01:56:49,056 iteration 6670 : loss : 0.011717, loss_ce: 0.004368
2021-12-13 01:56:50,491 iteration 6671 : loss : 0.011896, loss_ce: 0.005115
2021-12-13 01:56:51,869 iteration 6672 : loss : 0.011158, loss_ce: 0.002721
2021-12-13 01:56:53,357 iteration 6673 : loss : 0.012865, loss_ce: 0.004382
2021-12-13 01:56:54,829 iteration 6674 : loss : 0.014087, loss_ce: 0.005549
2021-12-13 01:56:56,348 iteration 6675 : loss : 0.012029, loss_ce: 0.003745
2021-12-13 01:56:57,766 iteration 6676 : loss : 0.010213, loss_ce: 0.003075
2021-12-13 01:56:59,218 iteration 6677 : loss : 0.014940, loss_ce: 0.003513
2021-12-13 01:57:00,573 iteration 6678 : loss : 0.008348, loss_ce: 0.003560
2021-12-13 01:57:02,139 iteration 6679 : loss : 0.012792, loss_ce: 0.005783
2021-12-13 01:57:03,584 iteration 6680 : loss : 0.018149, loss_ce: 0.006770
2021-12-13 01:57:05,084 iteration 6681 : loss : 0.014881, loss_ce: 0.005979
 98%|████████████████████████████▍| 393/400 [2:57:23<03:03, 26.23s/it]2021-12-13 01:57:06,593 iteration 6682 : loss : 0.010943, loss_ce: 0.005101
2021-12-13 01:57:08,136 iteration 6683 : loss : 0.012145, loss_ce: 0.004019
2021-12-13 01:57:09,552 iteration 6684 : loss : 0.011494, loss_ce: 0.003786
2021-12-13 01:57:11,060 iteration 6685 : loss : 0.019211, loss_ce: 0.008420
2021-12-13 01:57:12,467 iteration 6686 : loss : 0.012247, loss_ce: 0.005305
2021-12-13 01:57:13,929 iteration 6687 : loss : 0.011007, loss_ce: 0.002228
2021-12-13 01:57:15,434 iteration 6688 : loss : 0.012057, loss_ce: 0.004781
2021-12-13 01:57:16,848 iteration 6689 : loss : 0.010169, loss_ce: 0.003853
2021-12-13 01:57:18,267 iteration 6690 : loss : 0.011907, loss_ce: 0.004783
2021-12-13 01:57:19,779 iteration 6691 : loss : 0.016503, loss_ce: 0.006100
2021-12-13 01:57:21,272 iteration 6692 : loss : 0.014426, loss_ce: 0.003759
2021-12-13 01:57:22,792 iteration 6693 : loss : 0.010428, loss_ce: 0.003379
2021-12-13 01:57:24,290 iteration 6694 : loss : 0.016614, loss_ce: 0.006899
2021-12-13 01:57:25,809 iteration 6695 : loss : 0.014696, loss_ce: 0.006033
2021-12-13 01:57:27,233 iteration 6696 : loss : 0.009924, loss_ce: 0.004341
2021-12-13 01:57:28,758 iteration 6697 : loss : 0.013457, loss_ce: 0.004750
2021-12-13 01:57:30,221 iteration 6698 : loss : 0.012039, loss_ce: 0.004024
 98%|████████████████████████████▌| 394/400 [2:57:48<02:35, 25.90s/it]2021-12-13 01:57:31,690 iteration 6699 : loss : 0.010555, loss_ce: 0.005412
2021-12-13 01:57:33,223 iteration 6700 : loss : 0.017345, loss_ce: 0.007507
2021-12-13 01:57:34,664 iteration 6701 : loss : 0.010746, loss_ce: 0.004552
2021-12-13 01:57:36,088 iteration 6702 : loss : 0.012846, loss_ce: 0.004010
2021-12-13 01:57:37,541 iteration 6703 : loss : 0.012924, loss_ce: 0.004551
2021-12-13 01:57:39,048 iteration 6704 : loss : 0.011738, loss_ce: 0.003645
2021-12-13 01:57:40,479 iteration 6705 : loss : 0.016473, loss_ce: 0.005269
2021-12-13 01:57:41,905 iteration 6706 : loss : 0.009223, loss_ce: 0.004582
2021-12-13 01:57:43,341 iteration 6707 : loss : 0.013695, loss_ce: 0.003885
2021-12-13 01:57:44,743 iteration 6708 : loss : 0.011780, loss_ce: 0.004173
2021-12-13 01:57:46,168 iteration 6709 : loss : 0.010372, loss_ce: 0.003556
2021-12-13 01:57:47,588 iteration 6710 : loss : 0.011848, loss_ce: 0.004110
2021-12-13 01:57:49,003 iteration 6711 : loss : 0.014531, loss_ce: 0.002514
2021-12-13 01:57:50,487 iteration 6712 : loss : 0.014301, loss_ce: 0.005195
2021-12-13 01:57:52,017 iteration 6713 : loss : 0.014174, loss_ce: 0.004592
2021-12-13 01:57:53,497 iteration 6714 : loss : 0.013918, loss_ce: 0.006494
2021-12-13 01:57:53,497 Training Data Eval:
2021-12-13 01:58:01,006   Average segmentation loss on training set: 0.0059
2021-12-13 01:58:01,006 Validation Data Eval:
2021-12-13 01:58:03,611   Average segmentation loss on validation set: 0.0847
2021-12-13 01:58:05,130 iteration 6715 : loss : 0.012133, loss_ce: 0.004268
 99%|████████████████████████████▋| 395/400 [2:58:23<02:23, 28.61s/it]2021-12-13 01:58:06,644 iteration 6716 : loss : 0.007169, loss_ce: 0.002649
2021-12-13 01:58:08,107 iteration 6717 : loss : 0.014178, loss_ce: 0.005464
2021-12-13 01:58:09,518 iteration 6718 : loss : 0.010530, loss_ce: 0.003263
2021-12-13 01:58:10,962 iteration 6719 : loss : 0.010243, loss_ce: 0.003262
2021-12-13 01:58:12,430 iteration 6720 : loss : 0.025827, loss_ce: 0.015335
2021-12-13 01:58:13,945 iteration 6721 : loss : 0.017663, loss_ce: 0.007395
2021-12-13 01:58:15,452 iteration 6722 : loss : 0.017260, loss_ce: 0.004432
2021-12-13 01:58:16,896 iteration 6723 : loss : 0.013974, loss_ce: 0.005495
2021-12-13 01:58:18,328 iteration 6724 : loss : 0.010482, loss_ce: 0.004449
2021-12-13 01:58:19,826 iteration 6725 : loss : 0.012365, loss_ce: 0.005253
2021-12-13 01:58:21,300 iteration 6726 : loss : 0.014832, loss_ce: 0.004308
2021-12-13 01:58:22,794 iteration 6727 : loss : 0.015469, loss_ce: 0.006501
2021-12-13 01:58:24,278 iteration 6728 : loss : 0.013688, loss_ce: 0.006435
2021-12-13 01:58:25,686 iteration 6729 : loss : 0.010868, loss_ce: 0.003457
2021-12-13 01:58:27,116 iteration 6730 : loss : 0.013244, loss_ce: 0.004574
2021-12-13 01:58:28,547 iteration 6731 : loss : 0.010244, loss_ce: 0.004267
2021-12-13 01:58:30,008 iteration 6732 : loss : 0.010497, loss_ce: 0.005080
 99%|████████████████████████████▋| 396/400 [2:58:48<01:49, 27.48s/it]2021-12-13 01:58:31,543 iteration 6733 : loss : 0.012988, loss_ce: 0.005845
2021-12-13 01:58:32,965 iteration 6734 : loss : 0.005644, loss_ce: 0.001819
2021-12-13 01:58:34,449 iteration 6735 : loss : 0.012017, loss_ce: 0.005857
2021-12-13 01:58:35,912 iteration 6736 : loss : 0.011403, loss_ce: 0.003643
2021-12-13 01:58:37,352 iteration 6737 : loss : 0.012362, loss_ce: 0.006196
2021-12-13 01:58:38,816 iteration 6738 : loss : 0.010617, loss_ce: 0.004239
2021-12-13 01:58:40,309 iteration 6739 : loss : 0.016051, loss_ce: 0.006347
2021-12-13 01:58:41,844 iteration 6740 : loss : 0.016938, loss_ce: 0.005886
2021-12-13 01:58:43,250 iteration 6741 : loss : 0.008853, loss_ce: 0.003405
2021-12-13 01:58:44,744 iteration 6742 : loss : 0.012431, loss_ce: 0.005078
2021-12-13 01:58:46,224 iteration 6743 : loss : 0.012047, loss_ce: 0.003928
2021-12-13 01:58:47,768 iteration 6744 : loss : 0.012596, loss_ce: 0.005354
2021-12-13 01:58:49,204 iteration 6745 : loss : 0.012900, loss_ce: 0.003762
2021-12-13 01:58:50,639 iteration 6746 : loss : 0.016363, loss_ce: 0.006315
2021-12-13 01:58:52,088 iteration 6747 : loss : 0.012283, loss_ce: 0.004337
2021-12-13 01:58:53,567 iteration 6748 : loss : 0.012597, loss_ce: 0.004739
2021-12-13 01:58:55,071 iteration 6749 : loss : 0.017753, loss_ce: 0.005818
 99%|████████████████████████████▊| 397/400 [2:59:13<01:20, 26.76s/it]2021-12-13 01:58:56,563 iteration 6750 : loss : 0.011975, loss_ce: 0.004376
2021-12-13 01:58:58,067 iteration 6751 : loss : 0.014391, loss_ce: 0.006709
2021-12-13 01:58:59,555 iteration 6752 : loss : 0.018337, loss_ce: 0.008389
2021-12-13 01:59:01,027 iteration 6753 : loss : 0.013366, loss_ce: 0.006794
2021-12-13 01:59:02,542 iteration 6754 : loss : 0.020447, loss_ce: 0.005847
2021-12-13 01:59:03,992 iteration 6755 : loss : 0.006791, loss_ce: 0.002040
2021-12-13 01:59:05,457 iteration 6756 : loss : 0.009116, loss_ce: 0.003398
2021-12-13 01:59:06,936 iteration 6757 : loss : 0.012403, loss_ce: 0.005724
2021-12-13 01:59:08,359 iteration 6758 : loss : 0.007647, loss_ce: 0.003165
2021-12-13 01:59:09,863 iteration 6759 : loss : 0.012875, loss_ce: 0.004758
2021-12-13 01:59:11,323 iteration 6760 : loss : 0.013630, loss_ce: 0.005210
2021-12-13 01:59:12,826 iteration 6761 : loss : 0.011561, loss_ce: 0.004692
2021-12-13 01:59:14,185 iteration 6762 : loss : 0.008498, loss_ce: 0.002987
2021-12-13 01:59:15,653 iteration 6763 : loss : 0.013666, loss_ce: 0.003170
2021-12-13 01:59:17,091 iteration 6764 : loss : 0.014995, loss_ce: 0.004977
2021-12-13 01:59:18,504 iteration 6765 : loss : 0.011689, loss_ce: 0.003057
2021-12-13 01:59:19,942 iteration 6766 : loss : 0.013128, loss_ce: 0.005061
100%|████████████████████████████▊| 398/400 [2:59:38<00:52, 26.19s/it]2021-12-13 01:59:21,544 iteration 6767 : loss : 0.011861, loss_ce: 0.003924
2021-12-13 01:59:22,949 iteration 6768 : loss : 0.010481, loss_ce: 0.004893
2021-12-13 01:59:24,417 iteration 6769 : loss : 0.014150, loss_ce: 0.004557
2021-12-13 01:59:25,834 iteration 6770 : loss : 0.010085, loss_ce: 0.004005
2021-12-13 01:59:27,290 iteration 6771 : loss : 0.015678, loss_ce: 0.005817
2021-12-13 01:59:28,813 iteration 6772 : loss : 0.014335, loss_ce: 0.004028
2021-12-13 01:59:30,289 iteration 6773 : loss : 0.011768, loss_ce: 0.004992
2021-12-13 01:59:31,740 iteration 6774 : loss : 0.011892, loss_ce: 0.004804
2021-12-13 01:59:33,189 iteration 6775 : loss : 0.012254, loss_ce: 0.004576
2021-12-13 01:59:34,704 iteration 6776 : loss : 0.017822, loss_ce: 0.007493
2021-12-13 01:59:36,165 iteration 6777 : loss : 0.011633, loss_ce: 0.004366
2021-12-13 01:59:37,579 iteration 6778 : loss : 0.009128, loss_ce: 0.002868
2021-12-13 01:59:39,007 iteration 6779 : loss : 0.012198, loss_ce: 0.003803
2021-12-13 01:59:40,396 iteration 6780 : loss : 0.008664, loss_ce: 0.002988
2021-12-13 01:59:41,817 iteration 6781 : loss : 0.016405, loss_ce: 0.007070
2021-12-13 01:59:43,285 iteration 6782 : loss : 0.008469, loss_ce: 0.003373
2021-12-13 01:59:44,735 iteration 6783 : loss : 0.014019, loss_ce: 0.005968
100%|████████████████████████████▉| 399/400 [3:00:02<00:25, 25.78s/it]2021-12-13 01:59:46,336 iteration 6784 : loss : 0.020281, loss_ce: 0.006293
2021-12-13 01:59:47,745 iteration 6785 : loss : 0.013661, loss_ce: 0.006283
2021-12-13 01:59:49,126 iteration 6786 : loss : 0.011133, loss_ce: 0.005892
2021-12-13 01:59:50,612 iteration 6787 : loss : 0.013143, loss_ce: 0.004905
2021-12-13 01:59:52,009 iteration 6788 : loss : 0.014294, loss_ce: 0.003269
2021-12-13 01:59:53,496 iteration 6789 : loss : 0.008749, loss_ce: 0.003443
2021-12-13 01:59:54,981 iteration 6790 : loss : 0.010088, loss_ce: 0.003174
2021-12-13 01:59:56,516 iteration 6791 : loss : 0.018327, loss_ce: 0.005659
2021-12-13 01:59:58,005 iteration 6792 : loss : 0.013196, loss_ce: 0.004751
2021-12-13 01:59:59,465 iteration 6793 : loss : 0.012653, loss_ce: 0.003792
2021-12-13 02:00:00,935 iteration 6794 : loss : 0.012967, loss_ce: 0.004828
2021-12-13 02:00:02,373 iteration 6795 : loss : 0.009359, loss_ce: 0.003278
2021-12-13 02:00:03,837 iteration 6796 : loss : 0.013115, loss_ce: 0.004768
2021-12-13 02:00:05,271 iteration 6797 : loss : 0.013020, loss_ce: 0.004751
2021-12-13 02:00:06,662 iteration 6798 : loss : 0.010391, loss_ce: 0.003776
2021-12-13 02:00:08,118 iteration 6799 : loss : 0.014583, loss_ce: 0.007310
2021-12-13 02:00:08,118 Training Data Eval:
2021-12-13 02:00:15,633   Average segmentation loss on training set: 0.0060
2021-12-13 02:00:15,634 Validation Data Eval:
2021-12-13 02:00:18,234   Average segmentation loss on validation set: 0.0788
2021-12-13 02:00:19,694 iteration 6800 : loss : 0.009941, loss_ce: 0.004556
100%|█████████████████████████████| 400/400 [3:00:37<00:00, 28.53s/it]100%|█████████████████████████████| 400/400 [3:00:37<00:00, 27.09s/it]
