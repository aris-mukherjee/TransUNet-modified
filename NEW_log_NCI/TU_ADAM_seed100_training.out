2021-12-12 23:01:49,664 load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 256, 768])
load_pretrained: grid-size from 14 to 16
2021-12-12 23:01:50,736 Logging directory: /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/TransUNet/log_dir/trRUNMC_cv1_r3/i2i2l/
2021-12-12 23:01:50,736 Tensorboard directory: /scratch_net/biwidl217_second/arismu/Tensorboard/trRUNMC_cv1_r3/i2i2l/
2021-12-12 23:01:50,736 ============================================================
2021-12-12 23:01:50,736 EXPERIMENT NAME: trRUNMC_cv1_r3/i2i2l/
2021-12-12 23:01:50,736 ============================================================
2021-12-12 23:01:50,736 Loading data...
2021-12-12 23:01:50,736 Reading NCI - RUNMC images...
2021-12-12 23:01:50,736 Data root directory: /itet-stor/arismu/bmicdatasets-originals/Originals/Challenge_Datasets/NCI_Prostate/
2021-12-12 23:01:50,738 Already preprocessed this configuration. Loading now!
2021-12-12 23:01:50,762 Training Images: (256, 256, 286)
2021-12-12 23:01:50,762 Training Labels: (256, 256, 286)
2021-12-12 23:01:50,762 Validation Images: (256, 256, 98)
2021-12-12 23:01:50,762 Validation Labels: (256, 256, 98)
2021-12-12 23:01:50,762 ============================================================
2021-12-12 23:01:50,806 17 iterations per epoch. 6800 max iterations 
  0%|                                         | 0/400 [00:00<?, ?it/s]2021-12-12 23:01:53,304 iteration 1 : loss : 0.960786, loss_ce: 1.181713
2021-12-12 23:01:54,652 iteration 2 : loss : 0.919915, loss_ce: 1.092101
2021-12-12 23:01:56,019 iteration 3 : loss : 0.875265, loss_ce: 1.001750
2021-12-12 23:01:57,399 iteration 4 : loss : 0.802155, loss_ce: 0.911262
2021-12-12 23:01:58,685 iteration 5 : loss : 0.776474, loss_ce: 0.850080
2021-12-12 23:02:00,089 iteration 6 : loss : 0.728554, loss_ce: 0.774806
2021-12-12 23:02:01,462 iteration 7 : loss : 0.683602, loss_ce: 0.700056
2021-12-12 23:02:02,833 iteration 8 : loss : 0.641787, loss_ce: 0.639347
2021-12-12 23:02:04,099 iteration 9 : loss : 0.580542, loss_ce: 0.579633
2021-12-12 23:02:05,483 iteration 10 : loss : 0.557979, loss_ce: 0.537087
2021-12-12 23:02:06,874 iteration 11 : loss : 0.544488, loss_ce: 0.500043
2021-12-12 23:02:08,296 iteration 12 : loss : 0.504345, loss_ce: 0.453250
2021-12-12 23:02:09,627 iteration 13 : loss : 0.487888, loss_ce: 0.414665
2021-12-12 23:02:11,056 iteration 14 : loss : 0.457139, loss_ce: 0.374646
2021-12-12 23:02:12,416 iteration 15 : loss : 0.437654, loss_ce: 0.339424
2021-12-12 23:02:13,751 iteration 16 : loss : 0.403928, loss_ce: 0.309270
2021-12-12 23:02:15,059 iteration 17 : loss : 0.415812, loss_ce: 0.285029
  0%|                               | 1/400 [00:24<2:42:00, 24.36s/it]2021-12-12 23:02:16,546 iteration 18 : loss : 0.370368, loss_ce: 0.258982
2021-12-12 23:02:17,937 iteration 19 : loss : 0.381175, loss_ce: 0.233344
2021-12-12 23:02:19,418 iteration 20 : loss : 0.359827, loss_ce: 0.232489
2021-12-12 23:02:20,752 iteration 21 : loss : 0.336891, loss_ce: 0.207582
2021-12-12 23:02:22,037 iteration 22 : loss : 0.344872, loss_ce: 0.196735
2021-12-12 23:02:23,441 iteration 23 : loss : 0.310629, loss_ce: 0.174920
2021-12-12 23:02:24,846 iteration 24 : loss : 0.307293, loss_ce: 0.175962
2021-12-12 23:02:26,279 iteration 25 : loss : 0.303612, loss_ce: 0.192219
2021-12-12 23:02:27,631 iteration 26 : loss : 0.290358, loss_ce: 0.168300
2021-12-12 23:02:28,937 iteration 27 : loss : 0.279351, loss_ce: 0.149950
2021-12-12 23:02:30,231 iteration 28 : loss : 0.278456, loss_ce: 0.141473
2021-12-12 23:02:31,616 iteration 29 : loss : 0.293676, loss_ce: 0.150936
2021-12-12 23:02:32,943 iteration 30 : loss : 0.257149, loss_ce: 0.135480
2021-12-12 23:02:34,254 iteration 31 : loss : 0.283322, loss_ce: 0.133500
2021-12-12 23:02:35,600 iteration 32 : loss : 0.270178, loss_ce: 0.149627
2021-12-12 23:02:36,992 iteration 33 : loss : 0.242849, loss_ce: 0.119282
2021-12-12 23:02:38,444 iteration 34 : loss : 0.237852, loss_ce: 0.116033
  0%|▏                              | 2/400 [00:47<2:37:31, 23.75s/it]2021-12-12 23:02:39,871 iteration 35 : loss : 0.255048, loss_ce: 0.124791
2021-12-12 23:02:41,245 iteration 36 : loss : 0.269367, loss_ce: 0.106911
2021-12-12 23:02:42,645 iteration 37 : loss : 0.227610, loss_ce: 0.099667
2021-12-12 23:02:44,013 iteration 38 : loss : 0.250935, loss_ce: 0.104831
2021-12-12 23:02:45,295 iteration 39 : loss : 0.217673, loss_ce: 0.087449
2021-12-12 23:02:46,636 iteration 40 : loss : 0.239353, loss_ce: 0.111398
2021-12-12 23:02:47,905 iteration 41 : loss : 0.216173, loss_ce: 0.093232
2021-12-12 23:02:49,306 iteration 42 : loss : 0.206356, loss_ce: 0.090796
2021-12-12 23:02:50,688 iteration 43 : loss : 0.201341, loss_ce: 0.087741
2021-12-12 23:02:51,970 iteration 44 : loss : 0.204593, loss_ce: 0.101528
2021-12-12 23:02:53,401 iteration 45 : loss : 0.220769, loss_ce: 0.098844
2021-12-12 23:02:54,775 iteration 46 : loss : 0.199084, loss_ce: 0.086115
2021-12-12 23:02:56,147 iteration 47 : loss : 0.193717, loss_ce: 0.074172
2021-12-12 23:02:57,519 iteration 48 : loss : 0.245144, loss_ce: 0.119997
2021-12-12 23:02:58,940 iteration 49 : loss : 0.217304, loss_ce: 0.083148
2021-12-12 23:03:00,360 iteration 50 : loss : 0.197492, loss_ce: 0.075668
2021-12-12 23:03:01,796 iteration 51 : loss : 0.214183, loss_ce: 0.093419
  1%|▏                              | 3/400 [01:11<2:35:56, 23.57s/it]2021-12-12 23:03:03,150 iteration 52 : loss : 0.203028, loss_ce: 0.081041
2021-12-12 23:03:04,445 iteration 53 : loss : 0.202282, loss_ce: 0.086365
2021-12-12 23:03:05,868 iteration 54 : loss : 0.199211, loss_ce: 0.083250
2021-12-12 23:03:07,268 iteration 55 : loss : 0.215219, loss_ce: 0.082899
2021-12-12 23:03:08,721 iteration 56 : loss : 0.212902, loss_ce: 0.097312
2021-12-12 23:03:10,138 iteration 57 : loss : 0.199609, loss_ce: 0.083601
2021-12-12 23:03:11,552 iteration 58 : loss : 0.191144, loss_ce: 0.082647
2021-12-12 23:03:12,966 iteration 59 : loss : 0.173484, loss_ce: 0.068264
2021-12-12 23:03:14,396 iteration 60 : loss : 0.171444, loss_ce: 0.071462
2021-12-12 23:03:15,831 iteration 61 : loss : 0.187592, loss_ce: 0.079958
2021-12-12 23:03:17,339 iteration 62 : loss : 0.206427, loss_ce: 0.069665
2021-12-12 23:03:18,718 iteration 63 : loss : 0.198193, loss_ce: 0.073718
2021-12-12 23:03:20,151 iteration 64 : loss : 0.215858, loss_ce: 0.098211
2021-12-12 23:03:21,575 iteration 65 : loss : 0.220010, loss_ce: 0.086489
2021-12-12 23:03:23,052 iteration 66 : loss : 0.192428, loss_ce: 0.073798
2021-12-12 23:03:24,467 iteration 67 : loss : 0.195799, loss_ce: 0.077533
2021-12-12 23:03:25,839 iteration 68 : loss : 0.205607, loss_ce: 0.084327
  1%|▎                              | 4/400 [01:35<2:36:46, 23.75s/it]2021-12-12 23:03:27,369 iteration 69 : loss : 0.170481, loss_ce: 0.059965
2021-12-12 23:03:28,791 iteration 70 : loss : 0.197130, loss_ce: 0.065104
2021-12-12 23:03:30,224 iteration 71 : loss : 0.195700, loss_ce: 0.081416
2021-12-12 23:03:31,662 iteration 72 : loss : 0.167869, loss_ce: 0.063843
2021-12-12 23:03:33,114 iteration 73 : loss : 0.173174, loss_ce: 0.057681
2021-12-12 23:03:34,554 iteration 74 : loss : 0.194277, loss_ce: 0.075010
2021-12-12 23:03:35,957 iteration 75 : loss : 0.162322, loss_ce: 0.069154
2021-12-12 23:03:37,321 iteration 76 : loss : 0.165938, loss_ce: 0.061212
2021-12-12 23:03:38,783 iteration 77 : loss : 0.176565, loss_ce: 0.065179
2021-12-12 23:03:40,224 iteration 78 : loss : 0.174295, loss_ce: 0.060876
2021-12-12 23:03:41,666 iteration 79 : loss : 0.186101, loss_ce: 0.058253
2021-12-12 23:03:43,009 iteration 80 : loss : 0.151725, loss_ce: 0.048713
2021-12-12 23:03:44,502 iteration 81 : loss : 0.196636, loss_ce: 0.079559
2021-12-12 23:03:45,921 iteration 82 : loss : 0.196810, loss_ce: 0.063655
2021-12-12 23:03:47,318 iteration 83 : loss : 0.249679, loss_ce: 0.081249
2021-12-12 23:03:48,829 iteration 84 : loss : 0.210555, loss_ce: 0.086949
2021-12-12 23:03:48,830 Training Data Eval:
2021-12-12 23:03:56,222   Average segmentation loss on training set: 0.4108
2021-12-12 23:03:56,223 Validation Data Eval:
2021-12-12 23:03:58,918   Average segmentation loss on validation set: 0.3585
2021-12-12 23:04:05,234 Found new lowest validation loss at iteration 84! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-12 23:04:06,552 iteration 85 : loss : 0.189170, loss_ce: 0.074819
  1%|▍                              | 5/400 [02:15<3:16:39, 29.87s/it]2021-12-12 23:04:07,996 iteration 86 : loss : 0.175488, loss_ce: 0.071024
2021-12-12 23:04:09,347 iteration 87 : loss : 0.168567, loss_ce: 0.058332
2021-12-12 23:04:10,657 iteration 88 : loss : 0.179570, loss_ce: 0.075615
2021-12-12 23:04:12,033 iteration 89 : loss : 0.193999, loss_ce: 0.064220
2021-12-12 23:04:13,391 iteration 90 : loss : 0.164693, loss_ce: 0.063696
2021-12-12 23:04:14,802 iteration 91 : loss : 0.169975, loss_ce: 0.066327
2021-12-12 23:04:16,225 iteration 92 : loss : 0.163812, loss_ce: 0.052232
2021-12-12 23:04:17,536 iteration 93 : loss : 0.172871, loss_ce: 0.050911
2021-12-12 23:04:18,946 iteration 94 : loss : 0.156304, loss_ce: 0.053213
2021-12-12 23:04:20,310 iteration 95 : loss : 0.176558, loss_ce: 0.067005
2021-12-12 23:04:21,755 iteration 96 : loss : 0.167180, loss_ce: 0.057350
2021-12-12 23:04:23,160 iteration 97 : loss : 0.198782, loss_ce: 0.073152
2021-12-12 23:04:24,637 iteration 98 : loss : 0.231067, loss_ce: 0.085351
2021-12-12 23:04:26,099 iteration 99 : loss : 0.195314, loss_ce: 0.067516
2021-12-12 23:04:27,607 iteration 100 : loss : 0.163041, loss_ce: 0.058793
2021-12-12 23:04:29,058 iteration 101 : loss : 0.161402, loss_ce: 0.056443
2021-12-12 23:04:30,495 iteration 102 : loss : 0.173123, loss_ce: 0.067457
  2%|▍                              | 6/400 [02:39<3:02:54, 27.85s/it]2021-12-12 23:04:32,011 iteration 103 : loss : 0.164983, loss_ce: 0.049537
2021-12-12 23:04:33,524 iteration 104 : loss : 0.180369, loss_ce: 0.065488
2021-12-12 23:04:35,026 iteration 105 : loss : 0.162942, loss_ce: 0.055219
2021-12-12 23:04:36,591 iteration 106 : loss : 0.182856, loss_ce: 0.057331
2021-12-12 23:04:38,066 iteration 107 : loss : 0.167902, loss_ce: 0.049917
2021-12-12 23:04:39,499 iteration 108 : loss : 0.172990, loss_ce: 0.050488
2021-12-12 23:04:40,888 iteration 109 : loss : 0.215726, loss_ce: 0.074040
2021-12-12 23:04:42,308 iteration 110 : loss : 0.165567, loss_ce: 0.065835
2021-12-12 23:04:43,817 iteration 111 : loss : 0.154508, loss_ce: 0.058909
2021-12-12 23:04:45,265 iteration 112 : loss : 0.175789, loss_ce: 0.065868
2021-12-12 23:04:46,656 iteration 113 : loss : 0.154274, loss_ce: 0.051343
2021-12-12 23:04:48,130 iteration 114 : loss : 0.180915, loss_ce: 0.062900
2021-12-12 23:04:49,556 iteration 115 : loss : 0.188670, loss_ce: 0.082814
2021-12-12 23:04:51,043 iteration 116 : loss : 0.162510, loss_ce: 0.062239
2021-12-12 23:04:52,481 iteration 117 : loss : 0.172550, loss_ce: 0.069939
2021-12-12 23:04:53,931 iteration 118 : loss : 0.191211, loss_ce: 0.082376
2021-12-12 23:04:55,395 iteration 119 : loss : 0.153232, loss_ce: 0.057763
  2%|▌                              | 7/400 [03:04<2:56:07, 26.89s/it]2021-12-12 23:04:56,952 iteration 120 : loss : 0.167368, loss_ce: 0.063151
2021-12-12 23:04:58,435 iteration 121 : loss : 0.190994, loss_ce: 0.067609
2021-12-12 23:04:59,814 iteration 122 : loss : 0.166657, loss_ce: 0.066663
2021-12-12 23:05:01,303 iteration 123 : loss : 0.147915, loss_ce: 0.056496
2021-12-12 23:05:02,797 iteration 124 : loss : 0.138029, loss_ce: 0.043496
2021-12-12 23:05:04,238 iteration 125 : loss : 0.144757, loss_ce: 0.060719
2021-12-12 23:05:05,721 iteration 126 : loss : 0.172537, loss_ce: 0.062333
2021-12-12 23:05:07,219 iteration 127 : loss : 0.141601, loss_ce: 0.055009
2021-12-12 23:05:08,734 iteration 128 : loss : 0.143405, loss_ce: 0.061393
2021-12-12 23:05:10,162 iteration 129 : loss : 0.156324, loss_ce: 0.054225
2021-12-12 23:05:11,668 iteration 130 : loss : 0.157431, loss_ce: 0.070283
2021-12-12 23:05:13,104 iteration 131 : loss : 0.127145, loss_ce: 0.049628
2021-12-12 23:05:14,501 iteration 132 : loss : 0.165625, loss_ce: 0.057965
2021-12-12 23:05:16,001 iteration 133 : loss : 0.150977, loss_ce: 0.050185
2021-12-12 23:05:17,466 iteration 134 : loss : 0.139794, loss_ce: 0.053949
2021-12-12 23:05:18,936 iteration 135 : loss : 0.157321, loss_ce: 0.056856
2021-12-12 23:05:20,381 iteration 136 : loss : 0.141497, loss_ce: 0.060562
  2%|▌                              | 8/400 [03:29<2:51:41, 26.28s/it]2021-12-12 23:05:21,819 iteration 137 : loss : 0.143404, loss_ce: 0.046694
2021-12-12 23:05:23,246 iteration 138 : loss : 0.115517, loss_ce: 0.065683
2021-12-12 23:05:24,754 iteration 139 : loss : 0.151115, loss_ce: 0.059054
2021-12-12 23:05:26,292 iteration 140 : loss : 0.168249, loss_ce: 0.068235
2021-12-12 23:05:27,754 iteration 141 : loss : 0.172651, loss_ce: 0.064962
2021-12-12 23:05:29,165 iteration 142 : loss : 0.114355, loss_ce: 0.046610
2021-12-12 23:05:30,585 iteration 143 : loss : 0.103476, loss_ce: 0.041278
2021-12-12 23:05:32,084 iteration 144 : loss : 0.123954, loss_ce: 0.046741
2021-12-12 23:05:33,707 iteration 145 : loss : 0.157228, loss_ce: 0.067735
2021-12-12 23:05:35,128 iteration 146 : loss : 0.111823, loss_ce: 0.041548
2021-12-12 23:05:36,572 iteration 147 : loss : 0.122777, loss_ce: 0.054224
2021-12-12 23:05:38,033 iteration 148 : loss : 0.105277, loss_ce: 0.048836
2021-12-12 23:05:39,495 iteration 149 : loss : 0.137400, loss_ce: 0.057471
2021-12-12 23:05:40,942 iteration 150 : loss : 0.154183, loss_ce: 0.059592
2021-12-12 23:05:42,387 iteration 151 : loss : 0.115415, loss_ce: 0.047558
2021-12-12 23:05:43,899 iteration 152 : loss : 0.100495, loss_ce: 0.041268
2021-12-12 23:05:45,419 iteration 153 : loss : 0.122317, loss_ce: 0.066245
  2%|▋                              | 9/400 [03:54<2:48:44, 25.89s/it]2021-12-12 23:05:46,919 iteration 154 : loss : 0.118922, loss_ce: 0.048198
2021-12-12 23:05:48,395 iteration 155 : loss : 0.122861, loss_ce: 0.051718
2021-12-12 23:05:49,864 iteration 156 : loss : 0.147065, loss_ce: 0.062144
2021-12-12 23:05:51,349 iteration 157 : loss : 0.149741, loss_ce: 0.054591
2021-12-12 23:05:52,826 iteration 158 : loss : 0.110986, loss_ce: 0.049732
2021-12-12 23:05:54,289 iteration 159 : loss : 0.125319, loss_ce: 0.053099
2021-12-12 23:05:55,736 iteration 160 : loss : 0.161218, loss_ce: 0.052420
2021-12-12 23:05:57,223 iteration 161 : loss : 0.095284, loss_ce: 0.039345
2021-12-12 23:05:58,771 iteration 162 : loss : 0.130913, loss_ce: 0.061864
2021-12-12 23:06:00,130 iteration 163 : loss : 0.096097, loss_ce: 0.039515
2021-12-12 23:06:01,638 iteration 164 : loss : 0.130619, loss_ce: 0.051869
2021-12-12 23:06:03,080 iteration 165 : loss : 0.089948, loss_ce: 0.039578
2021-12-12 23:06:04,603 iteration 166 : loss : 0.111381, loss_ce: 0.046284
2021-12-12 23:06:06,112 iteration 167 : loss : 0.088399, loss_ce: 0.044713
2021-12-12 23:06:07,610 iteration 168 : loss : 0.127514, loss_ce: 0.051115
2021-12-12 23:06:09,072 iteration 169 : loss : 0.120358, loss_ce: 0.051437
2021-12-12 23:06:09,072 Training Data Eval:
2021-12-12 23:06:16,533   Average segmentation loss on training set: 0.6291
2021-12-12 23:06:16,533 Validation Data Eval:
2021-12-12 23:06:19,130   Average segmentation loss on validation set: 0.5773
2021-12-12 23:06:20,561 iteration 170 : loss : 0.120251, loss_ce: 0.055453
  2%|▊                             | 10/400 [04:29<3:06:51, 28.75s/it]2021-12-12 23:06:22,080 iteration 171 : loss : 0.125480, loss_ce: 0.053589
2021-12-12 23:06:23,443 iteration 172 : loss : 0.185208, loss_ce: 0.066756
2021-12-12 23:06:24,856 iteration 173 : loss : 0.104325, loss_ce: 0.046176
2021-12-12 23:06:26,379 iteration 174 : loss : 0.106968, loss_ce: 0.040775
2021-12-12 23:06:27,805 iteration 175 : loss : 0.101478, loss_ce: 0.043889
2021-12-12 23:06:29,362 iteration 176 : loss : 0.118395, loss_ce: 0.044934
2021-12-12 23:06:30,819 iteration 177 : loss : 0.122678, loss_ce: 0.041546
2021-12-12 23:06:32,317 iteration 178 : loss : 0.113239, loss_ce: 0.037921
2021-12-12 23:06:33,784 iteration 179 : loss : 0.112501, loss_ce: 0.048088
2021-12-12 23:06:35,269 iteration 180 : loss : 0.172338, loss_ce: 0.058121
2021-12-12 23:06:36,762 iteration 181 : loss : 0.082059, loss_ce: 0.034049
2021-12-12 23:06:38,247 iteration 182 : loss : 0.101053, loss_ce: 0.042402
2021-12-12 23:06:39,744 iteration 183 : loss : 0.106229, loss_ce: 0.040343
2021-12-12 23:06:41,213 iteration 184 : loss : 0.091926, loss_ce: 0.038304
2021-12-12 23:06:42,652 iteration 185 : loss : 0.080862, loss_ce: 0.037962
2021-12-12 23:06:44,097 iteration 186 : loss : 0.116873, loss_ce: 0.059854
2021-12-12 23:06:45,524 iteration 187 : loss : 0.114655, loss_ce: 0.047587
  3%|▊                             | 11/400 [04:54<2:58:51, 27.59s/it]2021-12-12 23:06:47,040 iteration 188 : loss : 0.117333, loss_ce: 0.046192
2021-12-12 23:06:48,532 iteration 189 : loss : 0.103173, loss_ce: 0.042117
2021-12-12 23:06:50,037 iteration 190 : loss : 0.128977, loss_ce: 0.040560
2021-12-12 23:06:51,495 iteration 191 : loss : 0.103469, loss_ce: 0.037331
2021-12-12 23:06:52,868 iteration 192 : loss : 0.106860, loss_ce: 0.043054
2021-12-12 23:06:54,281 iteration 193 : loss : 0.107449, loss_ce: 0.038698
2021-12-12 23:06:55,691 iteration 194 : loss : 0.118331, loss_ce: 0.037761
2021-12-12 23:06:57,230 iteration 195 : loss : 0.105391, loss_ce: 0.040400
2021-12-12 23:06:58,732 iteration 196 : loss : 0.094570, loss_ce: 0.034608
2021-12-12 23:07:00,211 iteration 197 : loss : 0.101152, loss_ce: 0.040473
2021-12-12 23:07:01,713 iteration 198 : loss : 0.121181, loss_ce: 0.053735
2021-12-12 23:07:03,204 iteration 199 : loss : 0.102283, loss_ce: 0.052441
2021-12-12 23:07:04,632 iteration 200 : loss : 0.144784, loss_ce: 0.051491
2021-12-12 23:07:06,077 iteration 201 : loss : 0.104340, loss_ce: 0.040787
2021-12-12 23:07:07,432 iteration 202 : loss : 0.146659, loss_ce: 0.049734
2021-12-12 23:07:08,959 iteration 203 : loss : 0.091771, loss_ce: 0.041386
2021-12-12 23:07:10,405 iteration 204 : loss : 0.124350, loss_ce: 0.066982
  3%|▉                             | 12/400 [05:19<2:53:06, 26.77s/it]2021-12-12 23:07:11,979 iteration 205 : loss : 0.080897, loss_ce: 0.035652
2021-12-12 23:07:13,442 iteration 206 : loss : 0.103533, loss_ce: 0.036519
2021-12-12 23:07:14,960 iteration 207 : loss : 0.096312, loss_ce: 0.039045
2021-12-12 23:07:16,464 iteration 208 : loss : 0.105812, loss_ce: 0.047560
2021-12-12 23:07:17,938 iteration 209 : loss : 0.105520, loss_ce: 0.040862
2021-12-12 23:07:19,384 iteration 210 : loss : 0.099791, loss_ce: 0.044587
2021-12-12 23:07:20,841 iteration 211 : loss : 0.093790, loss_ce: 0.039808
2021-12-12 23:07:22,353 iteration 212 : loss : 0.118363, loss_ce: 0.047340
2021-12-12 23:07:23,860 iteration 213 : loss : 0.120261, loss_ce: 0.063412
2021-12-12 23:07:25,306 iteration 214 : loss : 0.085524, loss_ce: 0.038307
2021-12-12 23:07:26,728 iteration 215 : loss : 0.094257, loss_ce: 0.037243
2021-12-12 23:07:28,237 iteration 216 : loss : 0.091685, loss_ce: 0.038718
2021-12-12 23:07:29,760 iteration 217 : loss : 0.083907, loss_ce: 0.033155
2021-12-12 23:07:31,215 iteration 218 : loss : 0.119964, loss_ce: 0.058628
2021-12-12 23:07:32,652 iteration 219 : loss : 0.084040, loss_ce: 0.035690
2021-12-12 23:07:34,126 iteration 220 : loss : 0.093692, loss_ce: 0.037882
2021-12-12 23:07:35,613 iteration 221 : loss : 0.101102, loss_ce: 0.038395
  3%|▉                             | 13/400 [05:44<2:49:35, 26.29s/it]2021-12-12 23:07:37,110 iteration 222 : loss : 0.083781, loss_ce: 0.036805
2021-12-12 23:07:38,549 iteration 223 : loss : 0.090387, loss_ce: 0.039173
2021-12-12 23:07:39,998 iteration 224 : loss : 0.092509, loss_ce: 0.034985
2021-12-12 23:07:41,563 iteration 225 : loss : 0.108312, loss_ce: 0.050909
2021-12-12 23:07:43,041 iteration 226 : loss : 0.099831, loss_ce: 0.039967
2021-12-12 23:07:44,489 iteration 227 : loss : 0.072632, loss_ce: 0.028132
2021-12-12 23:07:45,936 iteration 228 : loss : 0.094816, loss_ce: 0.040546
2021-12-12 23:07:47,414 iteration 229 : loss : 0.114976, loss_ce: 0.043418
2021-12-12 23:07:48,827 iteration 230 : loss : 0.077484, loss_ce: 0.031272
2021-12-12 23:07:50,288 iteration 231 : loss : 0.102533, loss_ce: 0.037705
2021-12-12 23:07:51,739 iteration 232 : loss : 0.106872, loss_ce: 0.043117
2021-12-12 23:07:53,138 iteration 233 : loss : 0.077536, loss_ce: 0.037687
2021-12-12 23:07:54,591 iteration 234 : loss : 0.105733, loss_ce: 0.046516
2021-12-12 23:07:56,024 iteration 235 : loss : 0.099026, loss_ce: 0.041288
2021-12-12 23:07:57,483 iteration 236 : loss : 0.148553, loss_ce: 0.047357
2021-12-12 23:07:58,894 iteration 237 : loss : 0.101736, loss_ce: 0.043103
2021-12-12 23:08:00,395 iteration 238 : loss : 0.103670, loss_ce: 0.036976
  4%|█                             | 14/400 [06:09<2:46:14, 25.84s/it]2021-12-12 23:08:01,888 iteration 239 : loss : 0.088386, loss_ce: 0.032263
2021-12-12 23:08:03,434 iteration 240 : loss : 0.099235, loss_ce: 0.032665
2021-12-12 23:08:04,937 iteration 241 : loss : 0.083447, loss_ce: 0.036085
2021-12-12 23:08:06,382 iteration 242 : loss : 0.059085, loss_ce: 0.023048
2021-12-12 23:08:07,821 iteration 243 : loss : 0.068502, loss_ce: 0.028286
2021-12-12 23:08:09,283 iteration 244 : loss : 0.102034, loss_ce: 0.040449
2021-12-12 23:08:10,717 iteration 245 : loss : 0.113159, loss_ce: 0.044321
2021-12-12 23:08:12,171 iteration 246 : loss : 0.071366, loss_ce: 0.024270
2021-12-12 23:08:13,660 iteration 247 : loss : 0.095433, loss_ce: 0.046416
2021-12-12 23:08:15,161 iteration 248 : loss : 0.128337, loss_ce: 0.062364
2021-12-12 23:08:16,605 iteration 249 : loss : 0.083330, loss_ce: 0.028501
2021-12-12 23:08:18,057 iteration 250 : loss : 0.076025, loss_ce: 0.029597
2021-12-12 23:08:19,466 iteration 251 : loss : 0.089029, loss_ce: 0.041329
2021-12-12 23:08:21,001 iteration 252 : loss : 0.080306, loss_ce: 0.041415
2021-12-12 23:08:22,464 iteration 253 : loss : 0.082907, loss_ce: 0.033062
2021-12-12 23:08:23,890 iteration 254 : loss : 0.068316, loss_ce: 0.032402
2021-12-12 23:08:23,890 Training Data Eval:
2021-12-12 23:08:31,357   Average segmentation loss on training set: 0.4032
2021-12-12 23:08:31,358 Validation Data Eval:
2021-12-12 23:08:33,943   Average segmentation loss on validation set: 0.3877
2021-12-12 23:08:35,355 iteration 255 : loss : 0.077300, loss_ce: 0.035157
  4%|█▏                            | 15/400 [06:44<3:03:25, 28.59s/it]2021-12-12 23:08:36,809 iteration 256 : loss : 0.067183, loss_ce: 0.029750
2021-12-12 23:08:38,229 iteration 257 : loss : 0.069222, loss_ce: 0.029291
2021-12-12 23:08:39,737 iteration 258 : loss : 0.063768, loss_ce: 0.028545
2021-12-12 23:08:41,203 iteration 259 : loss : 0.077055, loss_ce: 0.027703
2021-12-12 23:08:42,618 iteration 260 : loss : 0.071144, loss_ce: 0.038891
2021-12-12 23:08:44,108 iteration 261 : loss : 0.090434, loss_ce: 0.035647
2021-12-12 23:08:45,622 iteration 262 : loss : 0.083956, loss_ce: 0.033239
2021-12-12 23:08:47,036 iteration 263 : loss : 0.068375, loss_ce: 0.030378
2021-12-12 23:08:48,550 iteration 264 : loss : 0.107849, loss_ce: 0.027337
2021-12-12 23:08:50,108 iteration 265 : loss : 0.128485, loss_ce: 0.056262
2021-12-12 23:08:51,589 iteration 266 : loss : 0.078304, loss_ce: 0.029388
2021-12-12 23:08:53,138 iteration 267 : loss : 0.090330, loss_ce: 0.027950
2021-12-12 23:08:54,626 iteration 268 : loss : 0.078856, loss_ce: 0.031881
2021-12-12 23:08:56,107 iteration 269 : loss : 0.115802, loss_ce: 0.041154
2021-12-12 23:08:57,560 iteration 270 : loss : 0.093663, loss_ce: 0.040899
2021-12-12 23:08:58,997 iteration 271 : loss : 0.072075, loss_ce: 0.032258
2021-12-12 23:09:00,407 iteration 272 : loss : 0.076120, loss_ce: 0.031656
  4%|█▏                            | 16/400 [07:09<2:56:09, 27.52s/it]2021-12-12 23:09:01,953 iteration 273 : loss : 0.100911, loss_ce: 0.041521
2021-12-12 23:09:03,407 iteration 274 : loss : 0.072790, loss_ce: 0.026879
2021-12-12 23:09:04,837 iteration 275 : loss : 0.126764, loss_ce: 0.039683
2021-12-12 23:09:06,278 iteration 276 : loss : 0.110342, loss_ce: 0.042122
2021-12-12 23:09:07,721 iteration 277 : loss : 0.078635, loss_ce: 0.028375
2021-12-12 23:09:09,179 iteration 278 : loss : 0.112512, loss_ce: 0.038321
2021-12-12 23:09:10,622 iteration 279 : loss : 0.092505, loss_ce: 0.036841
2021-12-12 23:09:12,072 iteration 280 : loss : 0.087532, loss_ce: 0.038295
2021-12-12 23:09:13,570 iteration 281 : loss : 0.086424, loss_ce: 0.046049
2021-12-12 23:09:15,060 iteration 282 : loss : 0.100803, loss_ce: 0.037272
2021-12-12 23:09:16,498 iteration 283 : loss : 0.086789, loss_ce: 0.037450
2021-12-12 23:09:17,979 iteration 284 : loss : 0.080905, loss_ce: 0.044717
2021-12-12 23:09:19,469 iteration 285 : loss : 0.098289, loss_ce: 0.036108
2021-12-12 23:09:20,828 iteration 286 : loss : 0.089241, loss_ce: 0.036817
2021-12-12 23:09:22,278 iteration 287 : loss : 0.078119, loss_ce: 0.031886
2021-12-12 23:09:23,749 iteration 288 : loss : 0.081936, loss_ce: 0.030627
2021-12-12 23:09:25,186 iteration 289 : loss : 0.087867, loss_ce: 0.030934
  4%|█▎                            | 17/400 [07:34<2:50:29, 26.71s/it]2021-12-12 23:09:26,751 iteration 290 : loss : 0.085724, loss_ce: 0.034635
2021-12-12 23:09:28,163 iteration 291 : loss : 0.085356, loss_ce: 0.032329
2021-12-12 23:09:29,578 iteration 292 : loss : 0.075880, loss_ce: 0.034077
2021-12-12 23:09:31,076 iteration 293 : loss : 0.078657, loss_ce: 0.032545
2021-12-12 23:09:32,510 iteration 294 : loss : 0.078921, loss_ce: 0.040988
2021-12-12 23:09:34,003 iteration 295 : loss : 0.057365, loss_ce: 0.026858
2021-12-12 23:09:35,510 iteration 296 : loss : 0.076549, loss_ce: 0.030746
2021-12-12 23:09:36,981 iteration 297 : loss : 0.084151, loss_ce: 0.041365
2021-12-12 23:09:38,414 iteration 298 : loss : 0.100277, loss_ce: 0.044940
2021-12-12 23:09:39,807 iteration 299 : loss : 0.100747, loss_ce: 0.044762
2021-12-12 23:09:41,241 iteration 300 : loss : 0.099641, loss_ce: 0.046426
2021-12-12 23:09:42,620 iteration 301 : loss : 0.093408, loss_ce: 0.039330
2021-12-12 23:09:44,123 iteration 302 : loss : 0.086997, loss_ce: 0.036675
2021-12-12 23:09:45,610 iteration 303 : loss : 0.092962, loss_ce: 0.034549
2021-12-12 23:09:47,105 iteration 304 : loss : 0.097619, loss_ce: 0.041516
2021-12-12 23:09:48,526 iteration 305 : loss : 0.053531, loss_ce: 0.022467
2021-12-12 23:09:49,963 iteration 306 : loss : 0.092853, loss_ce: 0.031720
  4%|█▎                            | 18/400 [07:59<2:46:16, 26.12s/it]2021-12-12 23:09:51,386 iteration 307 : loss : 0.071755, loss_ce: 0.023288
2021-12-12 23:09:52,768 iteration 308 : loss : 0.073609, loss_ce: 0.032357
2021-12-12 23:09:54,181 iteration 309 : loss : 0.074176, loss_ce: 0.032822
2021-12-12 23:09:55,648 iteration 310 : loss : 0.068233, loss_ce: 0.029698
2021-12-12 23:09:57,126 iteration 311 : loss : 0.071598, loss_ce: 0.030275
2021-12-12 23:09:58,619 iteration 312 : loss : 0.058982, loss_ce: 0.023731
2021-12-12 23:10:00,038 iteration 313 : loss : 0.056210, loss_ce: 0.024907
2021-12-12 23:10:01,512 iteration 314 : loss : 0.075671, loss_ce: 0.036907
2021-12-12 23:10:03,030 iteration 315 : loss : 0.068490, loss_ce: 0.027896
2021-12-12 23:10:04,484 iteration 316 : loss : 0.059604, loss_ce: 0.024099
2021-12-12 23:10:05,887 iteration 317 : loss : 0.078090, loss_ce: 0.028657
2021-12-12 23:10:07,313 iteration 318 : loss : 0.086454, loss_ce: 0.032215
2021-12-12 23:10:08,818 iteration 319 : loss : 0.057709, loss_ce: 0.023951
2021-12-12 23:10:10,224 iteration 320 : loss : 0.072675, loss_ce: 0.026420
2021-12-12 23:10:11,613 iteration 321 : loss : 0.077419, loss_ce: 0.041412
2021-12-12 23:10:13,063 iteration 322 : loss : 0.081731, loss_ce: 0.032391
2021-12-12 23:10:14,559 iteration 323 : loss : 0.079790, loss_ce: 0.029349
  5%|█▍                            | 19/400 [08:23<2:42:57, 25.66s/it]2021-12-12 23:10:15,977 iteration 324 : loss : 0.065576, loss_ce: 0.021209
2021-12-12 23:10:17,414 iteration 325 : loss : 0.078487, loss_ce: 0.023126
2021-12-12 23:10:18,848 iteration 326 : loss : 0.070112, loss_ce: 0.026809
2021-12-12 23:10:20,374 iteration 327 : loss : 0.073270, loss_ce: 0.026768
2021-12-12 23:10:21,865 iteration 328 : loss : 0.084599, loss_ce: 0.034656
2021-12-12 23:10:23,323 iteration 329 : loss : 0.070663, loss_ce: 0.025016
2021-12-12 23:10:24,701 iteration 330 : loss : 0.075652, loss_ce: 0.029489
2021-12-12 23:10:26,216 iteration 331 : loss : 0.073571, loss_ce: 0.029916
2021-12-12 23:10:27,720 iteration 332 : loss : 0.079307, loss_ce: 0.035054
2021-12-12 23:10:29,126 iteration 333 : loss : 0.046949, loss_ce: 0.019577
2021-12-12 23:10:30,614 iteration 334 : loss : 0.091565, loss_ce: 0.043008
2021-12-12 23:10:32,043 iteration 335 : loss : 0.104583, loss_ce: 0.031986
2021-12-12 23:10:33,537 iteration 336 : loss : 0.069967, loss_ce: 0.028252
2021-12-12 23:10:34,950 iteration 337 : loss : 0.082056, loss_ce: 0.037589
2021-12-12 23:10:36,340 iteration 338 : loss : 0.057739, loss_ce: 0.025726
2021-12-12 23:10:37,802 iteration 339 : loss : 0.063366, loss_ce: 0.024717
2021-12-12 23:10:37,802 Training Data Eval:
2021-12-12 23:10:45,257   Average segmentation loss on training set: 0.1366
2021-12-12 23:10:45,258 Validation Data Eval:
2021-12-12 23:10:47,818   Average segmentation loss on validation set: 0.1406
2021-12-12 23:10:54,215 Found new lowest validation loss at iteration 339! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-12 23:10:55,567 iteration 340 : loss : 0.059520, loss_ce: 0.024415
  5%|█▌                            | 20/400 [09:04<3:11:41, 30.27s/it]2021-12-12 23:10:57,028 iteration 341 : loss : 0.059083, loss_ce: 0.022160
2021-12-12 23:10:58,462 iteration 342 : loss : 0.071778, loss_ce: 0.023111
2021-12-12 23:10:59,955 iteration 343 : loss : 0.080044, loss_ce: 0.036521
2021-12-12 23:11:01,324 iteration 344 : loss : 0.082442, loss_ce: 0.026010
2021-12-12 23:11:02,720 iteration 345 : loss : 0.065115, loss_ce: 0.027376
2021-12-12 23:11:04,202 iteration 346 : loss : 0.077709, loss_ce: 0.029083
2021-12-12 23:11:05,551 iteration 347 : loss : 0.060566, loss_ce: 0.027277
2021-12-12 23:11:07,034 iteration 348 : loss : 0.057980, loss_ce: 0.025193
2021-12-12 23:11:08,402 iteration 349 : loss : 0.049977, loss_ce: 0.021428
2021-12-12 23:11:09,694 iteration 350 : loss : 0.050282, loss_ce: 0.017642
2021-12-12 23:11:11,129 iteration 351 : loss : 0.082474, loss_ce: 0.027006
2021-12-12 23:11:12,516 iteration 352 : loss : 0.063334, loss_ce: 0.022335
2021-12-12 23:11:14,044 iteration 353 : loss : 0.061583, loss_ce: 0.025243
2021-12-12 23:11:15,549 iteration 354 : loss : 0.078718, loss_ce: 0.033081
2021-12-12 23:11:17,104 iteration 355 : loss : 0.111808, loss_ce: 0.048080
2021-12-12 23:11:18,551 iteration 356 : loss : 0.074543, loss_ce: 0.034001
2021-12-12 23:11:20,017 iteration 357 : loss : 0.068486, loss_ce: 0.028090
  5%|█▌                            | 21/400 [09:29<3:00:10, 28.52s/it]2021-12-12 23:11:21,595 iteration 358 : loss : 0.072015, loss_ce: 0.025666
2021-12-12 23:11:23,117 iteration 359 : loss : 0.076717, loss_ce: 0.034660
2021-12-12 23:11:24,590 iteration 360 : loss : 0.143815, loss_ce: 0.043933
2021-12-12 23:11:26,096 iteration 361 : loss : 0.083851, loss_ce: 0.026260
2021-12-12 23:11:27,496 iteration 362 : loss : 0.073762, loss_ce: 0.027212
2021-12-12 23:11:29,031 iteration 363 : loss : 0.106429, loss_ce: 0.044909
2021-12-12 23:11:30,511 iteration 364 : loss : 0.090122, loss_ce: 0.039918
2021-12-12 23:11:31,962 iteration 365 : loss : 0.069262, loss_ce: 0.025614
2021-12-12 23:11:33,416 iteration 366 : loss : 0.079587, loss_ce: 0.032697
2021-12-12 23:11:34,917 iteration 367 : loss : 0.084677, loss_ce: 0.044645
2021-12-12 23:11:36,339 iteration 368 : loss : 0.063331, loss_ce: 0.020164
2021-12-12 23:11:37,826 iteration 369 : loss : 0.065521, loss_ce: 0.023492
2021-12-12 23:11:39,208 iteration 370 : loss : 0.096508, loss_ce: 0.030991
2021-12-12 23:11:40,730 iteration 371 : loss : 0.065219, loss_ce: 0.028357
2021-12-12 23:11:42,251 iteration 372 : loss : 0.070349, loss_ce: 0.025996
2021-12-12 23:11:43,737 iteration 373 : loss : 0.059946, loss_ce: 0.022892
2021-12-12 23:11:45,177 iteration 374 : loss : 0.051790, loss_ce: 0.022239
  6%|█▋                            | 22/400 [09:54<2:53:19, 27.51s/it]2021-12-12 23:11:46,715 iteration 375 : loss : 0.072049, loss_ce: 0.026999
2021-12-12 23:11:48,203 iteration 376 : loss : 0.086736, loss_ce: 0.032164
2021-12-12 23:11:49,701 iteration 377 : loss : 0.101208, loss_ce: 0.031282
2021-12-12 23:11:51,189 iteration 378 : loss : 0.072841, loss_ce: 0.032476
2021-12-12 23:11:52,598 iteration 379 : loss : 0.076275, loss_ce: 0.024981
2021-12-12 23:11:54,094 iteration 380 : loss : 0.070361, loss_ce: 0.032481
2021-12-12 23:11:55,472 iteration 381 : loss : 0.055089, loss_ce: 0.017639
2021-12-12 23:11:57,027 iteration 382 : loss : 0.065653, loss_ce: 0.023547
2021-12-12 23:11:58,526 iteration 383 : loss : 0.068793, loss_ce: 0.027864
2021-12-12 23:11:59,987 iteration 384 : loss : 0.054353, loss_ce: 0.021913
2021-12-12 23:12:01,415 iteration 385 : loss : 0.053747, loss_ce: 0.022692
2021-12-12 23:12:02,917 iteration 386 : loss : 0.065330, loss_ce: 0.025701
2021-12-12 23:12:04,404 iteration 387 : loss : 0.115884, loss_ce: 0.048117
2021-12-12 23:12:05,923 iteration 388 : loss : 0.068858, loss_ce: 0.034194
2021-12-12 23:12:07,367 iteration 389 : loss : 0.103635, loss_ce: 0.041507
2021-12-12 23:12:08,868 iteration 390 : loss : 0.063264, loss_ce: 0.026836
2021-12-12 23:12:10,303 iteration 391 : loss : 0.085000, loss_ce: 0.036857
  6%|█▋                            | 23/400 [10:19<2:48:21, 26.80s/it]2021-12-12 23:12:11,909 iteration 392 : loss : 0.066813, loss_ce: 0.027490
2021-12-12 23:12:13,315 iteration 393 : loss : 0.061473, loss_ce: 0.029905
2021-12-12 23:12:14,777 iteration 394 : loss : 0.083469, loss_ce: 0.034170
2021-12-12 23:12:16,214 iteration 395 : loss : 0.059336, loss_ce: 0.027605
2021-12-12 23:12:17,723 iteration 396 : loss : 0.090568, loss_ce: 0.041548
2021-12-12 23:12:19,226 iteration 397 : loss : 0.065230, loss_ce: 0.027345
2021-12-12 23:12:20,714 iteration 398 : loss : 0.089620, loss_ce: 0.041321
2021-12-12 23:12:22,172 iteration 399 : loss : 0.059425, loss_ce: 0.020635
2021-12-12 23:12:23,692 iteration 400 : loss : 0.075194, loss_ce: 0.031090
2021-12-12 23:12:25,099 iteration 401 : loss : 0.061123, loss_ce: 0.024047
2021-12-12 23:12:26,620 iteration 402 : loss : 0.090390, loss_ce: 0.038406
2021-12-12 23:12:28,157 iteration 403 : loss : 0.056040, loss_ce: 0.023007
2021-12-12 23:12:29,622 iteration 404 : loss : 0.078254, loss_ce: 0.027570
2021-12-12 23:12:31,122 iteration 405 : loss : 0.069845, loss_ce: 0.025495
2021-12-12 23:12:32,549 iteration 406 : loss : 0.079854, loss_ce: 0.036992
2021-12-12 23:12:33,978 iteration 407 : loss : 0.060288, loss_ce: 0.026239
2021-12-12 23:12:35,405 iteration 408 : loss : 0.059488, loss_ce: 0.021690
  6%|█▊                            | 24/400 [10:44<2:44:43, 26.29s/it]2021-12-12 23:12:37,021 iteration 409 : loss : 0.076634, loss_ce: 0.030708
2021-12-12 23:12:38,475 iteration 410 : loss : 0.052792, loss_ce: 0.019934
2021-12-12 23:12:39,957 iteration 411 : loss : 0.070928, loss_ce: 0.024667
2021-12-12 23:12:41,416 iteration 412 : loss : 0.063952, loss_ce: 0.026561
2021-12-12 23:12:42,863 iteration 413 : loss : 0.066548, loss_ce: 0.027096
2021-12-12 23:12:44,352 iteration 414 : loss : 0.062804, loss_ce: 0.025048
2021-12-12 23:12:45,869 iteration 415 : loss : 0.065842, loss_ce: 0.034676
2021-12-12 23:12:47,219 iteration 416 : loss : 0.066711, loss_ce: 0.023850
2021-12-12 23:12:48,680 iteration 417 : loss : 0.091939, loss_ce: 0.034643
2021-12-12 23:12:50,150 iteration 418 : loss : 0.060703, loss_ce: 0.024072
2021-12-12 23:12:51,591 iteration 419 : loss : 0.083719, loss_ce: 0.027971
2021-12-12 23:12:53,057 iteration 420 : loss : 0.073471, loss_ce: 0.026270
2021-12-12 23:12:54,438 iteration 421 : loss : 0.076285, loss_ce: 0.019107
2021-12-12 23:12:55,937 iteration 422 : loss : 0.075632, loss_ce: 0.026842
2021-12-12 23:12:57,363 iteration 423 : loss : 0.073620, loss_ce: 0.025617
2021-12-12 23:12:58,785 iteration 424 : loss : 0.089628, loss_ce: 0.047955
2021-12-12 23:12:58,785 Training Data Eval:
2021-12-12 23:13:06,268   Average segmentation loss on training set: 0.0774
2021-12-12 23:13:06,268 Validation Data Eval:
2021-12-12 23:13:08,856   Average segmentation loss on validation set: 0.1852
2021-12-12 23:13:10,385 iteration 425 : loss : 0.079072, loss_ce: 0.032831
  6%|█▉                            | 25/400 [11:19<3:00:35, 28.89s/it]2021-12-12 23:13:11,938 iteration 426 : loss : 0.079625, loss_ce: 0.029257
2021-12-12 23:13:13,362 iteration 427 : loss : 0.071690, loss_ce: 0.030874
2021-12-12 23:13:14,921 iteration 428 : loss : 0.059100, loss_ce: 0.025011
2021-12-12 23:13:16,357 iteration 429 : loss : 0.065757, loss_ce: 0.023360
2021-12-12 23:13:17,749 iteration 430 : loss : 0.062685, loss_ce: 0.028220
2021-12-12 23:13:19,255 iteration 431 : loss : 0.067026, loss_ce: 0.034053
2021-12-12 23:13:20,747 iteration 432 : loss : 0.072746, loss_ce: 0.024441
2021-12-12 23:13:22,142 iteration 433 : loss : 0.063033, loss_ce: 0.025755
2021-12-12 23:13:23,553 iteration 434 : loss : 0.043257, loss_ce: 0.014710
2021-12-12 23:13:25,066 iteration 435 : loss : 0.050962, loss_ce: 0.018715
2021-12-12 23:13:26,564 iteration 436 : loss : 0.074277, loss_ce: 0.023112
2021-12-12 23:13:27,989 iteration 437 : loss : 0.069367, loss_ce: 0.028256
2021-12-12 23:13:29,413 iteration 438 : loss : 0.080292, loss_ce: 0.030107
2021-12-12 23:13:30,855 iteration 439 : loss : 0.063935, loss_ce: 0.021857
2021-12-12 23:13:32,437 iteration 440 : loss : 0.093634, loss_ce: 0.044659
2021-12-12 23:13:33,868 iteration 441 : loss : 0.084322, loss_ce: 0.042484
2021-12-12 23:13:35,287 iteration 442 : loss : 0.050141, loss_ce: 0.017766
  6%|█▉                            | 26/400 [11:44<2:52:39, 27.70s/it]2021-12-12 23:13:36,813 iteration 443 : loss : 0.060224, loss_ce: 0.024283
2021-12-12 23:13:38,230 iteration 444 : loss : 0.052607, loss_ce: 0.018344
2021-12-12 23:13:39,643 iteration 445 : loss : 0.064606, loss_ce: 0.027356
2021-12-12 23:13:41,093 iteration 446 : loss : 0.068113, loss_ce: 0.024619
2021-12-12 23:13:42,592 iteration 447 : loss : 0.060588, loss_ce: 0.023034
2021-12-12 23:13:43,976 iteration 448 : loss : 0.045692, loss_ce: 0.015595
2021-12-12 23:13:45,395 iteration 449 : loss : 0.066532, loss_ce: 0.019891
2021-12-12 23:13:46,778 iteration 450 : loss : 0.091328, loss_ce: 0.044200
2021-12-12 23:13:48,220 iteration 451 : loss : 0.064160, loss_ce: 0.026384
2021-12-12 23:13:49,675 iteration 452 : loss : 0.047153, loss_ce: 0.016863
2021-12-12 23:13:51,105 iteration 453 : loss : 0.042149, loss_ce: 0.018111
2021-12-12 23:13:52,651 iteration 454 : loss : 0.067567, loss_ce: 0.032485
2021-12-12 23:13:54,139 iteration 455 : loss : 0.061758, loss_ce: 0.026710
2021-12-12 23:13:55,593 iteration 456 : loss : 0.064082, loss_ce: 0.023217
2021-12-12 23:13:57,029 iteration 457 : loss : 0.066717, loss_ce: 0.035561
2021-12-12 23:13:58,469 iteration 458 : loss : 0.046254, loss_ce: 0.021695
2021-12-12 23:13:59,936 iteration 459 : loss : 0.057356, loss_ce: 0.023473
  7%|██                            | 27/400 [12:09<2:46:29, 26.78s/it]2021-12-12 23:14:01,379 iteration 460 : loss : 0.064316, loss_ce: 0.030530
2021-12-12 23:14:02,810 iteration 461 : loss : 0.054086, loss_ce: 0.025719
2021-12-12 23:14:04,321 iteration 462 : loss : 0.084824, loss_ce: 0.031938
2021-12-12 23:14:05,755 iteration 463 : loss : 0.064421, loss_ce: 0.022315
2021-12-12 23:14:07,313 iteration 464 : loss : 0.104734, loss_ce: 0.037436
2021-12-12 23:14:08,794 iteration 465 : loss : 0.078557, loss_ce: 0.033846
2021-12-12 23:14:10,220 iteration 466 : loss : 0.073644, loss_ce: 0.030002
2021-12-12 23:14:11,671 iteration 467 : loss : 0.071336, loss_ce: 0.022630
2021-12-12 23:14:13,102 iteration 468 : loss : 0.048259, loss_ce: 0.019072
2021-12-12 23:14:14,596 iteration 469 : loss : 0.060302, loss_ce: 0.026959
2021-12-12 23:14:16,052 iteration 470 : loss : 0.054606, loss_ce: 0.021444
2021-12-12 23:14:17,523 iteration 471 : loss : 0.066951, loss_ce: 0.029702
2021-12-12 23:14:19,024 iteration 472 : loss : 0.043643, loss_ce: 0.018881
2021-12-12 23:14:20,486 iteration 473 : loss : 0.067862, loss_ce: 0.027719
2021-12-12 23:14:21,904 iteration 474 : loss : 0.094666, loss_ce: 0.030443
2021-12-12 23:14:23,354 iteration 475 : loss : 0.070938, loss_ce: 0.019751
2021-12-12 23:14:24,884 iteration 476 : loss : 0.049244, loss_ce: 0.018447
  7%|██                            | 28/400 [12:34<2:42:38, 26.23s/it]2021-12-12 23:14:26,380 iteration 477 : loss : 0.064590, loss_ce: 0.028746
2021-12-12 23:14:27,781 iteration 478 : loss : 0.059501, loss_ce: 0.024898
2021-12-12 23:14:29,281 iteration 479 : loss : 0.066936, loss_ce: 0.026644
2021-12-12 23:14:30,736 iteration 480 : loss : 0.067735, loss_ce: 0.019358
2021-12-12 23:14:32,147 iteration 481 : loss : 0.051611, loss_ce: 0.017039
2021-12-12 23:14:33,688 iteration 482 : loss : 0.072761, loss_ce: 0.030131
2021-12-12 23:14:35,095 iteration 483 : loss : 0.066848, loss_ce: 0.027011
2021-12-12 23:14:36,570 iteration 484 : loss : 0.058707, loss_ce: 0.020947
2021-12-12 23:14:38,036 iteration 485 : loss : 0.119016, loss_ce: 0.047135
2021-12-12 23:14:39,582 iteration 486 : loss : 0.069268, loss_ce: 0.029134
2021-12-12 23:14:41,035 iteration 487 : loss : 0.089160, loss_ce: 0.029498
2021-12-12 23:14:42,411 iteration 488 : loss : 0.069227, loss_ce: 0.026767
2021-12-12 23:14:43,901 iteration 489 : loss : 0.054601, loss_ce: 0.029888
2021-12-12 23:14:45,355 iteration 490 : loss : 0.042013, loss_ce: 0.018332
2021-12-12 23:14:46,869 iteration 491 : loss : 0.130332, loss_ce: 0.047466
2021-12-12 23:14:48,294 iteration 492 : loss : 0.059221, loss_ce: 0.027878
2021-12-12 23:14:49,709 iteration 493 : loss : 0.050120, loss_ce: 0.021787
  7%|██▏                           | 29/400 [12:58<2:39:36, 25.81s/it]2021-12-12 23:14:51,201 iteration 494 : loss : 0.062413, loss_ce: 0.022290
2021-12-12 23:14:52,588 iteration 495 : loss : 0.094038, loss_ce: 0.033023
2021-12-12 23:14:54,043 iteration 496 : loss : 0.060971, loss_ce: 0.019367
2021-12-12 23:14:55,570 iteration 497 : loss : 0.080029, loss_ce: 0.030458
2021-12-12 23:14:57,116 iteration 498 : loss : 0.074875, loss_ce: 0.034857
2021-12-12 23:14:58,586 iteration 499 : loss : 0.064727, loss_ce: 0.022790
2021-12-12 23:15:00,150 iteration 500 : loss : 0.098640, loss_ce: 0.038974
2021-12-12 23:15:01,601 iteration 501 : loss : 0.070645, loss_ce: 0.024138
2021-12-12 23:15:03,009 iteration 502 : loss : 0.060191, loss_ce: 0.027255
2021-12-12 23:15:04,560 iteration 503 : loss : 0.060504, loss_ce: 0.019447
2021-12-12 23:15:06,106 iteration 504 : loss : 0.086968, loss_ce: 0.036141
2021-12-12 23:15:07,528 iteration 505 : loss : 0.075070, loss_ce: 0.032732
2021-12-12 23:15:09,010 iteration 506 : loss : 0.078323, loss_ce: 0.030422
2021-12-12 23:15:10,522 iteration 507 : loss : 0.053667, loss_ce: 0.023184
2021-12-12 23:15:11,975 iteration 508 : loss : 0.064815, loss_ce: 0.024710
2021-12-12 23:15:13,467 iteration 509 : loss : 0.064622, loss_ce: 0.029581
2021-12-12 23:15:13,467 Training Data Eval:
2021-12-12 23:15:20,907   Average segmentation loss on training set: 0.0677
2021-12-12 23:15:20,908 Validation Data Eval:
2021-12-12 23:15:23,485   Average segmentation loss on validation set: 0.1096
2021-12-12 23:15:29,816 Found new lowest validation loss at iteration 509! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-12 23:15:31,102 iteration 510 : loss : 0.057512, loss_ce: 0.022353
  8%|██▎                           | 30/400 [13:40<3:07:58, 30.48s/it]2021-12-12 23:15:32,378 iteration 511 : loss : 0.039965, loss_ce: 0.017303
2021-12-12 23:15:33,893 iteration 512 : loss : 0.072314, loss_ce: 0.037061
2021-12-12 23:15:35,214 iteration 513 : loss : 0.075756, loss_ce: 0.031892
2021-12-12 23:15:36,624 iteration 514 : loss : 0.076754, loss_ce: 0.026588
2021-12-12 23:15:37,973 iteration 515 : loss : 0.050770, loss_ce: 0.023529
2021-12-12 23:15:39,268 iteration 516 : loss : 0.044716, loss_ce: 0.021754
2021-12-12 23:15:40,783 iteration 517 : loss : 0.068620, loss_ce: 0.025640
2021-12-12 23:15:42,191 iteration 518 : loss : 0.079169, loss_ce: 0.041333
2021-12-12 23:15:43,532 iteration 519 : loss : 0.044164, loss_ce: 0.017060
2021-12-12 23:15:44,866 iteration 520 : loss : 0.079349, loss_ce: 0.034811
2021-12-12 23:15:46,328 iteration 521 : loss : 0.136492, loss_ce: 0.032312
2021-12-12 23:15:47,702 iteration 522 : loss : 0.046911, loss_ce: 0.019867
2021-12-12 23:15:49,189 iteration 523 : loss : 0.047319, loss_ce: 0.019755
2021-12-12 23:15:50,559 iteration 524 : loss : 0.054114, loss_ce: 0.019830
2021-12-12 23:15:52,026 iteration 525 : loss : 0.051515, loss_ce: 0.019934
2021-12-12 23:15:53,531 iteration 526 : loss : 0.071093, loss_ce: 0.026840
2021-12-12 23:15:54,998 iteration 527 : loss : 0.052523, loss_ce: 0.019088
  8%|██▎                           | 31/400 [14:04<2:55:20, 28.51s/it]2021-12-12 23:15:56,560 iteration 528 : loss : 0.042003, loss_ce: 0.014949
2021-12-12 23:15:58,034 iteration 529 : loss : 0.056214, loss_ce: 0.025401
2021-12-12 23:15:59,480 iteration 530 : loss : 0.047032, loss_ce: 0.016497
2021-12-12 23:16:01,073 iteration 531 : loss : 0.084416, loss_ce: 0.027825
2021-12-12 23:16:02,470 iteration 532 : loss : 0.076873, loss_ce: 0.025624
2021-12-12 23:16:03,964 iteration 533 : loss : 0.072489, loss_ce: 0.033542
2021-12-12 23:16:05,442 iteration 534 : loss : 0.093041, loss_ce: 0.044990
2021-12-12 23:16:06,922 iteration 535 : loss : 0.055236, loss_ce: 0.020784
2021-12-12 23:16:08,335 iteration 536 : loss : 0.048508, loss_ce: 0.023974
2021-12-12 23:16:09,801 iteration 537 : loss : 0.085401, loss_ce: 0.036842
2021-12-12 23:16:11,255 iteration 538 : loss : 0.079888, loss_ce: 0.031512
2021-12-12 23:16:12,680 iteration 539 : loss : 0.090831, loss_ce: 0.036352
2021-12-12 23:16:14,093 iteration 540 : loss : 0.045845, loss_ce: 0.018848
2021-12-12 23:16:15,556 iteration 541 : loss : 0.064774, loss_ce: 0.033253
2021-12-12 23:16:16,964 iteration 542 : loss : 0.051924, loss_ce: 0.020613
2021-12-12 23:16:18,394 iteration 543 : loss : 0.075111, loss_ce: 0.023786
2021-12-12 23:16:19,842 iteration 544 : loss : 0.072709, loss_ce: 0.024925
  8%|██▍                           | 32/400 [14:29<2:48:07, 27.41s/it]2021-12-12 23:16:21,318 iteration 545 : loss : 0.067819, loss_ce: 0.030847
2021-12-12 23:16:22,784 iteration 546 : loss : 0.058802, loss_ce: 0.023546
2021-12-12 23:16:24,238 iteration 547 : loss : 0.059209, loss_ce: 0.023985
2021-12-12 23:16:25,624 iteration 548 : loss : 0.059139, loss_ce: 0.023765
2021-12-12 23:16:27,086 iteration 549 : loss : 0.069610, loss_ce: 0.028518
2021-12-12 23:16:28,635 iteration 550 : loss : 0.037469, loss_ce: 0.014440
2021-12-12 23:16:30,121 iteration 551 : loss : 0.047106, loss_ce: 0.017770
2021-12-12 23:16:31,624 iteration 552 : loss : 0.058683, loss_ce: 0.025700
2021-12-12 23:16:33,130 iteration 553 : loss : 0.067690, loss_ce: 0.031462
2021-12-12 23:16:34,536 iteration 554 : loss : 0.039509, loss_ce: 0.017687
2021-12-12 23:16:36,028 iteration 555 : loss : 0.054774, loss_ce: 0.025816
2021-12-12 23:16:37,571 iteration 556 : loss : 0.064404, loss_ce: 0.024591
2021-12-12 23:16:39,017 iteration 557 : loss : 0.058608, loss_ce: 0.027404
2021-12-12 23:16:40,438 iteration 558 : loss : 0.069809, loss_ce: 0.026517
2021-12-12 23:16:41,923 iteration 559 : loss : 0.062752, loss_ce: 0.027837
2021-12-12 23:16:43,430 iteration 560 : loss : 0.069163, loss_ce: 0.024447
2021-12-12 23:16:44,850 iteration 561 : loss : 0.108169, loss_ce: 0.031161
  8%|██▍                           | 33/400 [14:54<2:43:14, 26.69s/it]2021-12-12 23:16:46,334 iteration 562 : loss : 0.057819, loss_ce: 0.021901
2021-12-12 23:16:47,818 iteration 563 : loss : 0.082602, loss_ce: 0.039200
2021-12-12 23:16:49,338 iteration 564 : loss : 0.066244, loss_ce: 0.033834
2021-12-12 23:16:50,822 iteration 565 : loss : 0.098412, loss_ce: 0.045549
2021-12-12 23:16:52,209 iteration 566 : loss : 0.049338, loss_ce: 0.017503
2021-12-12 23:16:53,721 iteration 567 : loss : 0.067281, loss_ce: 0.021953
2021-12-12 23:16:55,157 iteration 568 : loss : 0.084003, loss_ce: 0.029296
2021-12-12 23:16:56,619 iteration 569 : loss : 0.062684, loss_ce: 0.022449
2021-12-12 23:16:58,162 iteration 570 : loss : 0.070475, loss_ce: 0.027825
2021-12-12 23:16:59,676 iteration 571 : loss : 0.062915, loss_ce: 0.025317
2021-12-12 23:17:01,174 iteration 572 : loss : 0.066857, loss_ce: 0.024128
2021-12-12 23:17:02,629 iteration 573 : loss : 0.053312, loss_ce: 0.021539
2021-12-12 23:17:04,084 iteration 574 : loss : 0.055352, loss_ce: 0.024020
2021-12-12 23:17:05,594 iteration 575 : loss : 0.084670, loss_ce: 0.036502
2021-12-12 23:17:07,057 iteration 576 : loss : 0.065112, loss_ce: 0.035200
2021-12-12 23:17:08,547 iteration 577 : loss : 0.105589, loss_ce: 0.029912
2021-12-12 23:17:10,030 iteration 578 : loss : 0.057363, loss_ce: 0.020077
  8%|██▌                           | 34/400 [15:19<2:40:01, 26.23s/it]2021-12-12 23:17:11,515 iteration 579 : loss : 0.050520, loss_ce: 0.015706
2021-12-12 23:17:12,964 iteration 580 : loss : 0.065990, loss_ce: 0.023933
2021-12-12 23:17:14,437 iteration 581 : loss : 0.057987, loss_ce: 0.025763
2021-12-12 23:17:15,922 iteration 582 : loss : 0.057775, loss_ce: 0.020587
2021-12-12 23:17:17,362 iteration 583 : loss : 0.045312, loss_ce: 0.019357
2021-12-12 23:17:18,721 iteration 584 : loss : 0.054615, loss_ce: 0.021321
2021-12-12 23:17:20,131 iteration 585 : loss : 0.051848, loss_ce: 0.018112
2021-12-12 23:17:21,630 iteration 586 : loss : 0.073748, loss_ce: 0.031671
2021-12-12 23:17:23,088 iteration 587 : loss : 0.055381, loss_ce: 0.020328
2021-12-12 23:17:24,590 iteration 588 : loss : 0.071562, loss_ce: 0.025209
2021-12-12 23:17:26,054 iteration 589 : loss : 0.043197, loss_ce: 0.018967
2021-12-12 23:17:27,478 iteration 590 : loss : 0.065927, loss_ce: 0.033827
2021-12-12 23:17:28,919 iteration 591 : loss : 0.055810, loss_ce: 0.022421
2021-12-12 23:17:30,353 iteration 592 : loss : 0.065395, loss_ce: 0.029452
2021-12-12 23:17:31,849 iteration 593 : loss : 0.046264, loss_ce: 0.018198
2021-12-12 23:17:33,365 iteration 594 : loss : 0.059164, loss_ce: 0.028009
2021-12-12 23:17:33,365 Training Data Eval:
2021-12-12 23:17:40,826   Average segmentation loss on training set: 0.0729
2021-12-12 23:17:40,826 Validation Data Eval:
2021-12-12 23:17:43,404   Average segmentation loss on validation set: 0.1148
2021-12-12 23:17:44,901 iteration 595 : loss : 0.060680, loss_ce: 0.023591
  9%|██▋                           | 35/400 [15:54<2:55:22, 28.83s/it]2021-12-12 23:17:46,362 iteration 596 : loss : 0.039283, loss_ce: 0.017038
2021-12-12 23:17:47,825 iteration 597 : loss : 0.086273, loss_ce: 0.037146
2021-12-12 23:17:49,315 iteration 598 : loss : 0.042072, loss_ce: 0.017820
2021-12-12 23:17:50,827 iteration 599 : loss : 0.053730, loss_ce: 0.019776
2021-12-12 23:17:52,203 iteration 600 : loss : 0.043418, loss_ce: 0.019442
2021-12-12 23:17:53,657 iteration 601 : loss : 0.054189, loss_ce: 0.017633
2021-12-12 23:17:55,152 iteration 602 : loss : 0.050560, loss_ce: 0.021843
2021-12-12 23:17:56,512 iteration 603 : loss : 0.060262, loss_ce: 0.024206
2021-12-12 23:17:57,952 iteration 604 : loss : 0.053322, loss_ce: 0.019209
2021-12-12 23:17:59,403 iteration 605 : loss : 0.047579, loss_ce: 0.019665
2021-12-12 23:18:00,821 iteration 606 : loss : 0.071596, loss_ce: 0.024898
2021-12-12 23:18:02,253 iteration 607 : loss : 0.057097, loss_ce: 0.020826
2021-12-12 23:18:03,802 iteration 608 : loss : 0.049679, loss_ce: 0.018906
2021-12-12 23:18:05,244 iteration 609 : loss : 0.041096, loss_ce: 0.019192
2021-12-12 23:18:06,754 iteration 610 : loss : 0.055504, loss_ce: 0.020089
2021-12-12 23:18:08,202 iteration 611 : loss : 0.077797, loss_ce: 0.034105
2021-12-12 23:18:09,643 iteration 612 : loss : 0.057610, loss_ce: 0.026703
  9%|██▋                           | 36/400 [16:18<2:47:25, 27.60s/it]2021-12-12 23:18:11,142 iteration 613 : loss : 0.044038, loss_ce: 0.019811
2021-12-12 23:18:12,694 iteration 614 : loss : 0.049437, loss_ce: 0.022388
2021-12-12 23:18:14,129 iteration 615 : loss : 0.048029, loss_ce: 0.017434
2021-12-12 23:18:15,532 iteration 616 : loss : 0.075408, loss_ce: 0.047314
2021-12-12 23:18:16,995 iteration 617 : loss : 0.078206, loss_ce: 0.042251
2021-12-12 23:18:18,415 iteration 618 : loss : 0.060770, loss_ce: 0.022230
2021-12-12 23:18:19,848 iteration 619 : loss : 0.069780, loss_ce: 0.022120
2021-12-12 23:18:21,370 iteration 620 : loss : 0.051653, loss_ce: 0.016836
2021-12-12 23:18:22,782 iteration 621 : loss : 0.041300, loss_ce: 0.016090
2021-12-12 23:18:24,251 iteration 622 : loss : 0.050797, loss_ce: 0.019457
2021-12-12 23:18:25,748 iteration 623 : loss : 0.066176, loss_ce: 0.016001
2021-12-12 23:18:27,180 iteration 624 : loss : 0.048423, loss_ce: 0.015452
2021-12-12 23:18:28,578 iteration 625 : loss : 0.050860, loss_ce: 0.020241
2021-12-12 23:18:29,974 iteration 626 : loss : 0.038956, loss_ce: 0.014508
2021-12-12 23:18:31,394 iteration 627 : loss : 0.049497, loss_ce: 0.016764
2021-12-12 23:18:32,818 iteration 628 : loss : 0.066960, loss_ce: 0.037279
2021-12-12 23:18:34,285 iteration 629 : loss : 0.054580, loss_ce: 0.020363
  9%|██▊                           | 37/400 [16:43<2:41:37, 26.71s/it]2021-12-12 23:18:35,759 iteration 630 : loss : 0.045526, loss_ce: 0.016542
2021-12-12 23:18:37,256 iteration 631 : loss : 0.066288, loss_ce: 0.038094
2021-12-12 23:18:38,723 iteration 632 : loss : 0.066186, loss_ce: 0.028338
2021-12-12 23:18:40,205 iteration 633 : loss : 0.054378, loss_ce: 0.024193
2021-12-12 23:18:41,710 iteration 634 : loss : 0.069991, loss_ce: 0.030202
2021-12-12 23:18:43,151 iteration 635 : loss : 0.066427, loss_ce: 0.024011
2021-12-12 23:18:44,676 iteration 636 : loss : 0.053700, loss_ce: 0.022841
2021-12-12 23:18:46,085 iteration 637 : loss : 0.050566, loss_ce: 0.017625
2021-12-12 23:18:47,512 iteration 638 : loss : 0.067574, loss_ce: 0.026487
2021-12-12 23:18:49,009 iteration 639 : loss : 0.062353, loss_ce: 0.025093
2021-12-12 23:18:50,443 iteration 640 : loss : 0.056205, loss_ce: 0.021415
2021-12-12 23:18:51,910 iteration 641 : loss : 0.046255, loss_ce: 0.020500
2021-12-12 23:18:53,382 iteration 642 : loss : 0.047192, loss_ce: 0.017358
2021-12-12 23:18:54,832 iteration 643 : loss : 0.054695, loss_ce: 0.021993
2021-12-12 23:18:56,286 iteration 644 : loss : 0.033446, loss_ce: 0.012822
2021-12-12 23:18:57,759 iteration 645 : loss : 0.061894, loss_ce: 0.024587
2021-12-12 23:18:59,202 iteration 646 : loss : 0.049681, loss_ce: 0.020975
 10%|██▊                           | 38/400 [17:08<2:37:55, 26.17s/it]2021-12-12 23:19:00,676 iteration 647 : loss : 0.054003, loss_ce: 0.016958
2021-12-12 23:19:02,087 iteration 648 : loss : 0.061367, loss_ce: 0.032190
2021-12-12 23:19:03,492 iteration 649 : loss : 0.049370, loss_ce: 0.021495
2021-12-12 23:19:04,982 iteration 650 : loss : 0.122813, loss_ce: 0.037785
2021-12-12 23:19:06,467 iteration 651 : loss : 0.040388, loss_ce: 0.014569
2021-12-12 23:19:07,871 iteration 652 : loss : 0.051141, loss_ce: 0.020875
2021-12-12 23:19:09,278 iteration 653 : loss : 0.049998, loss_ce: 0.021081
2021-12-12 23:19:10,719 iteration 654 : loss : 0.056454, loss_ce: 0.019115
2021-12-12 23:19:12,103 iteration 655 : loss : 0.058086, loss_ce: 0.021273
2021-12-12 23:19:13,601 iteration 656 : loss : 0.080553, loss_ce: 0.033187
2021-12-12 23:19:15,041 iteration 657 : loss : 0.069507, loss_ce: 0.021602
2021-12-12 23:19:16,487 iteration 658 : loss : 0.080623, loss_ce: 0.027745
2021-12-12 23:19:17,979 iteration 659 : loss : 0.073690, loss_ce: 0.024575
2021-12-12 23:19:19,455 iteration 660 : loss : 0.058879, loss_ce: 0.024958
2021-12-12 23:19:20,915 iteration 661 : loss : 0.042476, loss_ce: 0.019972
2021-12-12 23:19:22,389 iteration 662 : loss : 0.075325, loss_ce: 0.035629
2021-12-12 23:19:23,837 iteration 663 : loss : 0.064715, loss_ce: 0.027432
 10%|██▉                           | 39/400 [17:33<2:34:42, 25.71s/it]2021-12-12 23:19:25,293 iteration 664 : loss : 0.073449, loss_ce: 0.030668
2021-12-12 23:19:26,777 iteration 665 : loss : 0.064555, loss_ce: 0.019823
2021-12-12 23:19:28,243 iteration 666 : loss : 0.044878, loss_ce: 0.012360
2021-12-12 23:19:29,748 iteration 667 : loss : 0.061013, loss_ce: 0.024614
2021-12-12 23:19:31,180 iteration 668 : loss : 0.043347, loss_ce: 0.018926
2021-12-12 23:19:32,680 iteration 669 : loss : 0.112976, loss_ce: 0.057723
2021-12-12 23:19:34,173 iteration 670 : loss : 0.133032, loss_ce: 0.065471
2021-12-12 23:19:35,632 iteration 671 : loss : 0.080049, loss_ce: 0.033247
2021-12-12 23:19:37,011 iteration 672 : loss : 0.067445, loss_ce: 0.029214
2021-12-12 23:19:38,461 iteration 673 : loss : 0.091356, loss_ce: 0.037832
2021-12-12 23:19:40,052 iteration 674 : loss : 0.069157, loss_ce: 0.033371
2021-12-12 23:19:41,517 iteration 675 : loss : 0.074589, loss_ce: 0.027708
2021-12-12 23:19:42,968 iteration 676 : loss : 0.066291, loss_ce: 0.028518
2021-12-12 23:19:44,527 iteration 677 : loss : 0.061734, loss_ce: 0.028044
2021-12-12 23:19:46,005 iteration 678 : loss : 0.087535, loss_ce: 0.027453
2021-12-12 23:19:47,421 iteration 679 : loss : 0.059127, loss_ce: 0.024279
2021-12-12 23:19:47,421 Training Data Eval:
2021-12-12 23:19:54,840   Average segmentation loss on training set: 0.3995
2021-12-12 23:19:54,841 Validation Data Eval:
2021-12-12 23:19:57,438   Average segmentation loss on validation set: 0.5236
2021-12-12 23:19:58,856 iteration 680 : loss : 0.070998, loss_ce: 0.031055
 10%|███                           | 40/400 [18:08<2:51:02, 28.51s/it]2021-12-12 23:20:00,458 iteration 681 : loss : 0.077659, loss_ce: 0.027866
2021-12-12 23:20:01,909 iteration 682 : loss : 0.053668, loss_ce: 0.021090
2021-12-12 23:20:03,318 iteration 683 : loss : 0.067505, loss_ce: 0.020476
2021-12-12 23:20:04,826 iteration 684 : loss : 0.060101, loss_ce: 0.026643
2021-12-12 23:20:06,338 iteration 685 : loss : 0.054509, loss_ce: 0.021920
2021-12-12 23:20:07,829 iteration 686 : loss : 0.057344, loss_ce: 0.023165
2021-12-12 23:20:09,329 iteration 687 : loss : 0.048740, loss_ce: 0.020923
2021-12-12 23:20:10,851 iteration 688 : loss : 0.062297, loss_ce: 0.023000
2021-12-12 23:20:12,343 iteration 689 : loss : 0.049354, loss_ce: 0.021601
2021-12-12 23:20:13,783 iteration 690 : loss : 0.054796, loss_ce: 0.025403
2021-12-12 23:20:15,274 iteration 691 : loss : 0.053961, loss_ce: 0.021219
2021-12-12 23:20:16,662 iteration 692 : loss : 0.044652, loss_ce: 0.019256
2021-12-12 23:20:18,084 iteration 693 : loss : 0.038926, loss_ce: 0.015691
2021-12-12 23:20:19,539 iteration 694 : loss : 0.089924, loss_ce: 0.032332
2021-12-12 23:20:20,990 iteration 695 : loss : 0.063565, loss_ce: 0.020999
2021-12-12 23:20:22,411 iteration 696 : loss : 0.119423, loss_ce: 0.025393
2021-12-12 23:20:23,794 iteration 697 : loss : 0.048605, loss_ce: 0.021287
 10%|███                           | 41/400 [18:33<2:44:09, 27.44s/it]2021-12-12 23:20:25,310 iteration 698 : loss : 0.061616, loss_ce: 0.028653
2021-12-12 23:20:26,793 iteration 699 : loss : 0.052532, loss_ce: 0.018708
2021-12-12 23:20:28,217 iteration 700 : loss : 0.061964, loss_ce: 0.023170
2021-12-12 23:20:29,649 iteration 701 : loss : 0.066711, loss_ce: 0.023629
2021-12-12 23:20:31,132 iteration 702 : loss : 0.054530, loss_ce: 0.022060
2021-12-12 23:20:32,581 iteration 703 : loss : 0.078923, loss_ce: 0.026917
2021-12-12 23:20:34,106 iteration 704 : loss : 0.083596, loss_ce: 0.032286
2021-12-12 23:20:35,599 iteration 705 : loss : 0.059894, loss_ce: 0.026271
2021-12-12 23:20:37,105 iteration 706 : loss : 0.086783, loss_ce: 0.029234
2021-12-12 23:20:38,531 iteration 707 : loss : 0.060668, loss_ce: 0.025398
2021-12-12 23:20:39,992 iteration 708 : loss : 0.075648, loss_ce: 0.026173
2021-12-12 23:20:41,457 iteration 709 : loss : 0.066261, loss_ce: 0.021813
2021-12-12 23:20:42,857 iteration 710 : loss : 0.052438, loss_ce: 0.021622
2021-12-12 23:20:44,356 iteration 711 : loss : 0.073314, loss_ce: 0.029460
2021-12-12 23:20:45,809 iteration 712 : loss : 0.065101, loss_ce: 0.018930
2021-12-12 23:20:47,208 iteration 713 : loss : 0.043883, loss_ce: 0.017646
2021-12-12 23:20:48,608 iteration 714 : loss : 0.086934, loss_ce: 0.026787
 10%|███▏                          | 42/400 [18:57<2:38:59, 26.65s/it]2021-12-12 23:20:50,148 iteration 715 : loss : 0.065908, loss_ce: 0.033199
2021-12-12 23:20:51,580 iteration 716 : loss : 0.046342, loss_ce: 0.018817
2021-12-12 23:20:53,014 iteration 717 : loss : 0.096777, loss_ce: 0.029709
2021-12-12 23:20:54,466 iteration 718 : loss : 0.048959, loss_ce: 0.020844
2021-12-12 23:20:55,995 iteration 719 : loss : 0.055077, loss_ce: 0.023475
2021-12-12 23:20:57,411 iteration 720 : loss : 0.077693, loss_ce: 0.023533
2021-12-12 23:20:58,901 iteration 721 : loss : 0.058134, loss_ce: 0.022520
2021-12-12 23:21:00,363 iteration 722 : loss : 0.058499, loss_ce: 0.024531
2021-12-12 23:21:01,778 iteration 723 : loss : 0.052421, loss_ce: 0.017937
2021-12-12 23:21:03,322 iteration 724 : loss : 0.071263, loss_ce: 0.035024
2021-12-12 23:21:04,713 iteration 725 : loss : 0.038881, loss_ce: 0.014552
2021-12-12 23:21:06,175 iteration 726 : loss : 0.062034, loss_ce: 0.018960
2021-12-12 23:21:07,664 iteration 727 : loss : 0.082323, loss_ce: 0.021158
2021-12-12 23:21:09,256 iteration 728 : loss : 0.070036, loss_ce: 0.033595
2021-12-12 23:21:10,607 iteration 729 : loss : 0.040614, loss_ce: 0.018440
2021-12-12 23:21:12,073 iteration 730 : loss : 0.042989, loss_ce: 0.018692
2021-12-12 23:21:13,539 iteration 731 : loss : 0.076101, loss_ce: 0.029613
 11%|███▏                          | 43/400 [19:22<2:35:28, 26.13s/it]2021-12-12 23:21:15,123 iteration 732 : loss : 0.056895, loss_ce: 0.025812
2021-12-12 23:21:16,588 iteration 733 : loss : 0.083005, loss_ce: 0.033699
2021-12-12 23:21:17,985 iteration 734 : loss : 0.056492, loss_ce: 0.021522
2021-12-12 23:21:19,435 iteration 735 : loss : 0.048368, loss_ce: 0.019812
2021-12-12 23:21:20,902 iteration 736 : loss : 0.057039, loss_ce: 0.026068
2021-12-12 23:21:22,409 iteration 737 : loss : 0.039977, loss_ce: 0.014499
2021-12-12 23:21:23,865 iteration 738 : loss : 0.037072, loss_ce: 0.015985
2021-12-12 23:21:25,299 iteration 739 : loss : 0.058202, loss_ce: 0.021705
2021-12-12 23:21:26,732 iteration 740 : loss : 0.057140, loss_ce: 0.027394
2021-12-12 23:21:28,187 iteration 741 : loss : 0.052470, loss_ce: 0.022048
2021-12-12 23:21:29,695 iteration 742 : loss : 0.046852, loss_ce: 0.016120
2021-12-12 23:21:31,121 iteration 743 : loss : 0.040414, loss_ce: 0.015085
2021-12-12 23:21:32,559 iteration 744 : loss : 0.055978, loss_ce: 0.019551
2021-12-12 23:21:33,975 iteration 745 : loss : 0.047331, loss_ce: 0.020178
2021-12-12 23:21:35,423 iteration 746 : loss : 0.052456, loss_ce: 0.021290
2021-12-12 23:21:36,896 iteration 747 : loss : 0.060427, loss_ce: 0.019893
2021-12-12 23:21:38,266 iteration 748 : loss : 0.034090, loss_ce: 0.014526
 11%|███▎                          | 44/400 [19:47<2:32:33, 25.71s/it]2021-12-12 23:21:39,769 iteration 749 : loss : 0.048264, loss_ce: 0.018082
2021-12-12 23:21:41,265 iteration 750 : loss : 0.044401, loss_ce: 0.017301
2021-12-12 23:21:42,651 iteration 751 : loss : 0.049957, loss_ce: 0.021265
2021-12-12 23:21:44,108 iteration 752 : loss : 0.048613, loss_ce: 0.020147
2021-12-12 23:21:45,638 iteration 753 : loss : 0.067229, loss_ce: 0.030275
2021-12-12 23:21:47,066 iteration 754 : loss : 0.091334, loss_ce: 0.037997
2021-12-12 23:21:48,518 iteration 755 : loss : 0.039201, loss_ce: 0.015842
2021-12-12 23:21:49,926 iteration 756 : loss : 0.045965, loss_ce: 0.020161
2021-12-12 23:21:51,358 iteration 757 : loss : 0.043547, loss_ce: 0.014964
2021-12-12 23:21:52,830 iteration 758 : loss : 0.041592, loss_ce: 0.015775
2021-12-12 23:21:54,214 iteration 759 : loss : 0.031635, loss_ce: 0.013356
2021-12-12 23:21:55,697 iteration 760 : loss : 0.083730, loss_ce: 0.030944
2021-12-12 23:21:57,195 iteration 761 : loss : 0.047330, loss_ce: 0.013858
2021-12-12 23:21:58,671 iteration 762 : loss : 0.062072, loss_ce: 0.030539
2021-12-12 23:22:00,102 iteration 763 : loss : 0.043975, loss_ce: 0.017673
2021-12-12 23:22:01,507 iteration 764 : loss : 0.032328, loss_ce: 0.012843
2021-12-12 23:22:01,507 Training Data Eval:
2021-12-12 23:22:08,959   Average segmentation loss on training set: 0.0364
2021-12-12 23:22:08,959 Validation Data Eval:
2021-12-12 23:22:11,545   Average segmentation loss on validation set: 0.0757
2021-12-12 23:22:17,953 Found new lowest validation loss at iteration 764! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-12 23:22:19,354 iteration 765 : loss : 0.057453, loss_ce: 0.020668
 11%|███▍                          | 45/400 [20:28<2:59:24, 30.32s/it]2021-12-12 23:22:20,736 iteration 766 : loss : 0.052919, loss_ce: 0.017782
2021-12-12 23:22:22,148 iteration 767 : loss : 0.042109, loss_ce: 0.013994
2021-12-12 23:22:23,423 iteration 768 : loss : 0.055234, loss_ce: 0.019524
2021-12-12 23:22:24,873 iteration 769 : loss : 0.081810, loss_ce: 0.020682
2021-12-12 23:22:26,186 iteration 770 : loss : 0.052354, loss_ce: 0.020377
2021-12-12 23:22:27,619 iteration 771 : loss : 0.046755, loss_ce: 0.015180
2021-12-12 23:22:29,049 iteration 772 : loss : 0.055358, loss_ce: 0.023422
2021-12-12 23:22:30,444 iteration 773 : loss : 0.048317, loss_ce: 0.017204
2021-12-12 23:22:31,827 iteration 774 : loss : 0.045660, loss_ce: 0.020228
2021-12-12 23:22:33,187 iteration 775 : loss : 0.037402, loss_ce: 0.014327
2021-12-12 23:22:34,477 iteration 776 : loss : 0.045714, loss_ce: 0.021169
2021-12-12 23:22:35,908 iteration 777 : loss : 0.061928, loss_ce: 0.023908
2021-12-12 23:22:37,335 iteration 778 : loss : 0.041379, loss_ce: 0.017487
2021-12-12 23:22:38,797 iteration 779 : loss : 0.053650, loss_ce: 0.027476
2021-12-12 23:22:40,224 iteration 780 : loss : 0.053189, loss_ce: 0.018770
2021-12-12 23:22:41,739 iteration 781 : loss : 0.062408, loss_ce: 0.027220
2021-12-12 23:22:43,246 iteration 782 : loss : 0.062904, loss_ce: 0.026209
 12%|███▍                          | 46/400 [20:52<2:47:30, 28.39s/it]2021-12-12 23:22:44,792 iteration 783 : loss : 0.039413, loss_ce: 0.017598
2021-12-12 23:22:46,261 iteration 784 : loss : 0.072800, loss_ce: 0.022960
2021-12-12 23:22:47,768 iteration 785 : loss : 0.045374, loss_ce: 0.019048
2021-12-12 23:22:49,223 iteration 786 : loss : 0.051606, loss_ce: 0.017495
2021-12-12 23:22:50,686 iteration 787 : loss : 0.056871, loss_ce: 0.023565
2021-12-12 23:22:52,177 iteration 788 : loss : 0.062160, loss_ce: 0.021697
2021-12-12 23:22:53,773 iteration 789 : loss : 0.072967, loss_ce: 0.046588
2021-12-12 23:22:55,289 iteration 790 : loss : 0.041281, loss_ce: 0.013176
2021-12-12 23:22:56,734 iteration 791 : loss : 0.055234, loss_ce: 0.019383
2021-12-12 23:22:58,232 iteration 792 : loss : 0.070611, loss_ce: 0.029876
2021-12-12 23:22:59,620 iteration 793 : loss : 0.052123, loss_ce: 0.018451
2021-12-12 23:23:01,086 iteration 794 : loss : 0.043690, loss_ce: 0.017565
2021-12-12 23:23:02,562 iteration 795 : loss : 0.047147, loss_ce: 0.019914
2021-12-12 23:23:04,026 iteration 796 : loss : 0.049151, loss_ce: 0.015795
2021-12-12 23:23:05,450 iteration 797 : loss : 0.056371, loss_ce: 0.023988
2021-12-12 23:23:06,881 iteration 798 : loss : 0.075901, loss_ce: 0.021799
2021-12-12 23:23:08,373 iteration 799 : loss : 0.041026, loss_ce: 0.014905
 12%|███▌                          | 47/400 [21:17<2:41:17, 27.41s/it]2021-12-12 23:23:09,926 iteration 800 : loss : 0.058545, loss_ce: 0.015563
2021-12-12 23:23:11,346 iteration 801 : loss : 0.055218, loss_ce: 0.018632
2021-12-12 23:23:12,792 iteration 802 : loss : 0.042733, loss_ce: 0.020128
2021-12-12 23:23:14,332 iteration 803 : loss : 0.061589, loss_ce: 0.033379
2021-12-12 23:23:15,749 iteration 804 : loss : 0.040991, loss_ce: 0.019491
2021-12-12 23:23:17,162 iteration 805 : loss : 0.107262, loss_ce: 0.025792
2021-12-12 23:23:18,639 iteration 806 : loss : 0.059679, loss_ce: 0.025143
2021-12-12 23:23:20,195 iteration 807 : loss : 0.057453, loss_ce: 0.022961
2021-12-12 23:23:21,694 iteration 808 : loss : 0.052299, loss_ce: 0.021502
2021-12-12 23:23:23,143 iteration 809 : loss : 0.082859, loss_ce: 0.021562
2021-12-12 23:23:24,646 iteration 810 : loss : 0.067607, loss_ce: 0.019905
2021-12-12 23:23:26,069 iteration 811 : loss : 0.035368, loss_ce: 0.013134
2021-12-12 23:23:27,602 iteration 812 : loss : 0.092362, loss_ce: 0.034503
2021-12-12 23:23:29,059 iteration 813 : loss : 0.065708, loss_ce: 0.025546
2021-12-12 23:23:30,541 iteration 814 : loss : 0.071945, loss_ce: 0.033613
2021-12-12 23:23:32,054 iteration 815 : loss : 0.058590, loss_ce: 0.021439
2021-12-12 23:23:33,412 iteration 816 : loss : 0.044137, loss_ce: 0.016574
 12%|███▌                          | 48/400 [21:42<2:36:39, 26.70s/it]2021-12-12 23:23:34,893 iteration 817 : loss : 0.037722, loss_ce: 0.014652
2021-12-12 23:23:36,399 iteration 818 : loss : 0.065194, loss_ce: 0.026843
2021-12-12 23:23:37,851 iteration 819 : loss : 0.053860, loss_ce: 0.022149
2021-12-12 23:23:39,406 iteration 820 : loss : 0.072327, loss_ce: 0.031937
2021-12-12 23:23:40,772 iteration 821 : loss : 0.073768, loss_ce: 0.029344
2021-12-12 23:23:42,257 iteration 822 : loss : 0.044092, loss_ce: 0.016946
2021-12-12 23:23:43,706 iteration 823 : loss : 0.049722, loss_ce: 0.016757
2021-12-12 23:23:45,142 iteration 824 : loss : 0.046950, loss_ce: 0.018185
2021-12-12 23:23:46,601 iteration 825 : loss : 0.061854, loss_ce: 0.016692
2021-12-12 23:23:48,089 iteration 826 : loss : 0.059869, loss_ce: 0.025003
2021-12-12 23:23:49,534 iteration 827 : loss : 0.096656, loss_ce: 0.021881
2021-12-12 23:23:51,032 iteration 828 : loss : 0.071065, loss_ce: 0.030670
2021-12-12 23:23:52,475 iteration 829 : loss : 0.048757, loss_ce: 0.016605
2021-12-12 23:23:54,017 iteration 830 : loss : 0.059628, loss_ce: 0.020656
2021-12-12 23:23:55,496 iteration 831 : loss : 0.061017, loss_ce: 0.025474
2021-12-12 23:23:56,939 iteration 832 : loss : 0.034540, loss_ce: 0.014764
2021-12-12 23:23:58,351 iteration 833 : loss : 0.048736, loss_ce: 0.024743
 12%|███▋                          | 49/400 [22:07<2:33:06, 26.17s/it]2021-12-12 23:23:59,818 iteration 834 : loss : 0.059522, loss_ce: 0.017568
2021-12-12 23:24:01,309 iteration 835 : loss : 0.049090, loss_ce: 0.020380
2021-12-12 23:24:02,788 iteration 836 : loss : 0.037524, loss_ce: 0.015767
2021-12-12 23:24:04,227 iteration 837 : loss : 0.039402, loss_ce: 0.018403
2021-12-12 23:24:05,661 iteration 838 : loss : 0.052818, loss_ce: 0.018978
2021-12-12 23:24:07,179 iteration 839 : loss : 0.057005, loss_ce: 0.019888
2021-12-12 23:24:08,651 iteration 840 : loss : 0.072065, loss_ce: 0.027575
2021-12-12 23:24:10,108 iteration 841 : loss : 0.051698, loss_ce: 0.026617
2021-12-12 23:24:11,675 iteration 842 : loss : 0.050091, loss_ce: 0.020384
2021-12-12 23:24:13,116 iteration 843 : loss : 0.038602, loss_ce: 0.014057
2021-12-12 23:24:14,612 iteration 844 : loss : 0.088878, loss_ce: 0.035074
2021-12-12 23:24:16,029 iteration 845 : loss : 0.068771, loss_ce: 0.039081
2021-12-12 23:24:17,489 iteration 846 : loss : 0.049729, loss_ce: 0.017879
2021-12-12 23:24:18,993 iteration 847 : loss : 0.059794, loss_ce: 0.025357
2021-12-12 23:24:20,370 iteration 848 : loss : 0.039420, loss_ce: 0.014739
2021-12-12 23:24:21,854 iteration 849 : loss : 0.049878, loss_ce: 0.023934
2021-12-12 23:24:21,854 Training Data Eval:
2021-12-12 23:24:29,318   Average segmentation loss on training set: 0.0643
2021-12-12 23:24:29,319 Validation Data Eval:
2021-12-12 23:24:31,915   Average segmentation loss on validation set: 0.1325
2021-12-12 23:24:33,445 iteration 850 : loss : 0.046395, loss_ce: 0.015427
 12%|███▊                          | 50/400 [22:42<2:48:16, 28.85s/it]2021-12-12 23:24:34,984 iteration 851 : loss : 0.044588, loss_ce: 0.022745
2021-12-12 23:24:36,472 iteration 852 : loss : 0.071332, loss_ce: 0.028322
2021-12-12 23:24:37,959 iteration 853 : loss : 0.056918, loss_ce: 0.023519
2021-12-12 23:24:39,366 iteration 854 : loss : 0.038126, loss_ce: 0.016486
2021-12-12 23:24:40,738 iteration 855 : loss : 0.038990, loss_ce: 0.014834
2021-12-12 23:24:42,166 iteration 856 : loss : 0.034013, loss_ce: 0.012728
2021-12-12 23:24:43,711 iteration 857 : loss : 0.045635, loss_ce: 0.018853
2021-12-12 23:24:45,168 iteration 858 : loss : 0.065122, loss_ce: 0.022270
2021-12-12 23:24:46,703 iteration 859 : loss : 0.058439, loss_ce: 0.020593
2021-12-12 23:24:48,207 iteration 860 : loss : 0.056796, loss_ce: 0.019033
2021-12-12 23:24:49,663 iteration 861 : loss : 0.050131, loss_ce: 0.018515
2021-12-12 23:24:51,121 iteration 862 : loss : 0.048447, loss_ce: 0.011154
2021-12-12 23:24:52,505 iteration 863 : loss : 0.059826, loss_ce: 0.029314
2021-12-12 23:24:53,952 iteration 864 : loss : 0.035823, loss_ce: 0.016304
2021-12-12 23:24:55,343 iteration 865 : loss : 0.049471, loss_ce: 0.023471
2021-12-12 23:24:56,759 iteration 866 : loss : 0.034733, loss_ce: 0.015506
2021-12-12 23:24:58,186 iteration 867 : loss : 0.047819, loss_ce: 0.020846
 13%|███▊                          | 51/400 [23:07<2:40:38, 27.62s/it]2021-12-12 23:24:59,710 iteration 868 : loss : 0.042885, loss_ce: 0.012758
2021-12-12 23:25:01,124 iteration 869 : loss : 0.057662, loss_ce: 0.024585
2021-12-12 23:25:02,592 iteration 870 : loss : 0.068632, loss_ce: 0.017115
2021-12-12 23:25:04,062 iteration 871 : loss : 0.058982, loss_ce: 0.023836
2021-12-12 23:25:05,470 iteration 872 : loss : 0.036919, loss_ce: 0.017634
2021-12-12 23:25:06,888 iteration 873 : loss : 0.044330, loss_ce: 0.015360
2021-12-12 23:25:08,372 iteration 874 : loss : 0.054413, loss_ce: 0.027026
2021-12-12 23:25:09,849 iteration 875 : loss : 0.061178, loss_ce: 0.025969
2021-12-12 23:25:11,299 iteration 876 : loss : 0.058285, loss_ce: 0.024868
2021-12-12 23:25:12,704 iteration 877 : loss : 0.042426, loss_ce: 0.014435
2021-12-12 23:25:14,124 iteration 878 : loss : 0.042759, loss_ce: 0.016931
2021-12-12 23:25:15,578 iteration 879 : loss : 0.056642, loss_ce: 0.021489
2021-12-12 23:25:16,995 iteration 880 : loss : 0.037766, loss_ce: 0.014165
2021-12-12 23:25:18,492 iteration 881 : loss : 0.050552, loss_ce: 0.021174
2021-12-12 23:25:19,920 iteration 882 : loss : 0.042619, loss_ce: 0.020434
2021-12-12 23:25:21,359 iteration 883 : loss : 0.070524, loss_ce: 0.024509
2021-12-12 23:25:22,918 iteration 884 : loss : 0.058254, loss_ce: 0.017965
 13%|███▉                          | 52/400 [23:32<2:35:08, 26.75s/it]2021-12-12 23:25:24,457 iteration 885 : loss : 0.070050, loss_ce: 0.028437
2021-12-12 23:25:25,878 iteration 886 : loss : 0.054463, loss_ce: 0.018610
2021-12-12 23:25:27,297 iteration 887 : loss : 0.055323, loss_ce: 0.024892
2021-12-12 23:25:28,739 iteration 888 : loss : 0.051176, loss_ce: 0.020810
2021-12-12 23:25:30,154 iteration 889 : loss : 0.055454, loss_ce: 0.016530
2021-12-12 23:25:31,660 iteration 890 : loss : 0.046117, loss_ce: 0.020149
2021-12-12 23:25:33,130 iteration 891 : loss : 0.048496, loss_ce: 0.025066
2021-12-12 23:25:34,597 iteration 892 : loss : 0.074260, loss_ce: 0.020707
2021-12-12 23:25:36,134 iteration 893 : loss : 0.048630, loss_ce: 0.020782
2021-12-12 23:25:37,590 iteration 894 : loss : 0.075688, loss_ce: 0.030780
2021-12-12 23:25:39,055 iteration 895 : loss : 0.043289, loss_ce: 0.014029
2021-12-12 23:25:40,554 iteration 896 : loss : 0.068957, loss_ce: 0.020507
2021-12-12 23:25:41,949 iteration 897 : loss : 0.039130, loss_ce: 0.014989
2021-12-12 23:25:43,506 iteration 898 : loss : 0.051385, loss_ce: 0.019917
2021-12-12 23:25:44,953 iteration 899 : loss : 0.035426, loss_ce: 0.013456
2021-12-12 23:25:46,421 iteration 900 : loss : 0.072346, loss_ce: 0.026120
2021-12-12 23:25:47,843 iteration 901 : loss : 0.071562, loss_ce: 0.043887
 13%|███▉                          | 53/400 [23:57<2:31:33, 26.21s/it]2021-12-12 23:25:49,325 iteration 902 : loss : 0.043166, loss_ce: 0.015368
2021-12-12 23:25:50,806 iteration 903 : loss : 0.038906, loss_ce: 0.012592
2021-12-12 23:25:52,246 iteration 904 : loss : 0.044256, loss_ce: 0.020431
2021-12-12 23:25:53,663 iteration 905 : loss : 0.077842, loss_ce: 0.022217
2021-12-12 23:25:55,081 iteration 906 : loss : 0.044022, loss_ce: 0.016148
2021-12-12 23:25:56,578 iteration 907 : loss : 0.033674, loss_ce: 0.015584
2021-12-12 23:25:57,982 iteration 908 : loss : 0.039450, loss_ce: 0.019959
2021-12-12 23:25:59,464 iteration 909 : loss : 0.061988, loss_ce: 0.027466
2021-12-12 23:26:00,923 iteration 910 : loss : 0.063756, loss_ce: 0.021626
2021-12-12 23:26:02,394 iteration 911 : loss : 0.048754, loss_ce: 0.020130
2021-12-12 23:26:03,756 iteration 912 : loss : 0.041847, loss_ce: 0.016161
2021-12-12 23:26:05,243 iteration 913 : loss : 0.054221, loss_ce: 0.020646
2021-12-12 23:26:06,659 iteration 914 : loss : 0.038718, loss_ce: 0.016437
2021-12-12 23:26:08,130 iteration 915 : loss : 0.055830, loss_ce: 0.026299
2021-12-12 23:26:09,554 iteration 916 : loss : 0.046503, loss_ce: 0.016176
2021-12-12 23:26:10,995 iteration 917 : loss : 0.045975, loss_ce: 0.016392
2021-12-12 23:26:12,437 iteration 918 : loss : 0.053569, loss_ce: 0.018254
 14%|████                          | 54/400 [24:21<2:28:19, 25.72s/it]2021-12-12 23:26:13,986 iteration 919 : loss : 0.036218, loss_ce: 0.014377
2021-12-12 23:26:15,388 iteration 920 : loss : 0.043550, loss_ce: 0.024894
2021-12-12 23:26:16,926 iteration 921 : loss : 0.035422, loss_ce: 0.015923
2021-12-12 23:26:18,286 iteration 922 : loss : 0.034118, loss_ce: 0.014147
2021-12-12 23:26:19,695 iteration 923 : loss : 0.041819, loss_ce: 0.014866
2021-12-12 23:26:21,139 iteration 924 : loss : 0.046222, loss_ce: 0.015492
2021-12-12 23:26:22,545 iteration 925 : loss : 0.038652, loss_ce: 0.014377
2021-12-12 23:26:23,945 iteration 926 : loss : 0.045799, loss_ce: 0.015596
2021-12-12 23:26:25,409 iteration 927 : loss : 0.052894, loss_ce: 0.022707
2021-12-12 23:26:26,815 iteration 928 : loss : 0.044050, loss_ce: 0.016720
2021-12-12 23:26:28,392 iteration 929 : loss : 0.071333, loss_ce: 0.033850
2021-12-12 23:26:29,835 iteration 930 : loss : 0.045611, loss_ce: 0.026327
2021-12-12 23:26:31,289 iteration 931 : loss : 0.042254, loss_ce: 0.014911
2021-12-12 23:26:32,757 iteration 932 : loss : 0.059086, loss_ce: 0.015801
2021-12-12 23:26:34,347 iteration 933 : loss : 0.081748, loss_ce: 0.023944
2021-12-12 23:26:35,789 iteration 934 : loss : 0.039425, loss_ce: 0.015432
2021-12-12 23:26:35,789 Training Data Eval:
2021-12-12 23:26:43,209   Average segmentation loss on training set: 0.0502
2021-12-12 23:26:43,209 Validation Data Eval:
2021-12-12 23:26:45,804   Average segmentation loss on validation set: 0.0852
2021-12-12 23:26:47,227 iteration 935 : loss : 0.042792, loss_ce: 0.013238
 14%|████▏                         | 55/400 [24:56<2:43:31, 28.44s/it]2021-12-12 23:26:48,708 iteration 936 : loss : 0.045783, loss_ce: 0.012347
2021-12-12 23:26:50,141 iteration 937 : loss : 0.045923, loss_ce: 0.017832
2021-12-12 23:26:51,620 iteration 938 : loss : 0.055672, loss_ce: 0.027600
2021-12-12 23:26:53,080 iteration 939 : loss : 0.077492, loss_ce: 0.031594
2021-12-12 23:26:54,516 iteration 940 : loss : 0.048541, loss_ce: 0.018982
2021-12-12 23:26:55,999 iteration 941 : loss : 0.071031, loss_ce: 0.022813
2021-12-12 23:26:57,440 iteration 942 : loss : 0.050908, loss_ce: 0.021539
2021-12-12 23:26:58,808 iteration 943 : loss : 0.084757, loss_ce: 0.027853
2021-12-12 23:27:00,237 iteration 944 : loss : 0.037118, loss_ce: 0.014834
2021-12-12 23:27:01,683 iteration 945 : loss : 0.081892, loss_ce: 0.056030
2021-12-12 23:27:03,146 iteration 946 : loss : 0.055160, loss_ce: 0.018176
2021-12-12 23:27:04,701 iteration 947 : loss : 0.054164, loss_ce: 0.024579
2021-12-12 23:27:06,124 iteration 948 : loss : 0.060533, loss_ce: 0.025651
2021-12-12 23:27:07,607 iteration 949 : loss : 0.037212, loss_ce: 0.013940
2021-12-12 23:27:09,084 iteration 950 : loss : 0.084649, loss_ce: 0.026600
2021-12-12 23:27:10,606 iteration 951 : loss : 0.055236, loss_ce: 0.025977
2021-12-12 23:27:12,005 iteration 952 : loss : 0.049553, loss_ce: 0.014598
 14%|████▏                         | 56/400 [25:21<2:36:45, 27.34s/it]2021-12-12 23:27:13,493 iteration 953 : loss : 0.047084, loss_ce: 0.017000
2021-12-12 23:27:15,036 iteration 954 : loss : 0.040844, loss_ce: 0.017608
2021-12-12 23:27:16,464 iteration 955 : loss : 0.037020, loss_ce: 0.014278
2021-12-12 23:27:17,884 iteration 956 : loss : 0.043408, loss_ce: 0.018089
2021-12-12 23:27:19,223 iteration 957 : loss : 0.038909, loss_ce: 0.014561
2021-12-12 23:27:20,664 iteration 958 : loss : 0.050697, loss_ce: 0.018218
2021-12-12 23:27:22,071 iteration 959 : loss : 0.045088, loss_ce: 0.020290
2021-12-12 23:27:23,466 iteration 960 : loss : 0.038918, loss_ce: 0.014711
2021-12-12 23:27:24,914 iteration 961 : loss : 0.072099, loss_ce: 0.027043
2021-12-12 23:27:26,333 iteration 962 : loss : 0.037631, loss_ce: 0.012259
2021-12-12 23:27:27,813 iteration 963 : loss : 0.051807, loss_ce: 0.019269
2021-12-12 23:27:29,283 iteration 964 : loss : 0.054620, loss_ce: 0.021254
2021-12-12 23:27:30,736 iteration 965 : loss : 0.034913, loss_ce: 0.014079
2021-12-12 23:27:32,271 iteration 966 : loss : 0.065072, loss_ce: 0.032280
2021-12-12 23:27:33,718 iteration 967 : loss : 0.069628, loss_ce: 0.031191
2021-12-12 23:27:35,184 iteration 968 : loss : 0.061703, loss_ce: 0.028767
2021-12-12 23:27:36,675 iteration 969 : loss : 0.049375, loss_ce: 0.018761
 14%|████▎                         | 57/400 [25:45<2:31:43, 26.54s/it]2021-12-12 23:27:38,151 iteration 970 : loss : 0.056047, loss_ce: 0.022598
2021-12-12 23:27:39,673 iteration 971 : loss : 0.051784, loss_ce: 0.016760
2021-12-12 23:27:41,053 iteration 972 : loss : 0.041023, loss_ce: 0.014817
2021-12-12 23:27:42,447 iteration 973 : loss : 0.049263, loss_ce: 0.017771
2021-12-12 23:27:43,887 iteration 974 : loss : 0.048121, loss_ce: 0.017986
2021-12-12 23:27:45,300 iteration 975 : loss : 0.052936, loss_ce: 0.016452
2021-12-12 23:27:46,734 iteration 976 : loss : 0.083066, loss_ce: 0.025890
2021-12-12 23:27:48,234 iteration 977 : loss : 0.051769, loss_ce: 0.019062
2021-12-12 23:27:49,710 iteration 978 : loss : 0.058384, loss_ce: 0.028297
2021-12-12 23:27:51,193 iteration 979 : loss : 0.041840, loss_ce: 0.018113
2021-12-12 23:27:52,588 iteration 980 : loss : 0.053598, loss_ce: 0.020785
2021-12-12 23:27:54,090 iteration 981 : loss : 0.051201, loss_ce: 0.018986
2021-12-12 23:27:55,479 iteration 982 : loss : 0.046361, loss_ce: 0.024167
2021-12-12 23:27:56,949 iteration 983 : loss : 0.063049, loss_ce: 0.028023
2021-12-12 23:27:58,392 iteration 984 : loss : 0.052387, loss_ce: 0.024002
2021-12-12 23:27:59,831 iteration 985 : loss : 0.054684, loss_ce: 0.020900
2021-12-12 23:28:01,269 iteration 986 : loss : 0.074287, loss_ce: 0.026095
 14%|████▎                         | 58/400 [26:10<2:27:56, 25.96s/it]2021-12-12 23:28:02,761 iteration 987 : loss : 0.044985, loss_ce: 0.018455
2021-12-12 23:28:04,270 iteration 988 : loss : 0.055350, loss_ce: 0.021607
2021-12-12 23:28:05,669 iteration 989 : loss : 0.052017, loss_ce: 0.015814
2021-12-12 23:28:07,169 iteration 990 : loss : 0.046516, loss_ce: 0.023556
2021-12-12 23:28:08,663 iteration 991 : loss : 0.061270, loss_ce: 0.027842
2021-12-12 23:28:10,067 iteration 992 : loss : 0.044142, loss_ce: 0.017750
2021-12-12 23:28:11,622 iteration 993 : loss : 0.037581, loss_ce: 0.017453
2021-12-12 23:28:13,101 iteration 994 : loss : 0.052809, loss_ce: 0.017660
2021-12-12 23:28:14,558 iteration 995 : loss : 0.038520, loss_ce: 0.016041
2021-12-12 23:28:15,978 iteration 996 : loss : 0.034221, loss_ce: 0.013463
2021-12-12 23:28:17,455 iteration 997 : loss : 0.052512, loss_ce: 0.024534
2021-12-12 23:28:18,895 iteration 998 : loss : 0.069096, loss_ce: 0.021791
2021-12-12 23:28:20,416 iteration 999 : loss : 0.046405, loss_ce: 0.017914
2021-12-12 23:28:21,878 iteration 1000 : loss : 0.058609, loss_ce: 0.027347
2021-12-12 23:28:23,349 iteration 1001 : loss : 0.042419, loss_ce: 0.015470
2021-12-12 23:28:24,748 iteration 1002 : loss : 0.036731, loss_ce: 0.012569
2021-12-12 23:28:26,173 iteration 1003 : loss : 0.054381, loss_ce: 0.022814
 15%|████▍                         | 59/400 [26:35<2:25:43, 25.64s/it]2021-12-12 23:28:27,642 iteration 1004 : loss : 0.037343, loss_ce: 0.015178
2021-12-12 23:28:29,165 iteration 1005 : loss : 0.055572, loss_ce: 0.017385
2021-12-12 23:28:30,605 iteration 1006 : loss : 0.051120, loss_ce: 0.023672
2021-12-12 23:28:32,065 iteration 1007 : loss : 0.038104, loss_ce: 0.014869
2021-12-12 23:28:33,518 iteration 1008 : loss : 0.043134, loss_ce: 0.013570
2021-12-12 23:28:34,978 iteration 1009 : loss : 0.050601, loss_ce: 0.015664
2021-12-12 23:28:36,393 iteration 1010 : loss : 0.057828, loss_ce: 0.022591
2021-12-12 23:28:37,825 iteration 1011 : loss : 0.040061, loss_ce: 0.014252
2021-12-12 23:28:39,342 iteration 1012 : loss : 0.075050, loss_ce: 0.020091
2021-12-12 23:28:40,766 iteration 1013 : loss : 0.043156, loss_ce: 0.014632
2021-12-12 23:28:42,250 iteration 1014 : loss : 0.061043, loss_ce: 0.017553
2021-12-12 23:28:43,682 iteration 1015 : loss : 0.045163, loss_ce: 0.022602
2021-12-12 23:28:45,059 iteration 1016 : loss : 0.047482, loss_ce: 0.025075
2021-12-12 23:28:46,603 iteration 1017 : loss : 0.065998, loss_ce: 0.022444
2021-12-12 23:28:48,093 iteration 1018 : loss : 0.055608, loss_ce: 0.022575
2021-12-12 23:28:49,598 iteration 1019 : loss : 0.068153, loss_ce: 0.028442
2021-12-12 23:28:49,598 Training Data Eval:
2021-12-12 23:28:57,019   Average segmentation loss on training set: 0.0450
2021-12-12 23:28:57,020 Validation Data Eval:
2021-12-12 23:28:59,608   Average segmentation loss on validation set: 0.1919
2021-12-12 23:29:01,125 iteration 1020 : loss : 0.050483, loss_ce: 0.020789
 15%|████▌                         | 60/400 [27:10<2:41:08, 28.44s/it]2021-12-12 23:29:02,690 iteration 1021 : loss : 0.058438, loss_ce: 0.021271
2021-12-12 23:29:04,128 iteration 1022 : loss : 0.048386, loss_ce: 0.017495
2021-12-12 23:29:05,553 iteration 1023 : loss : 0.081365, loss_ce: 0.030963
2021-12-12 23:29:07,032 iteration 1024 : loss : 0.043002, loss_ce: 0.019727
2021-12-12 23:29:08,451 iteration 1025 : loss : 0.055416, loss_ce: 0.021283
2021-12-12 23:29:09,924 iteration 1026 : loss : 0.051154, loss_ce: 0.018628
2021-12-12 23:29:11,364 iteration 1027 : loss : 0.071864, loss_ce: 0.042800
2021-12-12 23:29:12,767 iteration 1028 : loss : 0.052589, loss_ce: 0.015108
2021-12-12 23:29:14,235 iteration 1029 : loss : 0.047968, loss_ce: 0.016429
2021-12-12 23:29:15,737 iteration 1030 : loss : 0.046021, loss_ce: 0.017079
2021-12-12 23:29:17,254 iteration 1031 : loss : 0.060317, loss_ce: 0.025004
2021-12-12 23:29:18,656 iteration 1032 : loss : 0.033067, loss_ce: 0.012854
2021-12-12 23:29:20,155 iteration 1033 : loss : 0.056021, loss_ce: 0.021154
2021-12-12 23:29:21,664 iteration 1034 : loss : 0.034061, loss_ce: 0.015626
2021-12-12 23:29:23,152 iteration 1035 : loss : 0.045240, loss_ce: 0.015671
2021-12-12 23:29:24,700 iteration 1036 : loss : 0.054134, loss_ce: 0.022808
2021-12-12 23:29:26,040 iteration 1037 : loss : 0.049458, loss_ce: 0.021168
 15%|████▌                         | 61/400 [27:35<2:34:41, 27.38s/it]2021-12-12 23:29:27,473 iteration 1038 : loss : 0.034847, loss_ce: 0.014096
2021-12-12 23:29:28,914 iteration 1039 : loss : 0.048666, loss_ce: 0.019495
2021-12-12 23:29:30,309 iteration 1040 : loss : 0.047597, loss_ce: 0.017927
2021-12-12 23:29:31,824 iteration 1041 : loss : 0.039923, loss_ce: 0.014296
2021-12-12 23:29:33,331 iteration 1042 : loss : 0.068659, loss_ce: 0.022288
2021-12-12 23:29:34,733 iteration 1043 : loss : 0.039554, loss_ce: 0.013079
2021-12-12 23:29:36,164 iteration 1044 : loss : 0.050793, loss_ce: 0.021873
2021-12-12 23:29:37,578 iteration 1045 : loss : 0.043236, loss_ce: 0.023775
2021-12-12 23:29:39,020 iteration 1046 : loss : 0.063115, loss_ce: 0.019584
2021-12-12 23:29:40,541 iteration 1047 : loss : 0.057535, loss_ce: 0.027557
2021-12-12 23:29:42,005 iteration 1048 : loss : 0.082264, loss_ce: 0.028798
2021-12-12 23:29:43,408 iteration 1049 : loss : 0.040511, loss_ce: 0.017041
2021-12-12 23:29:44,823 iteration 1050 : loss : 0.037260, loss_ce: 0.015088
2021-12-12 23:29:46,282 iteration 1051 : loss : 0.044415, loss_ce: 0.016034
2021-12-12 23:29:47,732 iteration 1052 : loss : 0.050981, loss_ce: 0.019442
2021-12-12 23:29:49,269 iteration 1053 : loss : 0.036984, loss_ce: 0.014687
2021-12-12 23:29:50,681 iteration 1054 : loss : 0.046002, loss_ce: 0.015100
 16%|████▋                         | 62/400 [27:59<2:29:35, 26.56s/it]2021-12-12 23:29:52,148 iteration 1055 : loss : 0.036926, loss_ce: 0.014194
2021-12-12 23:29:53,584 iteration 1056 : loss : 0.055680, loss_ce: 0.023658
2021-12-12 23:29:55,063 iteration 1057 : loss : 0.075424, loss_ce: 0.018050
2021-12-12 23:29:56,449 iteration 1058 : loss : 0.037017, loss_ce: 0.016533
2021-12-12 23:29:57,974 iteration 1059 : loss : 0.043585, loss_ce: 0.018783
2021-12-12 23:29:59,409 iteration 1060 : loss : 0.045947, loss_ce: 0.023136
2021-12-12 23:30:00,899 iteration 1061 : loss : 0.031965, loss_ce: 0.011732
2021-12-12 23:30:02,341 iteration 1062 : loss : 0.039030, loss_ce: 0.014885
2021-12-12 23:30:03,854 iteration 1063 : loss : 0.040610, loss_ce: 0.013284
2021-12-12 23:30:05,261 iteration 1064 : loss : 0.038939, loss_ce: 0.017499
2021-12-12 23:30:06,628 iteration 1065 : loss : 0.046400, loss_ce: 0.017757
2021-12-12 23:30:08,082 iteration 1066 : loss : 0.034826, loss_ce: 0.015461
2021-12-12 23:30:09,650 iteration 1067 : loss : 0.047685, loss_ce: 0.016619
2021-12-12 23:30:11,147 iteration 1068 : loss : 0.055568, loss_ce: 0.022037
2021-12-12 23:30:12,549 iteration 1069 : loss : 0.044814, loss_ce: 0.020464
2021-12-12 23:30:14,089 iteration 1070 : loss : 0.035637, loss_ce: 0.014246
2021-12-12 23:30:15,525 iteration 1071 : loss : 0.048053, loss_ce: 0.019262
 16%|████▋                         | 63/400 [28:24<2:26:16, 26.04s/it]2021-12-12 23:30:16,979 iteration 1072 : loss : 0.036769, loss_ce: 0.015301
2021-12-12 23:30:18,503 iteration 1073 : loss : 0.045660, loss_ce: 0.016854
2021-12-12 23:30:19,921 iteration 1074 : loss : 0.030017, loss_ce: 0.014089
2021-12-12 23:30:21,379 iteration 1075 : loss : 0.032535, loss_ce: 0.011697
2021-12-12 23:30:22,798 iteration 1076 : loss : 0.050253, loss_ce: 0.019931
2021-12-12 23:30:24,276 iteration 1077 : loss : 0.080816, loss_ce: 0.021843
2021-12-12 23:30:25,658 iteration 1078 : loss : 0.079682, loss_ce: 0.032957
2021-12-12 23:30:27,108 iteration 1079 : loss : 0.043521, loss_ce: 0.021255
2021-12-12 23:30:28,576 iteration 1080 : loss : 0.074607, loss_ce: 0.034554
2021-12-12 23:30:30,054 iteration 1081 : loss : 0.062536, loss_ce: 0.032975
2021-12-12 23:30:31,507 iteration 1082 : loss : 0.060736, loss_ce: 0.025316
2021-12-12 23:30:32,963 iteration 1083 : loss : 0.057343, loss_ce: 0.021928
2021-12-12 23:30:34,472 iteration 1084 : loss : 0.068294, loss_ce: 0.021129
2021-12-12 23:30:35,909 iteration 1085 : loss : 0.052883, loss_ce: 0.017952
2021-12-12 23:30:37,391 iteration 1086 : loss : 0.042923, loss_ce: 0.015631
2021-12-12 23:30:38,781 iteration 1087 : loss : 0.047713, loss_ce: 0.020013
2021-12-12 23:30:40,208 iteration 1088 : loss : 0.052353, loss_ce: 0.025105
 16%|████▊                         | 64/400 [28:49<2:23:33, 25.64s/it]2021-12-12 23:30:41,610 iteration 1089 : loss : 0.035386, loss_ce: 0.015132
2021-12-12 23:30:43,074 iteration 1090 : loss : 0.053781, loss_ce: 0.017330
2021-12-12 23:30:44,557 iteration 1091 : loss : 0.050437, loss_ce: 0.025810
2021-12-12 23:30:46,006 iteration 1092 : loss : 0.049705, loss_ce: 0.014989
2021-12-12 23:30:47,466 iteration 1093 : loss : 0.068497, loss_ce: 0.020794
2021-12-12 23:30:49,009 iteration 1094 : loss : 0.105839, loss_ce: 0.021478
2021-12-12 23:30:50,390 iteration 1095 : loss : 0.040093, loss_ce: 0.013710
2021-12-12 23:30:51,807 iteration 1096 : loss : 0.057064, loss_ce: 0.025487
2021-12-12 23:30:53,194 iteration 1097 : loss : 0.064660, loss_ce: 0.023572
2021-12-12 23:30:54,696 iteration 1098 : loss : 0.076572, loss_ce: 0.036143
2021-12-12 23:30:56,148 iteration 1099 : loss : 0.054193, loss_ce: 0.018117
2021-12-12 23:30:57,649 iteration 1100 : loss : 0.061737, loss_ce: 0.029438
2021-12-12 23:30:59,151 iteration 1101 : loss : 0.050559, loss_ce: 0.020731
2021-12-12 23:31:00,588 iteration 1102 : loss : 0.045091, loss_ce: 0.017866
2021-12-12 23:31:02,050 iteration 1103 : loss : 0.030738, loss_ce: 0.012318
2021-12-12 23:31:03,490 iteration 1104 : loss : 0.043124, loss_ce: 0.019642
2021-12-12 23:31:03,490 Training Data Eval:
2021-12-12 23:31:10,876   Average segmentation loss on training set: 0.0388
2021-12-12 23:31:10,876 Validation Data Eval:
2021-12-12 23:31:13,451   Average segmentation loss on validation set: 0.0903
2021-12-12 23:31:14,903 iteration 1105 : loss : 0.041180, loss_ce: 0.017682
 16%|████▉                         | 65/400 [29:24<2:38:18, 28.35s/it]2021-12-12 23:31:16,427 iteration 1106 : loss : 0.059058, loss_ce: 0.022959
2021-12-12 23:31:17,875 iteration 1107 : loss : 0.041341, loss_ce: 0.017392
2021-12-12 23:31:19,307 iteration 1108 : loss : 0.047855, loss_ce: 0.015170
2021-12-12 23:31:20,823 iteration 1109 : loss : 0.083250, loss_ce: 0.036937
2021-12-12 23:31:22,259 iteration 1110 : loss : 0.041091, loss_ce: 0.015686
2021-12-12 23:31:23,776 iteration 1111 : loss : 0.068809, loss_ce: 0.020586
2021-12-12 23:31:25,177 iteration 1112 : loss : 0.038015, loss_ce: 0.016126
2021-12-12 23:31:26,624 iteration 1113 : loss : 0.042599, loss_ce: 0.014814
2021-12-12 23:31:28,080 iteration 1114 : loss : 0.058608, loss_ce: 0.019336
2021-12-12 23:31:29,543 iteration 1115 : loss : 0.043963, loss_ce: 0.016928
2021-12-12 23:31:30,926 iteration 1116 : loss : 0.048736, loss_ce: 0.024367
2021-12-12 23:31:32,335 iteration 1117 : loss : 0.044334, loss_ce: 0.019429
2021-12-12 23:31:33,806 iteration 1118 : loss : 0.045646, loss_ce: 0.020308
2021-12-12 23:31:35,280 iteration 1119 : loss : 0.044067, loss_ce: 0.016975
2021-12-12 23:31:36,725 iteration 1120 : loss : 0.039620, loss_ce: 0.011721
2021-12-12 23:31:38,147 iteration 1121 : loss : 0.040732, loss_ce: 0.017625
2021-12-12 23:31:39,534 iteration 1122 : loss : 0.040458, loss_ce: 0.013403
 16%|████▉                         | 66/400 [29:48<2:31:37, 27.24s/it]2021-12-12 23:31:41,103 iteration 1123 : loss : 0.031798, loss_ce: 0.012036
2021-12-12 23:31:42,541 iteration 1124 : loss : 0.033690, loss_ce: 0.016626
2021-12-12 23:31:43,943 iteration 1125 : loss : 0.035042, loss_ce: 0.011552
2021-12-12 23:31:45,355 iteration 1126 : loss : 0.032205, loss_ce: 0.011814
2021-12-12 23:31:46,771 iteration 1127 : loss : 0.042329, loss_ce: 0.018688
2021-12-12 23:31:48,287 iteration 1128 : loss : 0.042024, loss_ce: 0.017480
2021-12-12 23:31:49,820 iteration 1129 : loss : 0.050664, loss_ce: 0.021025
2021-12-12 23:31:51,211 iteration 1130 : loss : 0.033098, loss_ce: 0.012721
2021-12-12 23:31:52,706 iteration 1131 : loss : 0.052501, loss_ce: 0.022217
2021-12-12 23:31:54,236 iteration 1132 : loss : 0.044961, loss_ce: 0.017126
2021-12-12 23:31:55,739 iteration 1133 : loss : 0.047094, loss_ce: 0.019258
2021-12-12 23:31:57,239 iteration 1134 : loss : 0.055983, loss_ce: 0.016505
2021-12-12 23:31:58,642 iteration 1135 : loss : 0.059674, loss_ce: 0.018660
2021-12-12 23:32:00,064 iteration 1136 : loss : 0.027875, loss_ce: 0.012485
2021-12-12 23:32:01,485 iteration 1137 : loss : 0.052805, loss_ce: 0.026597
2021-12-12 23:32:02,953 iteration 1138 : loss : 0.048564, loss_ce: 0.016270
2021-12-12 23:32:04,341 iteration 1139 : loss : 0.062511, loss_ce: 0.023887
 17%|█████                         | 67/400 [30:13<2:27:07, 26.51s/it]2021-12-12 23:32:05,826 iteration 1140 : loss : 0.033499, loss_ce: 0.013637
2021-12-12 23:32:07,299 iteration 1141 : loss : 0.043759, loss_ce: 0.018733
2021-12-12 23:32:08,862 iteration 1142 : loss : 0.047506, loss_ce: 0.020132
2021-12-12 23:32:10,324 iteration 1143 : loss : 0.036780, loss_ce: 0.015568
2021-12-12 23:32:11,793 iteration 1144 : loss : 0.045341, loss_ce: 0.014105
2021-12-12 23:32:13,244 iteration 1145 : loss : 0.058927, loss_ce: 0.020768
2021-12-12 23:32:14,665 iteration 1146 : loss : 0.034287, loss_ce: 0.013517
2021-12-12 23:32:16,086 iteration 1147 : loss : 0.038809, loss_ce: 0.014168
2021-12-12 23:32:17,510 iteration 1148 : loss : 0.039225, loss_ce: 0.016102
2021-12-12 23:32:18,968 iteration 1149 : loss : 0.029834, loss_ce: 0.014598
2021-12-12 23:32:20,395 iteration 1150 : loss : 0.042315, loss_ce: 0.015942
2021-12-12 23:32:21,821 iteration 1151 : loss : 0.027903, loss_ce: 0.013022
2021-12-12 23:32:23,227 iteration 1152 : loss : 0.045449, loss_ce: 0.018377
2021-12-12 23:32:24,753 iteration 1153 : loss : 0.055948, loss_ce: 0.018496
2021-12-12 23:32:26,234 iteration 1154 : loss : 0.035962, loss_ce: 0.011363
2021-12-12 23:32:27,722 iteration 1155 : loss : 0.051481, loss_ce: 0.013345
2021-12-12 23:32:29,265 iteration 1156 : loss : 0.064244, loss_ce: 0.018437
 17%|█████                         | 68/400 [30:38<2:24:01, 26.03s/it]2021-12-12 23:32:30,760 iteration 1157 : loss : 0.061680, loss_ce: 0.024091
2021-12-12 23:32:32,197 iteration 1158 : loss : 0.035304, loss_ce: 0.012944
2021-12-12 23:32:33,566 iteration 1159 : loss : 0.034016, loss_ce: 0.014711
2021-12-12 23:32:34,990 iteration 1160 : loss : 0.038234, loss_ce: 0.019297
2021-12-12 23:32:36,455 iteration 1161 : loss : 0.040464, loss_ce: 0.016578
2021-12-12 23:32:37,920 iteration 1162 : loss : 0.037140, loss_ce: 0.015580
2021-12-12 23:32:39,373 iteration 1163 : loss : 0.034946, loss_ce: 0.017439
2021-12-12 23:32:40,882 iteration 1164 : loss : 0.042281, loss_ce: 0.018935
2021-12-12 23:32:42,268 iteration 1165 : loss : 0.037315, loss_ce: 0.016541
2021-12-12 23:32:43,682 iteration 1166 : loss : 0.052969, loss_ce: 0.019278
2021-12-12 23:32:45,134 iteration 1167 : loss : 0.046751, loss_ce: 0.022029
2021-12-12 23:32:46,646 iteration 1168 : loss : 0.075738, loss_ce: 0.019076
2021-12-12 23:32:48,035 iteration 1169 : loss : 0.057256, loss_ce: 0.018369
2021-12-12 23:32:49,502 iteration 1170 : loss : 0.043093, loss_ce: 0.012364
2021-12-12 23:32:51,065 iteration 1171 : loss : 0.066338, loss_ce: 0.019043
2021-12-12 23:32:52,451 iteration 1172 : loss : 0.043349, loss_ce: 0.017929
2021-12-12 23:32:53,850 iteration 1173 : loss : 0.051612, loss_ce: 0.020006
 17%|█████▏                        | 69/400 [31:03<2:21:13, 25.60s/it]2021-12-12 23:32:55,372 iteration 1174 : loss : 0.048454, loss_ce: 0.018704
2021-12-12 23:32:56,885 iteration 1175 : loss : 0.100955, loss_ce: 0.051972
2021-12-12 23:32:58,287 iteration 1176 : loss : 0.072395, loss_ce: 0.029413
2021-12-12 23:32:59,691 iteration 1177 : loss : 0.056927, loss_ce: 0.025443
2021-12-12 23:33:01,087 iteration 1178 : loss : 0.045912, loss_ce: 0.019342
2021-12-12 23:33:02,598 iteration 1179 : loss : 0.052920, loss_ce: 0.024229
2021-12-12 23:33:04,065 iteration 1180 : loss : 0.049276, loss_ce: 0.022131
2021-12-12 23:33:05,448 iteration 1181 : loss : 0.065757, loss_ce: 0.024431
2021-12-12 23:33:06,882 iteration 1182 : loss : 0.039120, loss_ce: 0.016898
2021-12-12 23:33:08,338 iteration 1183 : loss : 0.056930, loss_ce: 0.025617
2021-12-12 23:33:09,798 iteration 1184 : loss : 0.067623, loss_ce: 0.024024
2021-12-12 23:33:11,233 iteration 1185 : loss : 0.044994, loss_ce: 0.026171
2021-12-12 23:33:12,706 iteration 1186 : loss : 0.051117, loss_ce: 0.019279
2021-12-12 23:33:14,096 iteration 1187 : loss : 0.045750, loss_ce: 0.022788
2021-12-12 23:33:15,574 iteration 1188 : loss : 0.065725, loss_ce: 0.026651
2021-12-12 23:33:17,059 iteration 1189 : loss : 0.082702, loss_ce: 0.021554
2021-12-12 23:33:17,060 Training Data Eval:
2021-12-12 23:33:24,439   Average segmentation loss on training set: 0.0944
2021-12-12 23:33:24,440 Validation Data Eval:
2021-12-12 23:33:27,006   Average segmentation loss on validation set: 0.2335
2021-12-12 23:33:28,422 iteration 1190 : loss : 0.041125, loss_ce: 0.013350
 18%|█████▎                        | 70/400 [31:37<2:35:35, 28.29s/it]2021-12-12 23:33:29,909 iteration 1191 : loss : 0.039268, loss_ce: 0.014101
2021-12-12 23:33:31,320 iteration 1192 : loss : 0.085005, loss_ce: 0.043986
2021-12-12 23:33:32,692 iteration 1193 : loss : 0.060057, loss_ce: 0.024418
2021-12-12 23:33:34,156 iteration 1194 : loss : 0.042223, loss_ce: 0.015974
2021-12-12 23:33:35,600 iteration 1195 : loss : 0.042439, loss_ce: 0.017520
2021-12-12 23:33:37,053 iteration 1196 : loss : 0.046254, loss_ce: 0.016265
2021-12-12 23:33:38,526 iteration 1197 : loss : 0.071385, loss_ce: 0.027110
2021-12-12 23:33:39,891 iteration 1198 : loss : 0.034477, loss_ce: 0.012262
2021-12-12 23:33:41,318 iteration 1199 : loss : 0.044209, loss_ce: 0.022538
2021-12-12 23:33:42,703 iteration 1200 : loss : 0.045454, loss_ce: 0.018458
2021-12-12 23:33:44,128 iteration 1201 : loss : 0.043195, loss_ce: 0.014798
2021-12-12 23:33:45,626 iteration 1202 : loss : 0.048451, loss_ce: 0.019207
2021-12-12 23:33:47,126 iteration 1203 : loss : 0.044990, loss_ce: 0.020629
2021-12-12 23:33:48,503 iteration 1204 : loss : 0.045759, loss_ce: 0.011993
2021-12-12 23:33:49,980 iteration 1205 : loss : 0.066050, loss_ce: 0.028624
2021-12-12 23:33:51,382 iteration 1206 : loss : 0.063236, loss_ce: 0.020946
2021-12-12 23:33:52,874 iteration 1207 : loss : 0.035884, loss_ce: 0.016319
 18%|█████▎                        | 71/400 [32:02<2:28:48, 27.14s/it]2021-12-12 23:33:54,333 iteration 1208 : loss : 0.042798, loss_ce: 0.016533
2021-12-12 23:33:55,789 iteration 1209 : loss : 0.041650, loss_ce: 0.015262
2021-12-12 23:33:57,169 iteration 1210 : loss : 0.031511, loss_ce: 0.012473
2021-12-12 23:33:58,659 iteration 1211 : loss : 0.051488, loss_ce: 0.023516
2021-12-12 23:34:00,078 iteration 1212 : loss : 0.033806, loss_ce: 0.013971
2021-12-12 23:34:01,424 iteration 1213 : loss : 0.036492, loss_ce: 0.012148
2021-12-12 23:34:02,943 iteration 1214 : loss : 0.050685, loss_ce: 0.019160
2021-12-12 23:34:04,383 iteration 1215 : loss : 0.034840, loss_ce: 0.014808
2021-12-12 23:34:05,816 iteration 1216 : loss : 0.043198, loss_ce: 0.017499
2021-12-12 23:34:07,361 iteration 1217 : loss : 0.063836, loss_ce: 0.027929
2021-12-12 23:34:08,724 iteration 1218 : loss : 0.048116, loss_ce: 0.023445
2021-12-12 23:34:10,292 iteration 1219 : loss : 0.054776, loss_ce: 0.024713
2021-12-12 23:34:11,737 iteration 1220 : loss : 0.044295, loss_ce: 0.017555
2021-12-12 23:34:13,258 iteration 1221 : loss : 0.038771, loss_ce: 0.012748
2021-12-12 23:34:14,671 iteration 1222 : loss : 0.041663, loss_ce: 0.014346
2021-12-12 23:34:16,081 iteration 1223 : loss : 0.042434, loss_ce: 0.014691
2021-12-12 23:34:17,498 iteration 1224 : loss : 0.042732, loss_ce: 0.013107
 18%|█████▍                        | 72/400 [32:26<2:24:13, 26.38s/it]2021-12-12 23:34:18,964 iteration 1225 : loss : 0.034701, loss_ce: 0.011701
2021-12-12 23:34:20,416 iteration 1226 : loss : 0.033682, loss_ce: 0.010542
2021-12-12 23:34:21,819 iteration 1227 : loss : 0.037927, loss_ce: 0.014197
2021-12-12 23:34:23,237 iteration 1228 : loss : 0.045337, loss_ce: 0.014280
2021-12-12 23:34:24,793 iteration 1229 : loss : 0.091662, loss_ce: 0.050928
2021-12-12 23:34:26,268 iteration 1230 : loss : 0.066494, loss_ce: 0.040658
2021-12-12 23:34:27,727 iteration 1231 : loss : 0.033676, loss_ce: 0.013528
2021-12-12 23:34:29,147 iteration 1232 : loss : 0.039252, loss_ce: 0.015726
2021-12-12 23:34:30,649 iteration 1233 : loss : 0.034327, loss_ce: 0.012865
2021-12-12 23:34:32,185 iteration 1234 : loss : 0.049040, loss_ce: 0.017840
2021-12-12 23:34:33,546 iteration 1235 : loss : 0.051938, loss_ce: 0.018147
2021-12-12 23:34:35,028 iteration 1236 : loss : 0.053208, loss_ce: 0.024102
2021-12-12 23:34:36,476 iteration 1237 : loss : 0.046573, loss_ce: 0.016753
2021-12-12 23:34:37,876 iteration 1238 : loss : 0.047332, loss_ce: 0.020630
2021-12-12 23:34:39,305 iteration 1239 : loss : 0.037857, loss_ce: 0.016970
2021-12-12 23:34:40,823 iteration 1240 : loss : 0.069061, loss_ce: 0.022564
2021-12-12 23:34:42,270 iteration 1241 : loss : 0.034820, loss_ce: 0.014479
 18%|█████▍                        | 73/400 [32:51<2:21:10, 25.90s/it]2021-12-12 23:34:43,801 iteration 1242 : loss : 0.037938, loss_ce: 0.019603
2021-12-12 23:34:45,246 iteration 1243 : loss : 0.038124, loss_ce: 0.015163
2021-12-12 23:34:46,770 iteration 1244 : loss : 0.043918, loss_ce: 0.017429
2021-12-12 23:34:48,268 iteration 1245 : loss : 0.058441, loss_ce: 0.022565
2021-12-12 23:34:49,697 iteration 1246 : loss : 0.066106, loss_ce: 0.023703
2021-12-12 23:34:51,291 iteration 1247 : loss : 0.059696, loss_ce: 0.022760
2021-12-12 23:34:52,702 iteration 1248 : loss : 0.049860, loss_ce: 0.019022
2021-12-12 23:34:54,150 iteration 1249 : loss : 0.043731, loss_ce: 0.019692
2021-12-12 23:34:55,603 iteration 1250 : loss : 0.073837, loss_ce: 0.020479
2021-12-12 23:34:57,110 iteration 1251 : loss : 0.035446, loss_ce: 0.015485
2021-12-12 23:34:58,491 iteration 1252 : loss : 0.053011, loss_ce: 0.014314
2021-12-12 23:34:59,913 iteration 1253 : loss : 0.051446, loss_ce: 0.019213
2021-12-12 23:35:01,356 iteration 1254 : loss : 0.045126, loss_ce: 0.016178
2021-12-12 23:35:02,906 iteration 1255 : loss : 0.073588, loss_ce: 0.031695
2021-12-12 23:35:04,336 iteration 1256 : loss : 0.043326, loss_ce: 0.015152
2021-12-12 23:35:05,693 iteration 1257 : loss : 0.034698, loss_ce: 0.012522
2021-12-12 23:35:07,076 iteration 1258 : loss : 0.030513, loss_ce: 0.014610
 18%|█████▌                        | 74/400 [33:16<2:18:56, 25.57s/it]2021-12-12 23:35:08,547 iteration 1259 : loss : 0.036061, loss_ce: 0.014792
2021-12-12 23:35:10,095 iteration 1260 : loss : 0.039002, loss_ce: 0.015458
2021-12-12 23:35:11,537 iteration 1261 : loss : 0.040748, loss_ce: 0.012891
2021-12-12 23:35:12,945 iteration 1262 : loss : 0.033544, loss_ce: 0.011230
2021-12-12 23:35:14,394 iteration 1263 : loss : 0.033304, loss_ce: 0.012239
2021-12-12 23:35:15,853 iteration 1264 : loss : 0.052258, loss_ce: 0.020577
2021-12-12 23:35:17,298 iteration 1265 : loss : 0.037944, loss_ce: 0.014971
2021-12-12 23:35:18,710 iteration 1266 : loss : 0.037114, loss_ce: 0.014797
2021-12-12 23:35:20,116 iteration 1267 : loss : 0.054951, loss_ce: 0.023208
2021-12-12 23:35:21,528 iteration 1268 : loss : 0.035042, loss_ce: 0.013669
2021-12-12 23:35:22,952 iteration 1269 : loss : 0.036884, loss_ce: 0.017020
2021-12-12 23:35:24,400 iteration 1270 : loss : 0.026698, loss_ce: 0.011834
2021-12-12 23:35:25,906 iteration 1271 : loss : 0.060043, loss_ce: 0.026654
2021-12-12 23:35:27,253 iteration 1272 : loss : 0.040644, loss_ce: 0.015047
2021-12-12 23:35:28,661 iteration 1273 : loss : 0.052670, loss_ce: 0.017287
2021-12-12 23:35:30,128 iteration 1274 : loss : 0.045279, loss_ce: 0.019014
2021-12-12 23:35:30,129 Training Data Eval:
2021-12-12 23:35:37,544   Average segmentation loss on training set: 0.0369
2021-12-12 23:35:37,545 Validation Data Eval:
2021-12-12 23:35:40,119   Average segmentation loss on validation set: 0.0896
2021-12-12 23:35:41,535 iteration 1275 : loss : 0.038071, loss_ce: 0.017603
 19%|█████▋                        | 75/400 [33:50<2:32:58, 28.24s/it]2021-12-12 23:35:42,993 iteration 1276 : loss : 0.055265, loss_ce: 0.025405
2021-12-12 23:35:44,532 iteration 1277 : loss : 0.050720, loss_ce: 0.021922
2021-12-12 23:35:45,971 iteration 1278 : loss : 0.042918, loss_ce: 0.017959
2021-12-12 23:35:47,408 iteration 1279 : loss : 0.052524, loss_ce: 0.017610
2021-12-12 23:35:48,886 iteration 1280 : loss : 0.051286, loss_ce: 0.021794
2021-12-12 23:35:50,297 iteration 1281 : loss : 0.063177, loss_ce: 0.029236
2021-12-12 23:35:51,733 iteration 1282 : loss : 0.036654, loss_ce: 0.015854
2021-12-12 23:35:53,116 iteration 1283 : loss : 0.052480, loss_ce: 0.013114
2021-12-12 23:35:54,568 iteration 1284 : loss : 0.033764, loss_ce: 0.013912
2021-12-12 23:35:55,964 iteration 1285 : loss : 0.033832, loss_ce: 0.010871
2021-12-12 23:35:57,449 iteration 1286 : loss : 0.052168, loss_ce: 0.016380
2021-12-12 23:35:58,923 iteration 1287 : loss : 0.029477, loss_ce: 0.011874
2021-12-12 23:36:00,321 iteration 1288 : loss : 0.034944, loss_ce: 0.014524
2021-12-12 23:36:01,758 iteration 1289 : loss : 0.079085, loss_ce: 0.037658
2021-12-12 23:36:03,169 iteration 1290 : loss : 0.064012, loss_ce: 0.018599
2021-12-12 23:36:04,588 iteration 1291 : loss : 0.039966, loss_ce: 0.016834
2021-12-12 23:36:05,998 iteration 1292 : loss : 0.041342, loss_ce: 0.022709
 19%|█████▋                        | 76/400 [34:15<2:26:22, 27.11s/it]2021-12-12 23:36:07,559 iteration 1293 : loss : 0.064095, loss_ce: 0.027429
2021-12-12 23:36:08,924 iteration 1294 : loss : 0.033187, loss_ce: 0.013686
2021-12-12 23:36:10,404 iteration 1295 : loss : 0.044167, loss_ce: 0.013887
2021-12-12 23:36:11,854 iteration 1296 : loss : 0.066860, loss_ce: 0.017149
2021-12-12 23:36:13,190 iteration 1297 : loss : 0.030937, loss_ce: 0.012283
2021-12-12 23:36:14,710 iteration 1298 : loss : 0.050245, loss_ce: 0.020328
2021-12-12 23:36:16,134 iteration 1299 : loss : 0.038894, loss_ce: 0.015551
2021-12-12 23:36:17,660 iteration 1300 : loss : 0.039809, loss_ce: 0.013007
2021-12-12 23:36:19,187 iteration 1301 : loss : 0.048593, loss_ce: 0.014802
2021-12-12 23:36:20,578 iteration 1302 : loss : 0.041231, loss_ce: 0.016513
2021-12-12 23:36:22,060 iteration 1303 : loss : 0.037834, loss_ce: 0.011811
2021-12-12 23:36:23,506 iteration 1304 : loss : 0.051536, loss_ce: 0.024504
2021-12-12 23:36:25,033 iteration 1305 : loss : 0.074013, loss_ce: 0.026274
2021-12-12 23:36:26,500 iteration 1306 : loss : 0.041899, loss_ce: 0.016567
2021-12-12 23:36:27,926 iteration 1307 : loss : 0.044221, loss_ce: 0.015893
2021-12-12 23:36:29,380 iteration 1308 : loss : 0.055267, loss_ce: 0.028655
2021-12-12 23:36:30,804 iteration 1309 : loss : 0.027045, loss_ce: 0.011248
 19%|█████▊                        | 77/400 [34:40<2:22:12, 26.42s/it]2021-12-12 23:36:32,272 iteration 1310 : loss : 0.049872, loss_ce: 0.019594
2021-12-12 23:36:33,827 iteration 1311 : loss : 0.055761, loss_ce: 0.019510
2021-12-12 23:36:35,276 iteration 1312 : loss : 0.047876, loss_ce: 0.019075
2021-12-12 23:36:36,713 iteration 1313 : loss : 0.040563, loss_ce: 0.015688
2021-12-12 23:36:38,212 iteration 1314 : loss : 0.044545, loss_ce: 0.020828
2021-12-12 23:36:39,729 iteration 1315 : loss : 0.045384, loss_ce: 0.023150
2021-12-12 23:36:41,134 iteration 1316 : loss : 0.043750, loss_ce: 0.016738
2021-12-12 23:36:42,507 iteration 1317 : loss : 0.035956, loss_ce: 0.013755
2021-12-12 23:36:43,899 iteration 1318 : loss : 0.039687, loss_ce: 0.013057
2021-12-12 23:36:45,374 iteration 1319 : loss : 0.050272, loss_ce: 0.016134
2021-12-12 23:36:46,761 iteration 1320 : loss : 0.035215, loss_ce: 0.011640
2021-12-12 23:36:48,224 iteration 1321 : loss : 0.046896, loss_ce: 0.024549
2021-12-12 23:36:49,652 iteration 1322 : loss : 0.045682, loss_ce: 0.018123
2021-12-12 23:36:51,140 iteration 1323 : loss : 0.038354, loss_ce: 0.011311
2021-12-12 23:36:52,643 iteration 1324 : loss : 0.042234, loss_ce: 0.015933
2021-12-12 23:36:54,062 iteration 1325 : loss : 0.062444, loss_ce: 0.026578
2021-12-12 23:36:55,503 iteration 1326 : loss : 0.041550, loss_ce: 0.016459
 20%|█████▊                        | 78/400 [35:04<2:18:59, 25.90s/it]2021-12-12 23:36:56,970 iteration 1327 : loss : 0.050597, loss_ce: 0.028902
2021-12-12 23:36:58,425 iteration 1328 : loss : 0.052184, loss_ce: 0.019215
2021-12-12 23:36:59,878 iteration 1329 : loss : 0.062130, loss_ce: 0.022613
2021-12-12 23:37:01,394 iteration 1330 : loss : 0.054414, loss_ce: 0.017243
2021-12-12 23:37:02,835 iteration 1331 : loss : 0.040742, loss_ce: 0.016544
2021-12-12 23:37:04,249 iteration 1332 : loss : 0.037078, loss_ce: 0.014062
2021-12-12 23:37:05,667 iteration 1333 : loss : 0.032481, loss_ce: 0.012759
2021-12-12 23:37:07,154 iteration 1334 : loss : 0.028199, loss_ce: 0.012302
2021-12-12 23:37:08,625 iteration 1335 : loss : 0.040729, loss_ce: 0.016377
2021-12-12 23:37:10,029 iteration 1336 : loss : 0.039351, loss_ce: 0.018200
2021-12-12 23:37:11,523 iteration 1337 : loss : 0.040385, loss_ce: 0.015236
2021-12-12 23:37:12,943 iteration 1338 : loss : 0.030557, loss_ce: 0.013143
2021-12-12 23:37:14,349 iteration 1339 : loss : 0.038226, loss_ce: 0.015240
2021-12-12 23:37:15,751 iteration 1340 : loss : 0.032590, loss_ce: 0.012254
2021-12-12 23:37:17,217 iteration 1341 : loss : 0.043344, loss_ce: 0.016220
2021-12-12 23:37:18,730 iteration 1342 : loss : 0.067451, loss_ce: 0.021375
2021-12-12 23:37:20,094 iteration 1343 : loss : 0.035075, loss_ce: 0.011600
 20%|█████▉                        | 79/400 [35:29<2:16:27, 25.51s/it]2021-12-12 23:37:21,608 iteration 1344 : loss : 0.037278, loss_ce: 0.011817
2021-12-12 23:37:23,031 iteration 1345 : loss : 0.030618, loss_ce: 0.008543
2021-12-12 23:37:24,520 iteration 1346 : loss : 0.041473, loss_ce: 0.015187
2021-12-12 23:37:25,960 iteration 1347 : loss : 0.048467, loss_ce: 0.023618
2021-12-12 23:37:27,360 iteration 1348 : loss : 0.043023, loss_ce: 0.018057
2021-12-12 23:37:28,800 iteration 1349 : loss : 0.038556, loss_ce: 0.015014
2021-12-12 23:37:30,237 iteration 1350 : loss : 0.044385, loss_ce: 0.013650
2021-12-12 23:37:31,764 iteration 1351 : loss : 0.051637, loss_ce: 0.022930
2021-12-12 23:37:33,157 iteration 1352 : loss : 0.043477, loss_ce: 0.017021
2021-12-12 23:37:34,605 iteration 1353 : loss : 0.036485, loss_ce: 0.015164
2021-12-12 23:37:36,060 iteration 1354 : loss : 0.050857, loss_ce: 0.016938
2021-12-12 23:37:37,434 iteration 1355 : loss : 0.047229, loss_ce: 0.015439
2021-12-12 23:37:38,947 iteration 1356 : loss : 0.036836, loss_ce: 0.012054
2021-12-12 23:37:40,329 iteration 1357 : loss : 0.031876, loss_ce: 0.015158
2021-12-12 23:37:41,741 iteration 1358 : loss : 0.037165, loss_ce: 0.017742
2021-12-12 23:37:43,261 iteration 1359 : loss : 0.044848, loss_ce: 0.023056
2021-12-12 23:37:43,261 Training Data Eval:
2021-12-12 23:37:50,675   Average segmentation loss on training set: 0.0294
2021-12-12 23:37:50,675 Validation Data Eval:
2021-12-12 23:37:53,254   Average segmentation loss on validation set: 0.0782
2021-12-12 23:37:54,723 iteration 1360 : loss : 0.045182, loss_ce: 0.019533
 20%|██████                        | 80/400 [36:03<2:30:37, 28.24s/it]2021-12-12 23:37:56,268 iteration 1361 : loss : 0.050717, loss_ce: 0.016614
2021-12-12 23:37:57,698 iteration 1362 : loss : 0.038491, loss_ce: 0.011535
2021-12-12 23:37:59,157 iteration 1363 : loss : 0.030027, loss_ce: 0.012296
2021-12-12 23:38:00,535 iteration 1364 : loss : 0.038241, loss_ce: 0.018711
2021-12-12 23:38:01,958 iteration 1365 : loss : 0.034662, loss_ce: 0.010707
2021-12-12 23:38:03,478 iteration 1366 : loss : 0.042133, loss_ce: 0.016148
2021-12-12 23:38:04,930 iteration 1367 : loss : 0.039557, loss_ce: 0.020869
2021-12-12 23:38:06,537 iteration 1368 : loss : 0.049540, loss_ce: 0.018965
2021-12-12 23:38:07,965 iteration 1369 : loss : 0.033480, loss_ce: 0.012908
2021-12-12 23:38:09,370 iteration 1370 : loss : 0.038623, loss_ce: 0.016303
2021-12-12 23:38:10,816 iteration 1371 : loss : 0.045161, loss_ce: 0.018641
2021-12-12 23:38:12,383 iteration 1372 : loss : 0.054900, loss_ce: 0.020706
2021-12-12 23:38:13,806 iteration 1373 : loss : 0.038107, loss_ce: 0.016663
2021-12-12 23:38:15,219 iteration 1374 : loss : 0.043450, loss_ce: 0.019389
2021-12-12 23:38:16,655 iteration 1375 : loss : 0.029656, loss_ce: 0.013339
2021-12-12 23:38:18,108 iteration 1376 : loss : 0.026012, loss_ce: 0.008181
2021-12-12 23:38:19,617 iteration 1377 : loss : 0.036747, loss_ce: 0.019268
 20%|██████                        | 81/400 [36:28<2:24:49, 27.24s/it]2021-12-12 23:38:21,198 iteration 1378 : loss : 0.039613, loss_ce: 0.019395
2021-12-12 23:38:22,700 iteration 1379 : loss : 0.049920, loss_ce: 0.019446
2021-12-12 23:38:24,146 iteration 1380 : loss : 0.050317, loss_ce: 0.014914
2021-12-12 23:38:25,636 iteration 1381 : loss : 0.033171, loss_ce: 0.012696
2021-12-12 23:38:27,101 iteration 1382 : loss : 0.036408, loss_ce: 0.014256
2021-12-12 23:38:28,496 iteration 1383 : loss : 0.038487, loss_ce: 0.011984
2021-12-12 23:38:29,984 iteration 1384 : loss : 0.055815, loss_ce: 0.026324
2021-12-12 23:38:31,450 iteration 1385 : loss : 0.028106, loss_ce: 0.012997
2021-12-12 23:38:32,885 iteration 1386 : loss : 0.040720, loss_ce: 0.015337
2021-12-12 23:38:34,439 iteration 1387 : loss : 0.045403, loss_ce: 0.016238
2021-12-12 23:38:35,870 iteration 1388 : loss : 0.033544, loss_ce: 0.013189
2021-12-12 23:38:37,306 iteration 1389 : loss : 0.033462, loss_ce: 0.011733
2021-12-12 23:38:38,781 iteration 1390 : loss : 0.038610, loss_ce: 0.017687
2021-12-12 23:38:40,251 iteration 1391 : loss : 0.037751, loss_ce: 0.009496
2021-12-12 23:38:41,720 iteration 1392 : loss : 0.043973, loss_ce: 0.014037
2021-12-12 23:38:43,147 iteration 1393 : loss : 0.034870, loss_ce: 0.011602
2021-12-12 23:38:44,589 iteration 1394 : loss : 0.032967, loss_ce: 0.017447
 20%|██████▏                       | 82/400 [36:53<2:20:46, 26.56s/it]2021-12-12 23:38:46,080 iteration 1395 : loss : 0.042179, loss_ce: 0.014756
2021-12-12 23:38:47,483 iteration 1396 : loss : 0.031165, loss_ce: 0.011832
2021-12-12 23:38:48,933 iteration 1397 : loss : 0.058470, loss_ce: 0.020237
2021-12-12 23:38:50,457 iteration 1398 : loss : 0.032492, loss_ce: 0.013131
2021-12-12 23:38:51,938 iteration 1399 : loss : 0.039687, loss_ce: 0.017746
2021-12-12 23:38:53,370 iteration 1400 : loss : 0.045771, loss_ce: 0.020206
2021-12-12 23:38:54,800 iteration 1401 : loss : 0.034744, loss_ce: 0.012328
2021-12-12 23:38:56,182 iteration 1402 : loss : 0.032867, loss_ce: 0.012129
2021-12-12 23:38:57,723 iteration 1403 : loss : 0.046014, loss_ce: 0.015714
2021-12-12 23:38:59,209 iteration 1404 : loss : 0.033420, loss_ce: 0.010814
2021-12-12 23:39:00,689 iteration 1405 : loss : 0.035558, loss_ce: 0.015296
2021-12-12 23:39:02,161 iteration 1406 : loss : 0.064167, loss_ce: 0.026178
2021-12-12 23:39:03,567 iteration 1407 : loss : 0.038854, loss_ce: 0.020134
2021-12-12 23:39:04,993 iteration 1408 : loss : 0.039490, loss_ce: 0.012203
2021-12-12 23:39:06,508 iteration 1409 : loss : 0.046585, loss_ce: 0.013618
2021-12-12 23:39:07,976 iteration 1410 : loss : 0.069865, loss_ce: 0.020171
2021-12-12 23:39:09,399 iteration 1411 : loss : 0.032037, loss_ce: 0.014195
 21%|██████▏                       | 83/400 [37:18<2:17:31, 26.03s/it]2021-12-12 23:39:10,795 iteration 1412 : loss : 0.031086, loss_ce: 0.009318
2021-12-12 23:39:12,284 iteration 1413 : loss : 0.029899, loss_ce: 0.010947
2021-12-12 23:39:13,719 iteration 1414 : loss : 0.034553, loss_ce: 0.014665
2021-12-12 23:39:15,110 iteration 1415 : loss : 0.042370, loss_ce: 0.013743
2021-12-12 23:39:16,565 iteration 1416 : loss : 0.033614, loss_ce: 0.010905
2021-12-12 23:39:18,052 iteration 1417 : loss : 0.039832, loss_ce: 0.013455
2021-12-12 23:39:19,443 iteration 1418 : loss : 0.030248, loss_ce: 0.010719
2021-12-12 23:39:21,004 iteration 1419 : loss : 0.032332, loss_ce: 0.011878
2021-12-12 23:39:22,491 iteration 1420 : loss : 0.035208, loss_ce: 0.011555
2021-12-12 23:39:23,901 iteration 1421 : loss : 0.041132, loss_ce: 0.015933
2021-12-12 23:39:25,347 iteration 1422 : loss : 0.057517, loss_ce: 0.023316
2021-12-12 23:39:26,760 iteration 1423 : loss : 0.049156, loss_ce: 0.021290
2021-12-12 23:39:28,238 iteration 1424 : loss : 0.038645, loss_ce: 0.012908
2021-12-12 23:39:29,744 iteration 1425 : loss : 0.045459, loss_ce: 0.018152
2021-12-12 23:39:31,074 iteration 1426 : loss : 0.036918, loss_ce: 0.014774
2021-12-12 23:39:32,508 iteration 1427 : loss : 0.038713, loss_ce: 0.017880
2021-12-12 23:39:33,960 iteration 1428 : loss : 0.042022, loss_ce: 0.018621
 21%|██████▎                       | 84/400 [37:43<2:14:47, 25.59s/it]2021-12-12 23:39:35,530 iteration 1429 : loss : 0.052969, loss_ce: 0.019778
2021-12-12 23:39:36,936 iteration 1430 : loss : 0.059496, loss_ce: 0.018862
2021-12-12 23:39:38,386 iteration 1431 : loss : 0.041735, loss_ce: 0.017723
2021-12-12 23:39:39,849 iteration 1432 : loss : 0.038490, loss_ce: 0.015340
2021-12-12 23:39:41,383 iteration 1433 : loss : 0.036626, loss_ce: 0.015612
2021-12-12 23:39:42,878 iteration 1434 : loss : 0.049391, loss_ce: 0.019130
2021-12-12 23:39:44,231 iteration 1435 : loss : 0.037854, loss_ce: 0.011158
2021-12-12 23:39:45,739 iteration 1436 : loss : 0.035614, loss_ce: 0.015766
2021-12-12 23:39:47,124 iteration 1437 : loss : 0.057139, loss_ce: 0.013242
2021-12-12 23:39:48,487 iteration 1438 : loss : 0.034590, loss_ce: 0.017033
2021-12-12 23:39:49,934 iteration 1439 : loss : 0.026467, loss_ce: 0.008061
2021-12-12 23:39:51,458 iteration 1440 : loss : 0.052880, loss_ce: 0.023141
2021-12-12 23:39:52,885 iteration 1441 : loss : 0.029720, loss_ce: 0.012901
2021-12-12 23:39:54,294 iteration 1442 : loss : 0.038954, loss_ce: 0.012499
2021-12-12 23:39:55,779 iteration 1443 : loss : 0.036921, loss_ce: 0.014496
2021-12-12 23:39:57,296 iteration 1444 : loss : 0.031952, loss_ce: 0.013890
2021-12-12 23:39:57,296 Training Data Eval:
2021-12-12 23:40:04,715   Average segmentation loss on training set: 0.1193
2021-12-12 23:40:04,715 Validation Data Eval:
2021-12-12 23:40:07,275   Average segmentation loss on validation set: 0.1343
2021-12-12 23:40:08,757 iteration 1445 : loss : 0.039681, loss_ce: 0.012664
 21%|██████▍                       | 85/400 [38:17<2:28:51, 28.35s/it]2021-12-12 23:40:10,300 iteration 1446 : loss : 0.043063, loss_ce: 0.017599
2021-12-12 23:40:11,797 iteration 1447 : loss : 0.066622, loss_ce: 0.027678
2021-12-12 23:40:13,233 iteration 1448 : loss : 0.051667, loss_ce: 0.028225
2021-12-12 23:40:14,684 iteration 1449 : loss : 0.039840, loss_ce: 0.014464
2021-12-12 23:40:16,046 iteration 1450 : loss : 0.037514, loss_ce: 0.016289
2021-12-12 23:40:17,460 iteration 1451 : loss : 0.035590, loss_ce: 0.013873
2021-12-12 23:40:18,926 iteration 1452 : loss : 0.063324, loss_ce: 0.015092
2021-12-12 23:40:20,429 iteration 1453 : loss : 0.028050, loss_ce: 0.008202
2021-12-12 23:40:21,844 iteration 1454 : loss : 0.034238, loss_ce: 0.014184
2021-12-12 23:40:23,272 iteration 1455 : loss : 0.034540, loss_ce: 0.013122
2021-12-12 23:40:24,729 iteration 1456 : loss : 0.045867, loss_ce: 0.016547
2021-12-12 23:40:26,174 iteration 1457 : loss : 0.037603, loss_ce: 0.017185
2021-12-12 23:40:27,613 iteration 1458 : loss : 0.031389, loss_ce: 0.010906
2021-12-12 23:40:28,979 iteration 1459 : loss : 0.029763, loss_ce: 0.013029
2021-12-12 23:40:30,485 iteration 1460 : loss : 0.046818, loss_ce: 0.025011
2021-12-12 23:40:31,917 iteration 1461 : loss : 0.035750, loss_ce: 0.011758
2021-12-12 23:40:33,355 iteration 1462 : loss : 0.053087, loss_ce: 0.028366
 22%|██████▍                       | 86/400 [38:42<2:22:29, 27.23s/it]2021-12-12 23:40:34,823 iteration 1463 : loss : 0.049945, loss_ce: 0.023496
2021-12-12 23:40:36,311 iteration 1464 : loss : 0.042751, loss_ce: 0.013240
2021-12-12 23:40:37,818 iteration 1465 : loss : 0.035279, loss_ce: 0.015778
2021-12-12 23:40:39,249 iteration 1466 : loss : 0.035200, loss_ce: 0.013084
2021-12-12 23:40:40,679 iteration 1467 : loss : 0.038730, loss_ce: 0.015741
2021-12-12 23:40:42,146 iteration 1468 : loss : 0.041898, loss_ce: 0.015670
2021-12-12 23:40:43,620 iteration 1469 : loss : 0.033293, loss_ce: 0.014976
2021-12-12 23:40:45,068 iteration 1470 : loss : 0.039650, loss_ce: 0.016788
2021-12-12 23:40:46,436 iteration 1471 : loss : 0.040322, loss_ce: 0.015897
2021-12-12 23:40:47,870 iteration 1472 : loss : 0.047996, loss_ce: 0.016258
2021-12-12 23:40:49,380 iteration 1473 : loss : 0.043686, loss_ce: 0.020137
2021-12-12 23:40:50,777 iteration 1474 : loss : 0.036348, loss_ce: 0.014950
2021-12-12 23:40:52,226 iteration 1475 : loss : 0.053998, loss_ce: 0.022679
2021-12-12 23:40:53,723 iteration 1476 : loss : 0.057576, loss_ce: 0.032603
2021-12-12 23:40:55,170 iteration 1477 : loss : 0.032948, loss_ce: 0.011527
2021-12-12 23:40:56,679 iteration 1478 : loss : 0.031471, loss_ce: 0.011840
2021-12-12 23:40:58,154 iteration 1479 : loss : 0.063693, loss_ce: 0.028210
 22%|██████▌                       | 87/400 [39:07<2:18:14, 26.50s/it]2021-12-12 23:40:59,643 iteration 1480 : loss : 0.036143, loss_ce: 0.019344
2021-12-12 23:41:01,153 iteration 1481 : loss : 0.048010, loss_ce: 0.020402
2021-12-12 23:41:02,580 iteration 1482 : loss : 0.046128, loss_ce: 0.020485
2021-12-12 23:41:03,977 iteration 1483 : loss : 0.031011, loss_ce: 0.012286
2021-12-12 23:41:05,380 iteration 1484 : loss : 0.035110, loss_ce: 0.014579
2021-12-12 23:41:06,797 iteration 1485 : loss : 0.029375, loss_ce: 0.011104
2021-12-12 23:41:08,229 iteration 1486 : loss : 0.037569, loss_ce: 0.012581
2021-12-12 23:41:09,734 iteration 1487 : loss : 0.048534, loss_ce: 0.017056
2021-12-12 23:41:11,171 iteration 1488 : loss : 0.029094, loss_ce: 0.010582
2021-12-12 23:41:12,640 iteration 1489 : loss : 0.027939, loss_ce: 0.009789
2021-12-12 23:41:14,080 iteration 1490 : loss : 0.032663, loss_ce: 0.012477
2021-12-12 23:41:15,474 iteration 1491 : loss : 0.038456, loss_ce: 0.011061
2021-12-12 23:41:16,952 iteration 1492 : loss : 0.032174, loss_ce: 0.011504
2021-12-12 23:41:18,497 iteration 1493 : loss : 0.054208, loss_ce: 0.022244
2021-12-12 23:41:19,966 iteration 1494 : loss : 0.049720, loss_ce: 0.013249
2021-12-12 23:41:21,410 iteration 1495 : loss : 0.050955, loss_ce: 0.017360
2021-12-12 23:41:22,863 iteration 1496 : loss : 0.034493, loss_ce: 0.013435
 22%|██████▌                       | 88/400 [39:32<2:15:00, 25.96s/it]2021-12-12 23:41:24,320 iteration 1497 : loss : 0.028301, loss_ce: 0.011614
2021-12-12 23:41:25,674 iteration 1498 : loss : 0.030769, loss_ce: 0.014596
2021-12-12 23:41:27,066 iteration 1499 : loss : 0.028518, loss_ce: 0.012273
2021-12-12 23:41:28,625 iteration 1500 : loss : 0.071621, loss_ce: 0.031378
2021-12-12 23:41:29,993 iteration 1501 : loss : 0.042499, loss_ce: 0.013478
2021-12-12 23:41:31,448 iteration 1502 : loss : 0.037132, loss_ce: 0.014712
2021-12-12 23:41:32,957 iteration 1503 : loss : 0.050313, loss_ce: 0.017769
2021-12-12 23:41:34,368 iteration 1504 : loss : 0.048897, loss_ce: 0.022019
2021-12-12 23:41:35,772 iteration 1505 : loss : 0.036226, loss_ce: 0.013741
2021-12-12 23:41:37,265 iteration 1506 : loss : 0.036882, loss_ce: 0.012945
2021-12-12 23:41:38,674 iteration 1507 : loss : 0.038673, loss_ce: 0.015821
2021-12-12 23:41:40,117 iteration 1508 : loss : 0.058860, loss_ce: 0.010195
2021-12-12 23:41:41,538 iteration 1509 : loss : 0.032081, loss_ce: 0.012956
2021-12-12 23:41:42,953 iteration 1510 : loss : 0.035700, loss_ce: 0.009687
2021-12-12 23:41:44,491 iteration 1511 : loss : 0.067070, loss_ce: 0.035163
2021-12-12 23:41:45,952 iteration 1512 : loss : 0.055572, loss_ce: 0.016886
2021-12-12 23:41:47,420 iteration 1513 : loss : 0.036049, loss_ce: 0.012870
 22%|██████▋                       | 89/400 [39:56<2:12:22, 25.54s/it]2021-12-12 23:41:48,931 iteration 1514 : loss : 0.060038, loss_ce: 0.024920
2021-12-12 23:41:50,374 iteration 1515 : loss : 0.032300, loss_ce: 0.013468
2021-12-12 23:41:51,843 iteration 1516 : loss : 0.036914, loss_ce: 0.016460
2021-12-12 23:41:53,251 iteration 1517 : loss : 0.031764, loss_ce: 0.014000
2021-12-12 23:41:54,624 iteration 1518 : loss : 0.033989, loss_ce: 0.015209
2021-12-12 23:41:56,056 iteration 1519 : loss : 0.031036, loss_ce: 0.011381
2021-12-12 23:41:57,642 iteration 1520 : loss : 0.041148, loss_ce: 0.018520
2021-12-12 23:41:59,053 iteration 1521 : loss : 0.042444, loss_ce: 0.014579
2021-12-12 23:42:00,548 iteration 1522 : loss : 0.044316, loss_ce: 0.014990
2021-12-12 23:42:01,991 iteration 1523 : loss : 0.040136, loss_ce: 0.014638
2021-12-12 23:42:03,380 iteration 1524 : loss : 0.031916, loss_ce: 0.011166
2021-12-12 23:42:04,816 iteration 1525 : loss : 0.031662, loss_ce: 0.012668
2021-12-12 23:42:06,257 iteration 1526 : loss : 0.042369, loss_ce: 0.013895
2021-12-12 23:42:07,774 iteration 1527 : loss : 0.042153, loss_ce: 0.019663
2021-12-12 23:42:09,245 iteration 1528 : loss : 0.041482, loss_ce: 0.014630
2021-12-12 23:42:10,662 iteration 1529 : loss : 0.036871, loss_ce: 0.012362
2021-12-12 23:42:10,662 Training Data Eval:
2021-12-12 23:42:18,059   Average segmentation loss on training set: 0.0284
2021-12-12 23:42:18,059 Validation Data Eval:
2021-12-12 23:42:20,626   Average segmentation loss on validation set: 0.0953
2021-12-12 23:42:22,055 iteration 1530 : loss : 0.045301, loss_ce: 0.018969
 22%|██████▊                       | 90/400 [40:31<2:26:03, 28.27s/it]2021-12-12 23:42:23,566 iteration 1531 : loss : 0.043476, loss_ce: 0.018669
2021-12-12 23:42:25,037 iteration 1532 : loss : 0.082968, loss_ce: 0.023626
2021-12-12 23:42:26,426 iteration 1533 : loss : 0.035271, loss_ce: 0.013074
2021-12-12 23:42:27,851 iteration 1534 : loss : 0.030132, loss_ce: 0.014216
2021-12-12 23:42:29,264 iteration 1535 : loss : 0.037168, loss_ce: 0.015525
2021-12-12 23:42:30,736 iteration 1536 : loss : 0.053367, loss_ce: 0.015610
2021-12-12 23:42:32,155 iteration 1537 : loss : 0.029663, loss_ce: 0.015955
2021-12-12 23:42:33,502 iteration 1538 : loss : 0.107771, loss_ce: 0.036062
2021-12-12 23:42:34,910 iteration 1539 : loss : 0.034736, loss_ce: 0.014555
2021-12-12 23:42:36,369 iteration 1540 : loss : 0.033346, loss_ce: 0.015253
2021-12-12 23:42:37,866 iteration 1541 : loss : 0.037131, loss_ce: 0.015136
2021-12-12 23:42:39,407 iteration 1542 : loss : 0.037099, loss_ce: 0.016006
2021-12-12 23:42:40,861 iteration 1543 : loss : 0.055509, loss_ce: 0.012480
2021-12-12 23:42:42,327 iteration 1544 : loss : 0.042495, loss_ce: 0.017672
2021-12-12 23:42:43,723 iteration 1545 : loss : 0.054516, loss_ce: 0.031753
2021-12-12 23:42:45,158 iteration 1546 : loss : 0.085932, loss_ce: 0.033705
2021-12-12 23:42:46,625 iteration 1547 : loss : 0.042431, loss_ce: 0.017681
 23%|██████▊                       | 91/400 [40:55<2:19:52, 27.16s/it]2021-12-12 23:42:48,093 iteration 1548 : loss : 0.038486, loss_ce: 0.010647
2021-12-12 23:42:49,474 iteration 1549 : loss : 0.042394, loss_ce: 0.014898
2021-12-12 23:42:50,947 iteration 1550 : loss : 0.039442, loss_ce: 0.010530
2021-12-12 23:42:52,396 iteration 1551 : loss : 0.038427, loss_ce: 0.015563
2021-12-12 23:42:53,816 iteration 1552 : loss : 0.042125, loss_ce: 0.012448
2021-12-12 23:42:55,291 iteration 1553 : loss : 0.034340, loss_ce: 0.015587
2021-12-12 23:42:56,649 iteration 1554 : loss : 0.041999, loss_ce: 0.020663
2021-12-12 23:42:58,062 iteration 1555 : loss : 0.036910, loss_ce: 0.013007
2021-12-12 23:42:59,582 iteration 1556 : loss : 0.044367, loss_ce: 0.019819
2021-12-12 23:43:01,002 iteration 1557 : loss : 0.039279, loss_ce: 0.013018
2021-12-12 23:43:02,385 iteration 1558 : loss : 0.035164, loss_ce: 0.014565
2021-12-12 23:43:03,905 iteration 1559 : loss : 0.060111, loss_ce: 0.020926
2021-12-12 23:43:05,307 iteration 1560 : loss : 0.034283, loss_ce: 0.018510
2021-12-12 23:43:06,740 iteration 1561 : loss : 0.043270, loss_ce: 0.017525
2021-12-12 23:43:08,173 iteration 1562 : loss : 0.029411, loss_ce: 0.014830
2021-12-12 23:43:09,638 iteration 1563 : loss : 0.039020, loss_ce: 0.014200
2021-12-12 23:43:11,052 iteration 1564 : loss : 0.040776, loss_ce: 0.013173
 23%|██████▉                       | 92/400 [41:20<2:15:12, 26.34s/it]2021-12-12 23:43:12,487 iteration 1565 : loss : 0.030393, loss_ce: 0.014261
2021-12-12 23:43:13,976 iteration 1566 : loss : 0.056215, loss_ce: 0.016098
2021-12-12 23:43:15,434 iteration 1567 : loss : 0.032074, loss_ce: 0.013507
2021-12-12 23:43:16,975 iteration 1568 : loss : 0.042845, loss_ce: 0.013113
2021-12-12 23:43:18,410 iteration 1569 : loss : 0.031177, loss_ce: 0.014062
2021-12-12 23:43:19,856 iteration 1570 : loss : 0.024268, loss_ce: 0.008301
2021-12-12 23:43:21,295 iteration 1571 : loss : 0.037645, loss_ce: 0.011390
2021-12-12 23:43:22,832 iteration 1572 : loss : 0.049943, loss_ce: 0.018617
2021-12-12 23:43:24,200 iteration 1573 : loss : 0.030627, loss_ce: 0.014397
2021-12-12 23:43:25,676 iteration 1574 : loss : 0.042878, loss_ce: 0.019799
2021-12-12 23:43:27,192 iteration 1575 : loss : 0.038318, loss_ce: 0.016475
2021-12-12 23:43:28,704 iteration 1576 : loss : 0.038633, loss_ce: 0.015050
2021-12-12 23:43:30,078 iteration 1577 : loss : 0.029844, loss_ce: 0.009994
2021-12-12 23:43:31,501 iteration 1578 : loss : 0.033690, loss_ce: 0.011388
2021-12-12 23:43:32,998 iteration 1579 : loss : 0.050480, loss_ce: 0.016114
2021-12-12 23:43:34,471 iteration 1580 : loss : 0.051623, loss_ce: 0.018448
2021-12-12 23:43:36,022 iteration 1581 : loss : 0.050855, loss_ce: 0.025828
 23%|██████▉                       | 93/400 [41:45<2:12:40, 25.93s/it]2021-12-12 23:43:37,506 iteration 1582 : loss : 0.028012, loss_ce: 0.010841
2021-12-12 23:43:38,948 iteration 1583 : loss : 0.050342, loss_ce: 0.020347
2021-12-12 23:43:40,320 iteration 1584 : loss : 0.044257, loss_ce: 0.014646
2021-12-12 23:43:41,772 iteration 1585 : loss : 0.049721, loss_ce: 0.013397
2021-12-12 23:43:43,284 iteration 1586 : loss : 0.033195, loss_ce: 0.011260
2021-12-12 23:43:44,735 iteration 1587 : loss : 0.029950, loss_ce: 0.010040
2021-12-12 23:43:46,237 iteration 1588 : loss : 0.038548, loss_ce: 0.017065
2021-12-12 23:43:47,674 iteration 1589 : loss : 0.032702, loss_ce: 0.009928
2021-12-12 23:43:49,136 iteration 1590 : loss : 0.098357, loss_ce: 0.056552
2021-12-12 23:43:50,541 iteration 1591 : loss : 0.050972, loss_ce: 0.026799
2021-12-12 23:43:51,956 iteration 1592 : loss : 0.065447, loss_ce: 0.032840
2021-12-12 23:43:53,466 iteration 1593 : loss : 0.034190, loss_ce: 0.011680
2021-12-12 23:43:54,921 iteration 1594 : loss : 0.039252, loss_ce: 0.020404
2021-12-12 23:43:56,382 iteration 1595 : loss : 0.051483, loss_ce: 0.019710
2021-12-12 23:43:57,822 iteration 1596 : loss : 0.033786, loss_ce: 0.013212
2021-12-12 23:43:59,223 iteration 1597 : loss : 0.036322, loss_ce: 0.013548
2021-12-12 23:44:00,700 iteration 1598 : loss : 0.038388, loss_ce: 0.018128
 24%|███████                       | 94/400 [42:09<2:10:19, 25.55s/it]2021-12-12 23:44:02,205 iteration 1599 : loss : 0.026233, loss_ce: 0.011659
2021-12-12 23:44:03,621 iteration 1600 : loss : 0.041496, loss_ce: 0.014853
2021-12-12 23:44:05,067 iteration 1601 : loss : 0.045634, loss_ce: 0.015980
2021-12-12 23:44:06,488 iteration 1602 : loss : 0.038573, loss_ce: 0.016239
2021-12-12 23:44:08,004 iteration 1603 : loss : 0.049333, loss_ce: 0.022209
2021-12-12 23:44:09,422 iteration 1604 : loss : 0.037727, loss_ce: 0.017144
2021-12-12 23:44:10,937 iteration 1605 : loss : 0.037941, loss_ce: 0.013174
2021-12-12 23:44:12,431 iteration 1606 : loss : 0.037961, loss_ce: 0.012457
2021-12-12 23:44:13,874 iteration 1607 : loss : 0.035954, loss_ce: 0.014337
2021-12-12 23:44:15,335 iteration 1608 : loss : 0.030983, loss_ce: 0.010898
2021-12-12 23:44:16,795 iteration 1609 : loss : 0.040406, loss_ce: 0.013331
2021-12-12 23:44:18,215 iteration 1610 : loss : 0.038797, loss_ce: 0.015738
2021-12-12 23:44:19,667 iteration 1611 : loss : 0.043981, loss_ce: 0.015968
2021-12-12 23:44:21,109 iteration 1612 : loss : 0.040195, loss_ce: 0.017246
2021-12-12 23:44:22,566 iteration 1613 : loss : 0.038886, loss_ce: 0.014788
2021-12-12 23:44:24,033 iteration 1614 : loss : 0.034322, loss_ce: 0.010619
2021-12-12 23:44:24,034 Training Data Eval:
2021-12-12 23:44:31,434   Average segmentation loss on training set: 0.0261
2021-12-12 23:44:31,435 Validation Data Eval:
2021-12-12 23:44:34,025   Average segmentation loss on validation set: 0.0936
2021-12-12 23:44:35,534 iteration 1615 : loss : 0.035151, loss_ce: 0.015270
 24%|███████▏                      | 95/400 [42:44<2:24:03, 28.34s/it]2021-12-12 23:44:36,998 iteration 1616 : loss : 0.032570, loss_ce: 0.009105
2021-12-12 23:44:38,387 iteration 1617 : loss : 0.026324, loss_ce: 0.011254
2021-12-12 23:44:39,833 iteration 1618 : loss : 0.025454, loss_ce: 0.008859
2021-12-12 23:44:41,316 iteration 1619 : loss : 0.026669, loss_ce: 0.012391
2021-12-12 23:44:42,700 iteration 1620 : loss : 0.032925, loss_ce: 0.014636
2021-12-12 23:44:44,175 iteration 1621 : loss : 0.036927, loss_ce: 0.014731
2021-12-12 23:44:45,605 iteration 1622 : loss : 0.031285, loss_ce: 0.010999
2021-12-12 23:44:46,986 iteration 1623 : loss : 0.027859, loss_ce: 0.014313
2021-12-12 23:44:48,430 iteration 1624 : loss : 0.033763, loss_ce: 0.013040
2021-12-12 23:44:49,803 iteration 1625 : loss : 0.028763, loss_ce: 0.014315
2021-12-12 23:44:51,214 iteration 1626 : loss : 0.027445, loss_ce: 0.011286
2021-12-12 23:44:52,613 iteration 1627 : loss : 0.032129, loss_ce: 0.012055
2021-12-12 23:44:54,074 iteration 1628 : loss : 0.042716, loss_ce: 0.011243
2021-12-12 23:44:55,524 iteration 1629 : loss : 0.045105, loss_ce: 0.018247
2021-12-12 23:44:56,898 iteration 1630 : loss : 0.030453, loss_ce: 0.011523
2021-12-12 23:44:58,335 iteration 1631 : loss : 0.039418, loss_ce: 0.017998
2021-12-12 23:44:59,686 iteration 1632 : loss : 0.026022, loss_ce: 0.010121
 24%|███████▏                      | 96/400 [43:08<2:17:13, 27.08s/it]2021-12-12 23:45:01,229 iteration 1633 : loss : 0.044402, loss_ce: 0.017317
2021-12-12 23:45:02,688 iteration 1634 : loss : 0.034934, loss_ce: 0.015918
2021-12-12 23:45:04,105 iteration 1635 : loss : 0.042257, loss_ce: 0.020362
2021-12-12 23:45:05,448 iteration 1636 : loss : 0.031490, loss_ce: 0.013643
2021-12-12 23:45:06,945 iteration 1637 : loss : 0.031392, loss_ce: 0.011169
2021-12-12 23:45:08,404 iteration 1638 : loss : 0.052607, loss_ce: 0.016738
2021-12-12 23:45:09,900 iteration 1639 : loss : 0.034152, loss_ce: 0.013752
2021-12-12 23:45:11,330 iteration 1640 : loss : 0.044177, loss_ce: 0.019869
2021-12-12 23:45:12,792 iteration 1641 : loss : 0.050146, loss_ce: 0.018017
2021-12-12 23:45:14,328 iteration 1642 : loss : 0.045526, loss_ce: 0.014167
2021-12-12 23:45:15,793 iteration 1643 : loss : 0.034271, loss_ce: 0.015101
2021-12-12 23:45:17,245 iteration 1644 : loss : 0.047766, loss_ce: 0.017073
2021-12-12 23:45:18,603 iteration 1645 : loss : 0.034377, loss_ce: 0.010977
2021-12-12 23:45:20,036 iteration 1646 : loss : 0.035429, loss_ce: 0.013726
2021-12-12 23:45:21,545 iteration 1647 : loss : 0.046056, loss_ce: 0.026858
2021-12-12 23:45:22,967 iteration 1648 : loss : 0.034830, loss_ce: 0.015419
2021-12-12 23:45:24,483 iteration 1649 : loss : 0.060469, loss_ce: 0.020098
 24%|███████▎                      | 97/400 [43:33<2:13:17, 26.40s/it]2021-12-12 23:45:25,965 iteration 1650 : loss : 0.027176, loss_ce: 0.009359
2021-12-12 23:45:27,462 iteration 1651 : loss : 0.071552, loss_ce: 0.034320
2021-12-12 23:45:28,965 iteration 1652 : loss : 0.049659, loss_ce: 0.016500
2021-12-12 23:45:30,449 iteration 1653 : loss : 0.043600, loss_ce: 0.020323
2021-12-12 23:45:31,879 iteration 1654 : loss : 0.035222, loss_ce: 0.012797
2021-12-12 23:45:33,296 iteration 1655 : loss : 0.042615, loss_ce: 0.013452
2021-12-12 23:45:34,716 iteration 1656 : loss : 0.038775, loss_ce: 0.017938
2021-12-12 23:45:36,219 iteration 1657 : loss : 0.048806, loss_ce: 0.023184
2021-12-12 23:45:37,612 iteration 1658 : loss : 0.028241, loss_ce: 0.011100
2021-12-12 23:45:39,055 iteration 1659 : loss : 0.037376, loss_ce: 0.015447
2021-12-12 23:45:40,600 iteration 1660 : loss : 0.052339, loss_ce: 0.022258
2021-12-12 23:45:42,039 iteration 1661 : loss : 0.040175, loss_ce: 0.014863
2021-12-12 23:45:43,464 iteration 1662 : loss : 0.046268, loss_ce: 0.018185
2021-12-12 23:45:44,961 iteration 1663 : loss : 0.041719, loss_ce: 0.015512
2021-12-12 23:45:46,460 iteration 1664 : loss : 0.040568, loss_ce: 0.012728
2021-12-12 23:45:47,872 iteration 1665 : loss : 0.024006, loss_ce: 0.009805
2021-12-12 23:45:49,294 iteration 1666 : loss : 0.042369, loss_ce: 0.021489
 24%|███████▎                      | 98/400 [43:58<2:10:28, 25.92s/it]2021-12-12 23:45:50,782 iteration 1667 : loss : 0.034355, loss_ce: 0.015906
2021-12-12 23:45:52,288 iteration 1668 : loss : 0.054785, loss_ce: 0.023214
2021-12-12 23:45:53,717 iteration 1669 : loss : 0.028303, loss_ce: 0.011192
2021-12-12 23:45:55,155 iteration 1670 : loss : 0.041485, loss_ce: 0.012632
2021-12-12 23:45:56,634 iteration 1671 : loss : 0.034763, loss_ce: 0.013663
2021-12-12 23:45:58,066 iteration 1672 : loss : 0.029834, loss_ce: 0.009352
2021-12-12 23:45:59,482 iteration 1673 : loss : 0.025786, loss_ce: 0.010190
2021-12-12 23:46:00,987 iteration 1674 : loss : 0.028132, loss_ce: 0.012783
2021-12-12 23:46:02,410 iteration 1675 : loss : 0.029050, loss_ce: 0.010727
2021-12-12 23:46:03,900 iteration 1676 : loss : 0.041517, loss_ce: 0.019915
2021-12-12 23:46:05,410 iteration 1677 : loss : 0.042689, loss_ce: 0.019554
2021-12-12 23:46:06,893 iteration 1678 : loss : 0.047450, loss_ce: 0.012799
2021-12-12 23:46:08,382 iteration 1679 : loss : 0.021791, loss_ce: 0.006689
2021-12-12 23:46:09,842 iteration 1680 : loss : 0.038996, loss_ce: 0.022271
2021-12-12 23:46:11,269 iteration 1681 : loss : 0.064005, loss_ce: 0.020518
2021-12-12 23:46:12,680 iteration 1682 : loss : 0.033176, loss_ce: 0.014357
2021-12-12 23:46:14,161 iteration 1683 : loss : 0.060137, loss_ce: 0.026582
 25%|███████▍                      | 99/400 [44:23<2:08:26, 25.60s/it]2021-12-12 23:46:15,657 iteration 1684 : loss : 0.025888, loss_ce: 0.009464
2021-12-12 23:46:17,065 iteration 1685 : loss : 0.048723, loss_ce: 0.017181
2021-12-12 23:46:18,563 iteration 1686 : loss : 0.035326, loss_ce: 0.012551
2021-12-12 23:46:19,968 iteration 1687 : loss : 0.029410, loss_ce: 0.009291
2021-12-12 23:46:21,437 iteration 1688 : loss : 0.031428, loss_ce: 0.011844
2021-12-12 23:46:22,904 iteration 1689 : loss : 0.038986, loss_ce: 0.017151
2021-12-12 23:46:24,290 iteration 1690 : loss : 0.035191, loss_ce: 0.011261
2021-12-12 23:46:25,684 iteration 1691 : loss : 0.043780, loss_ce: 0.013722
2021-12-12 23:46:27,147 iteration 1692 : loss : 0.033373, loss_ce: 0.013652
2021-12-12 23:46:28,648 iteration 1693 : loss : 0.027458, loss_ce: 0.009681
2021-12-12 23:46:30,126 iteration 1694 : loss : 0.036895, loss_ce: 0.011202
2021-12-12 23:46:31,532 iteration 1695 : loss : 0.030929, loss_ce: 0.009149
2021-12-12 23:46:32,971 iteration 1696 : loss : 0.037857, loss_ce: 0.016369
2021-12-12 23:46:34,437 iteration 1697 : loss : 0.043883, loss_ce: 0.017475
2021-12-12 23:46:35,899 iteration 1698 : loss : 0.030949, loss_ce: 0.012229
2021-12-12 23:46:37,318 iteration 1699 : loss : 0.028552, loss_ce: 0.013002
2021-12-12 23:46:37,319 Training Data Eval:
2021-12-12 23:46:44,732   Average segmentation loss on training set: 0.0282
2021-12-12 23:46:44,732 Validation Data Eval:
2021-12-12 23:46:47,307   Average segmentation loss on validation set: 0.0808
2021-12-12 23:46:48,786 iteration 1700 : loss : 0.026492, loss_ce: 0.010657
 25%|███████▎                     | 100/400 [44:58<2:21:33, 28.31s/it]2021-12-12 23:46:50,270 iteration 1701 : loss : 0.029047, loss_ce: 0.012810
2021-12-12 23:46:51,709 iteration 1702 : loss : 0.034515, loss_ce: 0.012891
2021-12-12 23:46:53,210 iteration 1703 : loss : 0.052253, loss_ce: 0.021419
2021-12-12 23:46:54,650 iteration 1704 : loss : 0.028119, loss_ce: 0.013928
2021-12-12 23:46:56,132 iteration 1705 : loss : 0.036017, loss_ce: 0.013726
2021-12-12 23:46:57,648 iteration 1706 : loss : 0.042669, loss_ce: 0.016109
2021-12-12 23:46:59,078 iteration 1707 : loss : 0.035548, loss_ce: 0.016200
2021-12-12 23:47:00,521 iteration 1708 : loss : 0.065336, loss_ce: 0.018523
2021-12-12 23:47:01,955 iteration 1709 : loss : 0.038949, loss_ce: 0.016798
2021-12-12 23:47:03,435 iteration 1710 : loss : 0.042037, loss_ce: 0.016479
2021-12-12 23:47:04,868 iteration 1711 : loss : 0.037569, loss_ce: 0.017894
2021-12-12 23:47:06,252 iteration 1712 : loss : 0.030593, loss_ce: 0.014259
2021-12-12 23:47:07,722 iteration 1713 : loss : 0.035517, loss_ce: 0.010598
2021-12-12 23:47:09,237 iteration 1714 : loss : 0.029513, loss_ce: 0.008549
2021-12-12 23:47:10,728 iteration 1715 : loss : 0.058953, loss_ce: 0.027093
2021-12-12 23:47:12,099 iteration 1716 : loss : 0.027218, loss_ce: 0.007990
2021-12-12 23:47:13,582 iteration 1717 : loss : 0.035625, loss_ce: 0.011132
 25%|███████▎                     | 101/400 [45:22<2:15:49, 27.25s/it]2021-12-12 23:47:15,061 iteration 1718 : loss : 0.044537, loss_ce: 0.026146
2021-12-12 23:47:16,491 iteration 1719 : loss : 0.056884, loss_ce: 0.010696
2021-12-12 23:47:17,982 iteration 1720 : loss : 0.033652, loss_ce: 0.011423
2021-12-12 23:47:19,410 iteration 1721 : loss : 0.028938, loss_ce: 0.010193
2021-12-12 23:47:20,888 iteration 1722 : loss : 0.036500, loss_ce: 0.011864
2021-12-12 23:47:22,286 iteration 1723 : loss : 0.044755, loss_ce: 0.013908
2021-12-12 23:47:23,757 iteration 1724 : loss : 0.032523, loss_ce: 0.011606
2021-12-12 23:47:25,206 iteration 1725 : loss : 0.042870, loss_ce: 0.013798
2021-12-12 23:47:26,651 iteration 1726 : loss : 0.028807, loss_ce: 0.010951
2021-12-12 23:47:28,164 iteration 1727 : loss : 0.049043, loss_ce: 0.022015
2021-12-12 23:47:29,526 iteration 1728 : loss : 0.028453, loss_ce: 0.009521
2021-12-12 23:47:31,007 iteration 1729 : loss : 0.029191, loss_ce: 0.010301
2021-12-12 23:47:32,504 iteration 1730 : loss : 0.027137, loss_ce: 0.012145
2021-12-12 23:47:33,942 iteration 1731 : loss : 0.036951, loss_ce: 0.020110
2021-12-12 23:47:35,360 iteration 1732 : loss : 0.030690, loss_ce: 0.011794
2021-12-12 23:47:36,771 iteration 1733 : loss : 0.027481, loss_ce: 0.010497
2021-12-12 23:47:38,203 iteration 1734 : loss : 0.031422, loss_ce: 0.012389
 26%|███████▍                     | 102/400 [45:47<2:11:26, 26.46s/it]2021-12-12 23:47:39,813 iteration 1735 : loss : 0.028531, loss_ce: 0.010496
2021-12-12 23:47:41,224 iteration 1736 : loss : 0.039831, loss_ce: 0.014693
2021-12-12 23:47:42,776 iteration 1737 : loss : 0.034700, loss_ce: 0.015261
2021-12-12 23:47:44,221 iteration 1738 : loss : 0.032680, loss_ce: 0.014682
2021-12-12 23:47:45,615 iteration 1739 : loss : 0.025274, loss_ce: 0.009486
2021-12-12 23:47:47,110 iteration 1740 : loss : 0.041108, loss_ce: 0.017569
2021-12-12 23:47:48,590 iteration 1741 : loss : 0.037878, loss_ce: 0.014314
2021-12-12 23:47:50,069 iteration 1742 : loss : 0.038122, loss_ce: 0.013108
2021-12-12 23:47:51,451 iteration 1743 : loss : 0.037587, loss_ce: 0.010391
2021-12-12 23:47:52,975 iteration 1744 : loss : 0.039171, loss_ce: 0.015629
2021-12-12 23:47:54,477 iteration 1745 : loss : 0.062449, loss_ce: 0.022200
2021-12-12 23:47:55,923 iteration 1746 : loss : 0.037457, loss_ce: 0.017440
2021-12-12 23:47:57,323 iteration 1747 : loss : 0.033261, loss_ce: 0.013475
2021-12-12 23:47:58,778 iteration 1748 : loss : 0.029976, loss_ce: 0.010677
2021-12-12 23:48:00,132 iteration 1749 : loss : 0.032253, loss_ce: 0.009658
2021-12-12 23:48:01,604 iteration 1750 : loss : 0.059442, loss_ce: 0.011496
2021-12-12 23:48:03,144 iteration 1751 : loss : 0.031435, loss_ce: 0.011693
 26%|███████▍                     | 103/400 [46:12<2:08:44, 26.01s/it]2021-12-12 23:48:04,690 iteration 1752 : loss : 0.061999, loss_ce: 0.017128
2021-12-12 23:48:06,042 iteration 1753 : loss : 0.034379, loss_ce: 0.010773
2021-12-12 23:48:07,545 iteration 1754 : loss : 0.031523, loss_ce: 0.012037
2021-12-12 23:48:08,960 iteration 1755 : loss : 0.034503, loss_ce: 0.013318
2021-12-12 23:48:10,420 iteration 1756 : loss : 0.051897, loss_ce: 0.015509
2021-12-12 23:48:11,831 iteration 1757 : loss : 0.028051, loss_ce: 0.011130
2021-12-12 23:48:13,278 iteration 1758 : loss : 0.035999, loss_ce: 0.023668
2021-12-12 23:48:14,686 iteration 1759 : loss : 0.033762, loss_ce: 0.008986
2021-12-12 23:48:16,103 iteration 1760 : loss : 0.049949, loss_ce: 0.017113
2021-12-12 23:48:17,607 iteration 1761 : loss : 0.034003, loss_ce: 0.010463
2021-12-12 23:48:18,985 iteration 1762 : loss : 0.031030, loss_ce: 0.013080
2021-12-12 23:48:20,398 iteration 1763 : loss : 0.033030, loss_ce: 0.012672
2021-12-12 23:48:21,757 iteration 1764 : loss : 0.029174, loss_ce: 0.008468
2021-12-12 23:48:23,218 iteration 1765 : loss : 0.038708, loss_ce: 0.019509
2021-12-12 23:48:24,712 iteration 1766 : loss : 0.051978, loss_ce: 0.028392
2021-12-12 23:48:26,131 iteration 1767 : loss : 0.037628, loss_ce: 0.017819
2021-12-12 23:48:27,594 iteration 1768 : loss : 0.043676, loss_ce: 0.016021
 26%|███████▌                     | 104/400 [46:36<2:06:00, 25.54s/it]2021-12-12 23:48:29,077 iteration 1769 : loss : 0.031041, loss_ce: 0.012170
2021-12-12 23:48:30,493 iteration 1770 : loss : 0.035132, loss_ce: 0.013950
2021-12-12 23:48:31,870 iteration 1771 : loss : 0.045274, loss_ce: 0.017423
2021-12-12 23:48:33,278 iteration 1772 : loss : 0.030072, loss_ce: 0.013482
2021-12-12 23:48:34,764 iteration 1773 : loss : 0.048944, loss_ce: 0.015979
2021-12-12 23:48:36,221 iteration 1774 : loss : 0.031873, loss_ce: 0.010609
2021-12-12 23:48:37,697 iteration 1775 : loss : 0.036870, loss_ce: 0.014494
2021-12-12 23:48:39,098 iteration 1776 : loss : 0.027513, loss_ce: 0.012944
2021-12-12 23:48:40,500 iteration 1777 : loss : 0.027437, loss_ce: 0.009843
2021-12-12 23:48:41,898 iteration 1778 : loss : 0.041079, loss_ce: 0.013073
2021-12-12 23:48:43,386 iteration 1779 : loss : 0.045697, loss_ce: 0.014528
2021-12-12 23:48:44,830 iteration 1780 : loss : 0.039157, loss_ce: 0.017456
2021-12-12 23:48:46,225 iteration 1781 : loss : 0.032172, loss_ce: 0.012431
2021-12-12 23:48:47,701 iteration 1782 : loss : 0.033809, loss_ce: 0.013025
2021-12-12 23:48:49,156 iteration 1783 : loss : 0.046339, loss_ce: 0.017791
2021-12-12 23:48:50,571 iteration 1784 : loss : 0.041620, loss_ce: 0.014375
2021-12-12 23:48:50,571 Training Data Eval:
2021-12-12 23:48:57,967   Average segmentation loss on training set: 0.1459
2021-12-12 23:48:57,968 Validation Data Eval:
2021-12-12 23:49:00,569   Average segmentation loss on validation set: 0.2927
2021-12-12 23:49:02,073 iteration 1785 : loss : 0.040123, loss_ce: 0.013984
 26%|███████▌                     | 105/400 [47:11<2:18:45, 28.22s/it]2021-12-12 23:49:03,570 iteration 1786 : loss : 0.035050, loss_ce: 0.014683
2021-12-12 23:49:04,934 iteration 1787 : loss : 0.039350, loss_ce: 0.014997
2021-12-12 23:49:06,423 iteration 1788 : loss : 0.033917, loss_ce: 0.015323
2021-12-12 23:49:07,884 iteration 1789 : loss : 0.031930, loss_ce: 0.010917
2021-12-12 23:49:09,335 iteration 1790 : loss : 0.027750, loss_ce: 0.012289
2021-12-12 23:49:10,839 iteration 1791 : loss : 0.054559, loss_ce: 0.021394
2021-12-12 23:49:12,243 iteration 1792 : loss : 0.035839, loss_ce: 0.012325
2021-12-12 23:49:13,676 iteration 1793 : loss : 0.044829, loss_ce: 0.015534
2021-12-12 23:49:15,122 iteration 1794 : loss : 0.034327, loss_ce: 0.012277
2021-12-12 23:49:16,606 iteration 1795 : loss : 0.041279, loss_ce: 0.015366
2021-12-12 23:49:18,042 iteration 1796 : loss : 0.032364, loss_ce: 0.013259
2021-12-12 23:49:19,571 iteration 1797 : loss : 0.055671, loss_ce: 0.017353
2021-12-12 23:49:21,080 iteration 1798 : loss : 0.033344, loss_ce: 0.012133
2021-12-12 23:49:22,496 iteration 1799 : loss : 0.037288, loss_ce: 0.014281
2021-12-12 23:49:23,955 iteration 1800 : loss : 0.034785, loss_ce: 0.012376
2021-12-12 23:49:25,357 iteration 1801 : loss : 0.028337, loss_ce: 0.010095
2021-12-12 23:49:26,803 iteration 1802 : loss : 0.050458, loss_ce: 0.016991
 26%|███████▋                     | 106/400 [47:36<2:13:09, 27.17s/it]2021-12-12 23:49:28,368 iteration 1803 : loss : 0.037949, loss_ce: 0.013028
2021-12-12 23:49:29,868 iteration 1804 : loss : 0.034478, loss_ce: 0.009200
2021-12-12 23:49:31,293 iteration 1805 : loss : 0.034518, loss_ce: 0.009193
2021-12-12 23:49:32,722 iteration 1806 : loss : 0.041144, loss_ce: 0.021452
2021-12-12 23:49:34,150 iteration 1807 : loss : 0.053456, loss_ce: 0.018342
2021-12-12 23:49:35,580 iteration 1808 : loss : 0.033327, loss_ce: 0.013882
2021-12-12 23:49:37,003 iteration 1809 : loss : 0.026765, loss_ce: 0.010359
2021-12-12 23:49:38,368 iteration 1810 : loss : 0.026416, loss_ce: 0.009445
2021-12-12 23:49:39,867 iteration 1811 : loss : 0.030561, loss_ce: 0.013905
2021-12-12 23:49:41,367 iteration 1812 : loss : 0.034152, loss_ce: 0.013236
2021-12-12 23:49:42,923 iteration 1813 : loss : 0.034382, loss_ce: 0.011882
2021-12-12 23:49:44,392 iteration 1814 : loss : 0.034971, loss_ce: 0.016831
2021-12-12 23:49:45,787 iteration 1815 : loss : 0.032208, loss_ce: 0.009260
2021-12-12 23:49:47,148 iteration 1816 : loss : 0.030608, loss_ce: 0.013532
2021-12-12 23:49:48,649 iteration 1817 : loss : 0.037563, loss_ce: 0.015426
2021-12-12 23:49:50,098 iteration 1818 : loss : 0.040552, loss_ce: 0.015456
2021-12-12 23:49:51,584 iteration 1819 : loss : 0.041435, loss_ce: 0.017523
 27%|███████▊                     | 107/400 [48:00<2:09:11, 26.46s/it]2021-12-12 23:49:53,146 iteration 1820 : loss : 0.029115, loss_ce: 0.012664
2021-12-12 23:49:54,563 iteration 1821 : loss : 0.036759, loss_ce: 0.020509
2021-12-12 23:49:56,026 iteration 1822 : loss : 0.029887, loss_ce: 0.010295
2021-12-12 23:49:57,395 iteration 1823 : loss : 0.025944, loss_ce: 0.007850
2021-12-12 23:49:58,734 iteration 1824 : loss : 0.024867, loss_ce: 0.010113
2021-12-12 23:50:00,217 iteration 1825 : loss : 0.037058, loss_ce: 0.012709
2021-12-12 23:50:01,583 iteration 1826 : loss : 0.027154, loss_ce: 0.013067
2021-12-12 23:50:03,124 iteration 1827 : loss : 0.135787, loss_ce: 0.034969
2021-12-12 23:50:04,545 iteration 1828 : loss : 0.035940, loss_ce: 0.013377
2021-12-12 23:50:05,963 iteration 1829 : loss : 0.041120, loss_ce: 0.011561
2021-12-12 23:50:07,388 iteration 1830 : loss : 0.041501, loss_ce: 0.020759
2021-12-12 23:50:08,904 iteration 1831 : loss : 0.038720, loss_ce: 0.020933
2021-12-12 23:50:10,334 iteration 1832 : loss : 0.032147, loss_ce: 0.008421
2021-12-12 23:50:11,775 iteration 1833 : loss : 0.031118, loss_ce: 0.016387
2021-12-12 23:50:13,301 iteration 1834 : loss : 0.035374, loss_ce: 0.015072
2021-12-12 23:50:14,732 iteration 1835 : loss : 0.040532, loss_ce: 0.019600
2021-12-12 23:50:16,188 iteration 1836 : loss : 0.046110, loss_ce: 0.013768
 27%|███████▊                     | 108/400 [48:25<2:06:03, 25.90s/it]2021-12-12 23:50:17,720 iteration 1837 : loss : 0.028120, loss_ce: 0.010368
2021-12-12 23:50:19,215 iteration 1838 : loss : 0.038420, loss_ce: 0.016395
2021-12-12 23:50:20,632 iteration 1839 : loss : 0.042842, loss_ce: 0.017817
2021-12-12 23:50:22,005 iteration 1840 : loss : 0.034428, loss_ce: 0.015383
2021-12-12 23:50:23,477 iteration 1841 : loss : 0.043910, loss_ce: 0.019405
2021-12-12 23:50:24,970 iteration 1842 : loss : 0.054443, loss_ce: 0.021680
2021-12-12 23:50:26,358 iteration 1843 : loss : 0.031629, loss_ce: 0.013392
2021-12-12 23:50:27,821 iteration 1844 : loss : 0.036291, loss_ce: 0.014658
2021-12-12 23:50:29,217 iteration 1845 : loss : 0.028851, loss_ce: 0.011439
2021-12-12 23:50:30,748 iteration 1846 : loss : 0.036046, loss_ce: 0.017734
2021-12-12 23:50:32,229 iteration 1847 : loss : 0.033276, loss_ce: 0.011150
2021-12-12 23:50:33,669 iteration 1848 : loss : 0.028547, loss_ce: 0.012022
2021-12-12 23:50:35,035 iteration 1849 : loss : 0.025701, loss_ce: 0.012853
2021-12-12 23:50:36,491 iteration 1850 : loss : 0.054443, loss_ce: 0.016466
2021-12-12 23:50:37,971 iteration 1851 : loss : 0.028757, loss_ce: 0.010681
2021-12-12 23:50:39,427 iteration 1852 : loss : 0.025360, loss_ce: 0.011428
2021-12-12 23:50:40,883 iteration 1853 : loss : 0.041625, loss_ce: 0.009112
 27%|███████▉                     | 109/400 [48:50<2:03:52, 25.54s/it]2021-12-12 23:50:42,350 iteration 1854 : loss : 0.028590, loss_ce: 0.011652
2021-12-12 23:50:43,781 iteration 1855 : loss : 0.035672, loss_ce: 0.011135
2021-12-12 23:50:45,233 iteration 1856 : loss : 0.033150, loss_ce: 0.007559
2021-12-12 23:50:46,680 iteration 1857 : loss : 0.041480, loss_ce: 0.014175
2021-12-12 23:50:48,122 iteration 1858 : loss : 0.031899, loss_ce: 0.016383
2021-12-12 23:50:49,526 iteration 1859 : loss : 0.030614, loss_ce: 0.015251
2021-12-12 23:50:51,073 iteration 1860 : loss : 0.055308, loss_ce: 0.022652
2021-12-12 23:50:52,534 iteration 1861 : loss : 0.034983, loss_ce: 0.011690
2021-12-12 23:50:53,961 iteration 1862 : loss : 0.025875, loss_ce: 0.012393
2021-12-12 23:50:55,438 iteration 1863 : loss : 0.040183, loss_ce: 0.013978
2021-12-12 23:50:56,903 iteration 1864 : loss : 0.059572, loss_ce: 0.020377
2021-12-12 23:50:58,432 iteration 1865 : loss : 0.035986, loss_ce: 0.016830
2021-12-12 23:50:59,918 iteration 1866 : loss : 0.033085, loss_ce: 0.015455
2021-12-12 23:51:01,376 iteration 1867 : loss : 0.041643, loss_ce: 0.011620
2021-12-12 23:51:02,791 iteration 1868 : loss : 0.028425, loss_ce: 0.013040
2021-12-12 23:51:04,238 iteration 1869 : loss : 0.048856, loss_ce: 0.016871
2021-12-12 23:51:04,239 Training Data Eval:
2021-12-12 23:51:11,646   Average segmentation loss on training set: 0.0998
2021-12-12 23:51:11,646 Validation Data Eval:
2021-12-12 23:51:14,224   Average segmentation loss on validation set: 0.1153
2021-12-12 23:51:15,633 iteration 1870 : loss : 0.037460, loss_ce: 0.010488
 28%|███████▉                     | 110/400 [49:24<2:16:47, 28.30s/it]2021-12-12 23:51:17,117 iteration 1871 : loss : 0.033311, loss_ce: 0.016040
2021-12-12 23:51:18,528 iteration 1872 : loss : 0.032363, loss_ce: 0.012637
2021-12-12 23:51:19,980 iteration 1873 : loss : 0.045824, loss_ce: 0.018644
2021-12-12 23:51:21,465 iteration 1874 : loss : 0.035097, loss_ce: 0.014608
2021-12-12 23:51:22,975 iteration 1875 : loss : 0.033323, loss_ce: 0.017983
2021-12-12 23:51:24,488 iteration 1876 : loss : 0.034808, loss_ce: 0.009695
2021-12-12 23:51:25,985 iteration 1877 : loss : 0.057891, loss_ce: 0.015818
2021-12-12 23:51:27,390 iteration 1878 : loss : 0.035549, loss_ce: 0.015448
2021-12-12 23:51:28,805 iteration 1879 : loss : 0.031968, loss_ce: 0.014321
2021-12-12 23:51:30,217 iteration 1880 : loss : 0.030825, loss_ce: 0.010384
2021-12-12 23:51:31,624 iteration 1881 : loss : 0.019416, loss_ce: 0.006422
2021-12-12 23:51:33,072 iteration 1882 : loss : 0.031586, loss_ce: 0.009734
2021-12-12 23:51:34,457 iteration 1883 : loss : 0.033477, loss_ce: 0.012047
2021-12-12 23:51:35,969 iteration 1884 : loss : 0.029368, loss_ce: 0.011132
2021-12-12 23:51:37,369 iteration 1885 : loss : 0.026131, loss_ce: 0.009854
2021-12-12 23:51:38,825 iteration 1886 : loss : 0.030088, loss_ce: 0.014583
2021-12-12 23:51:40,232 iteration 1887 : loss : 0.028871, loss_ce: 0.009318
 28%|████████                     | 111/400 [49:49<2:10:58, 27.19s/it]2021-12-12 23:51:41,746 iteration 1888 : loss : 0.048501, loss_ce: 0.018441
2021-12-12 23:51:43,266 iteration 1889 : loss : 0.037017, loss_ce: 0.014891
2021-12-12 23:51:44,650 iteration 1890 : loss : 0.023049, loss_ce: 0.008060
2021-12-12 23:51:46,109 iteration 1891 : loss : 0.029638, loss_ce: 0.014814
2021-12-12 23:51:47,555 iteration 1892 : loss : 0.037505, loss_ce: 0.015321
2021-12-12 23:51:49,036 iteration 1893 : loss : 0.053498, loss_ce: 0.021775
2021-12-12 23:51:50,468 iteration 1894 : loss : 0.050235, loss_ce: 0.020623
2021-12-12 23:51:51,926 iteration 1895 : loss : 0.035875, loss_ce: 0.011264
2021-12-12 23:51:53,368 iteration 1896 : loss : 0.031528, loss_ce: 0.013054
2021-12-12 23:51:54,806 iteration 1897 : loss : 0.050734, loss_ce: 0.022185
2021-12-12 23:51:56,325 iteration 1898 : loss : 0.039340, loss_ce: 0.016552
2021-12-12 23:51:57,703 iteration 1899 : loss : 0.028150, loss_ce: 0.010600
2021-12-12 23:51:59,225 iteration 1900 : loss : 0.036251, loss_ce: 0.015716
2021-12-12 23:52:00,760 iteration 1901 : loss : 0.035975, loss_ce: 0.011668
2021-12-12 23:52:02,193 iteration 1902 : loss : 0.030510, loss_ce: 0.009494
2021-12-12 23:52:03,686 iteration 1903 : loss : 0.041740, loss_ce: 0.019054
2021-12-12 23:52:05,181 iteration 1904 : loss : 0.053677, loss_ce: 0.019722
 28%|████████                     | 112/400 [50:14<2:07:17, 26.52s/it]2021-12-12 23:52:06,711 iteration 1905 : loss : 0.058360, loss_ce: 0.024808
2021-12-12 23:52:08,157 iteration 1906 : loss : 0.034883, loss_ce: 0.011119
2021-12-12 23:52:09,593 iteration 1907 : loss : 0.029681, loss_ce: 0.012246
2021-12-12 23:52:11,155 iteration 1908 : loss : 0.044923, loss_ce: 0.018153
2021-12-12 23:52:12,626 iteration 1909 : loss : 0.044972, loss_ce: 0.018323
2021-12-12 23:52:14,111 iteration 1910 : loss : 0.082386, loss_ce: 0.021919
2021-12-12 23:52:15,611 iteration 1911 : loss : 0.032274, loss_ce: 0.010683
2021-12-12 23:52:16,991 iteration 1912 : loss : 0.029136, loss_ce: 0.011135
2021-12-12 23:52:18,451 iteration 1913 : loss : 0.039948, loss_ce: 0.017808
2021-12-12 23:52:19,914 iteration 1914 : loss : 0.036595, loss_ce: 0.015717
2021-12-12 23:52:21,386 iteration 1915 : loss : 0.046741, loss_ce: 0.021693
2021-12-12 23:52:22,825 iteration 1916 : loss : 0.048561, loss_ce: 0.018758
2021-12-12 23:52:24,263 iteration 1917 : loss : 0.043350, loss_ce: 0.019308
2021-12-12 23:52:25,734 iteration 1918 : loss : 0.032701, loss_ce: 0.011208
2021-12-12 23:52:27,155 iteration 1919 : loss : 0.030728, loss_ce: 0.011439
2021-12-12 23:52:28,577 iteration 1920 : loss : 0.039135, loss_ce: 0.017348
2021-12-12 23:52:30,094 iteration 1921 : loss : 0.055970, loss_ce: 0.027380
 28%|████████▏                    | 113/400 [50:39<2:04:32, 26.04s/it]2021-12-12 23:52:31,561 iteration 1922 : loss : 0.032230, loss_ce: 0.014975
2021-12-12 23:52:33,011 iteration 1923 : loss : 0.025678, loss_ce: 0.011390
2021-12-12 23:52:34,511 iteration 1924 : loss : 0.034914, loss_ce: 0.015739
2021-12-12 23:52:35,966 iteration 1925 : loss : 0.049326, loss_ce: 0.021621
2021-12-12 23:52:37,380 iteration 1926 : loss : 0.026029, loss_ce: 0.010019
2021-12-12 23:52:38,789 iteration 1927 : loss : 0.035484, loss_ce: 0.013256
2021-12-12 23:52:40,321 iteration 1928 : loss : 0.034062, loss_ce: 0.014759
2021-12-12 23:52:41,744 iteration 1929 : loss : 0.032918, loss_ce: 0.011126
2021-12-12 23:52:43,155 iteration 1930 : loss : 0.030423, loss_ce: 0.014783
2021-12-12 23:52:44,626 iteration 1931 : loss : 0.056095, loss_ce: 0.011227
2021-12-12 23:52:46,137 iteration 1932 : loss : 0.045387, loss_ce: 0.016519
2021-12-12 23:52:47,642 iteration 1933 : loss : 0.045636, loss_ce: 0.026693
2021-12-12 23:52:49,000 iteration 1934 : loss : 0.021519, loss_ce: 0.008576
2021-12-12 23:52:50,461 iteration 1935 : loss : 0.070460, loss_ce: 0.023305
2021-12-12 23:52:51,979 iteration 1936 : loss : 0.062294, loss_ce: 0.033838
2021-12-12 23:52:53,370 iteration 1937 : loss : 0.033663, loss_ce: 0.009228
2021-12-12 23:52:54,745 iteration 1938 : loss : 0.032735, loss_ce: 0.010801
 28%|████████▎                    | 114/400 [51:03<2:02:07, 25.62s/it]2021-12-12 23:52:56,199 iteration 1939 : loss : 0.026536, loss_ce: 0.008829
2021-12-12 23:52:57,742 iteration 1940 : loss : 0.042861, loss_ce: 0.016817
2021-12-12 23:52:59,273 iteration 1941 : loss : 0.033012, loss_ce: 0.014004
2021-12-12 23:53:00,734 iteration 1942 : loss : 0.032648, loss_ce: 0.012432
2021-12-12 23:53:02,156 iteration 1943 : loss : 0.037742, loss_ce: 0.016109
2021-12-12 23:53:03,600 iteration 1944 : loss : 0.032557, loss_ce: 0.012630
2021-12-12 23:53:04,998 iteration 1945 : loss : 0.042126, loss_ce: 0.014864
2021-12-12 23:53:06,452 iteration 1946 : loss : 0.030630, loss_ce: 0.010913
2021-12-12 23:53:07,946 iteration 1947 : loss : 0.045878, loss_ce: 0.020680
2021-12-12 23:53:09,406 iteration 1948 : loss : 0.060410, loss_ce: 0.019271
2021-12-12 23:53:10,840 iteration 1949 : loss : 0.023392, loss_ce: 0.009161
2021-12-12 23:53:12,247 iteration 1950 : loss : 0.036489, loss_ce: 0.016261
2021-12-12 23:53:13,748 iteration 1951 : loss : 0.042635, loss_ce: 0.013807
2021-12-12 23:53:15,222 iteration 1952 : loss : 0.034415, loss_ce: 0.010217
2021-12-12 23:53:16,726 iteration 1953 : loss : 0.043282, loss_ce: 0.020117
2021-12-12 23:53:18,177 iteration 1954 : loss : 0.031809, loss_ce: 0.016478
2021-12-12 23:53:18,177 Training Data Eval:
2021-12-12 23:53:25,580   Average segmentation loss on training set: 0.0488
2021-12-12 23:53:25,581 Validation Data Eval:
2021-12-12 23:53:28,168   Average segmentation loss on validation set: 0.1898
2021-12-12 23:53:29,649 iteration 1955 : loss : 0.032981, loss_ce: 0.009798
 29%|████████▎                    | 115/400 [51:38<2:14:55, 28.41s/it]2021-12-12 23:53:31,106 iteration 1956 : loss : 0.034339, loss_ce: 0.008340
2021-12-12 23:53:32,644 iteration 1957 : loss : 0.037888, loss_ce: 0.014818
2021-12-12 23:53:34,181 iteration 1958 : loss : 0.033535, loss_ce: 0.012717
2021-12-12 23:53:35,648 iteration 1959 : loss : 0.036273, loss_ce: 0.013171
2021-12-12 23:53:37,040 iteration 1960 : loss : 0.037617, loss_ce: 0.012346
2021-12-12 23:53:38,524 iteration 1961 : loss : 0.040603, loss_ce: 0.017095
2021-12-12 23:53:40,013 iteration 1962 : loss : 0.028047, loss_ce: 0.012396
2021-12-12 23:53:41,405 iteration 1963 : loss : 0.027004, loss_ce: 0.009862
2021-12-12 23:53:42,820 iteration 1964 : loss : 0.025173, loss_ce: 0.010174
2021-12-12 23:53:44,244 iteration 1965 : loss : 0.037278, loss_ce: 0.017489
2021-12-12 23:53:45,758 iteration 1966 : loss : 0.036898, loss_ce: 0.014105
2021-12-12 23:53:47,267 iteration 1967 : loss : 0.036241, loss_ce: 0.013231
2021-12-12 23:53:48,755 iteration 1968 : loss : 0.032443, loss_ce: 0.013726
2021-12-12 23:53:50,223 iteration 1969 : loss : 0.049074, loss_ce: 0.019970
2021-12-12 23:53:51,647 iteration 1970 : loss : 0.058945, loss_ce: 0.019845
2021-12-12 23:53:53,133 iteration 1971 : loss : 0.041998, loss_ce: 0.017908
2021-12-12 23:53:54,542 iteration 1972 : loss : 0.049621, loss_ce: 0.017543
 29%|████████▍                    | 116/400 [52:03<2:09:27, 27.35s/it]2021-12-12 23:53:55,912 iteration 1973 : loss : 0.026923, loss_ce: 0.010241
2021-12-12 23:53:57,382 iteration 1974 : loss : 0.031506, loss_ce: 0.012768
2021-12-12 23:53:58,822 iteration 1975 : loss : 0.044919, loss_ce: 0.012926
2021-12-12 23:54:00,337 iteration 1976 : loss : 0.033972, loss_ce: 0.014559
2021-12-12 23:54:01,792 iteration 1977 : loss : 0.026237, loss_ce: 0.008114
2021-12-12 23:54:03,166 iteration 1978 : loss : 0.023634, loss_ce: 0.009948
2021-12-12 23:54:04,546 iteration 1979 : loss : 0.032165, loss_ce: 0.012646
2021-12-12 23:54:06,014 iteration 1980 : loss : 0.029794, loss_ce: 0.013337
2021-12-12 23:54:07,418 iteration 1981 : loss : 0.034672, loss_ce: 0.013680
2021-12-12 23:54:08,792 iteration 1982 : loss : 0.033055, loss_ce: 0.011612
2021-12-12 23:54:10,311 iteration 1983 : loss : 0.041584, loss_ce: 0.019497
2021-12-12 23:54:11,700 iteration 1984 : loss : 0.027792, loss_ce: 0.006899
2021-12-12 23:54:13,154 iteration 1985 : loss : 0.020589, loss_ce: 0.008126
2021-12-12 23:54:14,615 iteration 1986 : loss : 0.043123, loss_ce: 0.024265
2021-12-12 23:54:16,114 iteration 1987 : loss : 0.023616, loss_ce: 0.010220
2021-12-12 23:54:17,503 iteration 1988 : loss : 0.034700, loss_ce: 0.009328
2021-12-12 23:54:18,931 iteration 1989 : loss : 0.029832, loss_ce: 0.013800
 29%|████████▍                    | 117/400 [52:28<2:04:49, 26.46s/it]2021-12-12 23:54:20,335 iteration 1990 : loss : 0.021956, loss_ce: 0.009413
2021-12-12 23:54:21,755 iteration 1991 : loss : 0.019066, loss_ce: 0.007430
2021-12-12 23:54:23,241 iteration 1992 : loss : 0.030721, loss_ce: 0.010956
2021-12-12 23:54:24,819 iteration 1993 : loss : 0.036212, loss_ce: 0.017461
2021-12-12 23:54:26,233 iteration 1994 : loss : 0.025114, loss_ce: 0.009560
2021-12-12 23:54:27,696 iteration 1995 : loss : 0.050556, loss_ce: 0.012718
2021-12-12 23:54:29,160 iteration 1996 : loss : 0.039736, loss_ce: 0.012941
2021-12-12 23:54:30,600 iteration 1997 : loss : 0.024176, loss_ce: 0.008033
2021-12-12 23:54:32,044 iteration 1998 : loss : 0.040030, loss_ce: 0.013561
2021-12-12 23:54:33,467 iteration 1999 : loss : 0.035092, loss_ce: 0.017767
2021-12-12 23:54:34,987 iteration 2000 : loss : 0.027063, loss_ce: 0.009259
2021-12-12 23:54:36,426 iteration 2001 : loss : 0.030343, loss_ce: 0.012901
2021-12-12 23:54:37,949 iteration 2002 : loss : 0.024513, loss_ce: 0.011667
2021-12-12 23:54:39,361 iteration 2003 : loss : 0.031548, loss_ce: 0.014592
2021-12-12 23:54:40,827 iteration 2004 : loss : 0.032810, loss_ce: 0.011739
2021-12-12 23:54:42,313 iteration 2005 : loss : 0.033067, loss_ce: 0.013686
2021-12-12 23:54:43,794 iteration 2006 : loss : 0.031099, loss_ce: 0.012048
 30%|████████▌                    | 118/400 [52:53<2:02:07, 25.98s/it]2021-12-12 23:54:45,314 iteration 2007 : loss : 0.031573, loss_ce: 0.013919
2021-12-12 23:54:46,724 iteration 2008 : loss : 0.029043, loss_ce: 0.011395
2021-12-12 23:54:48,163 iteration 2009 : loss : 0.044875, loss_ce: 0.014364
2021-12-12 23:54:49,560 iteration 2010 : loss : 0.028133, loss_ce: 0.010389
2021-12-12 23:54:51,001 iteration 2011 : loss : 0.026465, loss_ce: 0.010876
2021-12-12 23:54:52,462 iteration 2012 : loss : 0.045960, loss_ce: 0.015094
2021-12-12 23:54:53,950 iteration 2013 : loss : 0.045331, loss_ce: 0.015065
2021-12-12 23:54:55,429 iteration 2014 : loss : 0.022869, loss_ce: 0.007701
2021-12-12 23:54:56,812 iteration 2015 : loss : 0.024917, loss_ce: 0.009031
2021-12-12 23:54:58,254 iteration 2016 : loss : 0.032127, loss_ce: 0.009893
2021-12-12 23:54:59,618 iteration 2017 : loss : 0.020327, loss_ce: 0.008159
2021-12-12 23:55:01,079 iteration 2018 : loss : 0.034330, loss_ce: 0.013947
2021-12-12 23:55:02,489 iteration 2019 : loss : 0.022981, loss_ce: 0.009989
2021-12-12 23:55:03,948 iteration 2020 : loss : 0.027543, loss_ce: 0.012260
2021-12-12 23:55:05,414 iteration 2021 : loss : 0.035939, loss_ce: 0.012940
2021-12-12 23:55:06,911 iteration 2022 : loss : 0.034029, loss_ce: 0.014109
2021-12-12 23:55:08,342 iteration 2023 : loss : 0.042293, loss_ce: 0.012884
 30%|████████▋                    | 119/400 [53:17<1:59:39, 25.55s/it]2021-12-12 23:55:09,842 iteration 2024 : loss : 0.036542, loss_ce: 0.014363
2021-12-12 23:55:11,230 iteration 2025 : loss : 0.024826, loss_ce: 0.007868
2021-12-12 23:55:12,641 iteration 2026 : loss : 0.032489, loss_ce: 0.013361
2021-12-12 23:55:14,121 iteration 2027 : loss : 0.033187, loss_ce: 0.012584
2021-12-12 23:55:15,600 iteration 2028 : loss : 0.032851, loss_ce: 0.013502
2021-12-12 23:55:16,997 iteration 2029 : loss : 0.028449, loss_ce: 0.011849
2021-12-12 23:55:18,461 iteration 2030 : loss : 0.030267, loss_ce: 0.010270
2021-12-12 23:55:19,933 iteration 2031 : loss : 0.030334, loss_ce: 0.009885
2021-12-12 23:55:21,410 iteration 2032 : loss : 0.033009, loss_ce: 0.011678
2021-12-12 23:55:22,837 iteration 2033 : loss : 0.042311, loss_ce: 0.012059
2021-12-12 23:55:24,210 iteration 2034 : loss : 0.022127, loss_ce: 0.007708
2021-12-12 23:55:25,600 iteration 2035 : loss : 0.024381, loss_ce: 0.010872
2021-12-12 23:55:27,085 iteration 2036 : loss : 0.026163, loss_ce: 0.011497
2021-12-12 23:55:28,535 iteration 2037 : loss : 0.039941, loss_ce: 0.013436
2021-12-12 23:55:29,948 iteration 2038 : loss : 0.027093, loss_ce: 0.009854
2021-12-12 23:55:31,416 iteration 2039 : loss : 0.030082, loss_ce: 0.013572
2021-12-12 23:55:31,416 Training Data Eval:
2021-12-12 23:55:38,816   Average segmentation loss on training set: 0.1308
2021-12-12 23:55:38,817 Validation Data Eval:
2021-12-12 23:55:41,388   Average segmentation loss on validation set: 0.2721
2021-12-12 23:55:42,833 iteration 2040 : loss : 0.027319, loss_ce: 0.008986
 30%|████████▋                    | 120/400 [53:52<2:11:45, 28.23s/it]2021-12-12 23:55:44,331 iteration 2041 : loss : 0.026325, loss_ce: 0.010402
2021-12-12 23:55:45,773 iteration 2042 : loss : 0.024917, loss_ce: 0.010139
2021-12-12 23:55:47,216 iteration 2043 : loss : 0.025411, loss_ce: 0.011584
2021-12-12 23:55:48,716 iteration 2044 : loss : 0.022673, loss_ce: 0.008771
2021-12-12 23:55:50,245 iteration 2045 : loss : 0.027064, loss_ce: 0.010363
2021-12-12 23:55:51,721 iteration 2046 : loss : 0.037022, loss_ce: 0.013738
2021-12-12 23:55:53,175 iteration 2047 : loss : 0.034929, loss_ce: 0.013725
2021-12-12 23:55:54,543 iteration 2048 : loss : 0.026580, loss_ce: 0.008120
2021-12-12 23:55:55,965 iteration 2049 : loss : 0.020395, loss_ce: 0.007237
2021-12-12 23:55:57,444 iteration 2050 : loss : 0.035085, loss_ce: 0.010572
2021-12-12 23:55:58,933 iteration 2051 : loss : 0.037119, loss_ce: 0.013297
2021-12-12 23:56:00,344 iteration 2052 : loss : 0.032646, loss_ce: 0.015650
2021-12-12 23:56:01,753 iteration 2053 : loss : 0.029321, loss_ce: 0.009581
2021-12-12 23:56:03,211 iteration 2054 : loss : 0.036519, loss_ce: 0.012918
2021-12-12 23:56:04,685 iteration 2055 : loss : 0.058298, loss_ce: 0.029956
2021-12-12 23:56:06,158 iteration 2056 : loss : 0.032680, loss_ce: 0.015159
2021-12-12 23:56:07,657 iteration 2057 : loss : 0.023480, loss_ce: 0.010183
 30%|████████▊                    | 121/400 [54:16<2:06:32, 27.21s/it]2021-12-12 23:56:09,229 iteration 2058 : loss : 0.030578, loss_ce: 0.015657
2021-12-12 23:56:10,701 iteration 2059 : loss : 0.030721, loss_ce: 0.011076
2021-12-12 23:56:12,191 iteration 2060 : loss : 0.029719, loss_ce: 0.010180
2021-12-12 23:56:13,604 iteration 2061 : loss : 0.030638, loss_ce: 0.015192
2021-12-12 23:56:14,994 iteration 2062 : loss : 0.026131, loss_ce: 0.009711
2021-12-12 23:56:16,407 iteration 2063 : loss : 0.020729, loss_ce: 0.008932
2021-12-12 23:56:17,881 iteration 2064 : loss : 0.033503, loss_ce: 0.016979
2021-12-12 23:56:19,344 iteration 2065 : loss : 0.033062, loss_ce: 0.012657
2021-12-12 23:56:20,838 iteration 2066 : loss : 0.032080, loss_ce: 0.011711
2021-12-12 23:56:22,266 iteration 2067 : loss : 0.032306, loss_ce: 0.011425
2021-12-12 23:56:23,772 iteration 2068 : loss : 0.033120, loss_ce: 0.015641
2021-12-12 23:56:25,277 iteration 2069 : loss : 0.038948, loss_ce: 0.010486
2021-12-12 23:56:26,697 iteration 2070 : loss : 0.028348, loss_ce: 0.009433
2021-12-12 23:56:28,120 iteration 2071 : loss : 0.031996, loss_ce: 0.013949
2021-12-12 23:56:29,517 iteration 2072 : loss : 0.035984, loss_ce: 0.015259
2021-12-12 23:56:30,918 iteration 2073 : loss : 0.025886, loss_ce: 0.008318
2021-12-12 23:56:32,375 iteration 2074 : loss : 0.046217, loss_ce: 0.013162
 30%|████████▊                    | 122/400 [54:41<2:02:36, 26.46s/it]2021-12-12 23:56:33,870 iteration 2075 : loss : 0.027831, loss_ce: 0.009498
2021-12-12 23:56:35,372 iteration 2076 : loss : 0.034756, loss_ce: 0.009721
2021-12-12 23:56:36,829 iteration 2077 : loss : 0.023278, loss_ce: 0.009383
2021-12-12 23:56:38,230 iteration 2078 : loss : 0.025411, loss_ce: 0.010455
2021-12-12 23:56:39,655 iteration 2079 : loss : 0.026178, loss_ce: 0.008550
2021-12-12 23:56:41,157 iteration 2080 : loss : 0.034789, loss_ce: 0.012863
2021-12-12 23:56:42,624 iteration 2081 : loss : 0.031256, loss_ce: 0.014081
2021-12-12 23:56:44,068 iteration 2082 : loss : 0.036622, loss_ce: 0.011500
2021-12-12 23:56:45,502 iteration 2083 : loss : 0.024167, loss_ce: 0.007869
2021-12-12 23:56:46,943 iteration 2084 : loss : 0.033994, loss_ce: 0.012095
2021-12-12 23:56:48,364 iteration 2085 : loss : 0.033920, loss_ce: 0.015844
2021-12-12 23:56:49,801 iteration 2086 : loss : 0.025040, loss_ce: 0.010794
2021-12-12 23:56:51,205 iteration 2087 : loss : 0.028117, loss_ce: 0.010117
2021-12-12 23:56:52,763 iteration 2088 : loss : 0.051761, loss_ce: 0.025853
2021-12-12 23:56:54,184 iteration 2089 : loss : 0.023200, loss_ce: 0.008729
2021-12-12 23:56:55,670 iteration 2090 : loss : 0.035596, loss_ce: 0.011742
2021-12-12 23:56:57,108 iteration 2091 : loss : 0.034605, loss_ce: 0.014149
 31%|████████▉                    | 123/400 [55:06<1:59:45, 25.94s/it]2021-12-12 23:56:58,574 iteration 2092 : loss : 0.028175, loss_ce: 0.012020
2021-12-12 23:57:00,104 iteration 2093 : loss : 0.037683, loss_ce: 0.015433
2021-12-12 23:57:01,587 iteration 2094 : loss : 0.023571, loss_ce: 0.010058
2021-12-12 23:57:03,063 iteration 2095 : loss : 0.028939, loss_ce: 0.011032
2021-12-12 23:57:04,558 iteration 2096 : loss : 0.051652, loss_ce: 0.018952
2021-12-12 23:57:05,964 iteration 2097 : loss : 0.030678, loss_ce: 0.015339
2021-12-12 23:57:07,472 iteration 2098 : loss : 0.028635, loss_ce: 0.011212
2021-12-12 23:57:08,963 iteration 2099 : loss : 0.033360, loss_ce: 0.011642
2021-12-12 23:57:10,495 iteration 2100 : loss : 0.035732, loss_ce: 0.015414
2021-12-12 23:57:11,943 iteration 2101 : loss : 0.051205, loss_ce: 0.012726
2021-12-12 23:57:13,360 iteration 2102 : loss : 0.025548, loss_ce: 0.009673
2021-12-12 23:57:14,907 iteration 2103 : loss : 0.034417, loss_ce: 0.013218
2021-12-12 23:57:16,392 iteration 2104 : loss : 0.022250, loss_ce: 0.007934
2021-12-12 23:57:17,825 iteration 2105 : loss : 0.024166, loss_ce: 0.006820
2021-12-12 23:57:19,357 iteration 2106 : loss : 0.041242, loss_ce: 0.009637
2021-12-12 23:57:20,806 iteration 2107 : loss : 0.027967, loss_ce: 0.009889
2021-12-12 23:57:22,266 iteration 2108 : loss : 0.036989, loss_ce: 0.016897
 31%|████████▉                    | 124/400 [55:31<1:58:15, 25.71s/it]2021-12-12 23:57:23,753 iteration 2109 : loss : 0.028910, loss_ce: 0.013115
2021-12-12 23:57:25,196 iteration 2110 : loss : 0.032751, loss_ce: 0.011446
2021-12-12 23:57:26,771 iteration 2111 : loss : 0.038879, loss_ce: 0.011871
2021-12-12 23:57:28,351 iteration 2112 : loss : 0.028898, loss_ce: 0.011849
2021-12-12 23:57:29,769 iteration 2113 : loss : 0.047139, loss_ce: 0.017694
2021-12-12 23:57:31,185 iteration 2114 : loss : 0.038026, loss_ce: 0.016813
2021-12-12 23:57:32,516 iteration 2115 : loss : 0.037037, loss_ce: 0.010319
2021-12-12 23:57:33,993 iteration 2116 : loss : 0.027286, loss_ce: 0.008833
2021-12-12 23:57:35,522 iteration 2117 : loss : 0.035368, loss_ce: 0.011780
2021-12-12 23:57:36,975 iteration 2118 : loss : 0.030304, loss_ce: 0.012979
2021-12-12 23:57:38,455 iteration 2119 : loss : 0.051539, loss_ce: 0.026073
2021-12-12 23:57:39,902 iteration 2120 : loss : 0.038462, loss_ce: 0.013144
2021-12-12 23:57:41,432 iteration 2121 : loss : 0.041602, loss_ce: 0.014324
2021-12-12 23:57:42,832 iteration 2122 : loss : 0.048554, loss_ce: 0.022539
2021-12-12 23:57:44,258 iteration 2123 : loss : 0.036259, loss_ce: 0.018853
2021-12-12 23:57:45,742 iteration 2124 : loss : 0.033569, loss_ce: 0.012609
2021-12-12 23:57:45,742 Training Data Eval:
2021-12-12 23:57:53,130   Average segmentation loss on training set: 0.0220
2021-12-12 23:57:53,130 Validation Data Eval:
2021-12-12 23:57:55,703   Average segmentation loss on validation set: 0.0878
2021-12-12 23:57:57,185 iteration 2125 : loss : 0.026661, loss_ce: 0.009177
 31%|█████████                    | 125/400 [56:06<2:10:29, 28.47s/it]2021-12-12 23:57:58,675 iteration 2126 : loss : 0.039493, loss_ce: 0.013443
2021-12-12 23:58:00,195 iteration 2127 : loss : 0.034262, loss_ce: 0.012628
2021-12-12 23:58:01,599 iteration 2128 : loss : 0.023083, loss_ce: 0.011771
2021-12-12 23:58:03,064 iteration 2129 : loss : 0.030845, loss_ce: 0.010975
2021-12-12 23:58:04,467 iteration 2130 : loss : 0.032219, loss_ce: 0.010312
2021-12-12 23:58:05,988 iteration 2131 : loss : 0.053366, loss_ce: 0.024733
2021-12-12 23:58:07,502 iteration 2132 : loss : 0.070006, loss_ce: 0.028483
2021-12-12 23:58:08,986 iteration 2133 : loss : 0.041074, loss_ce: 0.014317
2021-12-12 23:58:10,486 iteration 2134 : loss : 0.057115, loss_ce: 0.017227
2021-12-12 23:58:11,956 iteration 2135 : loss : 0.033006, loss_ce: 0.011104
2021-12-12 23:58:13,413 iteration 2136 : loss : 0.037240, loss_ce: 0.014347
2021-12-12 23:58:14,866 iteration 2137 : loss : 0.052669, loss_ce: 0.017955
2021-12-12 23:58:16,274 iteration 2138 : loss : 0.041832, loss_ce: 0.012038
2021-12-12 23:58:17,655 iteration 2139 : loss : 0.033697, loss_ce: 0.017699
2021-12-12 23:58:19,089 iteration 2140 : loss : 0.029937, loss_ce: 0.009665
2021-12-12 23:58:20,550 iteration 2141 : loss : 0.028954, loss_ce: 0.010951
2021-12-12 23:58:21,993 iteration 2142 : loss : 0.039238, loss_ce: 0.018735
 32%|█████████▏                   | 126/400 [56:31<2:05:00, 27.37s/it]2021-12-12 23:58:23,505 iteration 2143 : loss : 0.029714, loss_ce: 0.007846
2021-12-12 23:58:24,931 iteration 2144 : loss : 0.037351, loss_ce: 0.010760
2021-12-12 23:58:26,287 iteration 2145 : loss : 0.025148, loss_ce: 0.012297
2021-12-12 23:58:27,863 iteration 2146 : loss : 0.035710, loss_ce: 0.013113
2021-12-12 23:58:29,322 iteration 2147 : loss : 0.027497, loss_ce: 0.010534
2021-12-12 23:58:30,773 iteration 2148 : loss : 0.028749, loss_ce: 0.011120
2021-12-12 23:58:32,237 iteration 2149 : loss : 0.032532, loss_ce: 0.013797
2021-12-12 23:58:33,740 iteration 2150 : loss : 0.043197, loss_ce: 0.014373
2021-12-12 23:58:35,237 iteration 2151 : loss : 0.048360, loss_ce: 0.019122
2021-12-12 23:58:36,638 iteration 2152 : loss : 0.024890, loss_ce: 0.009313
2021-12-12 23:58:38,063 iteration 2153 : loss : 0.028850, loss_ce: 0.007661
2021-12-12 23:58:39,444 iteration 2154 : loss : 0.026698, loss_ce: 0.012567
2021-12-12 23:58:40,889 iteration 2155 : loss : 0.027084, loss_ce: 0.010533
2021-12-12 23:58:42,375 iteration 2156 : loss : 0.039137, loss_ce: 0.015404
2021-12-12 23:58:43,845 iteration 2157 : loss : 0.029120, loss_ce: 0.012659
2021-12-12 23:58:45,270 iteration 2158 : loss : 0.028832, loss_ce: 0.010680
2021-12-12 23:58:46,779 iteration 2159 : loss : 0.049974, loss_ce: 0.017957
 32%|█████████▏                   | 127/400 [56:56<2:01:01, 26.60s/it]2021-12-12 23:58:48,205 iteration 2160 : loss : 0.023203, loss_ce: 0.008540
2021-12-12 23:58:49,676 iteration 2161 : loss : 0.029247, loss_ce: 0.011345
2021-12-12 23:58:51,181 iteration 2162 : loss : 0.032455, loss_ce: 0.012854
2021-12-12 23:58:52,527 iteration 2163 : loss : 0.034812, loss_ce: 0.009385
2021-12-12 23:58:53,982 iteration 2164 : loss : 0.031914, loss_ce: 0.013662
2021-12-12 23:58:55,425 iteration 2165 : loss : 0.021957, loss_ce: 0.006816
2021-12-12 23:58:56,927 iteration 2166 : loss : 0.032431, loss_ce: 0.016840
2021-12-12 23:58:58,381 iteration 2167 : loss : 0.025368, loss_ce: 0.013259
2021-12-12 23:58:59,838 iteration 2168 : loss : 0.033984, loss_ce: 0.012897
2021-12-12 23:59:01,310 iteration 2169 : loss : 0.030601, loss_ce: 0.010602
2021-12-12 23:59:02,731 iteration 2170 : loss : 0.023805, loss_ce: 0.006743
2021-12-12 23:59:04,161 iteration 2171 : loss : 0.021042, loss_ce: 0.006592
2021-12-12 23:59:05,514 iteration 2172 : loss : 0.027865, loss_ce: 0.012925
2021-12-12 23:59:06,961 iteration 2173 : loss : 0.036335, loss_ce: 0.016210
2021-12-12 23:59:08,443 iteration 2174 : loss : 0.034519, loss_ce: 0.013509
2021-12-12 23:59:09,850 iteration 2175 : loss : 0.035307, loss_ce: 0.011727
2021-12-12 23:59:11,284 iteration 2176 : loss : 0.026074, loss_ce: 0.012152
 32%|█████████▎                   | 128/400 [57:20<1:57:42, 25.97s/it]2021-12-12 23:59:12,825 iteration 2177 : loss : 0.036529, loss_ce: 0.011817
2021-12-12 23:59:14,215 iteration 2178 : loss : 0.029166, loss_ce: 0.012874
2021-12-12 23:59:15,640 iteration 2179 : loss : 0.032917, loss_ce: 0.014209
2021-12-12 23:59:17,111 iteration 2180 : loss : 0.026283, loss_ce: 0.008977
2021-12-12 23:59:18,532 iteration 2181 : loss : 0.025431, loss_ce: 0.009407
2021-12-12 23:59:19,953 iteration 2182 : loss : 0.028782, loss_ce: 0.010411
2021-12-12 23:59:21,370 iteration 2183 : loss : 0.033285, loss_ce: 0.009726
2021-12-12 23:59:22,773 iteration 2184 : loss : 0.031658, loss_ce: 0.014345
2021-12-12 23:59:24,146 iteration 2185 : loss : 0.025825, loss_ce: 0.010768
2021-12-12 23:59:25,692 iteration 2186 : loss : 0.035617, loss_ce: 0.015395
2021-12-12 23:59:27,078 iteration 2187 : loss : 0.024916, loss_ce: 0.013112
2021-12-12 23:59:28,569 iteration 2188 : loss : 0.044850, loss_ce: 0.016421
2021-12-12 23:59:29,967 iteration 2189 : loss : 0.040948, loss_ce: 0.014821
2021-12-12 23:59:31,470 iteration 2190 : loss : 0.026720, loss_ce: 0.010021
2021-12-12 23:59:32,848 iteration 2191 : loss : 0.022928, loss_ce: 0.010135
2021-12-12 23:59:34,295 iteration 2192 : loss : 0.032603, loss_ce: 0.012061
2021-12-12 23:59:35,812 iteration 2193 : loss : 0.045758, loss_ce: 0.023821
 32%|█████████▎                   | 129/400 [57:45<1:55:20, 25.54s/it]2021-12-12 23:59:37,261 iteration 2194 : loss : 0.036801, loss_ce: 0.014267
2021-12-12 23:59:38,665 iteration 2195 : loss : 0.018874, loss_ce: 0.006773
2021-12-12 23:59:40,114 iteration 2196 : loss : 0.025985, loss_ce: 0.011849
2021-12-12 23:59:41,590 iteration 2197 : loss : 0.041920, loss_ce: 0.013307
2021-12-12 23:59:43,013 iteration 2198 : loss : 0.022920, loss_ce: 0.010693
2021-12-12 23:59:44,611 iteration 2199 : loss : 0.032834, loss_ce: 0.013977
2021-12-12 23:59:46,049 iteration 2200 : loss : 0.028828, loss_ce: 0.010426
2021-12-12 23:59:47,498 iteration 2201 : loss : 0.033809, loss_ce: 0.010068
2021-12-12 23:59:48,936 iteration 2202 : loss : 0.039853, loss_ce: 0.009579
2021-12-12 23:59:50,412 iteration 2203 : loss : 0.026733, loss_ce: 0.008740
2021-12-12 23:59:51,903 iteration 2204 : loss : 0.030123, loss_ce: 0.010920
2021-12-12 23:59:53,253 iteration 2205 : loss : 0.026804, loss_ce: 0.012108
2021-12-12 23:59:54,633 iteration 2206 : loss : 0.024042, loss_ce: 0.011095
2021-12-12 23:59:56,081 iteration 2207 : loss : 0.038213, loss_ce: 0.015522
2021-12-12 23:59:57,509 iteration 2208 : loss : 0.029298, loss_ce: 0.010437
2021-12-12 23:59:59,004 iteration 2209 : loss : 0.028543, loss_ce: 0.009287
2021-12-12 23:59:59,005 Training Data Eval:
2021-12-13 00:00:06,407   Average segmentation loss on training set: 0.0255
2021-12-13 00:00:06,407 Validation Data Eval:
2021-12-13 00:00:08,988   Average segmentation loss on validation set: 0.1021
2021-12-13 00:00:10,460 iteration 2210 : loss : 0.028118, loss_ce: 0.009018
 32%|█████████▍                   | 130/400 [58:19<2:07:12, 28.27s/it]2021-12-13 00:00:11,956 iteration 2211 : loss : 0.030613, loss_ce: 0.014010
2021-12-13 00:00:13,328 iteration 2212 : loss : 0.021305, loss_ce: 0.007387
2021-12-13 00:00:14,717 iteration 2213 : loss : 0.025563, loss_ce: 0.009596
2021-12-13 00:00:16,169 iteration 2214 : loss : 0.025639, loss_ce: 0.009856
2021-12-13 00:00:17,590 iteration 2215 : loss : 0.023306, loss_ce: 0.008340
2021-12-13 00:00:18,984 iteration 2216 : loss : 0.025276, loss_ce: 0.011411
2021-12-13 00:00:20,352 iteration 2217 : loss : 0.025266, loss_ce: 0.011083
2021-12-13 00:00:21,814 iteration 2218 : loss : 0.029489, loss_ce: 0.011223
2021-12-13 00:00:23,240 iteration 2219 : loss : 0.031644, loss_ce: 0.014678
2021-12-13 00:00:24,698 iteration 2220 : loss : 0.025576, loss_ce: 0.012461
2021-12-13 00:00:26,204 iteration 2221 : loss : 0.028845, loss_ce: 0.013677
2021-12-13 00:00:27,603 iteration 2222 : loss : 0.033506, loss_ce: 0.008897
2021-12-13 00:00:29,139 iteration 2223 : loss : 0.037688, loss_ce: 0.013210
2021-12-13 00:00:30,550 iteration 2224 : loss : 0.046596, loss_ce: 0.013442
2021-12-13 00:00:31,989 iteration 2225 : loss : 0.028552, loss_ce: 0.011571
2021-12-13 00:00:33,561 iteration 2226 : loss : 0.040567, loss_ce: 0.013642
2021-12-13 00:00:35,039 iteration 2227 : loss : 0.035386, loss_ce: 0.010483
 33%|█████████▍                   | 131/400 [58:44<2:01:46, 27.16s/it]2021-12-13 00:00:36,553 iteration 2228 : loss : 0.041359, loss_ce: 0.014015
2021-12-13 00:00:38,015 iteration 2229 : loss : 0.033191, loss_ce: 0.014211
2021-12-13 00:00:39,431 iteration 2230 : loss : 0.027663, loss_ce: 0.009722
2021-12-13 00:00:40,825 iteration 2231 : loss : 0.020294, loss_ce: 0.009078
2021-12-13 00:00:42,229 iteration 2232 : loss : 0.026592, loss_ce: 0.009937
2021-12-13 00:00:43,632 iteration 2233 : loss : 0.029673, loss_ce: 0.008640
2021-12-13 00:00:45,099 iteration 2234 : loss : 0.034357, loss_ce: 0.011689
2021-12-13 00:00:46,486 iteration 2235 : loss : 0.028918, loss_ce: 0.012431
2021-12-13 00:00:47,884 iteration 2236 : loss : 0.026605, loss_ce: 0.011072
2021-12-13 00:00:49,308 iteration 2237 : loss : 0.028958, loss_ce: 0.013343
2021-12-13 00:00:50,712 iteration 2238 : loss : 0.043448, loss_ce: 0.013831
2021-12-13 00:00:52,173 iteration 2239 : loss : 0.030605, loss_ce: 0.009636
2021-12-13 00:00:53,552 iteration 2240 : loss : 0.026696, loss_ce: 0.010349
2021-12-13 00:00:55,036 iteration 2241 : loss : 0.030475, loss_ce: 0.011905
2021-12-13 00:00:56,426 iteration 2242 : loss : 0.038064, loss_ce: 0.018525
2021-12-13 00:00:57,825 iteration 2243 : loss : 0.028079, loss_ce: 0.007110
2021-12-13 00:00:59,257 iteration 2244 : loss : 0.020126, loss_ce: 0.007821
 33%|█████████▌                   | 132/400 [59:08<1:57:22, 26.28s/it]2021-12-13 00:01:00,707 iteration 2245 : loss : 0.024084, loss_ce: 0.009677
2021-12-13 00:01:02,170 iteration 2246 : loss : 0.027077, loss_ce: 0.010657
2021-12-13 00:01:03,610 iteration 2247 : loss : 0.039407, loss_ce: 0.014609
2021-12-13 00:01:04,962 iteration 2248 : loss : 0.024090, loss_ce: 0.009809
2021-12-13 00:01:06,477 iteration 2249 : loss : 0.042236, loss_ce: 0.016907
2021-12-13 00:01:08,041 iteration 2250 : loss : 0.034316, loss_ce: 0.014583
2021-12-13 00:01:09,415 iteration 2251 : loss : 0.026705, loss_ce: 0.010670
2021-12-13 00:01:10,889 iteration 2252 : loss : 0.030031, loss_ce: 0.009919
2021-12-13 00:01:12,295 iteration 2253 : loss : 0.036019, loss_ce: 0.010744
2021-12-13 00:01:13,794 iteration 2254 : loss : 0.049283, loss_ce: 0.018797
2021-12-13 00:01:15,289 iteration 2255 : loss : 0.024953, loss_ce: 0.011235
2021-12-13 00:01:16,817 iteration 2256 : loss : 0.033216, loss_ce: 0.012652
2021-12-13 00:01:18,245 iteration 2257 : loss : 0.027561, loss_ce: 0.009105
2021-12-13 00:01:19,693 iteration 2258 : loss : 0.031004, loss_ce: 0.013168
2021-12-13 00:01:21,185 iteration 2259 : loss : 0.033581, loss_ce: 0.011152
2021-12-13 00:01:22,636 iteration 2260 : loss : 0.037951, loss_ce: 0.013838
2021-12-13 00:01:24,038 iteration 2261 : loss : 0.036303, loss_ce: 0.008345
 33%|█████████▋                   | 133/400 [59:33<1:54:56, 25.83s/it]2021-12-13 00:01:25,646 iteration 2262 : loss : 0.033250, loss_ce: 0.015063
2021-12-13 00:01:27,112 iteration 2263 : loss : 0.024677, loss_ce: 0.009936
2021-12-13 00:01:28,593 iteration 2264 : loss : 0.035749, loss_ce: 0.010884
2021-12-13 00:01:30,074 iteration 2265 : loss : 0.023116, loss_ce: 0.008502
2021-12-13 00:01:31,519 iteration 2266 : loss : 0.031775, loss_ce: 0.011751
2021-12-13 00:01:32,974 iteration 2267 : loss : 0.027104, loss_ce: 0.009244
2021-12-13 00:01:34,351 iteration 2268 : loss : 0.024053, loss_ce: 0.010431
2021-12-13 00:01:35,816 iteration 2269 : loss : 0.037694, loss_ce: 0.015286
2021-12-13 00:01:37,204 iteration 2270 : loss : 0.029711, loss_ce: 0.010206
2021-12-13 00:01:38,611 iteration 2271 : loss : 0.038146, loss_ce: 0.021368
2021-12-13 00:01:40,014 iteration 2272 : loss : 0.024517, loss_ce: 0.006730
2021-12-13 00:01:41,495 iteration 2273 : loss : 0.039642, loss_ce: 0.011696
2021-12-13 00:01:42,883 iteration 2274 : loss : 0.029912, loss_ce: 0.009966
2021-12-13 00:01:44,315 iteration 2275 : loss : 0.025797, loss_ce: 0.010675
2021-12-13 00:01:45,769 iteration 2276 : loss : 0.043503, loss_ce: 0.013760
2021-12-13 00:01:47,191 iteration 2277 : loss : 0.027211, loss_ce: 0.010967
2021-12-13 00:01:48,625 iteration 2278 : loss : 0.026405, loss_ce: 0.011855
 34%|█████████▋                   | 134/400 [59:57<1:52:51, 25.46s/it]2021-12-13 00:01:50,187 iteration 2279 : loss : 0.035144, loss_ce: 0.016971
2021-12-13 00:01:51,653 iteration 2280 : loss : 0.033235, loss_ce: 0.015807
2021-12-13 00:01:53,027 iteration 2281 : loss : 0.025205, loss_ce: 0.009534
2021-12-13 00:01:54,568 iteration 2282 : loss : 0.039967, loss_ce: 0.013895
2021-12-13 00:01:55,975 iteration 2283 : loss : 0.026685, loss_ce: 0.009483
2021-12-13 00:01:57,515 iteration 2284 : loss : 0.047358, loss_ce: 0.015444
2021-12-13 00:01:58,913 iteration 2285 : loss : 0.029563, loss_ce: 0.010513
2021-12-13 00:02:00,336 iteration 2286 : loss : 0.020625, loss_ce: 0.006560
2021-12-13 00:02:01,824 iteration 2287 : loss : 0.044526, loss_ce: 0.011701
2021-12-13 00:02:03,200 iteration 2288 : loss : 0.034010, loss_ce: 0.013140
2021-12-13 00:02:04,663 iteration 2289 : loss : 0.031172, loss_ce: 0.012005
2021-12-13 00:02:06,111 iteration 2290 : loss : 0.026008, loss_ce: 0.009386
2021-12-13 00:02:07,531 iteration 2291 : loss : 0.024280, loss_ce: 0.008830
2021-12-13 00:02:09,027 iteration 2292 : loss : 0.041660, loss_ce: 0.018210
2021-12-13 00:02:10,410 iteration 2293 : loss : 0.025621, loss_ce: 0.010730
2021-12-13 00:02:11,835 iteration 2294 : loss : 0.026374, loss_ce: 0.011542
2021-12-13 00:02:11,835 Training Data Eval:
2021-12-13 00:02:19,251   Average segmentation loss on training set: 0.0543
2021-12-13 00:02:19,252 Validation Data Eval:
2021-12-13 00:02:21,842   Average segmentation loss on validation set: 0.2287
2021-12-13 00:02:23,302 iteration 2295 : loss : 0.023940, loss_ce: 0.008499
 34%|█████████                  | 135/400 [1:00:32<2:04:38, 28.22s/it]2021-12-13 00:02:24,783 iteration 2296 : loss : 0.036143, loss_ce: 0.013770
2021-12-13 00:02:26,220 iteration 2297 : loss : 0.029957, loss_ce: 0.008589
2021-12-13 00:02:27,758 iteration 2298 : loss : 0.033687, loss_ce: 0.014022
2021-12-13 00:02:29,182 iteration 2299 : loss : 0.029559, loss_ce: 0.008385
2021-12-13 00:02:30,701 iteration 2300 : loss : 0.036222, loss_ce: 0.012728
2021-12-13 00:02:32,127 iteration 2301 : loss : 0.039664, loss_ce: 0.019987
2021-12-13 00:02:33,554 iteration 2302 : loss : 0.029481, loss_ce: 0.012745
2021-12-13 00:02:34,953 iteration 2303 : loss : 0.032792, loss_ce: 0.010543
2021-12-13 00:02:36,330 iteration 2304 : loss : 0.027481, loss_ce: 0.011033
2021-12-13 00:02:37,828 iteration 2305 : loss : 0.028897, loss_ce: 0.009435
2021-12-13 00:02:39,230 iteration 2306 : loss : 0.025820, loss_ce: 0.008330
2021-12-13 00:02:40,616 iteration 2307 : loss : 0.029863, loss_ce: 0.010114
2021-12-13 00:02:42,035 iteration 2308 : loss : 0.031892, loss_ce: 0.014800
2021-12-13 00:02:43,504 iteration 2309 : loss : 0.031700, loss_ce: 0.012741
2021-12-13 00:02:44,976 iteration 2310 : loss : 0.029628, loss_ce: 0.013651
2021-12-13 00:02:46,504 iteration 2311 : loss : 0.037113, loss_ce: 0.011941
2021-12-13 00:02:47,968 iteration 2312 : loss : 0.033299, loss_ce: 0.014237
 34%|█████████▏                 | 136/400 [1:00:57<1:59:29, 27.16s/it]2021-12-13 00:02:49,449 iteration 2313 : loss : 0.028402, loss_ce: 0.013218
2021-12-13 00:02:50,844 iteration 2314 : loss : 0.041642, loss_ce: 0.016519
2021-12-13 00:02:52,290 iteration 2315 : loss : 0.025377, loss_ce: 0.008935
2021-12-13 00:02:53,756 iteration 2316 : loss : 0.028147, loss_ce: 0.013430
2021-12-13 00:02:55,125 iteration 2317 : loss : 0.049592, loss_ce: 0.020597
2021-12-13 00:02:56,629 iteration 2318 : loss : 0.022458, loss_ce: 0.009559
2021-12-13 00:02:58,156 iteration 2319 : loss : 0.040335, loss_ce: 0.013283
2021-12-13 00:02:59,546 iteration 2320 : loss : 0.033270, loss_ce: 0.016095
2021-12-13 00:03:00,976 iteration 2321 : loss : 0.031371, loss_ce: 0.008335
2021-12-13 00:03:02,423 iteration 2322 : loss : 0.034429, loss_ce: 0.013792
2021-12-13 00:03:03,931 iteration 2323 : loss : 0.057050, loss_ce: 0.016178
2021-12-13 00:03:05,398 iteration 2324 : loss : 0.035028, loss_ce: 0.009890
2021-12-13 00:03:06,842 iteration 2325 : loss : 0.029894, loss_ce: 0.014439
2021-12-13 00:03:08,318 iteration 2326 : loss : 0.036732, loss_ce: 0.020600
2021-12-13 00:03:09,737 iteration 2327 : loss : 0.026417, loss_ce: 0.009038
2021-12-13 00:03:11,267 iteration 2328 : loss : 0.035851, loss_ce: 0.014511
2021-12-13 00:03:12,704 iteration 2329 : loss : 0.038210, loss_ce: 0.013751
 34%|█████████▏                 | 137/400 [1:01:21<1:55:51, 26.43s/it]2021-12-13 00:03:14,169 iteration 2330 : loss : 0.027300, loss_ce: 0.011144
2021-12-13 00:03:15,561 iteration 2331 : loss : 0.037979, loss_ce: 0.009478
2021-12-13 00:03:17,074 iteration 2332 : loss : 0.039827, loss_ce: 0.018269
2021-12-13 00:03:18,451 iteration 2333 : loss : 0.023185, loss_ce: 0.012647
2021-12-13 00:03:19,883 iteration 2334 : loss : 0.029915, loss_ce: 0.007049
2021-12-13 00:03:21,442 iteration 2335 : loss : 0.054361, loss_ce: 0.021807
2021-12-13 00:03:22,857 iteration 2336 : loss : 0.031872, loss_ce: 0.014820
2021-12-13 00:03:24,299 iteration 2337 : loss : 0.027965, loss_ce: 0.009754
2021-12-13 00:03:25,771 iteration 2338 : loss : 0.024109, loss_ce: 0.007882
2021-12-13 00:03:27,204 iteration 2339 : loss : 0.059976, loss_ce: 0.019621
2021-12-13 00:03:28,677 iteration 2340 : loss : 0.034867, loss_ce: 0.015090
2021-12-13 00:03:30,131 iteration 2341 : loss : 0.040256, loss_ce: 0.016028
2021-12-13 00:03:31,609 iteration 2342 : loss : 0.022688, loss_ce: 0.007007
2021-12-13 00:03:33,064 iteration 2343 : loss : 0.029592, loss_ce: 0.011837
2021-12-13 00:03:34,436 iteration 2344 : loss : 0.026729, loss_ce: 0.009934
2021-12-13 00:03:35,845 iteration 2345 : loss : 0.028614, loss_ce: 0.011444
2021-12-13 00:03:37,215 iteration 2346 : loss : 0.035651, loss_ce: 0.012431
 34%|█████████▎                 | 138/400 [1:01:46<1:52:53, 25.85s/it]2021-12-13 00:03:38,742 iteration 2347 : loss : 0.034689, loss_ce: 0.012914
2021-12-13 00:03:40,172 iteration 2348 : loss : 0.026826, loss_ce: 0.008220
2021-12-13 00:03:41,638 iteration 2349 : loss : 0.030918, loss_ce: 0.015271
2021-12-13 00:03:43,012 iteration 2350 : loss : 0.023507, loss_ce: 0.010925
2021-12-13 00:03:44,482 iteration 2351 : loss : 0.041835, loss_ce: 0.013482
2021-12-13 00:03:46,010 iteration 2352 : loss : 0.026237, loss_ce: 0.010559
2021-12-13 00:03:47,373 iteration 2353 : loss : 0.023559, loss_ce: 0.009912
2021-12-13 00:03:48,822 iteration 2354 : loss : 0.038554, loss_ce: 0.011769
2021-12-13 00:03:50,211 iteration 2355 : loss : 0.029557, loss_ce: 0.012313
2021-12-13 00:03:51,741 iteration 2356 : loss : 0.030794, loss_ce: 0.011243
2021-12-13 00:03:53,240 iteration 2357 : loss : 0.033221, loss_ce: 0.015250
2021-12-13 00:03:54,757 iteration 2358 : loss : 0.044973, loss_ce: 0.017627
2021-12-13 00:03:56,245 iteration 2359 : loss : 0.035666, loss_ce: 0.010083
2021-12-13 00:03:57,603 iteration 2360 : loss : 0.041840, loss_ce: 0.007276
2021-12-13 00:03:59,001 iteration 2361 : loss : 0.025279, loss_ce: 0.008009
2021-12-13 00:04:00,450 iteration 2362 : loss : 0.034148, loss_ce: 0.014424
2021-12-13 00:04:01,895 iteration 2363 : loss : 0.030516, loss_ce: 0.010017
 35%|█████████▍                 | 139/400 [1:02:11<1:50:56, 25.50s/it]2021-12-13 00:04:03,374 iteration 2364 : loss : 0.040832, loss_ce: 0.017053
2021-12-13 00:04:04,759 iteration 2365 : loss : 0.035980, loss_ce: 0.011747
2021-12-13 00:04:06,229 iteration 2366 : loss : 0.027035, loss_ce: 0.011422
2021-12-13 00:04:07,651 iteration 2367 : loss : 0.059530, loss_ce: 0.016223
2021-12-13 00:04:09,180 iteration 2368 : loss : 0.033172, loss_ce: 0.009728
2021-12-13 00:04:10,601 iteration 2369 : loss : 0.035225, loss_ce: 0.013323
2021-12-13 00:04:11,999 iteration 2370 : loss : 0.020511, loss_ce: 0.007212
2021-12-13 00:04:13,446 iteration 2371 : loss : 0.027934, loss_ce: 0.011119
2021-12-13 00:04:14,830 iteration 2372 : loss : 0.022507, loss_ce: 0.011478
2021-12-13 00:04:16,283 iteration 2373 : loss : 0.024650, loss_ce: 0.008675
2021-12-13 00:04:17,777 iteration 2374 : loss : 0.028621, loss_ce: 0.010760
2021-12-13 00:04:19,167 iteration 2375 : loss : 0.035923, loss_ce: 0.011869
2021-12-13 00:04:20,660 iteration 2376 : loss : 0.031489, loss_ce: 0.012846
2021-12-13 00:04:22,097 iteration 2377 : loss : 0.023458, loss_ce: 0.006239
2021-12-13 00:04:23,634 iteration 2378 : loss : 0.041341, loss_ce: 0.020899
2021-12-13 00:04:25,100 iteration 2379 : loss : 0.035286, loss_ce: 0.011145
2021-12-13 00:04:25,100 Training Data Eval:
2021-12-13 00:04:32,515   Average segmentation loss on training set: 0.0428
2021-12-13 00:04:32,516 Validation Data Eval:
2021-12-13 00:04:35,100   Average segmentation loss on validation set: 0.0809
2021-12-13 00:04:36,669 iteration 2380 : loss : 0.028557, loss_ce: 0.010554
 35%|█████████▍                 | 140/400 [1:02:45<2:02:32, 28.28s/it]2021-12-13 00:04:38,109 iteration 2381 : loss : 0.031668, loss_ce: 0.009480
2021-12-13 00:04:39,607 iteration 2382 : loss : 0.046525, loss_ce: 0.022151
2021-12-13 00:04:41,109 iteration 2383 : loss : 0.027756, loss_ce: 0.010330
2021-12-13 00:04:42,558 iteration 2384 : loss : 0.037089, loss_ce: 0.010649
2021-12-13 00:04:44,022 iteration 2385 : loss : 0.033570, loss_ce: 0.013288
2021-12-13 00:04:45,543 iteration 2386 : loss : 0.027239, loss_ce: 0.009441
2021-12-13 00:04:46,964 iteration 2387 : loss : 0.032325, loss_ce: 0.011604
2021-12-13 00:04:48,444 iteration 2388 : loss : 0.022081, loss_ce: 0.009000
2021-12-13 00:04:49,849 iteration 2389 : loss : 0.031275, loss_ce: 0.011818
2021-12-13 00:04:51,302 iteration 2390 : loss : 0.022354, loss_ce: 0.008944
2021-12-13 00:04:52,719 iteration 2391 : loss : 0.027185, loss_ce: 0.009836
2021-12-13 00:04:54,120 iteration 2392 : loss : 0.023976, loss_ce: 0.010759
2021-12-13 00:04:55,529 iteration 2393 : loss : 0.023031, loss_ce: 0.009889
2021-12-13 00:04:56,989 iteration 2394 : loss : 0.055746, loss_ce: 0.013375
2021-12-13 00:04:58,569 iteration 2395 : loss : 0.037298, loss_ce: 0.016177
2021-12-13 00:05:00,084 iteration 2396 : loss : 0.018165, loss_ce: 0.006779
2021-12-13 00:05:01,526 iteration 2397 : loss : 0.049555, loss_ce: 0.019212
 35%|█████████▌                 | 141/400 [1:03:10<1:57:39, 27.26s/it]2021-12-13 00:05:03,110 iteration 2398 : loss : 0.030601, loss_ce: 0.014056
2021-12-13 00:05:04,490 iteration 2399 : loss : 0.023598, loss_ce: 0.009681
2021-12-13 00:05:05,919 iteration 2400 : loss : 0.024879, loss_ce: 0.006347
2021-12-13 00:05:07,375 iteration 2401 : loss : 0.027714, loss_ce: 0.010399
2021-12-13 00:05:08,796 iteration 2402 : loss : 0.029230, loss_ce: 0.011784
2021-12-13 00:05:10,242 iteration 2403 : loss : 0.020707, loss_ce: 0.007246
2021-12-13 00:05:11,660 iteration 2404 : loss : 0.029978, loss_ce: 0.015618
2021-12-13 00:05:13,103 iteration 2405 : loss : 0.033917, loss_ce: 0.011952
2021-12-13 00:05:14,628 iteration 2406 : loss : 0.044201, loss_ce: 0.017527
2021-12-13 00:05:16,054 iteration 2407 : loss : 0.025813, loss_ce: 0.009230
2021-12-13 00:05:17,524 iteration 2408 : loss : 0.030060, loss_ce: 0.013504
2021-12-13 00:05:18,995 iteration 2409 : loss : 0.039386, loss_ce: 0.014972
2021-12-13 00:05:20,479 iteration 2410 : loss : 0.045135, loss_ce: 0.013632
2021-12-13 00:05:21,867 iteration 2411 : loss : 0.031348, loss_ce: 0.011833
2021-12-13 00:05:23,377 iteration 2412 : loss : 0.055242, loss_ce: 0.024785
2021-12-13 00:05:24,912 iteration 2413 : loss : 0.047873, loss_ce: 0.019989
2021-12-13 00:05:26,407 iteration 2414 : loss : 0.031434, loss_ce: 0.013542
 36%|█████████▌                 | 142/400 [1:03:35<1:54:07, 26.54s/it]2021-12-13 00:05:27,900 iteration 2415 : loss : 0.029252, loss_ce: 0.009164
2021-12-13 00:05:29,336 iteration 2416 : loss : 0.031985, loss_ce: 0.015044
2021-12-13 00:05:30,808 iteration 2417 : loss : 0.049503, loss_ce: 0.015229
2021-12-13 00:05:32,287 iteration 2418 : loss : 0.052557, loss_ce: 0.019307
2021-12-13 00:05:33,735 iteration 2419 : loss : 0.041606, loss_ce: 0.020460
2021-12-13 00:05:35,130 iteration 2420 : loss : 0.029408, loss_ce: 0.011798
2021-12-13 00:05:36,693 iteration 2421 : loss : 0.035628, loss_ce: 0.010668
2021-12-13 00:05:38,185 iteration 2422 : loss : 0.041303, loss_ce: 0.015581
2021-12-13 00:05:39,662 iteration 2423 : loss : 0.036368, loss_ce: 0.016824
2021-12-13 00:05:41,064 iteration 2424 : loss : 0.038676, loss_ce: 0.013115
2021-12-13 00:05:42,595 iteration 2425 : loss : 0.034887, loss_ce: 0.017345
2021-12-13 00:05:44,043 iteration 2426 : loss : 0.028475, loss_ce: 0.011273
2021-12-13 00:05:45,589 iteration 2427 : loss : 0.059006, loss_ce: 0.017106
2021-12-13 00:05:47,115 iteration 2428 : loss : 0.049599, loss_ce: 0.017591
2021-12-13 00:05:48,647 iteration 2429 : loss : 0.040380, loss_ce: 0.018162
2021-12-13 00:05:50,095 iteration 2430 : loss : 0.044272, loss_ce: 0.018307
2021-12-13 00:05:51,495 iteration 2431 : loss : 0.024079, loss_ce: 0.010926
 36%|█████████▋                 | 143/400 [1:04:00<1:51:49, 26.11s/it]2021-12-13 00:05:53,019 iteration 2432 : loss : 0.034986, loss_ce: 0.014807
2021-12-13 00:05:54,480 iteration 2433 : loss : 0.057711, loss_ce: 0.023456
2021-12-13 00:05:55,932 iteration 2434 : loss : 0.030430, loss_ce: 0.007904
2021-12-13 00:05:57,502 iteration 2435 : loss : 0.062771, loss_ce: 0.038110
2021-12-13 00:05:58,866 iteration 2436 : loss : 0.028265, loss_ce: 0.010515
2021-12-13 00:06:00,267 iteration 2437 : loss : 0.031729, loss_ce: 0.013874
2021-12-13 00:06:01,862 iteration 2438 : loss : 0.036910, loss_ce: 0.015151
2021-12-13 00:06:03,343 iteration 2439 : loss : 0.030381, loss_ce: 0.012861
2021-12-13 00:06:04,793 iteration 2440 : loss : 0.032813, loss_ce: 0.011377
2021-12-13 00:06:06,242 iteration 2441 : loss : 0.037724, loss_ce: 0.009768
2021-12-13 00:06:07,668 iteration 2442 : loss : 0.033620, loss_ce: 0.011632
2021-12-13 00:06:09,058 iteration 2443 : loss : 0.026723, loss_ce: 0.011892
2021-12-13 00:06:10,550 iteration 2444 : loss : 0.029005, loss_ce: 0.010372
2021-12-13 00:06:11,914 iteration 2445 : loss : 0.066011, loss_ce: 0.012256
2021-12-13 00:06:13,460 iteration 2446 : loss : 0.032207, loss_ce: 0.011431
2021-12-13 00:06:14,984 iteration 2447 : loss : 0.041518, loss_ce: 0.018289
2021-12-13 00:06:16,445 iteration 2448 : loss : 0.035378, loss_ce: 0.012311
 36%|█████████▋                 | 144/400 [1:04:25<1:49:54, 25.76s/it]2021-12-13 00:06:17,914 iteration 2449 : loss : 0.034940, loss_ce: 0.014923
2021-12-13 00:06:19,428 iteration 2450 : loss : 0.047305, loss_ce: 0.014516
2021-12-13 00:06:20,943 iteration 2451 : loss : 0.030823, loss_ce: 0.011571
2021-12-13 00:06:22,323 iteration 2452 : loss : 0.022911, loss_ce: 0.010190
2021-12-13 00:06:23,761 iteration 2453 : loss : 0.043966, loss_ce: 0.012862
2021-12-13 00:06:25,251 iteration 2454 : loss : 0.036583, loss_ce: 0.018104
2021-12-13 00:06:26,726 iteration 2455 : loss : 0.034456, loss_ce: 0.016114
2021-12-13 00:06:28,308 iteration 2456 : loss : 0.039805, loss_ce: 0.016315
2021-12-13 00:06:29,763 iteration 2457 : loss : 0.036105, loss_ce: 0.013056
2021-12-13 00:06:31,295 iteration 2458 : loss : 0.035177, loss_ce: 0.012052
2021-12-13 00:06:32,703 iteration 2459 : loss : 0.048389, loss_ce: 0.015713
2021-12-13 00:06:34,150 iteration 2460 : loss : 0.029461, loss_ce: 0.008943
2021-12-13 00:06:35,619 iteration 2461 : loss : 0.047881, loss_ce: 0.018764
2021-12-13 00:06:37,058 iteration 2462 : loss : 0.022891, loss_ce: 0.009412
2021-12-13 00:06:38,531 iteration 2463 : loss : 0.042268, loss_ce: 0.015401
2021-12-13 00:06:40,054 iteration 2464 : loss : 0.029473, loss_ce: 0.014164
2021-12-13 00:06:40,054 Training Data Eval:
2021-12-13 00:06:47,485   Average segmentation loss on training set: 0.0341
2021-12-13 00:06:47,486 Validation Data Eval:
2021-12-13 00:06:50,075   Average segmentation loss on validation set: 0.1034
2021-12-13 00:06:51,519 iteration 2465 : loss : 0.028753, loss_ce: 0.010435
 36%|█████████▊                 | 145/400 [1:05:00<2:01:20, 28.55s/it]2021-12-13 00:06:52,997 iteration 2466 : loss : 0.025167, loss_ce: 0.009853
2021-12-13 00:06:54,503 iteration 2467 : loss : 0.030760, loss_ce: 0.019036
2021-12-13 00:06:55,913 iteration 2468 : loss : 0.032425, loss_ce: 0.015806
2021-12-13 00:06:57,299 iteration 2469 : loss : 0.018171, loss_ce: 0.008913
2021-12-13 00:06:58,793 iteration 2470 : loss : 0.040098, loss_ce: 0.014911
2021-12-13 00:07:00,292 iteration 2471 : loss : 0.025198, loss_ce: 0.010108
2021-12-13 00:07:01,842 iteration 2472 : loss : 0.033794, loss_ce: 0.012612
2021-12-13 00:07:03,221 iteration 2473 : loss : 0.029346, loss_ce: 0.011102
2021-12-13 00:07:04,702 iteration 2474 : loss : 0.035363, loss_ce: 0.011224
2021-12-13 00:07:06,093 iteration 2475 : loss : 0.022907, loss_ce: 0.009964
2021-12-13 00:07:07,635 iteration 2476 : loss : 0.033797, loss_ce: 0.008957
2021-12-13 00:07:09,097 iteration 2477 : loss : 0.024006, loss_ce: 0.009925
2021-12-13 00:07:10,547 iteration 2478 : loss : 0.025258, loss_ce: 0.007833
2021-12-13 00:07:12,116 iteration 2479 : loss : 0.032813, loss_ce: 0.011876
2021-12-13 00:07:13,619 iteration 2480 : loss : 0.032709, loss_ce: 0.012927
2021-12-13 00:07:15,045 iteration 2481 : loss : 0.031755, loss_ce: 0.012882
2021-12-13 00:07:16,514 iteration 2482 : loss : 0.030598, loss_ce: 0.011296
 36%|█████████▊                 | 146/400 [1:05:25<1:56:21, 27.49s/it]2021-12-13 00:07:18,017 iteration 2483 : loss : 0.024573, loss_ce: 0.009571
2021-12-13 00:07:19,537 iteration 2484 : loss : 0.024387, loss_ce: 0.008470
2021-12-13 00:07:21,078 iteration 2485 : loss : 0.036313, loss_ce: 0.012614
2021-12-13 00:07:22,480 iteration 2486 : loss : 0.021937, loss_ce: 0.009918
2021-12-13 00:07:23,907 iteration 2487 : loss : 0.023738, loss_ce: 0.008211
2021-12-13 00:07:25,412 iteration 2488 : loss : 0.040657, loss_ce: 0.017188
2021-12-13 00:07:26,915 iteration 2489 : loss : 0.028389, loss_ce: 0.011718
2021-12-13 00:07:28,351 iteration 2490 : loss : 0.021544, loss_ce: 0.009430
2021-12-13 00:07:29,829 iteration 2491 : loss : 0.021698, loss_ce: 0.008556
2021-12-13 00:07:31,250 iteration 2492 : loss : 0.048020, loss_ce: 0.019940
2021-12-13 00:07:32,685 iteration 2493 : loss : 0.024907, loss_ce: 0.007937
2021-12-13 00:07:34,097 iteration 2494 : loss : 0.026489, loss_ce: 0.011723
2021-12-13 00:07:35,542 iteration 2495 : loss : 0.027360, loss_ce: 0.008652
2021-12-13 00:07:37,044 iteration 2496 : loss : 0.033951, loss_ce: 0.009889
2021-12-13 00:07:38,509 iteration 2497 : loss : 0.038905, loss_ce: 0.016819
2021-12-13 00:07:39,875 iteration 2498 : loss : 0.026163, loss_ce: 0.012566
2021-12-13 00:07:41,390 iteration 2499 : loss : 0.026259, loss_ce: 0.013559
 37%|█████████▉                 | 147/400 [1:05:50<1:52:35, 26.70s/it]2021-12-13 00:07:42,905 iteration 2500 : loss : 0.034898, loss_ce: 0.011161
2021-12-13 00:07:44,315 iteration 2501 : loss : 0.028587, loss_ce: 0.009605
2021-12-13 00:07:45,763 iteration 2502 : loss : 0.027961, loss_ce: 0.010668
2021-12-13 00:07:47,223 iteration 2503 : loss : 0.032374, loss_ce: 0.014256
2021-12-13 00:07:48,683 iteration 2504 : loss : 0.028671, loss_ce: 0.010035
2021-12-13 00:07:50,073 iteration 2505 : loss : 0.020263, loss_ce: 0.008991
2021-12-13 00:07:51,495 iteration 2506 : loss : 0.056038, loss_ce: 0.016256
2021-12-13 00:07:52,982 iteration 2507 : loss : 0.022223, loss_ce: 0.008095
2021-12-13 00:07:54,402 iteration 2508 : loss : 0.025712, loss_ce: 0.012251
2021-12-13 00:07:55,902 iteration 2509 : loss : 0.034288, loss_ce: 0.013864
2021-12-13 00:07:57,320 iteration 2510 : loss : 0.032194, loss_ce: 0.010941
2021-12-13 00:07:58,713 iteration 2511 : loss : 0.023907, loss_ce: 0.010778
2021-12-13 00:08:00,223 iteration 2512 : loss : 0.025636, loss_ce: 0.008602
2021-12-13 00:08:01,641 iteration 2513 : loss : 0.023091, loss_ce: 0.008915
2021-12-13 00:08:03,116 iteration 2514 : loss : 0.029343, loss_ce: 0.011372
2021-12-13 00:08:04,532 iteration 2515 : loss : 0.025524, loss_ce: 0.011366
2021-12-13 00:08:06,129 iteration 2516 : loss : 0.024333, loss_ce: 0.008862
 37%|█████████▉                 | 148/400 [1:06:15<1:49:41, 26.12s/it]2021-12-13 00:08:07,636 iteration 2517 : loss : 0.027573, loss_ce: 0.009541
2021-12-13 00:08:09,128 iteration 2518 : loss : 0.051323, loss_ce: 0.011975
2021-12-13 00:08:10,525 iteration 2519 : loss : 0.016954, loss_ce: 0.005505
2021-12-13 00:08:12,021 iteration 2520 : loss : 0.025092, loss_ce: 0.011179
2021-12-13 00:08:13,493 iteration 2521 : loss : 0.028063, loss_ce: 0.012098
2021-12-13 00:08:14,974 iteration 2522 : loss : 0.034401, loss_ce: 0.013011
2021-12-13 00:08:16,434 iteration 2523 : loss : 0.027760, loss_ce: 0.007157
2021-12-13 00:08:17,934 iteration 2524 : loss : 0.025735, loss_ce: 0.010062
2021-12-13 00:08:19,367 iteration 2525 : loss : 0.022514, loss_ce: 0.007144
2021-12-13 00:08:20,770 iteration 2526 : loss : 0.024518, loss_ce: 0.009210
2021-12-13 00:08:22,237 iteration 2527 : loss : 0.029032, loss_ce: 0.015379
2021-12-13 00:08:23,680 iteration 2528 : loss : 0.027148, loss_ce: 0.012944
2021-12-13 00:08:25,168 iteration 2529 : loss : 0.037011, loss_ce: 0.014322
2021-12-13 00:08:26,561 iteration 2530 : loss : 0.030154, loss_ce: 0.010976
2021-12-13 00:08:28,039 iteration 2531 : loss : 0.043446, loss_ce: 0.015042
2021-12-13 00:08:29,562 iteration 2532 : loss : 0.028774, loss_ce: 0.014211
2021-12-13 00:08:30,946 iteration 2533 : loss : 0.031391, loss_ce: 0.007156
 37%|██████████                 | 149/400 [1:06:40<1:47:36, 25.72s/it]2021-12-13 00:08:32,439 iteration 2534 : loss : 0.025023, loss_ce: 0.008994
2021-12-13 00:08:33,799 iteration 2535 : loss : 0.030458, loss_ce: 0.013463
2021-12-13 00:08:35,200 iteration 2536 : loss : 0.021130, loss_ce: 0.010044
2021-12-13 00:08:36,739 iteration 2537 : loss : 0.031980, loss_ce: 0.017075
2021-12-13 00:08:38,066 iteration 2538 : loss : 0.025785, loss_ce: 0.008620
2021-12-13 00:08:39,447 iteration 2539 : loss : 0.019738, loss_ce: 0.007759
2021-12-13 00:08:40,890 iteration 2540 : loss : 0.030342, loss_ce: 0.012428
2021-12-13 00:08:42,407 iteration 2541 : loss : 0.037486, loss_ce: 0.013587
2021-12-13 00:08:43,855 iteration 2542 : loss : 0.033923, loss_ce: 0.008888
2021-12-13 00:08:45,379 iteration 2543 : loss : 0.028273, loss_ce: 0.009052
2021-12-13 00:08:46,906 iteration 2544 : loss : 0.039652, loss_ce: 0.013638
2021-12-13 00:08:48,304 iteration 2545 : loss : 0.032955, loss_ce: 0.014161
2021-12-13 00:08:49,921 iteration 2546 : loss : 0.036648, loss_ce: 0.013188
2021-12-13 00:08:51,416 iteration 2547 : loss : 0.035557, loss_ce: 0.012768
2021-12-13 00:08:52,939 iteration 2548 : loss : 0.028173, loss_ce: 0.011898
2021-12-13 00:08:54,382 iteration 2549 : loss : 0.033242, loss_ce: 0.011563
2021-12-13 00:08:54,383 Training Data Eval:
2021-12-13 00:09:01,837   Average segmentation loss on training set: 0.3141
2021-12-13 00:09:01,837 Validation Data Eval:
2021-12-13 00:09:04,414   Average segmentation loss on validation set: 0.2841
2021-12-13 00:09:05,884 iteration 2550 : loss : 0.031377, loss_ce: 0.007848
 38%|██████████▏                | 150/400 [1:07:15<1:58:42, 28.49s/it]2021-12-13 00:09:07,378 iteration 2551 : loss : 0.048263, loss_ce: 0.020483
2021-12-13 00:09:08,834 iteration 2552 : loss : 0.025025, loss_ce: 0.009767
2021-12-13 00:09:10,294 iteration 2553 : loss : 0.025710, loss_ce: 0.008341
2021-12-13 00:09:11,735 iteration 2554 : loss : 0.025914, loss_ce: 0.010134
2021-12-13 00:09:13,168 iteration 2555 : loss : 0.026149, loss_ce: 0.009624
2021-12-13 00:09:14,619 iteration 2556 : loss : 0.030390, loss_ce: 0.014028
2021-12-13 00:09:16,052 iteration 2557 : loss : 0.032458, loss_ce: 0.011598
2021-12-13 00:09:17,479 iteration 2558 : loss : 0.022717, loss_ce: 0.007416
2021-12-13 00:09:18,871 iteration 2559 : loss : 0.033412, loss_ce: 0.016548
2021-12-13 00:09:20,396 iteration 2560 : loss : 0.033547, loss_ce: 0.011821
2021-12-13 00:09:21,834 iteration 2561 : loss : 0.030324, loss_ce: 0.010647
2021-12-13 00:09:23,307 iteration 2562 : loss : 0.021467, loss_ce: 0.008882
2021-12-13 00:09:24,691 iteration 2563 : loss : 0.029021, loss_ce: 0.011507
2021-12-13 00:09:26,104 iteration 2564 : loss : 0.021891, loss_ce: 0.009007
2021-12-13 00:09:27,528 iteration 2565 : loss : 0.021947, loss_ce: 0.009275
2021-12-13 00:09:28,898 iteration 2566 : loss : 0.022550, loss_ce: 0.008545
2021-12-13 00:09:30,308 iteration 2567 : loss : 0.062609, loss_ce: 0.016237
 38%|██████████▏                | 151/400 [1:07:39<1:53:10, 27.27s/it]2021-12-13 00:09:31,773 iteration 2568 : loss : 0.024089, loss_ce: 0.010223
2021-12-13 00:09:33,210 iteration 2569 : loss : 0.042037, loss_ce: 0.016472
2021-12-13 00:09:34,734 iteration 2570 : loss : 0.026911, loss_ce: 0.008825
2021-12-13 00:09:36,169 iteration 2571 : loss : 0.024418, loss_ce: 0.007203
2021-12-13 00:09:37,555 iteration 2572 : loss : 0.025789, loss_ce: 0.009123
2021-12-13 00:09:38,993 iteration 2573 : loss : 0.029238, loss_ce: 0.011977
2021-12-13 00:09:40,407 iteration 2574 : loss : 0.026846, loss_ce: 0.011028
2021-12-13 00:09:41,782 iteration 2575 : loss : 0.029225, loss_ce: 0.010946
2021-12-13 00:09:43,166 iteration 2576 : loss : 0.026725, loss_ce: 0.007633
2021-12-13 00:09:44,642 iteration 2577 : loss : 0.031047, loss_ce: 0.014903
2021-12-13 00:09:46,055 iteration 2578 : loss : 0.025322, loss_ce: 0.009020
2021-12-13 00:09:47,505 iteration 2579 : loss : 0.030527, loss_ce: 0.010555
2021-12-13 00:09:48,887 iteration 2580 : loss : 0.024712, loss_ce: 0.008005
2021-12-13 00:09:50,347 iteration 2581 : loss : 0.025839, loss_ce: 0.011028
2021-12-13 00:09:51,852 iteration 2582 : loss : 0.022565, loss_ce: 0.009616
2021-12-13 00:09:53,266 iteration 2583 : loss : 0.023150, loss_ce: 0.010638
2021-12-13 00:09:54,687 iteration 2584 : loss : 0.035944, loss_ce: 0.010315
 38%|██████████▎                | 152/400 [1:08:03<1:49:07, 26.40s/it]2021-12-13 00:09:56,174 iteration 2585 : loss : 0.029684, loss_ce: 0.010329
2021-12-13 00:09:57,783 iteration 2586 : loss : 0.033305, loss_ce: 0.010276
2021-12-13 00:09:59,285 iteration 2587 : loss : 0.033907, loss_ce: 0.011051
2021-12-13 00:10:00,737 iteration 2588 : loss : 0.032205, loss_ce: 0.011930
2021-12-13 00:10:02,122 iteration 2589 : loss : 0.031107, loss_ce: 0.008885
2021-12-13 00:10:03,610 iteration 2590 : loss : 0.032327, loss_ce: 0.009412
2021-12-13 00:10:05,050 iteration 2591 : loss : 0.026215, loss_ce: 0.011071
2021-12-13 00:10:06,463 iteration 2592 : loss : 0.024884, loss_ce: 0.012896
2021-12-13 00:10:07,820 iteration 2593 : loss : 0.025359, loss_ce: 0.011756
2021-12-13 00:10:09,262 iteration 2594 : loss : 0.030184, loss_ce: 0.014130
2021-12-13 00:10:10,644 iteration 2595 : loss : 0.022434, loss_ce: 0.007358
2021-12-13 00:10:12,057 iteration 2596 : loss : 0.034927, loss_ce: 0.010786
2021-12-13 00:10:13,484 iteration 2597 : loss : 0.019675, loss_ce: 0.007091
2021-12-13 00:10:14,931 iteration 2598 : loss : 0.024618, loss_ce: 0.009744
2021-12-13 00:10:16,374 iteration 2599 : loss : 0.022306, loss_ce: 0.008424
2021-12-13 00:10:17,781 iteration 2600 : loss : 0.028405, loss_ce: 0.011896
2021-12-13 00:10:19,169 iteration 2601 : loss : 0.025615, loss_ce: 0.009729
 38%|██████████▎                | 153/400 [1:08:28<1:46:19, 25.83s/it]2021-12-13 00:10:20,627 iteration 2602 : loss : 0.036984, loss_ce: 0.012823
2021-12-13 00:10:22,075 iteration 2603 : loss : 0.041495, loss_ce: 0.007644
2021-12-13 00:10:23,506 iteration 2604 : loss : 0.023339, loss_ce: 0.008813
2021-12-13 00:10:24,934 iteration 2605 : loss : 0.026574, loss_ce: 0.008225
2021-12-13 00:10:26,373 iteration 2606 : loss : 0.024623, loss_ce: 0.008900
2021-12-13 00:10:27,824 iteration 2607 : loss : 0.025534, loss_ce: 0.010548
2021-12-13 00:10:29,231 iteration 2608 : loss : 0.024958, loss_ce: 0.009328
2021-12-13 00:10:30,721 iteration 2609 : loss : 0.024053, loss_ce: 0.008982
2021-12-13 00:10:32,188 iteration 2610 : loss : 0.028881, loss_ce: 0.010511
2021-12-13 00:10:33,684 iteration 2611 : loss : 0.039485, loss_ce: 0.016396
2021-12-13 00:10:35,163 iteration 2612 : loss : 0.035213, loss_ce: 0.011501
2021-12-13 00:10:36,677 iteration 2613 : loss : 0.041333, loss_ce: 0.016551
2021-12-13 00:10:38,160 iteration 2614 : loss : 0.024455, loss_ce: 0.009855
2021-12-13 00:10:39,614 iteration 2615 : loss : 0.029420, loss_ce: 0.012528
2021-12-13 00:10:41,113 iteration 2616 : loss : 0.022715, loss_ce: 0.007786
2021-12-13 00:10:42,568 iteration 2617 : loss : 0.031592, loss_ce: 0.012956
2021-12-13 00:10:44,053 iteration 2618 : loss : 0.038254, loss_ce: 0.011901
 38%|██████████▍                | 154/400 [1:08:53<1:44:43, 25.54s/it]2021-12-13 00:10:45,646 iteration 2619 : loss : 0.031483, loss_ce: 0.013367
2021-12-13 00:10:47,098 iteration 2620 : loss : 0.025459, loss_ce: 0.008294
2021-12-13 00:10:48,442 iteration 2621 : loss : 0.025493, loss_ce: 0.010623
2021-12-13 00:10:49,907 iteration 2622 : loss : 0.037055, loss_ce: 0.010834
2021-12-13 00:10:51,320 iteration 2623 : loss : 0.023278, loss_ce: 0.009049
2021-12-13 00:10:52,812 iteration 2624 : loss : 0.034149, loss_ce: 0.013415
2021-12-13 00:10:54,301 iteration 2625 : loss : 0.031137, loss_ce: 0.014074
2021-12-13 00:10:55,769 iteration 2626 : loss : 0.026724, loss_ce: 0.010378
2021-12-13 00:10:57,139 iteration 2627 : loss : 0.022687, loss_ce: 0.011958
2021-12-13 00:10:58,524 iteration 2628 : loss : 0.020255, loss_ce: 0.007492
2021-12-13 00:10:59,884 iteration 2629 : loss : 0.030477, loss_ce: 0.007202
2021-12-13 00:11:01,377 iteration 2630 : loss : 0.055687, loss_ce: 0.010027
2021-12-13 00:11:02,772 iteration 2631 : loss : 0.030449, loss_ce: 0.017064
2021-12-13 00:11:04,177 iteration 2632 : loss : 0.032843, loss_ce: 0.011664
2021-12-13 00:11:05,625 iteration 2633 : loss : 0.016979, loss_ce: 0.005761
2021-12-13 00:11:07,035 iteration 2634 : loss : 0.026792, loss_ce: 0.008843
2021-12-13 00:11:07,036 Training Data Eval:
2021-12-13 00:11:14,435   Average segmentation loss on training set: 0.0370
2021-12-13 00:11:14,436 Validation Data Eval:
2021-12-13 00:11:17,024   Average segmentation loss on validation set: 0.1302
2021-12-13 00:11:18,456 iteration 2635 : loss : 0.026328, loss_ce: 0.010250
 39%|██████████▍                | 155/400 [1:09:27<1:55:08, 28.20s/it]2021-12-13 00:11:19,895 iteration 2636 : loss : 0.026148, loss_ce: 0.008449
2021-12-13 00:11:21,321 iteration 2637 : loss : 0.019466, loss_ce: 0.008534
2021-12-13 00:11:22,848 iteration 2638 : loss : 0.040110, loss_ce: 0.017006
2021-12-13 00:11:24,289 iteration 2639 : loss : 0.025339, loss_ce: 0.008598
2021-12-13 00:11:25,748 iteration 2640 : loss : 0.032585, loss_ce: 0.014362
2021-12-13 00:11:27,181 iteration 2641 : loss : 0.024200, loss_ce: 0.011086
2021-12-13 00:11:28,645 iteration 2642 : loss : 0.025283, loss_ce: 0.008065
2021-12-13 00:11:30,065 iteration 2643 : loss : 0.025777, loss_ce: 0.010431
2021-12-13 00:11:31,525 iteration 2644 : loss : 0.031389, loss_ce: 0.015670
2021-12-13 00:11:32,916 iteration 2645 : loss : 0.025609, loss_ce: 0.011070
2021-12-13 00:11:34,327 iteration 2646 : loss : 0.019877, loss_ce: 0.005764
2021-12-13 00:11:35,845 iteration 2647 : loss : 0.036990, loss_ce: 0.014792
2021-12-13 00:11:37,257 iteration 2648 : loss : 0.027471, loss_ce: 0.009203
2021-12-13 00:11:38,703 iteration 2649 : loss : 0.036350, loss_ce: 0.011313
2021-12-13 00:11:40,258 iteration 2650 : loss : 0.031206, loss_ce: 0.010377
2021-12-13 00:11:41,686 iteration 2651 : loss : 0.024621, loss_ce: 0.009043
2021-12-13 00:11:43,204 iteration 2652 : loss : 0.023988, loss_ce: 0.008891
 39%|██████████▌                | 156/400 [1:09:52<1:50:28, 27.16s/it]2021-12-13 00:11:44,741 iteration 2653 : loss : 0.031638, loss_ce: 0.012724
2021-12-13 00:11:46,120 iteration 2654 : loss : 0.018771, loss_ce: 0.007854
2021-12-13 00:11:47,542 iteration 2655 : loss : 0.021947, loss_ce: 0.009335
2021-12-13 00:11:48,962 iteration 2656 : loss : 0.030755, loss_ce: 0.014846
2021-12-13 00:11:50,431 iteration 2657 : loss : 0.024416, loss_ce: 0.010526
2021-12-13 00:11:51,935 iteration 2658 : loss : 0.031361, loss_ce: 0.010537
2021-12-13 00:11:53,404 iteration 2659 : loss : 0.026852, loss_ce: 0.009869
2021-12-13 00:11:54,931 iteration 2660 : loss : 0.029082, loss_ce: 0.012144
2021-12-13 00:11:56,284 iteration 2661 : loss : 0.023251, loss_ce: 0.007645
2021-12-13 00:11:57,797 iteration 2662 : loss : 0.024132, loss_ce: 0.008555
2021-12-13 00:11:59,283 iteration 2663 : loss : 0.033127, loss_ce: 0.013426
2021-12-13 00:12:00,672 iteration 2664 : loss : 0.024998, loss_ce: 0.009117
2021-12-13 00:12:02,094 iteration 2665 : loss : 0.015502, loss_ce: 0.005832
2021-12-13 00:12:03,615 iteration 2666 : loss : 0.028326, loss_ce: 0.010989
2021-12-13 00:12:05,022 iteration 2667 : loss : 0.020911, loss_ce: 0.007737
2021-12-13 00:12:06,538 iteration 2668 : loss : 0.024349, loss_ce: 0.009635
2021-12-13 00:12:07,963 iteration 2669 : loss : 0.023692, loss_ce: 0.005347
 39%|██████████▌                | 157/400 [1:10:17<1:47:06, 26.45s/it]2021-12-13 00:12:09,377 iteration 2670 : loss : 0.022832, loss_ce: 0.008237
2021-12-13 00:12:10,756 iteration 2671 : loss : 0.021693, loss_ce: 0.007986
2021-12-13 00:12:12,167 iteration 2672 : loss : 0.048283, loss_ce: 0.020630
2021-12-13 00:12:13,564 iteration 2673 : loss : 0.031669, loss_ce: 0.009223
2021-12-13 00:12:15,016 iteration 2674 : loss : 0.026489, loss_ce: 0.008849
2021-12-13 00:12:16,500 iteration 2675 : loss : 0.023653, loss_ce: 0.010131
2021-12-13 00:12:17,924 iteration 2676 : loss : 0.020554, loss_ce: 0.006215
2021-12-13 00:12:19,361 iteration 2677 : loss : 0.020933, loss_ce: 0.007943
2021-12-13 00:12:20,732 iteration 2678 : loss : 0.019550, loss_ce: 0.008608
2021-12-13 00:12:22,171 iteration 2679 : loss : 0.026247, loss_ce: 0.010547
2021-12-13 00:12:23,670 iteration 2680 : loss : 0.025741, loss_ce: 0.009590
2021-12-13 00:12:25,122 iteration 2681 : loss : 0.027207, loss_ce: 0.010139
2021-12-13 00:12:26,609 iteration 2682 : loss : 0.022208, loss_ce: 0.008993
2021-12-13 00:12:28,017 iteration 2683 : loss : 0.021122, loss_ce: 0.008746
2021-12-13 00:12:29,472 iteration 2684 : loss : 0.025937, loss_ce: 0.010657
2021-12-13 00:12:30,952 iteration 2685 : loss : 0.025976, loss_ce: 0.012222
2021-12-13 00:12:32,432 iteration 2686 : loss : 0.043024, loss_ce: 0.010150
 40%|██████████▋                | 158/400 [1:10:41<1:44:16, 25.85s/it]2021-12-13 00:12:33,879 iteration 2687 : loss : 0.027741, loss_ce: 0.011439
2021-12-13 00:12:35,298 iteration 2688 : loss : 0.022703, loss_ce: 0.008003
2021-12-13 00:12:36,685 iteration 2689 : loss : 0.022959, loss_ce: 0.006996
2021-12-13 00:12:38,166 iteration 2690 : loss : 0.044473, loss_ce: 0.007548
2021-12-13 00:12:39,549 iteration 2691 : loss : 0.020884, loss_ce: 0.008204
2021-12-13 00:12:40,940 iteration 2692 : loss : 0.048959, loss_ce: 0.015760
2021-12-13 00:12:42,339 iteration 2693 : loss : 0.024757, loss_ce: 0.010713
2021-12-13 00:12:43,802 iteration 2694 : loss : 0.026926, loss_ce: 0.011540
2021-12-13 00:12:45,236 iteration 2695 : loss : 0.029129, loss_ce: 0.014606
2021-12-13 00:12:46,673 iteration 2696 : loss : 0.019542, loss_ce: 0.008532
2021-12-13 00:12:48,078 iteration 2697 : loss : 0.027188, loss_ce: 0.012101
2021-12-13 00:12:49,473 iteration 2698 : loss : 0.045845, loss_ce: 0.016392
2021-12-13 00:12:50,901 iteration 2699 : loss : 0.030625, loss_ce: 0.013786
2021-12-13 00:12:52,308 iteration 2700 : loss : 0.033362, loss_ce: 0.012251
2021-12-13 00:12:53,845 iteration 2701 : loss : 0.028019, loss_ce: 0.010274
2021-12-13 00:12:55,317 iteration 2702 : loss : 0.028558, loss_ce: 0.014118
2021-12-13 00:12:56,821 iteration 2703 : loss : 0.027827, loss_ce: 0.010246
 40%|██████████▋                | 159/400 [1:11:06<1:42:04, 25.41s/it]2021-12-13 00:12:58,360 iteration 2704 : loss : 0.049128, loss_ce: 0.015930
2021-12-13 00:12:59,750 iteration 2705 : loss : 0.024400, loss_ce: 0.010213
2021-12-13 00:13:01,225 iteration 2706 : loss : 0.043285, loss_ce: 0.017819
2021-12-13 00:13:02,640 iteration 2707 : loss : 0.026140, loss_ce: 0.012541
2021-12-13 00:13:04,112 iteration 2708 : loss : 0.024661, loss_ce: 0.009562
2021-12-13 00:13:05,538 iteration 2709 : loss : 0.024289, loss_ce: 0.009764
2021-12-13 00:13:06,911 iteration 2710 : loss : 0.020264, loss_ce: 0.008265
2021-12-13 00:13:08,374 iteration 2711 : loss : 0.021424, loss_ce: 0.007627
2021-12-13 00:13:09,848 iteration 2712 : loss : 0.031103, loss_ce: 0.008998
2021-12-13 00:13:11,245 iteration 2713 : loss : 0.021241, loss_ce: 0.011036
2021-12-13 00:13:12,736 iteration 2714 : loss : 0.023583, loss_ce: 0.008982
2021-12-13 00:13:14,203 iteration 2715 : loss : 0.029134, loss_ce: 0.008924
2021-12-13 00:13:15,678 iteration 2716 : loss : 0.030593, loss_ce: 0.010730
2021-12-13 00:13:17,120 iteration 2717 : loss : 0.029468, loss_ce: 0.012075
2021-12-13 00:13:18,600 iteration 2718 : loss : 0.041656, loss_ce: 0.014482
2021-12-13 00:13:20,022 iteration 2719 : loss : 0.025422, loss_ce: 0.009493
2021-12-13 00:13:20,022 Training Data Eval:
2021-12-13 00:13:27,407   Average segmentation loss on training set: 0.0502
2021-12-13 00:13:27,408 Validation Data Eval:
2021-12-13 00:13:29,987   Average segmentation loss on validation set: 0.2114
2021-12-13 00:13:31,383 iteration 2720 : loss : 0.027835, loss_ce: 0.009797
 40%|██████████▊                | 160/400 [1:11:40<1:52:37, 28.16s/it]2021-12-13 00:13:32,887 iteration 2721 : loss : 0.030374, loss_ce: 0.014359
2021-12-13 00:13:34,350 iteration 2722 : loss : 0.030193, loss_ce: 0.012486
2021-12-13 00:13:35,831 iteration 2723 : loss : 0.022246, loss_ce: 0.009471
2021-12-13 00:13:37,276 iteration 2724 : loss : 0.043584, loss_ce: 0.016995
2021-12-13 00:13:38,691 iteration 2725 : loss : 0.039142, loss_ce: 0.012617
2021-12-13 00:13:40,259 iteration 2726 : loss : 0.058112, loss_ce: 0.023009
2021-12-13 00:13:41,752 iteration 2727 : loss : 0.029015, loss_ce: 0.011971
2021-12-13 00:13:43,195 iteration 2728 : loss : 0.020653, loss_ce: 0.007907
2021-12-13 00:13:44,625 iteration 2729 : loss : 0.028265, loss_ce: 0.013739
2021-12-13 00:13:46,001 iteration 2730 : loss : 0.020673, loss_ce: 0.007364
2021-12-13 00:13:47,464 iteration 2731 : loss : 0.024315, loss_ce: 0.008403
2021-12-13 00:13:48,980 iteration 2732 : loss : 0.054011, loss_ce: 0.023828
2021-12-13 00:13:50,435 iteration 2733 : loss : 0.033980, loss_ce: 0.012263
2021-12-13 00:13:51,866 iteration 2734 : loss : 0.026884, loss_ce: 0.008697
2021-12-13 00:13:53,386 iteration 2735 : loss : 0.034264, loss_ce: 0.012217
2021-12-13 00:13:54,826 iteration 2736 : loss : 0.022641, loss_ce: 0.010638
2021-12-13 00:13:56,314 iteration 2737 : loss : 0.029271, loss_ce: 0.010806
 40%|██████████▊                | 161/400 [1:12:05<1:48:18, 27.19s/it]2021-12-13 00:13:57,736 iteration 2738 : loss : 0.018417, loss_ce: 0.007506
2021-12-13 00:13:59,236 iteration 2739 : loss : 0.029037, loss_ce: 0.011966
2021-12-13 00:14:00,745 iteration 2740 : loss : 0.033114, loss_ce: 0.013020
2021-12-13 00:14:02,158 iteration 2741 : loss : 0.021157, loss_ce: 0.007586
2021-12-13 00:14:03,537 iteration 2742 : loss : 0.026978, loss_ce: 0.009378
2021-12-13 00:14:04,996 iteration 2743 : loss : 0.027514, loss_ce: 0.010052
2021-12-13 00:14:06,559 iteration 2744 : loss : 0.033016, loss_ce: 0.011972
2021-12-13 00:14:07,980 iteration 2745 : loss : 0.035001, loss_ce: 0.014595
2021-12-13 00:14:09,401 iteration 2746 : loss : 0.019208, loss_ce: 0.006418
2021-12-13 00:14:10,953 iteration 2747 : loss : 0.036162, loss_ce: 0.013701
2021-12-13 00:14:12,367 iteration 2748 : loss : 0.024571, loss_ce: 0.009238
2021-12-13 00:14:13,811 iteration 2749 : loss : 0.033128, loss_ce: 0.017486
2021-12-13 00:14:15,234 iteration 2750 : loss : 0.024906, loss_ce: 0.007282
2021-12-13 00:14:16,653 iteration 2751 : loss : 0.018560, loss_ce: 0.004552
2021-12-13 00:14:18,059 iteration 2752 : loss : 0.025539, loss_ce: 0.010737
2021-12-13 00:14:19,478 iteration 2753 : loss : 0.030144, loss_ce: 0.012081
2021-12-13 00:14:20,926 iteration 2754 : loss : 0.031058, loss_ce: 0.010220
 40%|██████████▉                | 162/400 [1:12:30<1:44:47, 26.42s/it]2021-12-13 00:14:22,409 iteration 2755 : loss : 0.026490, loss_ce: 0.010822
2021-12-13 00:14:23,877 iteration 2756 : loss : 0.022960, loss_ce: 0.009891
2021-12-13 00:14:25,301 iteration 2757 : loss : 0.022253, loss_ce: 0.009237
2021-12-13 00:14:26,745 iteration 2758 : loss : 0.030465, loss_ce: 0.011834
2021-12-13 00:14:28,180 iteration 2759 : loss : 0.020595, loss_ce: 0.007059
2021-12-13 00:14:29,667 iteration 2760 : loss : 0.039322, loss_ce: 0.010653
2021-12-13 00:14:31,109 iteration 2761 : loss : 0.025686, loss_ce: 0.009645
2021-12-13 00:14:32,534 iteration 2762 : loss : 0.030478, loss_ce: 0.013709
2021-12-13 00:14:33,955 iteration 2763 : loss : 0.031955, loss_ce: 0.011047
2021-12-13 00:14:35,337 iteration 2764 : loss : 0.026705, loss_ce: 0.012219
2021-12-13 00:14:36,790 iteration 2765 : loss : 0.028747, loss_ce: 0.011170
2021-12-13 00:14:38,291 iteration 2766 : loss : 0.023853, loss_ce: 0.009498
2021-12-13 00:14:39,667 iteration 2767 : loss : 0.022738, loss_ce: 0.005203
2021-12-13 00:14:41,217 iteration 2768 : loss : 0.025780, loss_ce: 0.010899
2021-12-13 00:14:42,623 iteration 2769 : loss : 0.022671, loss_ce: 0.008236
2021-12-13 00:14:44,000 iteration 2770 : loss : 0.021445, loss_ce: 0.010486
2021-12-13 00:14:45,422 iteration 2771 : loss : 0.022886, loss_ce: 0.011746
 41%|███████████                | 163/400 [1:12:54<1:42:04, 25.84s/it]2021-12-13 00:14:46,966 iteration 2772 : loss : 0.032410, loss_ce: 0.010552
2021-12-13 00:14:48,337 iteration 2773 : loss : 0.024249, loss_ce: 0.007162
2021-12-13 00:14:49,754 iteration 2774 : loss : 0.020597, loss_ce: 0.008659
2021-12-13 00:14:51,200 iteration 2775 : loss : 0.022980, loss_ce: 0.009023
2021-12-13 00:14:52,650 iteration 2776 : loss : 0.025242, loss_ce: 0.010534
2021-12-13 00:14:54,128 iteration 2777 : loss : 0.032078, loss_ce: 0.013952
2021-12-13 00:14:55,494 iteration 2778 : loss : 0.019434, loss_ce: 0.008340
2021-12-13 00:14:56,965 iteration 2779 : loss : 0.025956, loss_ce: 0.010337
2021-12-13 00:14:58,478 iteration 2780 : loss : 0.029660, loss_ce: 0.012336
2021-12-13 00:14:59,848 iteration 2781 : loss : 0.024185, loss_ce: 0.010032
2021-12-13 00:15:01,317 iteration 2782 : loss : 0.026976, loss_ce: 0.010984
2021-12-13 00:15:02,822 iteration 2783 : loss : 0.029948, loss_ce: 0.010974
2021-12-13 00:15:04,357 iteration 2784 : loss : 0.035244, loss_ce: 0.016124
2021-12-13 00:15:05,718 iteration 2785 : loss : 0.020862, loss_ce: 0.007329
2021-12-13 00:15:07,179 iteration 2786 : loss : 0.026458, loss_ce: 0.009194
2021-12-13 00:15:08,704 iteration 2787 : loss : 0.030014, loss_ce: 0.007492
2021-12-13 00:15:10,161 iteration 2788 : loss : 0.022322, loss_ce: 0.006692
 41%|███████████                | 164/400 [1:13:19<1:40:19, 25.51s/it]2021-12-13 00:15:11,644 iteration 2789 : loss : 0.019068, loss_ce: 0.009273
2021-12-13 00:15:13,057 iteration 2790 : loss : 0.024068, loss_ce: 0.006626
2021-12-13 00:15:14,521 iteration 2791 : loss : 0.019629, loss_ce: 0.005968
2021-12-13 00:15:16,011 iteration 2792 : loss : 0.048177, loss_ce: 0.011388
2021-12-13 00:15:17,455 iteration 2793 : loss : 0.022108, loss_ce: 0.009722
2021-12-13 00:15:18,913 iteration 2794 : loss : 0.023467, loss_ce: 0.009020
2021-12-13 00:15:20,415 iteration 2795 : loss : 0.024653, loss_ce: 0.009206
2021-12-13 00:15:21,951 iteration 2796 : loss : 0.028681, loss_ce: 0.010322
2021-12-13 00:15:23,435 iteration 2797 : loss : 0.046847, loss_ce: 0.020412
2021-12-13 00:15:24,963 iteration 2798 : loss : 0.033970, loss_ce: 0.009875
2021-12-13 00:15:26,456 iteration 2799 : loss : 0.026346, loss_ce: 0.009438
2021-12-13 00:15:27,923 iteration 2800 : loss : 0.021204, loss_ce: 0.009598
2021-12-13 00:15:29,350 iteration 2801 : loss : 0.027340, loss_ce: 0.011661
2021-12-13 00:15:30,728 iteration 2802 : loss : 0.017568, loss_ce: 0.006570
2021-12-13 00:15:32,263 iteration 2803 : loss : 0.033718, loss_ce: 0.010981
2021-12-13 00:15:33,716 iteration 2804 : loss : 0.030380, loss_ce: 0.011958
2021-12-13 00:15:33,716 Training Data Eval:
2021-12-13 00:15:41,126   Average segmentation loss on training set: 0.0212
2021-12-13 00:15:41,126 Validation Data Eval:
2021-12-13 00:15:43,706   Average segmentation loss on validation set: 0.1130
2021-12-13 00:15:45,135 iteration 2805 : loss : 0.028967, loss_ce: 0.009497
 41%|███████████▏               | 165/400 [1:13:54<1:51:01, 28.35s/it]2021-12-13 00:15:46,657 iteration 2806 : loss : 0.026476, loss_ce: 0.008159
2021-12-13 00:15:48,248 iteration 2807 : loss : 0.031042, loss_ce: 0.012164
2021-12-13 00:15:49,606 iteration 2808 : loss : 0.021064, loss_ce: 0.010997
2021-12-13 00:15:51,052 iteration 2809 : loss : 0.038245, loss_ce: 0.011280
2021-12-13 00:15:52,544 iteration 2810 : loss : 0.025078, loss_ce: 0.008755
2021-12-13 00:15:53,963 iteration 2811 : loss : 0.024095, loss_ce: 0.009684
2021-12-13 00:15:55,415 iteration 2812 : loss : 0.020686, loss_ce: 0.008064
2021-12-13 00:15:56,889 iteration 2813 : loss : 0.025157, loss_ce: 0.006767
2021-12-13 00:15:58,345 iteration 2814 : loss : 0.029402, loss_ce: 0.013588
2021-12-13 00:15:59,766 iteration 2815 : loss : 0.017755, loss_ce: 0.007233
2021-12-13 00:16:01,194 iteration 2816 : loss : 0.020557, loss_ce: 0.008608
2021-12-13 00:16:02,616 iteration 2817 : loss : 0.020918, loss_ce: 0.006843
2021-12-13 00:16:04,138 iteration 2818 : loss : 0.030197, loss_ce: 0.008809
2021-12-13 00:16:05,639 iteration 2819 : loss : 0.023695, loss_ce: 0.010316
2021-12-13 00:16:07,192 iteration 2820 : loss : 0.038487, loss_ce: 0.019273
2021-12-13 00:16:08,628 iteration 2821 : loss : 0.033565, loss_ce: 0.014062
2021-12-13 00:16:10,037 iteration 2822 : loss : 0.028178, loss_ce: 0.008461
 42%|███████████▏               | 166/400 [1:14:19<1:46:31, 27.31s/it]2021-12-13 00:16:11,600 iteration 2823 : loss : 0.035913, loss_ce: 0.013195
2021-12-13 00:16:13,010 iteration 2824 : loss : 0.017358, loss_ce: 0.006369
2021-12-13 00:16:14,493 iteration 2825 : loss : 0.029746, loss_ce: 0.014410
2021-12-13 00:16:15,907 iteration 2826 : loss : 0.023070, loss_ce: 0.010044
2021-12-13 00:16:17,384 iteration 2827 : loss : 0.030112, loss_ce: 0.015045
2021-12-13 00:16:18,845 iteration 2828 : loss : 0.022970, loss_ce: 0.010489
2021-12-13 00:16:20,396 iteration 2829 : loss : 0.026894, loss_ce: 0.009504
2021-12-13 00:16:21,772 iteration 2830 : loss : 0.020845, loss_ce: 0.008679
2021-12-13 00:16:23,213 iteration 2831 : loss : 0.022503, loss_ce: 0.009556
2021-12-13 00:16:24,701 iteration 2832 : loss : 0.023461, loss_ce: 0.007207
2021-12-13 00:16:26,201 iteration 2833 : loss : 0.036584, loss_ce: 0.013728
2021-12-13 00:16:27,636 iteration 2834 : loss : 0.047711, loss_ce: 0.013596
2021-12-13 00:16:29,122 iteration 2835 : loss : 0.040560, loss_ce: 0.011119
2021-12-13 00:16:30,634 iteration 2836 : loss : 0.035628, loss_ce: 0.014188
2021-12-13 00:16:32,098 iteration 2837 : loss : 0.032674, loss_ce: 0.008231
2021-12-13 00:16:33,496 iteration 2838 : loss : 0.021607, loss_ce: 0.006678
2021-12-13 00:16:34,984 iteration 2839 : loss : 0.034821, loss_ce: 0.011605
 42%|███████████▎               | 167/400 [1:14:44<1:43:18, 26.60s/it]2021-12-13 00:16:36,455 iteration 2840 : loss : 0.036079, loss_ce: 0.018047
2021-12-13 00:16:37,921 iteration 2841 : loss : 0.021825, loss_ce: 0.008611
2021-12-13 00:16:39,373 iteration 2842 : loss : 0.038545, loss_ce: 0.015610
2021-12-13 00:16:40,742 iteration 2843 : loss : 0.024142, loss_ce: 0.011746
2021-12-13 00:16:42,104 iteration 2844 : loss : 0.016054, loss_ce: 0.005636
2021-12-13 00:16:43,532 iteration 2845 : loss : 0.023696, loss_ce: 0.009063
2021-12-13 00:16:45,084 iteration 2846 : loss : 0.036723, loss_ce: 0.010786
2021-12-13 00:16:46,574 iteration 2847 : loss : 0.033860, loss_ce: 0.013056
2021-12-13 00:16:48,016 iteration 2848 : loss : 0.038411, loss_ce: 0.012691
2021-12-13 00:16:49,508 iteration 2849 : loss : 0.029000, loss_ce: 0.011786
2021-12-13 00:16:50,974 iteration 2850 : loss : 0.024561, loss_ce: 0.012238
2021-12-13 00:16:52,512 iteration 2851 : loss : 0.024003, loss_ce: 0.009727
2021-12-13 00:16:53,927 iteration 2852 : loss : 0.025646, loss_ce: 0.007254
2021-12-13 00:16:55,401 iteration 2853 : loss : 0.028176, loss_ce: 0.008337
2021-12-13 00:16:56,787 iteration 2854 : loss : 0.023810, loss_ce: 0.006811
2021-12-13 00:16:58,193 iteration 2855 : loss : 0.021520, loss_ce: 0.010446
2021-12-13 00:16:59,558 iteration 2856 : loss : 0.019662, loss_ce: 0.010068
 42%|███████████▎               | 168/400 [1:15:08<1:40:31, 26.00s/it]2021-12-13 00:17:01,062 iteration 2857 : loss : 0.027085, loss_ce: 0.011276
2021-12-13 00:17:02,628 iteration 2858 : loss : 0.026761, loss_ce: 0.007258
2021-12-13 00:17:04,107 iteration 2859 : loss : 0.027837, loss_ce: 0.011226
2021-12-13 00:17:05,589 iteration 2860 : loss : 0.021277, loss_ce: 0.008173
2021-12-13 00:17:07,051 iteration 2861 : loss : 0.025665, loss_ce: 0.006986
2021-12-13 00:17:08,559 iteration 2862 : loss : 0.026673, loss_ce: 0.007503
2021-12-13 00:17:09,988 iteration 2863 : loss : 0.019376, loss_ce: 0.007186
2021-12-13 00:17:11,436 iteration 2864 : loss : 0.024630, loss_ce: 0.009041
2021-12-13 00:17:12,876 iteration 2865 : loss : 0.025459, loss_ce: 0.010051
2021-12-13 00:17:14,303 iteration 2866 : loss : 0.017807, loss_ce: 0.006456
2021-12-13 00:17:15,836 iteration 2867 : loss : 0.039535, loss_ce: 0.013814
2021-12-13 00:17:17,323 iteration 2868 : loss : 0.031927, loss_ce: 0.011429
2021-12-13 00:17:18,825 iteration 2869 : loss : 0.023930, loss_ce: 0.008778
2021-12-13 00:17:20,373 iteration 2870 : loss : 0.026300, loss_ce: 0.010321
2021-12-13 00:17:21,758 iteration 2871 : loss : 0.034430, loss_ce: 0.016518
2021-12-13 00:17:23,169 iteration 2872 : loss : 0.025329, loss_ce: 0.011166
2021-12-13 00:17:24,603 iteration 2873 : loss : 0.023435, loss_ce: 0.009878
 42%|███████████▍               | 169/400 [1:15:33<1:38:59, 25.71s/it]2021-12-13 00:17:26,089 iteration 2874 : loss : 0.020075, loss_ce: 0.007666
2021-12-13 00:17:27,613 iteration 2875 : loss : 0.027421, loss_ce: 0.011699
2021-12-13 00:17:29,043 iteration 2876 : loss : 0.029504, loss_ce: 0.011450
2021-12-13 00:17:30,435 iteration 2877 : loss : 0.026981, loss_ce: 0.008865
2021-12-13 00:17:31,874 iteration 2878 : loss : 0.020178, loss_ce: 0.005807
2021-12-13 00:17:33,246 iteration 2879 : loss : 0.020047, loss_ce: 0.008477
2021-12-13 00:17:34,716 iteration 2880 : loss : 0.026937, loss_ce: 0.014419
2021-12-13 00:17:36,086 iteration 2881 : loss : 0.017962, loss_ce: 0.007620
2021-12-13 00:17:37,494 iteration 2882 : loss : 0.037189, loss_ce: 0.010364
2021-12-13 00:17:38,971 iteration 2883 : loss : 0.032092, loss_ce: 0.009914
2021-12-13 00:17:40,460 iteration 2884 : loss : 0.034991, loss_ce: 0.014348
2021-12-13 00:17:41,918 iteration 2885 : loss : 0.024264, loss_ce: 0.008003
2021-12-13 00:17:43,334 iteration 2886 : loss : 0.024508, loss_ce: 0.008284
2021-12-13 00:17:44,737 iteration 2887 : loss : 0.023605, loss_ce: 0.007726
2021-12-13 00:17:46,218 iteration 2888 : loss : 0.022365, loss_ce: 0.010449
2021-12-13 00:17:47,676 iteration 2889 : loss : 0.023218, loss_ce: 0.009517
2021-12-13 00:17:47,676 Training Data Eval:
2021-12-13 00:17:55,103   Average segmentation loss on training set: 0.0324
2021-12-13 00:17:55,103 Validation Data Eval:
2021-12-13 00:17:57,684   Average segmentation loss on validation set: 0.1045
2021-12-13 00:17:59,112 iteration 2890 : loss : 0.028949, loss_ce: 0.011825
 42%|███████████▍               | 170/400 [1:16:08<1:48:40, 28.35s/it]2021-12-13 00:18:00,593 iteration 2891 : loss : 0.022587, loss_ce: 0.010160
2021-12-13 00:18:02,065 iteration 2892 : loss : 0.026981, loss_ce: 0.010650
2021-12-13 00:18:03,448 iteration 2893 : loss : 0.019082, loss_ce: 0.007679
2021-12-13 00:18:04,873 iteration 2894 : loss : 0.016727, loss_ce: 0.005795
2021-12-13 00:18:06,296 iteration 2895 : loss : 0.026362, loss_ce: 0.010083
2021-12-13 00:18:07,746 iteration 2896 : loss : 0.025587, loss_ce: 0.007963
2021-12-13 00:18:09,298 iteration 2897 : loss : 0.047472, loss_ce: 0.012585
2021-12-13 00:18:10,753 iteration 2898 : loss : 0.029419, loss_ce: 0.009932
2021-12-13 00:18:12,193 iteration 2899 : loss : 0.028926, loss_ce: 0.012575
2021-12-13 00:18:13,752 iteration 2900 : loss : 0.039065, loss_ce: 0.018654
2021-12-13 00:18:15,228 iteration 2901 : loss : 0.017249, loss_ce: 0.006706
2021-12-13 00:18:16,644 iteration 2902 : loss : 0.026691, loss_ce: 0.012281
2021-12-13 00:18:18,089 iteration 2903 : loss : 0.023610, loss_ce: 0.006970
2021-12-13 00:18:19,514 iteration 2904 : loss : 0.022460, loss_ce: 0.009179
2021-12-13 00:18:20,983 iteration 2905 : loss : 0.022456, loss_ce: 0.009257
2021-12-13 00:18:22,376 iteration 2906 : loss : 0.023468, loss_ce: 0.009912
2021-12-13 00:18:23,822 iteration 2907 : loss : 0.020025, loss_ce: 0.008057
 43%|███████████▌               | 171/400 [1:16:33<1:44:01, 27.26s/it]2021-12-13 00:18:25,328 iteration 2908 : loss : 0.026561, loss_ce: 0.008913
2021-12-13 00:18:26,826 iteration 2909 : loss : 0.039582, loss_ce: 0.013190
2021-12-13 00:18:28,310 iteration 2910 : loss : 0.017038, loss_ce: 0.006153
2021-12-13 00:18:29,803 iteration 2911 : loss : 0.025171, loss_ce: 0.009274
2021-12-13 00:18:31,205 iteration 2912 : loss : 0.020238, loss_ce: 0.007480
2021-12-13 00:18:32,657 iteration 2913 : loss : 0.026242, loss_ce: 0.008033
2021-12-13 00:18:34,149 iteration 2914 : loss : 0.034119, loss_ce: 0.013422
2021-12-13 00:18:35,621 iteration 2915 : loss : 0.029987, loss_ce: 0.015976
2021-12-13 00:18:37,074 iteration 2916 : loss : 0.036055, loss_ce: 0.016133
2021-12-13 00:18:38,524 iteration 2917 : loss : 0.032843, loss_ce: 0.013437
2021-12-13 00:18:39,908 iteration 2918 : loss : 0.022123, loss_ce: 0.012256
2021-12-13 00:18:41,369 iteration 2919 : loss : 0.022881, loss_ce: 0.007616
2021-12-13 00:18:42,791 iteration 2920 : loss : 0.020777, loss_ce: 0.007971
2021-12-13 00:18:44,236 iteration 2921 : loss : 0.023227, loss_ce: 0.010570
2021-12-13 00:18:45,676 iteration 2922 : loss : 0.026188, loss_ce: 0.008010
2021-12-13 00:18:47,211 iteration 2923 : loss : 0.026233, loss_ce: 0.007312
2021-12-13 00:18:48,705 iteration 2924 : loss : 0.020475, loss_ce: 0.008106
 43%|███████████▌               | 172/400 [1:16:57<1:40:52, 26.55s/it]2021-12-13 00:18:50,215 iteration 2925 : loss : 0.024332, loss_ce: 0.010452
2021-12-13 00:18:51,614 iteration 2926 : loss : 0.020997, loss_ce: 0.007403
2021-12-13 00:18:53,069 iteration 2927 : loss : 0.016629, loss_ce: 0.005694
2021-12-13 00:18:54,541 iteration 2928 : loss : 0.025443, loss_ce: 0.010352
2021-12-13 00:18:55,937 iteration 2929 : loss : 0.024890, loss_ce: 0.007485
2021-12-13 00:18:57,344 iteration 2930 : loss : 0.019389, loss_ce: 0.009025
2021-12-13 00:18:58,785 iteration 2931 : loss : 0.054378, loss_ce: 0.008934
2021-12-13 00:19:00,305 iteration 2932 : loss : 0.027326, loss_ce: 0.011256
2021-12-13 00:19:01,781 iteration 2933 : loss : 0.034651, loss_ce: 0.016210
2021-12-13 00:19:03,298 iteration 2934 : loss : 0.031341, loss_ce: 0.018511
2021-12-13 00:19:04,730 iteration 2935 : loss : 0.024401, loss_ce: 0.007864
2021-12-13 00:19:06,179 iteration 2936 : loss : 0.028025, loss_ce: 0.011253
2021-12-13 00:19:07,647 iteration 2937 : loss : 0.026721, loss_ce: 0.011761
2021-12-13 00:19:09,120 iteration 2938 : loss : 0.029150, loss_ce: 0.009912
2021-12-13 00:19:10,476 iteration 2939 : loss : 0.024620, loss_ce: 0.007303
2021-12-13 00:19:11,901 iteration 2940 : loss : 0.022962, loss_ce: 0.009762
2021-12-13 00:19:13,334 iteration 2941 : loss : 0.029183, loss_ce: 0.012272
 43%|███████████▋               | 173/400 [1:17:22<1:38:15, 25.97s/it]2021-12-13 00:19:14,911 iteration 2942 : loss : 0.033037, loss_ce: 0.017580
2021-12-13 00:19:16,393 iteration 2943 : loss : 0.025070, loss_ce: 0.009930
2021-12-13 00:19:17,852 iteration 2944 : loss : 0.035244, loss_ce: 0.013557
2021-12-13 00:19:19,301 iteration 2945 : loss : 0.029941, loss_ce: 0.013892
2021-12-13 00:19:20,818 iteration 2946 : loss : 0.021389, loss_ce: 0.008881
2021-12-13 00:19:22,248 iteration 2947 : loss : 0.020404, loss_ce: 0.007701
2021-12-13 00:19:23,729 iteration 2948 : loss : 0.021114, loss_ce: 0.008573
2021-12-13 00:19:25,157 iteration 2949 : loss : 0.025834, loss_ce: 0.009395
2021-12-13 00:19:26,533 iteration 2950 : loss : 0.017436, loss_ce: 0.006301
2021-12-13 00:19:27,974 iteration 2951 : loss : 0.024549, loss_ce: 0.007659
2021-12-13 00:19:29,339 iteration 2952 : loss : 0.052642, loss_ce: 0.010413
2021-12-13 00:19:30,849 iteration 2953 : loss : 0.029755, loss_ce: 0.011367
2021-12-13 00:19:32,302 iteration 2954 : loss : 0.032369, loss_ce: 0.015434
2021-12-13 00:19:33,760 iteration 2955 : loss : 0.049125, loss_ce: 0.011514
2021-12-13 00:19:35,156 iteration 2956 : loss : 0.038542, loss_ce: 0.021553
2021-12-13 00:19:36,547 iteration 2957 : loss : 0.023836, loss_ce: 0.007878
2021-12-13 00:19:37,999 iteration 2958 : loss : 0.033384, loss_ce: 0.013485
 44%|███████████▋               | 174/400 [1:17:47<1:36:20, 25.58s/it]2021-12-13 00:19:39,504 iteration 2959 : loss : 0.040857, loss_ce: 0.022053
2021-12-13 00:19:40,946 iteration 2960 : loss : 0.023388, loss_ce: 0.010246
2021-12-13 00:19:42,433 iteration 2961 : loss : 0.035501, loss_ce: 0.016525
2021-12-13 00:19:43,918 iteration 2962 : loss : 0.024237, loss_ce: 0.010281
2021-12-13 00:19:45,334 iteration 2963 : loss : 0.024581, loss_ce: 0.011444
2021-12-13 00:19:46,743 iteration 2964 : loss : 0.036979, loss_ce: 0.015153
2021-12-13 00:19:48,124 iteration 2965 : loss : 0.034021, loss_ce: 0.012787
2021-12-13 00:19:49,501 iteration 2966 : loss : 0.026829, loss_ce: 0.010228
2021-12-13 00:19:50,962 iteration 2967 : loss : 0.026827, loss_ce: 0.011761
2021-12-13 00:19:52,496 iteration 2968 : loss : 0.037515, loss_ce: 0.009275
2021-12-13 00:19:53,974 iteration 2969 : loss : 0.027576, loss_ce: 0.011346
2021-12-13 00:19:55,391 iteration 2970 : loss : 0.030987, loss_ce: 0.010511
2021-12-13 00:19:56,773 iteration 2971 : loss : 0.029268, loss_ce: 0.012135
2021-12-13 00:19:58,251 iteration 2972 : loss : 0.033673, loss_ce: 0.011542
2021-12-13 00:19:59,660 iteration 2973 : loss : 0.030581, loss_ce: 0.012034
2021-12-13 00:20:01,165 iteration 2974 : loss : 0.018262, loss_ce: 0.005955
2021-12-13 00:20:01,165 Training Data Eval:
2021-12-13 00:20:08,607   Average segmentation loss on training set: 0.0225
2021-12-13 00:20:08,607 Validation Data Eval:
2021-12-13 00:20:11,194   Average segmentation loss on validation set: 0.1569
2021-12-13 00:20:12,686 iteration 2975 : loss : 0.030804, loss_ce: 0.007921
 44%|███████████▊               | 175/400 [1:18:21<1:46:10, 28.31s/it]2021-12-13 00:20:14,271 iteration 2976 : loss : 0.029533, loss_ce: 0.017002
2021-12-13 00:20:15,659 iteration 2977 : loss : 0.023661, loss_ce: 0.008721
2021-12-13 00:20:17,031 iteration 2978 : loss : 0.024473, loss_ce: 0.008558
2021-12-13 00:20:18,519 iteration 2979 : loss : 0.019297, loss_ce: 0.006846
2021-12-13 00:20:20,085 iteration 2980 : loss : 0.035380, loss_ce: 0.014857
2021-12-13 00:20:21,540 iteration 2981 : loss : 0.026419, loss_ce: 0.008255
2021-12-13 00:20:23,066 iteration 2982 : loss : 0.025517, loss_ce: 0.011396
2021-12-13 00:20:24,506 iteration 2983 : loss : 0.024075, loss_ce: 0.010546
2021-12-13 00:20:26,021 iteration 2984 : loss : 0.025030, loss_ce: 0.009569
2021-12-13 00:20:27,494 iteration 2985 : loss : 0.034756, loss_ce: 0.009665
2021-12-13 00:20:29,001 iteration 2986 : loss : 0.025597, loss_ce: 0.009675
2021-12-13 00:20:30,405 iteration 2987 : loss : 0.024773, loss_ce: 0.010981
2021-12-13 00:20:31,832 iteration 2988 : loss : 0.017352, loss_ce: 0.005385
2021-12-13 00:20:33,302 iteration 2989 : loss : 0.020608, loss_ce: 0.005357
2021-12-13 00:20:34,787 iteration 2990 : loss : 0.032292, loss_ce: 0.011742
2021-12-13 00:20:36,327 iteration 2991 : loss : 0.022660, loss_ce: 0.007923
2021-12-13 00:20:37,904 iteration 2992 : loss : 0.034120, loss_ce: 0.014342
 44%|███████████▉               | 176/400 [1:18:47<1:42:13, 27.38s/it]2021-12-13 00:20:39,323 iteration 2993 : loss : 0.019540, loss_ce: 0.005766
2021-12-13 00:20:40,769 iteration 2994 : loss : 0.027884, loss_ce: 0.010305
2021-12-13 00:20:42,305 iteration 2995 : loss : 0.027921, loss_ce: 0.012759
2021-12-13 00:20:43,747 iteration 2996 : loss : 0.024721, loss_ce: 0.009478
2021-12-13 00:20:45,192 iteration 2997 : loss : 0.022178, loss_ce: 0.008599
2021-12-13 00:20:46,631 iteration 2998 : loss : 0.018668, loss_ce: 0.005265
2021-12-13 00:20:48,114 iteration 2999 : loss : 0.023005, loss_ce: 0.008571
2021-12-13 00:20:49,556 iteration 3000 : loss : 0.036486, loss_ce: 0.011792
2021-12-13 00:20:51,052 iteration 3001 : loss : 0.021090, loss_ce: 0.008595
2021-12-13 00:20:52,432 iteration 3002 : loss : 0.023912, loss_ce: 0.010068
2021-12-13 00:20:53,943 iteration 3003 : loss : 0.018456, loss_ce: 0.006880
2021-12-13 00:20:55,318 iteration 3004 : loss : 0.023024, loss_ce: 0.009289
2021-12-13 00:20:56,796 iteration 3005 : loss : 0.035511, loss_ce: 0.012263
2021-12-13 00:20:58,272 iteration 3006 : loss : 0.036900, loss_ce: 0.017543
2021-12-13 00:20:59,695 iteration 3007 : loss : 0.017117, loss_ce: 0.006474
2021-12-13 00:21:01,257 iteration 3008 : loss : 0.026658, loss_ce: 0.010997
2021-12-13 00:21:02,694 iteration 3009 : loss : 0.024020, loss_ce: 0.013656
 44%|███████████▉               | 177/400 [1:19:11<1:38:52, 26.60s/it]2021-12-13 00:21:04,170 iteration 3010 : loss : 0.018721, loss_ce: 0.006963
2021-12-13 00:21:05,608 iteration 3011 : loss : 0.025789, loss_ce: 0.010110
2021-12-13 00:21:07,015 iteration 3012 : loss : 0.018948, loss_ce: 0.005994
2021-12-13 00:21:08,424 iteration 3013 : loss : 0.018183, loss_ce: 0.007864
2021-12-13 00:21:09,943 iteration 3014 : loss : 0.023495, loss_ce: 0.008811
2021-12-13 00:21:11,400 iteration 3015 : loss : 0.022538, loss_ce: 0.009285
2021-12-13 00:21:12,829 iteration 3016 : loss : 0.023602, loss_ce: 0.010941
2021-12-13 00:21:14,268 iteration 3017 : loss : 0.028065, loss_ce: 0.007737
2021-12-13 00:21:15,677 iteration 3018 : loss : 0.017444, loss_ce: 0.004837
2021-12-13 00:21:17,108 iteration 3019 : loss : 0.040666, loss_ce: 0.014479
2021-12-13 00:21:18,449 iteration 3020 : loss : 0.015987, loss_ce: 0.007920
2021-12-13 00:21:19,818 iteration 3021 : loss : 0.020233, loss_ce: 0.007006
2021-12-13 00:21:21,238 iteration 3022 : loss : 0.026490, loss_ce: 0.007524
2021-12-13 00:21:22,667 iteration 3023 : loss : 0.023014, loss_ce: 0.011810
2021-12-13 00:21:24,123 iteration 3024 : loss : 0.032105, loss_ce: 0.012287
2021-12-13 00:21:25,488 iteration 3025 : loss : 0.019646, loss_ce: 0.008187
2021-12-13 00:21:26,971 iteration 3026 : loss : 0.021136, loss_ce: 0.009640
 44%|████████████               | 178/400 [1:19:36<1:35:51, 25.91s/it]2021-12-13 00:21:28,455 iteration 3027 : loss : 0.023642, loss_ce: 0.010801
2021-12-13 00:21:29,895 iteration 3028 : loss : 0.023499, loss_ce: 0.010228
2021-12-13 00:21:31,352 iteration 3029 : loss : 0.019824, loss_ce: 0.008235
2021-12-13 00:21:32,882 iteration 3030 : loss : 0.025549, loss_ce: 0.010446
2021-12-13 00:21:34,229 iteration 3031 : loss : 0.018748, loss_ce: 0.007272
2021-12-13 00:21:35,661 iteration 3032 : loss : 0.020578, loss_ce: 0.006295
2021-12-13 00:21:37,127 iteration 3033 : loss : 0.026478, loss_ce: 0.011953
2021-12-13 00:21:38,557 iteration 3034 : loss : 0.016981, loss_ce: 0.005037
2021-12-13 00:21:40,075 iteration 3035 : loss : 0.026733, loss_ce: 0.008095
2021-12-13 00:21:41,529 iteration 3036 : loss : 0.019938, loss_ce: 0.007889
2021-12-13 00:21:43,020 iteration 3037 : loss : 0.018049, loss_ce: 0.006256
2021-12-13 00:21:44,405 iteration 3038 : loss : 0.020394, loss_ce: 0.004718
2021-12-13 00:21:46,003 iteration 3039 : loss : 0.033106, loss_ce: 0.013707
2021-12-13 00:21:47,375 iteration 3040 : loss : 0.025733, loss_ce: 0.011441
2021-12-13 00:21:48,775 iteration 3041 : loss : 0.026369, loss_ce: 0.009458
2021-12-13 00:21:50,182 iteration 3042 : loss : 0.019146, loss_ce: 0.007896
2021-12-13 00:21:51,734 iteration 3043 : loss : 0.020476, loss_ce: 0.007922
 45%|████████████               | 179/400 [1:20:00<1:34:09, 25.56s/it]2021-12-13 00:21:53,240 iteration 3044 : loss : 0.037270, loss_ce: 0.014481
2021-12-13 00:21:54,676 iteration 3045 : loss : 0.022114, loss_ce: 0.009458
2021-12-13 00:21:56,106 iteration 3046 : loss : 0.023481, loss_ce: 0.008397
2021-12-13 00:21:57,670 iteration 3047 : loss : 0.025108, loss_ce: 0.010412
2021-12-13 00:21:59,163 iteration 3048 : loss : 0.024639, loss_ce: 0.011139
2021-12-13 00:22:00,568 iteration 3049 : loss : 0.027399, loss_ce: 0.011306
2021-12-13 00:22:02,102 iteration 3050 : loss : 0.035209, loss_ce: 0.015472
2021-12-13 00:22:03,584 iteration 3051 : loss : 0.033614, loss_ce: 0.009835
2021-12-13 00:22:05,103 iteration 3052 : loss : 0.025280, loss_ce: 0.010976
2021-12-13 00:22:06,571 iteration 3053 : loss : 0.024403, loss_ce: 0.010956
2021-12-13 00:22:08,032 iteration 3054 : loss : 0.024717, loss_ce: 0.007935
2021-12-13 00:22:09,502 iteration 3055 : loss : 0.026413, loss_ce: 0.010027
2021-12-13 00:22:10,940 iteration 3056 : loss : 0.022126, loss_ce: 0.006515
2021-12-13 00:22:12,333 iteration 3057 : loss : 0.017380, loss_ce: 0.006100
2021-12-13 00:22:13,836 iteration 3058 : loss : 0.036678, loss_ce: 0.011520
2021-12-13 00:22:15,349 iteration 3059 : loss : 0.073870, loss_ce: 0.037116
2021-12-13 00:22:15,349 Training Data Eval:
2021-12-13 00:22:22,768   Average segmentation loss on training set: 0.0406
2021-12-13 00:22:22,768 Validation Data Eval:
2021-12-13 00:22:25,340   Average segmentation loss on validation set: 0.0920
2021-12-13 00:22:26,793 iteration 3060 : loss : 0.022476, loss_ce: 0.008846
 45%|████████████▏              | 180/400 [1:20:36<1:44:10, 28.41s/it]2021-12-13 00:22:28,249 iteration 3061 : loss : 0.029605, loss_ce: 0.011365
2021-12-13 00:22:29,727 iteration 3062 : loss : 0.037299, loss_ce: 0.012736
2021-12-13 00:22:31,152 iteration 3063 : loss : 0.054938, loss_ce: 0.018312
2021-12-13 00:22:32,651 iteration 3064 : loss : 0.030618, loss_ce: 0.016660
2021-12-13 00:22:34,094 iteration 3065 : loss : 0.069974, loss_ce: 0.025476
2021-12-13 00:22:35,524 iteration 3066 : loss : 0.070655, loss_ce: 0.030807
2021-12-13 00:22:36,982 iteration 3067 : loss : 0.037349, loss_ce: 0.018739
2021-12-13 00:22:38,486 iteration 3068 : loss : 0.028522, loss_ce: 0.010408
2021-12-13 00:22:39,991 iteration 3069 : loss : 0.056234, loss_ce: 0.013481
2021-12-13 00:22:41,382 iteration 3070 : loss : 0.031048, loss_ce: 0.011585
2021-12-13 00:22:42,903 iteration 3071 : loss : 0.046394, loss_ce: 0.018141
2021-12-13 00:22:44,365 iteration 3072 : loss : 0.039273, loss_ce: 0.014385
2021-12-13 00:22:45,765 iteration 3073 : loss : 0.045657, loss_ce: 0.017517
2021-12-13 00:22:47,302 iteration 3074 : loss : 0.049760, loss_ce: 0.020449
2021-12-13 00:22:48,792 iteration 3075 : loss : 0.026446, loss_ce: 0.010712
2021-12-13 00:22:50,214 iteration 3076 : loss : 0.038175, loss_ce: 0.017262
2021-12-13 00:22:51,726 iteration 3077 : loss : 0.035584, loss_ce: 0.018382
 45%|████████████▏              | 181/400 [1:21:00<1:39:53, 27.37s/it]2021-12-13 00:22:53,091 iteration 3078 : loss : 0.025377, loss_ce: 0.010686
2021-12-13 00:22:54,566 iteration 3079 : loss : 0.051490, loss_ce: 0.021149
2021-12-13 00:22:55,997 iteration 3080 : loss : 0.031525, loss_ce: 0.013388
2021-12-13 00:22:57,412 iteration 3081 : loss : 0.032858, loss_ce: 0.010893
2021-12-13 00:22:58,860 iteration 3082 : loss : 0.034137, loss_ce: 0.013402
2021-12-13 00:23:00,308 iteration 3083 : loss : 0.030054, loss_ce: 0.013893
2021-12-13 00:23:01,734 iteration 3084 : loss : 0.026416, loss_ce: 0.010321
2021-12-13 00:23:03,181 iteration 3085 : loss : 0.117247, loss_ce: 0.023065
2021-12-13 00:23:04,593 iteration 3086 : loss : 0.030145, loss_ce: 0.011120
2021-12-13 00:23:06,008 iteration 3087 : loss : 0.030554, loss_ce: 0.010454
2021-12-13 00:23:07,420 iteration 3088 : loss : 0.026052, loss_ce: 0.008933
2021-12-13 00:23:08,837 iteration 3089 : loss : 0.036804, loss_ce: 0.014864
2021-12-13 00:23:10,312 iteration 3090 : loss : 0.053979, loss_ce: 0.020426
2021-12-13 00:23:11,710 iteration 3091 : loss : 0.028741, loss_ce: 0.012918
2021-12-13 00:23:13,077 iteration 3092 : loss : 0.033401, loss_ce: 0.016313
2021-12-13 00:23:14,521 iteration 3093 : loss : 0.025637, loss_ce: 0.008305
2021-12-13 00:23:15,934 iteration 3094 : loss : 0.029976, loss_ce: 0.015069
 46%|████████████▎              | 182/400 [1:21:25<1:35:59, 26.42s/it]2021-12-13 00:23:17,466 iteration 3095 : loss : 0.027384, loss_ce: 0.009778
2021-12-13 00:23:18,880 iteration 3096 : loss : 0.025647, loss_ce: 0.010740
2021-12-13 00:23:20,304 iteration 3097 : loss : 0.037691, loss_ce: 0.014023
2021-12-13 00:23:21,705 iteration 3098 : loss : 0.028135, loss_ce: 0.010624
2021-12-13 00:23:23,208 iteration 3099 : loss : 0.041060, loss_ce: 0.012886
2021-12-13 00:23:24,613 iteration 3100 : loss : 0.028011, loss_ce: 0.009338
2021-12-13 00:23:26,063 iteration 3101 : loss : 0.031167, loss_ce: 0.015400
2021-12-13 00:23:27,552 iteration 3102 : loss : 0.031747, loss_ce: 0.015507
2021-12-13 00:23:28,968 iteration 3103 : loss : 0.034299, loss_ce: 0.009606
2021-12-13 00:23:30,401 iteration 3104 : loss : 0.024097, loss_ce: 0.008305
2021-12-13 00:23:31,816 iteration 3105 : loss : 0.026309, loss_ce: 0.009449
2021-12-13 00:23:33,400 iteration 3106 : loss : 0.037116, loss_ce: 0.016486
2021-12-13 00:23:34,837 iteration 3107 : loss : 0.027642, loss_ce: 0.011226
2021-12-13 00:23:36,220 iteration 3108 : loss : 0.022376, loss_ce: 0.008266
2021-12-13 00:23:37,713 iteration 3109 : loss : 0.029856, loss_ce: 0.015792
2021-12-13 00:23:39,202 iteration 3110 : loss : 0.032005, loss_ce: 0.014188
2021-12-13 00:23:40,596 iteration 3111 : loss : 0.032801, loss_ce: 0.011028
 46%|████████████▎              | 183/400 [1:21:49<1:33:38, 25.89s/it]2021-12-13 00:23:42,030 iteration 3112 : loss : 0.021274, loss_ce: 0.008532
2021-12-13 00:23:43,465 iteration 3113 : loss : 0.025761, loss_ce: 0.010917
2021-12-13 00:23:45,020 iteration 3114 : loss : 0.060927, loss_ce: 0.016952
2021-12-13 00:23:46,506 iteration 3115 : loss : 0.027569, loss_ce: 0.011660
2021-12-13 00:23:47,963 iteration 3116 : loss : 0.026963, loss_ce: 0.010737
2021-12-13 00:23:49,399 iteration 3117 : loss : 0.030131, loss_ce: 0.013657
2021-12-13 00:23:50,901 iteration 3118 : loss : 0.026118, loss_ce: 0.009820
2021-12-13 00:23:52,376 iteration 3119 : loss : 0.039176, loss_ce: 0.014160
2021-12-13 00:23:53,841 iteration 3120 : loss : 0.025868, loss_ce: 0.008571
2021-12-13 00:23:55,314 iteration 3121 : loss : 0.026689, loss_ce: 0.008708
2021-12-13 00:23:56,821 iteration 3122 : loss : 0.039485, loss_ce: 0.010037
2021-12-13 00:23:58,262 iteration 3123 : loss : 0.029005, loss_ce: 0.011291
2021-12-13 00:23:59,720 iteration 3124 : loss : 0.024964, loss_ce: 0.009577
2021-12-13 00:24:01,173 iteration 3125 : loss : 0.029702, loss_ce: 0.013245
2021-12-13 00:24:02,555 iteration 3126 : loss : 0.027229, loss_ce: 0.009921
2021-12-13 00:24:04,010 iteration 3127 : loss : 0.038835, loss_ce: 0.014759
2021-12-13 00:24:05,381 iteration 3128 : loss : 0.020518, loss_ce: 0.007459
 46%|████████████▍              | 184/400 [1:22:14<1:32:00, 25.56s/it]2021-12-13 00:24:06,908 iteration 3129 : loss : 0.047157, loss_ce: 0.017528
2021-12-13 00:24:08,391 iteration 3130 : loss : 0.023242, loss_ce: 0.007772
2021-12-13 00:24:09,906 iteration 3131 : loss : 0.046356, loss_ce: 0.019619
2021-12-13 00:24:11,328 iteration 3132 : loss : 0.024111, loss_ce: 0.009388
2021-12-13 00:24:12,717 iteration 3133 : loss : 0.032346, loss_ce: 0.014175
2021-12-13 00:24:14,170 iteration 3134 : loss : 0.020522, loss_ce: 0.006296
2021-12-13 00:24:15,614 iteration 3135 : loss : 0.025909, loss_ce: 0.009341
2021-12-13 00:24:17,111 iteration 3136 : loss : 0.038769, loss_ce: 0.014569
2021-12-13 00:24:18,560 iteration 3137 : loss : 0.046864, loss_ce: 0.022155
2021-12-13 00:24:20,040 iteration 3138 : loss : 0.027563, loss_ce: 0.012271
2021-12-13 00:24:21,553 iteration 3139 : loss : 0.032888, loss_ce: 0.011206
2021-12-13 00:24:23,036 iteration 3140 : loss : 0.035740, loss_ce: 0.015272
2021-12-13 00:24:24,519 iteration 3141 : loss : 0.028931, loss_ce: 0.010663
2021-12-13 00:24:25,959 iteration 3142 : loss : 0.027387, loss_ce: 0.009603
2021-12-13 00:24:27,454 iteration 3143 : loss : 0.027762, loss_ce: 0.012048
2021-12-13 00:24:28,961 iteration 3144 : loss : 0.026438, loss_ce: 0.013363
2021-12-13 00:24:28,961 Training Data Eval:
2021-12-13 00:24:36,333   Average segmentation loss on training set: 0.0191
2021-12-13 00:24:36,333 Validation Data Eval:
2021-12-13 00:24:38,893   Average segmentation loss on validation set: 0.0741
2021-12-13 00:24:45,204 Found new lowest validation loss at iteration 3144! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 00:24:46,493 iteration 3145 : loss : 0.022355, loss_ce: 0.007969
 46%|████████████▍              | 185/400 [1:22:55<1:48:18, 30.23s/it]2021-12-13 00:24:47,812 iteration 3146 : loss : 0.023271, loss_ce: 0.008202
2021-12-13 00:24:49,152 iteration 3147 : loss : 0.026367, loss_ce: 0.011799
2021-12-13 00:24:50,506 iteration 3148 : loss : 0.025890, loss_ce: 0.008166
2021-12-13 00:24:51,846 iteration 3149 : loss : 0.021708, loss_ce: 0.007414
2021-12-13 00:24:53,200 iteration 3150 : loss : 0.025310, loss_ce: 0.010592
2021-12-13 00:24:54,533 iteration 3151 : loss : 0.030103, loss_ce: 0.008058
2021-12-13 00:24:55,879 iteration 3152 : loss : 0.021540, loss_ce: 0.008513
2021-12-13 00:24:57,261 iteration 3153 : loss : 0.020927, loss_ce: 0.007831
2021-12-13 00:24:58,594 iteration 3154 : loss : 0.040534, loss_ce: 0.018208
2021-12-13 00:24:59,945 iteration 3155 : loss : 0.022421, loss_ce: 0.007992
2021-12-13 00:25:01,385 iteration 3156 : loss : 0.038587, loss_ce: 0.015995
2021-12-13 00:25:02,806 iteration 3157 : loss : 0.026466, loss_ce: 0.011198
2021-12-13 00:25:04,225 iteration 3158 : loss : 0.023365, loss_ce: 0.009613
2021-12-13 00:25:05,685 iteration 3159 : loss : 0.021430, loss_ce: 0.008265
2021-12-13 00:25:07,158 iteration 3160 : loss : 0.025130, loss_ce: 0.010260
2021-12-13 00:25:08,588 iteration 3161 : loss : 0.025291, loss_ce: 0.009631
2021-12-13 00:25:10,131 iteration 3162 : loss : 0.028037, loss_ce: 0.011450
 46%|████████████▌              | 186/400 [1:23:19<1:40:45, 28.25s/it]2021-12-13 00:25:11,691 iteration 3163 : loss : 0.022378, loss_ce: 0.010658
2021-12-13 00:25:13,182 iteration 3164 : loss : 0.017437, loss_ce: 0.006420
2021-12-13 00:25:14,617 iteration 3165 : loss : 0.017425, loss_ce: 0.006058
2021-12-13 00:25:16,133 iteration 3166 : loss : 0.023831, loss_ce: 0.007872
2021-12-13 00:25:17,593 iteration 3167 : loss : 0.015273, loss_ce: 0.005836
2021-12-13 00:25:19,165 iteration 3168 : loss : 0.048874, loss_ce: 0.027827
2021-12-13 00:25:20,691 iteration 3169 : loss : 0.028594, loss_ce: 0.014830
2021-12-13 00:25:22,122 iteration 3170 : loss : 0.020870, loss_ce: 0.008962
2021-12-13 00:25:23,523 iteration 3171 : loss : 0.017778, loss_ce: 0.008009
2021-12-13 00:25:25,014 iteration 3172 : loss : 0.025003, loss_ce: 0.010869
2021-12-13 00:25:26,527 iteration 3173 : loss : 0.023619, loss_ce: 0.008615
2021-12-13 00:25:27,978 iteration 3174 : loss : 0.024161, loss_ce: 0.010270
2021-12-13 00:25:29,511 iteration 3175 : loss : 0.038818, loss_ce: 0.010763
2021-12-13 00:25:30,958 iteration 3176 : loss : 0.031809, loss_ce: 0.010999
2021-12-13 00:25:32,461 iteration 3177 : loss : 0.035151, loss_ce: 0.011983
2021-12-13 00:25:33,853 iteration 3178 : loss : 0.022196, loss_ce: 0.007559
2021-12-13 00:25:35,276 iteration 3179 : loss : 0.029307, loss_ce: 0.008233
 47%|████████████▌              | 187/400 [1:23:44<1:36:58, 27.32s/it]2021-12-13 00:25:36,821 iteration 3180 : loss : 0.046958, loss_ce: 0.017098
2021-12-13 00:25:38,248 iteration 3181 : loss : 0.022030, loss_ce: 0.007519
2021-12-13 00:25:39,722 iteration 3182 : loss : 0.024977, loss_ce: 0.008472
2021-12-13 00:25:41,167 iteration 3183 : loss : 0.016631, loss_ce: 0.004036
2021-12-13 00:25:42,628 iteration 3184 : loss : 0.027351, loss_ce: 0.010107
2021-12-13 00:25:44,119 iteration 3185 : loss : 0.023827, loss_ce: 0.008645
2021-12-13 00:25:45,511 iteration 3186 : loss : 0.022276, loss_ce: 0.010823
2021-12-13 00:25:46,989 iteration 3187 : loss : 0.017730, loss_ce: 0.006140
2021-12-13 00:25:48,421 iteration 3188 : loss : 0.018689, loss_ce: 0.007718
2021-12-13 00:25:49,891 iteration 3189 : loss : 0.024363, loss_ce: 0.010463
2021-12-13 00:25:51,336 iteration 3190 : loss : 0.023269, loss_ce: 0.009542
2021-12-13 00:25:52,892 iteration 3191 : loss : 0.037676, loss_ce: 0.008840
2021-12-13 00:25:54,309 iteration 3192 : loss : 0.029549, loss_ce: 0.008740
2021-12-13 00:25:55,817 iteration 3193 : loss : 0.024419, loss_ce: 0.010695
2021-12-13 00:25:57,314 iteration 3194 : loss : 0.025981, loss_ce: 0.007556
2021-12-13 00:25:58,784 iteration 3195 : loss : 0.021613, loss_ce: 0.009174
2021-12-13 00:26:00,240 iteration 3196 : loss : 0.023386, loss_ce: 0.009082
 47%|████████████▋              | 188/400 [1:24:09<1:34:01, 26.61s/it]2021-12-13 00:26:01,681 iteration 3197 : loss : 0.019720, loss_ce: 0.008048
2021-12-13 00:26:03,124 iteration 3198 : loss : 0.024183, loss_ce: 0.008935
2021-12-13 00:26:04,576 iteration 3199 : loss : 0.028225, loss_ce: 0.012913
2021-12-13 00:26:06,127 iteration 3200 : loss : 0.022221, loss_ce: 0.009122
2021-12-13 00:26:07,607 iteration 3201 : loss : 0.021719, loss_ce: 0.006786
2021-12-13 00:26:09,055 iteration 3202 : loss : 0.039387, loss_ce: 0.017301
2021-12-13 00:26:10,603 iteration 3203 : loss : 0.028006, loss_ce: 0.013295
2021-12-13 00:26:12,044 iteration 3204 : loss : 0.020855, loss_ce: 0.007195
2021-12-13 00:26:13,556 iteration 3205 : loss : 0.019511, loss_ce: 0.006507
2021-12-13 00:26:15,026 iteration 3206 : loss : 0.021906, loss_ce: 0.008979
2021-12-13 00:26:16,573 iteration 3207 : loss : 0.036598, loss_ce: 0.015151
2021-12-13 00:26:17,975 iteration 3208 : loss : 0.018085, loss_ce: 0.004953
2021-12-13 00:26:19,388 iteration 3209 : loss : 0.033120, loss_ce: 0.019804
2021-12-13 00:26:20,753 iteration 3210 : loss : 0.017819, loss_ce: 0.008394
2021-12-13 00:26:22,194 iteration 3211 : loss : 0.025963, loss_ce: 0.008293
2021-12-13 00:26:23,628 iteration 3212 : loss : 0.033622, loss_ce: 0.014708
2021-12-13 00:26:25,085 iteration 3213 : loss : 0.032586, loss_ce: 0.008729
 47%|████████████▊              | 189/400 [1:24:34<1:31:43, 26.08s/it]2021-12-13 00:26:26,586 iteration 3214 : loss : 0.020918, loss_ce: 0.009775
2021-12-13 00:26:28,114 iteration 3215 : loss : 0.028909, loss_ce: 0.010480
2021-12-13 00:26:29,614 iteration 3216 : loss : 0.027075, loss_ce: 0.009329
2021-12-13 00:26:31,120 iteration 3217 : loss : 0.040054, loss_ce: 0.007871
2021-12-13 00:26:32,597 iteration 3218 : loss : 0.029380, loss_ce: 0.011393
2021-12-13 00:26:34,037 iteration 3219 : loss : 0.040543, loss_ce: 0.022278
2021-12-13 00:26:35,541 iteration 3220 : loss : 0.026617, loss_ce: 0.010138
2021-12-13 00:26:36,963 iteration 3221 : loss : 0.024363, loss_ce: 0.009832
2021-12-13 00:26:38,426 iteration 3222 : loss : 0.025547, loss_ce: 0.015025
2021-12-13 00:26:39,912 iteration 3223 : loss : 0.022298, loss_ce: 0.006313
2021-12-13 00:26:41,424 iteration 3224 : loss : 0.022564, loss_ce: 0.007281
2021-12-13 00:26:42,867 iteration 3225 : loss : 0.026159, loss_ce: 0.009316
2021-12-13 00:26:44,407 iteration 3226 : loss : 0.024830, loss_ce: 0.009486
2021-12-13 00:26:45,877 iteration 3227 : loss : 0.022843, loss_ce: 0.009693
2021-12-13 00:26:47,272 iteration 3228 : loss : 0.017698, loss_ce: 0.008256
2021-12-13 00:26:48,807 iteration 3229 : loss : 0.024380, loss_ce: 0.010592
2021-12-13 00:26:48,807 Training Data Eval:
2021-12-13 00:26:56,259   Average segmentation loss on training set: 0.0306
2021-12-13 00:26:56,259 Validation Data Eval:
2021-12-13 00:26:58,841   Average segmentation loss on validation set: 0.1104
2021-12-13 00:27:00,411 iteration 3230 : loss : 0.027640, loss_ce: 0.008731
 48%|████████████▊              | 190/400 [1:25:09<1:40:59, 28.85s/it]2021-12-13 00:27:01,893 iteration 3231 : loss : 0.019496, loss_ce: 0.007248
2021-12-13 00:27:03,363 iteration 3232 : loss : 0.021294, loss_ce: 0.009666
2021-12-13 00:27:04,815 iteration 3233 : loss : 0.026903, loss_ce: 0.008654
2021-12-13 00:27:06,220 iteration 3234 : loss : 0.031698, loss_ce: 0.011461
2021-12-13 00:27:07,642 iteration 3235 : loss : 0.016963, loss_ce: 0.004241
2021-12-13 00:27:09,123 iteration 3236 : loss : 0.024241, loss_ce: 0.011363
2021-12-13 00:27:10,624 iteration 3237 : loss : 0.018411, loss_ce: 0.007361
2021-12-13 00:27:12,095 iteration 3238 : loss : 0.020882, loss_ce: 0.005936
2021-12-13 00:27:13,551 iteration 3239 : loss : 0.017242, loss_ce: 0.007052
2021-12-13 00:27:15,033 iteration 3240 : loss : 0.022080, loss_ce: 0.007334
2021-12-13 00:27:16,534 iteration 3241 : loss : 0.028743, loss_ce: 0.011099
2021-12-13 00:27:18,074 iteration 3242 : loss : 0.022601, loss_ce: 0.010772
2021-12-13 00:27:19,488 iteration 3243 : loss : 0.018623, loss_ce: 0.008100
2021-12-13 00:27:20,946 iteration 3244 : loss : 0.027206, loss_ce: 0.007091
2021-12-13 00:27:22,381 iteration 3245 : loss : 0.020934, loss_ce: 0.008459
2021-12-13 00:27:23,892 iteration 3246 : loss : 0.031010, loss_ce: 0.017104
2021-12-13 00:27:25,359 iteration 3247 : loss : 0.023493, loss_ce: 0.010288
 48%|████████████▉              | 191/400 [1:25:34<1:36:25, 27.68s/it]2021-12-13 00:27:27,012 iteration 3248 : loss : 0.024876, loss_ce: 0.010799
2021-12-13 00:27:28,380 iteration 3249 : loss : 0.013947, loss_ce: 0.003973
2021-12-13 00:27:29,859 iteration 3250 : loss : 0.025602, loss_ce: 0.009326
2021-12-13 00:27:31,325 iteration 3251 : loss : 0.027533, loss_ce: 0.005858
2021-12-13 00:27:32,742 iteration 3252 : loss : 0.016404, loss_ce: 0.006364
2021-12-13 00:27:34,236 iteration 3253 : loss : 0.026262, loss_ce: 0.011032
2021-12-13 00:27:35,707 iteration 3254 : loss : 0.023900, loss_ce: 0.007301
2021-12-13 00:27:37,208 iteration 3255 : loss : 0.015618, loss_ce: 0.006120
2021-12-13 00:27:38,604 iteration 3256 : loss : 0.016967, loss_ce: 0.009899
2021-12-13 00:27:40,054 iteration 3257 : loss : 0.020920, loss_ce: 0.005821
2021-12-13 00:27:41,590 iteration 3258 : loss : 0.025573, loss_ce: 0.010286
2021-12-13 00:27:43,045 iteration 3259 : loss : 0.028083, loss_ce: 0.010856
2021-12-13 00:27:44,478 iteration 3260 : loss : 0.019012, loss_ce: 0.007222
2021-12-13 00:27:45,984 iteration 3261 : loss : 0.028076, loss_ce: 0.010737
2021-12-13 00:27:47,416 iteration 3262 : loss : 0.025389, loss_ce: 0.011350
2021-12-13 00:27:48,843 iteration 3263 : loss : 0.028927, loss_ce: 0.008850
2021-12-13 00:27:50,262 iteration 3264 : loss : 0.021463, loss_ce: 0.007228
 48%|████████████▉              | 192/400 [1:25:59<1:33:04, 26.85s/it]2021-12-13 00:27:51,644 iteration 3265 : loss : 0.015180, loss_ce: 0.005663
2021-12-13 00:27:53,126 iteration 3266 : loss : 0.017844, loss_ce: 0.008031
2021-12-13 00:27:54,535 iteration 3267 : loss : 0.023691, loss_ce: 0.009834
2021-12-13 00:27:56,088 iteration 3268 : loss : 0.023957, loss_ce: 0.010649
2021-12-13 00:27:57,477 iteration 3269 : loss : 0.016577, loss_ce: 0.006105
2021-12-13 00:27:58,877 iteration 3270 : loss : 0.017984, loss_ce: 0.007049
2021-12-13 00:28:00,400 iteration 3271 : loss : 0.025055, loss_ce: 0.008125
2021-12-13 00:28:01,835 iteration 3272 : loss : 0.018481, loss_ce: 0.007102
2021-12-13 00:28:03,253 iteration 3273 : loss : 0.024084, loss_ce: 0.010317
2021-12-13 00:28:04,738 iteration 3274 : loss : 0.022078, loss_ce: 0.007420
2021-12-13 00:28:06,147 iteration 3275 : loss : 0.017598, loss_ce: 0.007588
2021-12-13 00:28:07,595 iteration 3276 : loss : 0.019837, loss_ce: 0.007178
2021-12-13 00:28:09,096 iteration 3277 : loss : 0.018300, loss_ce: 0.007065
2021-12-13 00:28:10,537 iteration 3278 : loss : 0.023836, loss_ce: 0.008806
2021-12-13 00:28:12,033 iteration 3279 : loss : 0.043103, loss_ce: 0.021845
2021-12-13 00:28:13,501 iteration 3280 : loss : 0.025097, loss_ce: 0.011159
2021-12-13 00:28:14,959 iteration 3281 : loss : 0.019819, loss_ce: 0.006075
 48%|█████████████              | 193/400 [1:26:24<1:30:24, 26.20s/it]2021-12-13 00:28:16,421 iteration 3282 : loss : 0.021016, loss_ce: 0.008521
2021-12-13 00:28:17,965 iteration 3283 : loss : 0.031994, loss_ce: 0.011984
2021-12-13 00:28:19,373 iteration 3284 : loss : 0.017363, loss_ce: 0.007753
2021-12-13 00:28:20,738 iteration 3285 : loss : 0.015723, loss_ce: 0.005662
2021-12-13 00:28:22,252 iteration 3286 : loss : 0.018501, loss_ce: 0.004505
2021-12-13 00:28:23,750 iteration 3287 : loss : 0.024204, loss_ce: 0.010278
2021-12-13 00:28:25,214 iteration 3288 : loss : 0.022922, loss_ce: 0.008699
2021-12-13 00:28:26,683 iteration 3289 : loss : 0.019103, loss_ce: 0.004821
2021-12-13 00:28:28,089 iteration 3290 : loss : 0.021437, loss_ce: 0.006265
2021-12-13 00:28:29,605 iteration 3291 : loss : 0.021552, loss_ce: 0.007062
2021-12-13 00:28:31,034 iteration 3292 : loss : 0.023117, loss_ce: 0.009943
2021-12-13 00:28:32,419 iteration 3293 : loss : 0.018675, loss_ce: 0.007138
2021-12-13 00:28:33,838 iteration 3294 : loss : 0.019374, loss_ce: 0.007364
2021-12-13 00:28:35,287 iteration 3295 : loss : 0.022721, loss_ce: 0.009755
2021-12-13 00:28:36,752 iteration 3296 : loss : 0.019004, loss_ce: 0.006090
2021-12-13 00:28:38,175 iteration 3297 : loss : 0.029733, loss_ce: 0.011288
2021-12-13 00:28:39,568 iteration 3298 : loss : 0.019322, loss_ce: 0.007482
 48%|█████████████              | 194/400 [1:26:48<1:28:19, 25.73s/it]2021-12-13 00:28:41,028 iteration 3299 : loss : 0.016636, loss_ce: 0.006477
2021-12-13 00:28:42,468 iteration 3300 : loss : 0.036250, loss_ce: 0.011935
2021-12-13 00:28:43,958 iteration 3301 : loss : 0.032561, loss_ce: 0.010105
2021-12-13 00:28:45,332 iteration 3302 : loss : 0.018807, loss_ce: 0.005636
2021-12-13 00:28:46,815 iteration 3303 : loss : 0.023007, loss_ce: 0.007843
2021-12-13 00:28:48,278 iteration 3304 : loss : 0.028524, loss_ce: 0.017670
2021-12-13 00:28:49,767 iteration 3305 : loss : 0.029905, loss_ce: 0.009236
2021-12-13 00:28:51,196 iteration 3306 : loss : 0.017090, loss_ce: 0.006584
2021-12-13 00:28:52,729 iteration 3307 : loss : 0.022001, loss_ce: 0.008483
2021-12-13 00:28:54,248 iteration 3308 : loss : 0.023705, loss_ce: 0.009338
2021-12-13 00:28:55,710 iteration 3309 : loss : 0.015947, loss_ce: 0.006188
2021-12-13 00:28:57,228 iteration 3310 : loss : 0.026762, loss_ce: 0.008407
2021-12-13 00:28:58,668 iteration 3311 : loss : 0.017325, loss_ce: 0.005045
2021-12-13 00:29:00,070 iteration 3312 : loss : 0.016536, loss_ce: 0.007109
2021-12-13 00:29:01,567 iteration 3313 : loss : 0.033125, loss_ce: 0.012891
2021-12-13 00:29:02,916 iteration 3314 : loss : 0.018201, loss_ce: 0.007911
2021-12-13 00:29:02,916 Training Data Eval:
2021-12-13 00:29:10,382   Average segmentation loss on training set: 0.0206
2021-12-13 00:29:10,383 Validation Data Eval:
2021-12-13 00:29:12,957   Average segmentation loss on validation set: 0.0817
2021-12-13 00:29:14,385 iteration 3315 : loss : 0.022144, loss_ce: 0.008462
 49%|█████████████▏             | 195/400 [1:27:23<1:37:12, 28.45s/it]2021-12-13 00:29:15,877 iteration 3316 : loss : 0.019234, loss_ce: 0.004581
2021-12-13 00:29:17,354 iteration 3317 : loss : 0.028016, loss_ce: 0.011423
2021-12-13 00:29:18,811 iteration 3318 : loss : 0.023179, loss_ce: 0.009380
2021-12-13 00:29:20,203 iteration 3319 : loss : 0.019312, loss_ce: 0.007386
2021-12-13 00:29:21,734 iteration 3320 : loss : 0.029116, loss_ce: 0.010122
2021-12-13 00:29:23,114 iteration 3321 : loss : 0.016884, loss_ce: 0.008347
2021-12-13 00:29:24,476 iteration 3322 : loss : 0.018895, loss_ce: 0.005892
2021-12-13 00:29:25,943 iteration 3323 : loss : 0.033616, loss_ce: 0.015950
2021-12-13 00:29:27,400 iteration 3324 : loss : 0.026668, loss_ce: 0.008389
2021-12-13 00:29:28,901 iteration 3325 : loss : 0.024298, loss_ce: 0.008361
2021-12-13 00:29:30,364 iteration 3326 : loss : 0.015842, loss_ce: 0.005723
2021-12-13 00:29:31,950 iteration 3327 : loss : 0.043182, loss_ce: 0.014052
2021-12-13 00:29:33,352 iteration 3328 : loss : 0.020743, loss_ce: 0.009851
2021-12-13 00:29:34,763 iteration 3329 : loss : 0.023771, loss_ce: 0.009245
2021-12-13 00:29:36,225 iteration 3330 : loss : 0.021676, loss_ce: 0.009737
2021-12-13 00:29:37,599 iteration 3331 : loss : 0.019626, loss_ce: 0.007379
2021-12-13 00:29:38,969 iteration 3332 : loss : 0.016833, loss_ce: 0.005679
 49%|█████████████▏             | 196/400 [1:27:48<1:32:47, 27.29s/it]2021-12-13 00:29:40,463 iteration 3333 : loss : 0.017362, loss_ce: 0.006517
2021-12-13 00:29:41,930 iteration 3334 : loss : 0.023068, loss_ce: 0.010636
2021-12-13 00:29:43,440 iteration 3335 : loss : 0.025277, loss_ce: 0.009784
2021-12-13 00:29:44,849 iteration 3336 : loss : 0.018264, loss_ce: 0.006973
2021-12-13 00:29:46,249 iteration 3337 : loss : 0.022941, loss_ce: 0.008863
2021-12-13 00:29:47,735 iteration 3338 : loss : 0.025074, loss_ce: 0.008851
2021-12-13 00:29:49,237 iteration 3339 : loss : 0.033001, loss_ce: 0.009035
2021-12-13 00:29:50,700 iteration 3340 : loss : 0.024077, loss_ce: 0.008505
2021-12-13 00:29:52,116 iteration 3341 : loss : 0.021106, loss_ce: 0.008569
2021-12-13 00:29:53,534 iteration 3342 : loss : 0.029523, loss_ce: 0.016055
2021-12-13 00:29:54,976 iteration 3343 : loss : 0.024225, loss_ce: 0.009446
2021-12-13 00:29:56,483 iteration 3344 : loss : 0.027170, loss_ce: 0.008124
2021-12-13 00:29:57,987 iteration 3345 : loss : 0.023446, loss_ce: 0.010615
2021-12-13 00:29:59,443 iteration 3346 : loss : 0.030256, loss_ce: 0.009116
2021-12-13 00:30:00,883 iteration 3347 : loss : 0.030169, loss_ce: 0.011367
2021-12-13 00:30:02,405 iteration 3348 : loss : 0.019448, loss_ce: 0.007474
2021-12-13 00:30:03,800 iteration 3349 : loss : 0.023479, loss_ce: 0.006114
 49%|█████████████▎             | 197/400 [1:28:13<1:29:50, 26.55s/it]2021-12-13 00:30:05,227 iteration 3350 : loss : 0.017909, loss_ce: 0.008480
2021-12-13 00:30:06,695 iteration 3351 : loss : 0.019091, loss_ce: 0.007395
2021-12-13 00:30:08,091 iteration 3352 : loss : 0.028547, loss_ce: 0.008836
2021-12-13 00:30:09,535 iteration 3353 : loss : 0.017320, loss_ce: 0.005416
2021-12-13 00:30:10,955 iteration 3354 : loss : 0.018468, loss_ce: 0.005361
2021-12-13 00:30:12,419 iteration 3355 : loss : 0.019562, loss_ce: 0.008600
2021-12-13 00:30:13,833 iteration 3356 : loss : 0.026089, loss_ce: 0.010562
2021-12-13 00:30:15,249 iteration 3357 : loss : 0.017371, loss_ce: 0.007302
2021-12-13 00:30:16,688 iteration 3358 : loss : 0.023022, loss_ce: 0.007930
2021-12-13 00:30:18,115 iteration 3359 : loss : 0.022256, loss_ce: 0.009811
2021-12-13 00:30:19,605 iteration 3360 : loss : 0.020509, loss_ce: 0.006740
2021-12-13 00:30:21,058 iteration 3361 : loss : 0.019383, loss_ce: 0.007476
2021-12-13 00:30:22,467 iteration 3362 : loss : 0.022697, loss_ce: 0.007629
2021-12-13 00:30:23,835 iteration 3363 : loss : 0.022328, loss_ce: 0.007257
2021-12-13 00:30:25,346 iteration 3364 : loss : 0.027023, loss_ce: 0.011518
2021-12-13 00:30:26,780 iteration 3365 : loss : 0.035909, loss_ce: 0.015908
2021-12-13 00:30:28,209 iteration 3366 : loss : 0.021692, loss_ce: 0.008195
 50%|█████████████▎             | 198/400 [1:28:37<1:27:13, 25.91s/it]2021-12-13 00:30:29,786 iteration 3367 : loss : 0.023530, loss_ce: 0.009713
2021-12-13 00:30:31,218 iteration 3368 : loss : 0.022274, loss_ce: 0.010602
2021-12-13 00:30:32,676 iteration 3369 : loss : 0.025680, loss_ce: 0.010881
2021-12-13 00:30:34,084 iteration 3370 : loss : 0.023618, loss_ce: 0.005902
2021-12-13 00:30:35,526 iteration 3371 : loss : 0.018947, loss_ce: 0.007328
2021-12-13 00:30:37,025 iteration 3372 : loss : 0.029725, loss_ce: 0.009367
2021-12-13 00:30:38,476 iteration 3373 : loss : 0.028268, loss_ce: 0.010547
2021-12-13 00:30:40,002 iteration 3374 : loss : 0.021492, loss_ce: 0.008953
2021-12-13 00:30:41,562 iteration 3375 : loss : 0.042849, loss_ce: 0.012762
2021-12-13 00:30:42,937 iteration 3376 : loss : 0.013861, loss_ce: 0.004688
2021-12-13 00:30:44,433 iteration 3377 : loss : 0.022162, loss_ce: 0.008733
2021-12-13 00:30:45,842 iteration 3378 : loss : 0.016736, loss_ce: 0.004712
2021-12-13 00:30:47,322 iteration 3379 : loss : 0.018687, loss_ce: 0.006838
2021-12-13 00:30:48,729 iteration 3380 : loss : 0.017256, loss_ce: 0.005343
2021-12-13 00:30:50,194 iteration 3381 : loss : 0.022036, loss_ce: 0.011139
2021-12-13 00:30:51,681 iteration 3382 : loss : 0.023351, loss_ce: 0.007173
2021-12-13 00:30:53,122 iteration 3383 : loss : 0.020901, loss_ce: 0.009127
 50%|█████████████▍             | 199/400 [1:29:02<1:25:47, 25.61s/it]2021-12-13 00:30:54,608 iteration 3384 : loss : 0.028126, loss_ce: 0.013656
2021-12-13 00:30:56,015 iteration 3385 : loss : 0.022828, loss_ce: 0.008326
2021-12-13 00:30:57,416 iteration 3386 : loss : 0.018942, loss_ce: 0.007060
2021-12-13 00:30:58,818 iteration 3387 : loss : 0.024105, loss_ce: 0.007579
2021-12-13 00:31:00,316 iteration 3388 : loss : 0.021763, loss_ce: 0.007344
2021-12-13 00:31:01,717 iteration 3389 : loss : 0.021457, loss_ce: 0.006488
2021-12-13 00:31:03,175 iteration 3390 : loss : 0.027618, loss_ce: 0.014559
2021-12-13 00:31:04,709 iteration 3391 : loss : 0.030595, loss_ce: 0.019295
2021-12-13 00:31:06,196 iteration 3392 : loss : 0.022641, loss_ce: 0.008270
2021-12-13 00:31:07,596 iteration 3393 : loss : 0.018327, loss_ce: 0.007347
2021-12-13 00:31:09,041 iteration 3394 : loss : 0.020714, loss_ce: 0.007015
2021-12-13 00:31:10,497 iteration 3395 : loss : 0.018531, loss_ce: 0.006851
2021-12-13 00:31:11,948 iteration 3396 : loss : 0.024070, loss_ce: 0.008388
2021-12-13 00:31:13,332 iteration 3397 : loss : 0.021633, loss_ce: 0.008206
2021-12-13 00:31:14,899 iteration 3398 : loss : 0.024654, loss_ce: 0.009165
2021-12-13 00:31:16,350 iteration 3399 : loss : 0.022881, loss_ce: 0.010157
2021-12-13 00:31:16,351 Training Data Eval:
2021-12-13 00:31:23,801   Average segmentation loss on training set: 0.0159
2021-12-13 00:31:23,802 Validation Data Eval:
2021-12-13 00:31:26,399   Average segmentation loss on validation set: 0.0893
2021-12-13 00:31:27,880 iteration 3400 : loss : 0.024907, loss_ce: 0.007329
 50%|█████████████▌             | 200/400 [1:29:37<1:34:30, 28.35s/it]2021-12-13 00:31:29,413 iteration 3401 : loss : 0.029593, loss_ce: 0.012093
2021-12-13 00:31:30,896 iteration 3402 : loss : 0.017571, loss_ce: 0.006631
2021-12-13 00:31:32,437 iteration 3403 : loss : 0.028134, loss_ce: 0.009777
2021-12-13 00:31:33,852 iteration 3404 : loss : 0.015673, loss_ce: 0.004935
2021-12-13 00:31:35,304 iteration 3405 : loss : 0.023433, loss_ce: 0.005334
2021-12-13 00:31:36,698 iteration 3406 : loss : 0.021360, loss_ce: 0.009766
2021-12-13 00:31:38,116 iteration 3407 : loss : 0.018823, loss_ce: 0.006616
2021-12-13 00:31:39,578 iteration 3408 : loss : 0.019293, loss_ce: 0.006463
2021-12-13 00:31:41,016 iteration 3409 : loss : 0.018213, loss_ce: 0.003391
2021-12-13 00:31:42,467 iteration 3410 : loss : 0.019228, loss_ce: 0.007613
2021-12-13 00:31:43,963 iteration 3411 : loss : 0.028430, loss_ce: 0.008506
2021-12-13 00:31:45,465 iteration 3412 : loss : 0.019507, loss_ce: 0.008214
2021-12-13 00:31:46,990 iteration 3413 : loss : 0.021573, loss_ce: 0.010233
2021-12-13 00:31:48,486 iteration 3414 : loss : 0.042658, loss_ce: 0.010994
2021-12-13 00:31:49,853 iteration 3415 : loss : 0.017590, loss_ce: 0.007110
2021-12-13 00:31:51,345 iteration 3416 : loss : 0.019737, loss_ce: 0.007859
2021-12-13 00:31:52,771 iteration 3417 : loss : 0.016443, loss_ce: 0.007100
 50%|█████████████▌             | 201/400 [1:30:02<1:30:36, 27.32s/it]2021-12-13 00:31:54,342 iteration 3418 : loss : 0.048027, loss_ce: 0.013743
2021-12-13 00:31:55,799 iteration 3419 : loss : 0.024638, loss_ce: 0.011708
2021-12-13 00:31:57,195 iteration 3420 : loss : 0.019547, loss_ce: 0.010142
2021-12-13 00:31:58,665 iteration 3421 : loss : 0.025675, loss_ce: 0.006832
2021-12-13 00:32:00,127 iteration 3422 : loss : 0.021573, loss_ce: 0.007000
2021-12-13 00:32:01,644 iteration 3423 : loss : 0.020665, loss_ce: 0.009802
2021-12-13 00:32:03,026 iteration 3424 : loss : 0.017553, loss_ce: 0.005095
2021-12-13 00:32:04,486 iteration 3425 : loss : 0.019187, loss_ce: 0.009161
2021-12-13 00:32:05,913 iteration 3426 : loss : 0.021969, loss_ce: 0.005667
2021-12-13 00:32:07,466 iteration 3427 : loss : 0.029674, loss_ce: 0.009681
2021-12-13 00:32:08,931 iteration 3428 : loss : 0.019509, loss_ce: 0.007431
2021-12-13 00:32:10,400 iteration 3429 : loss : 0.026147, loss_ce: 0.011092
2021-12-13 00:32:11,867 iteration 3430 : loss : 0.020426, loss_ce: 0.007200
2021-12-13 00:32:13,386 iteration 3431 : loss : 0.043051, loss_ce: 0.014105
2021-12-13 00:32:14,817 iteration 3432 : loss : 0.019964, loss_ce: 0.005564
2021-12-13 00:32:16,283 iteration 3433 : loss : 0.025977, loss_ce: 0.007572
2021-12-13 00:32:17,719 iteration 3434 : loss : 0.021981, loss_ce: 0.006140
 50%|█████████████▋             | 202/400 [1:30:26<1:27:48, 26.61s/it]2021-12-13 00:32:19,163 iteration 3435 : loss : 0.031414, loss_ce: 0.016222
2021-12-13 00:32:20,601 iteration 3436 : loss : 0.024301, loss_ce: 0.009554
2021-12-13 00:32:22,017 iteration 3437 : loss : 0.017548, loss_ce: 0.005650
2021-12-13 00:32:23,464 iteration 3438 : loss : 0.019671, loss_ce: 0.009214
2021-12-13 00:32:24,990 iteration 3439 : loss : 0.023192, loss_ce: 0.009661
2021-12-13 00:32:26,507 iteration 3440 : loss : 0.031348, loss_ce: 0.010096
2021-12-13 00:32:27,845 iteration 3441 : loss : 0.016195, loss_ce: 0.007859
2021-12-13 00:32:29,255 iteration 3442 : loss : 0.016171, loss_ce: 0.005319
2021-12-13 00:32:30,745 iteration 3443 : loss : 0.021481, loss_ce: 0.007442
2021-12-13 00:32:32,192 iteration 3444 : loss : 0.017384, loss_ce: 0.005968
2021-12-13 00:32:33,681 iteration 3445 : loss : 0.018812, loss_ce: 0.006120
2021-12-13 00:32:35,121 iteration 3446 : loss : 0.024853, loss_ce: 0.008087
2021-12-13 00:32:36,575 iteration 3447 : loss : 0.019079, loss_ce: 0.009402
2021-12-13 00:32:37,952 iteration 3448 : loss : 0.018119, loss_ce: 0.006136
2021-12-13 00:32:39,422 iteration 3449 : loss : 0.027771, loss_ce: 0.010309
2021-12-13 00:32:40,920 iteration 3450 : loss : 0.017339, loss_ce: 0.006566
2021-12-13 00:32:42,307 iteration 3451 : loss : 0.018677, loss_ce: 0.007843
 51%|█████████████▋             | 203/400 [1:30:51<1:25:22, 26.00s/it]2021-12-13 00:32:43,773 iteration 3452 : loss : 0.019699, loss_ce: 0.006579
2021-12-13 00:32:45,261 iteration 3453 : loss : 0.019686, loss_ce: 0.006991
2021-12-13 00:32:46,768 iteration 3454 : loss : 0.033059, loss_ce: 0.010727
2021-12-13 00:32:48,248 iteration 3455 : loss : 0.020134, loss_ce: 0.008833
2021-12-13 00:32:49,717 iteration 3456 : loss : 0.020902, loss_ce: 0.006902
2021-12-13 00:32:51,186 iteration 3457 : loss : 0.029932, loss_ce: 0.014038
2021-12-13 00:32:52,664 iteration 3458 : loss : 0.015828, loss_ce: 0.008162
2021-12-13 00:32:54,201 iteration 3459 : loss : 0.023287, loss_ce: 0.011947
2021-12-13 00:32:55,696 iteration 3460 : loss : 0.023299, loss_ce: 0.009484
2021-12-13 00:32:57,154 iteration 3461 : loss : 0.024323, loss_ce: 0.009770
2021-12-13 00:32:58,559 iteration 3462 : loss : 0.016795, loss_ce: 0.005586
2021-12-13 00:32:59,939 iteration 3463 : loss : 0.015095, loss_ce: 0.004521
2021-12-13 00:33:01,387 iteration 3464 : loss : 0.021268, loss_ce: 0.007655
2021-12-13 00:33:02,792 iteration 3465 : loss : 0.022214, loss_ce: 0.006697
2021-12-13 00:33:04,260 iteration 3466 : loss : 0.016948, loss_ce: 0.006742
2021-12-13 00:33:05,793 iteration 3467 : loss : 0.034324, loss_ce: 0.015438
2021-12-13 00:33:07,353 iteration 3468 : loss : 0.031135, loss_ce: 0.010544
 51%|█████████████▊             | 204/400 [1:31:16<1:23:59, 25.71s/it]2021-12-13 00:33:08,752 iteration 3469 : loss : 0.017262, loss_ce: 0.006950
2021-12-13 00:33:10,332 iteration 3470 : loss : 0.019144, loss_ce: 0.006135
2021-12-13 00:33:11,820 iteration 3471 : loss : 0.021755, loss_ce: 0.008063
2021-12-13 00:33:13,321 iteration 3472 : loss : 0.024592, loss_ce: 0.009488
2021-12-13 00:33:14,832 iteration 3473 : loss : 0.019432, loss_ce: 0.008620
2021-12-13 00:33:16,261 iteration 3474 : loss : 0.020639, loss_ce: 0.007769
2021-12-13 00:33:17,792 iteration 3475 : loss : 0.033850, loss_ce: 0.010483
2021-12-13 00:33:19,228 iteration 3476 : loss : 0.022634, loss_ce: 0.007693
2021-12-13 00:33:20,719 iteration 3477 : loss : 0.028114, loss_ce: 0.008232
2021-12-13 00:33:22,198 iteration 3478 : loss : 0.024112, loss_ce: 0.008095
2021-12-13 00:33:23,651 iteration 3479 : loss : 0.019759, loss_ce: 0.008733
2021-12-13 00:33:25,069 iteration 3480 : loss : 0.019011, loss_ce: 0.006659
2021-12-13 00:33:26,522 iteration 3481 : loss : 0.021103, loss_ce: 0.012449
2021-12-13 00:33:27,906 iteration 3482 : loss : 0.021574, loss_ce: 0.006820
2021-12-13 00:33:29,422 iteration 3483 : loss : 0.021857, loss_ce: 0.008266
2021-12-13 00:33:30,870 iteration 3484 : loss : 0.021026, loss_ce: 0.005526
2021-12-13 00:33:30,870 Training Data Eval:
2021-12-13 00:33:38,309   Average segmentation loss on training set: 0.0186
2021-12-13 00:33:38,310 Validation Data Eval:
2021-12-13 00:33:40,885   Average segmentation loss on validation set: 0.0889
2021-12-13 00:33:42,349 iteration 3485 : loss : 0.016610, loss_ce: 0.006088
 51%|█████████████▊             | 205/400 [1:31:51<1:32:37, 28.50s/it]2021-12-13 00:33:43,812 iteration 3486 : loss : 0.021032, loss_ce: 0.006751
2021-12-13 00:33:45,267 iteration 3487 : loss : 0.018968, loss_ce: 0.006832
2021-12-13 00:33:46,753 iteration 3488 : loss : 0.023175, loss_ce: 0.012874
2021-12-13 00:33:48,165 iteration 3489 : loss : 0.021861, loss_ce: 0.007047
2021-12-13 00:33:49,683 iteration 3490 : loss : 0.025317, loss_ce: 0.012120
2021-12-13 00:33:51,169 iteration 3491 : loss : 0.023015, loss_ce: 0.010552
2021-12-13 00:33:52,542 iteration 3492 : loss : 0.019104, loss_ce: 0.005233
2021-12-13 00:33:54,072 iteration 3493 : loss : 0.021649, loss_ce: 0.005547
2021-12-13 00:33:55,621 iteration 3494 : loss : 0.018907, loss_ce: 0.010007
2021-12-13 00:33:56,974 iteration 3495 : loss : 0.016485, loss_ce: 0.006932
2021-12-13 00:33:58,456 iteration 3496 : loss : 0.029835, loss_ce: 0.007654
2021-12-13 00:33:59,977 iteration 3497 : loss : 0.017266, loss_ce: 0.008238
2021-12-13 00:34:01,434 iteration 3498 : loss : 0.021588, loss_ce: 0.008551
2021-12-13 00:34:02,938 iteration 3499 : loss : 0.026372, loss_ce: 0.006069
2021-12-13 00:34:04,374 iteration 3500 : loss : 0.022430, loss_ce: 0.006686
2021-12-13 00:34:05,843 iteration 3501 : loss : 0.022934, loss_ce: 0.008467
2021-12-13 00:34:07,300 iteration 3502 : loss : 0.020370, loss_ce: 0.007340
 52%|█████████████▉             | 206/400 [1:32:16<1:28:42, 27.43s/it]2021-12-13 00:34:08,724 iteration 3503 : loss : 0.018932, loss_ce: 0.008678
2021-12-13 00:34:10,191 iteration 3504 : loss : 0.016403, loss_ce: 0.005092
2021-12-13 00:34:11,649 iteration 3505 : loss : 0.021780, loss_ce: 0.010608
2021-12-13 00:34:13,188 iteration 3506 : loss : 0.024671, loss_ce: 0.008057
2021-12-13 00:34:14,619 iteration 3507 : loss : 0.019484, loss_ce: 0.008434
2021-12-13 00:34:16,011 iteration 3508 : loss : 0.019057, loss_ce: 0.005682
2021-12-13 00:34:17,456 iteration 3509 : loss : 0.020792, loss_ce: 0.009320
2021-12-13 00:34:18,999 iteration 3510 : loss : 0.017842, loss_ce: 0.006711
2021-12-13 00:34:20,416 iteration 3511 : loss : 0.019759, loss_ce: 0.008709
2021-12-13 00:34:21,879 iteration 3512 : loss : 0.022990, loss_ce: 0.008939
2021-12-13 00:34:23,268 iteration 3513 : loss : 0.019894, loss_ce: 0.006113
2021-12-13 00:34:24,651 iteration 3514 : loss : 0.013109, loss_ce: 0.005449
2021-12-13 00:34:26,097 iteration 3515 : loss : 0.017809, loss_ce: 0.006196
2021-12-13 00:34:27,578 iteration 3516 : loss : 0.021958, loss_ce: 0.007667
2021-12-13 00:34:29,018 iteration 3517 : loss : 0.029658, loss_ce: 0.012444
2021-12-13 00:34:30,409 iteration 3518 : loss : 0.016275, loss_ce: 0.008184
2021-12-13 00:34:31,821 iteration 3519 : loss : 0.026514, loss_ce: 0.009968
 52%|█████████████▉             | 207/400 [1:32:41<1:25:26, 26.56s/it]2021-12-13 00:34:33,300 iteration 3520 : loss : 0.018385, loss_ce: 0.006027
2021-12-13 00:34:34,779 iteration 3521 : loss : 0.019177, loss_ce: 0.007058
2021-12-13 00:34:36,246 iteration 3522 : loss : 0.020795, loss_ce: 0.008309
2021-12-13 00:34:37,783 iteration 3523 : loss : 0.034040, loss_ce: 0.012223
2021-12-13 00:34:39,215 iteration 3524 : loss : 0.024664, loss_ce: 0.006672
2021-12-13 00:34:40,686 iteration 3525 : loss : 0.024283, loss_ce: 0.010398
2021-12-13 00:34:42,147 iteration 3526 : loss : 0.024572, loss_ce: 0.011604
2021-12-13 00:34:43,613 iteration 3527 : loss : 0.018109, loss_ce: 0.006614
2021-12-13 00:34:45,005 iteration 3528 : loss : 0.016870, loss_ce: 0.007762
2021-12-13 00:34:46,463 iteration 3529 : loss : 0.022718, loss_ce: 0.008459
2021-12-13 00:34:47,906 iteration 3530 : loss : 0.021695, loss_ce: 0.006845
2021-12-13 00:34:49,381 iteration 3531 : loss : 0.018182, loss_ce: 0.006784
2021-12-13 00:34:50,798 iteration 3532 : loss : 0.015284, loss_ce: 0.005181
2021-12-13 00:34:52,195 iteration 3533 : loss : 0.020038, loss_ce: 0.007646
2021-12-13 00:34:53,608 iteration 3534 : loss : 0.020849, loss_ce: 0.010905
2021-12-13 00:34:55,001 iteration 3535 : loss : 0.020804, loss_ce: 0.006604
2021-12-13 00:34:56,409 iteration 3536 : loss : 0.016028, loss_ce: 0.005463
 52%|██████████████             | 208/400 [1:33:05<1:23:06, 25.97s/it]2021-12-13 00:34:57,868 iteration 3537 : loss : 0.019852, loss_ce: 0.007536
2021-12-13 00:34:59,317 iteration 3538 : loss : 0.020988, loss_ce: 0.006323
2021-12-13 00:35:00,798 iteration 3539 : loss : 0.020803, loss_ce: 0.009690
2021-12-13 00:35:02,203 iteration 3540 : loss : 0.019690, loss_ce: 0.004734
2021-12-13 00:35:03,719 iteration 3541 : loss : 0.027256, loss_ce: 0.009485
2021-12-13 00:35:05,142 iteration 3542 : loss : 0.016727, loss_ce: 0.004557
2021-12-13 00:35:06,602 iteration 3543 : loss : 0.020144, loss_ce: 0.009063
2021-12-13 00:35:08,088 iteration 3544 : loss : 0.023717, loss_ce: 0.008837
2021-12-13 00:35:09,504 iteration 3545 : loss : 0.026706, loss_ce: 0.011507
2021-12-13 00:35:10,878 iteration 3546 : loss : 0.016839, loss_ce: 0.007996
2021-12-13 00:35:12,366 iteration 3547 : loss : 0.029381, loss_ce: 0.012411
2021-12-13 00:35:13,852 iteration 3548 : loss : 0.019580, loss_ce: 0.006265
2021-12-13 00:35:15,302 iteration 3549 : loss : 0.019676, loss_ce: 0.008068
2021-12-13 00:35:16,701 iteration 3550 : loss : 0.017536, loss_ce: 0.005504
2021-12-13 00:35:18,210 iteration 3551 : loss : 0.026168, loss_ce: 0.007456
2021-12-13 00:35:19,719 iteration 3552 : loss : 0.034272, loss_ce: 0.014771
2021-12-13 00:35:21,217 iteration 3553 : loss : 0.029354, loss_ce: 0.010131
 52%|██████████████             | 209/400 [1:33:30<1:21:32, 25.62s/it]2021-12-13 00:35:22,673 iteration 3554 : loss : 0.023228, loss_ce: 0.009099
2021-12-13 00:35:24,145 iteration 3555 : loss : 0.023805, loss_ce: 0.010284
2021-12-13 00:35:25,574 iteration 3556 : loss : 0.038793, loss_ce: 0.012739
2021-12-13 00:35:26,995 iteration 3557 : loss : 0.029363, loss_ce: 0.013371
2021-12-13 00:35:28,384 iteration 3558 : loss : 0.020155, loss_ce: 0.006306
2021-12-13 00:35:29,891 iteration 3559 : loss : 0.027539, loss_ce: 0.009798
2021-12-13 00:35:31,317 iteration 3560 : loss : 0.024011, loss_ce: 0.006983
2021-12-13 00:35:32,787 iteration 3561 : loss : 0.018196, loss_ce: 0.008015
2021-12-13 00:35:34,222 iteration 3562 : loss : 0.021917, loss_ce: 0.007558
2021-12-13 00:35:35,673 iteration 3563 : loss : 0.016812, loss_ce: 0.005988
2021-12-13 00:35:37,153 iteration 3564 : loss : 0.029087, loss_ce: 0.010707
2021-12-13 00:35:38,562 iteration 3565 : loss : 0.018978, loss_ce: 0.007866
2021-12-13 00:35:39,909 iteration 3566 : loss : 0.014322, loss_ce: 0.005545
2021-12-13 00:35:41,297 iteration 3567 : loss : 0.020146, loss_ce: 0.006090
2021-12-13 00:35:42,773 iteration 3568 : loss : 0.024631, loss_ce: 0.009694
2021-12-13 00:35:44,162 iteration 3569 : loss : 0.020540, loss_ce: 0.008883
2021-12-13 00:35:44,162 Training Data Eval:
2021-12-13 00:35:51,586   Average segmentation loss on training set: 0.0177
2021-12-13 00:35:51,586 Validation Data Eval:
2021-12-13 00:35:54,154   Average segmentation loss on validation set: 0.1103
2021-12-13 00:35:55,590 iteration 3570 : loss : 0.015659, loss_ce: 0.004817
 52%|██████████████▏            | 210/400 [1:34:04<1:29:26, 28.25s/it]2021-12-13 00:35:57,100 iteration 3571 : loss : 0.020039, loss_ce: 0.008736
2021-12-13 00:35:58,613 iteration 3572 : loss : 0.025612, loss_ce: 0.010907
2021-12-13 00:36:00,081 iteration 3573 : loss : 0.021854, loss_ce: 0.009130
2021-12-13 00:36:01,500 iteration 3574 : loss : 0.014489, loss_ce: 0.006510
2021-12-13 00:36:02,903 iteration 3575 : loss : 0.018776, loss_ce: 0.007193
2021-12-13 00:36:04,317 iteration 3576 : loss : 0.020458, loss_ce: 0.008052
2021-12-13 00:36:05,792 iteration 3577 : loss : 0.021043, loss_ce: 0.009207
2021-12-13 00:36:07,224 iteration 3578 : loss : 0.018123, loss_ce: 0.007696
2021-12-13 00:36:08,679 iteration 3579 : loss : 0.014822, loss_ce: 0.005188
2021-12-13 00:36:10,154 iteration 3580 : loss : 0.020044, loss_ce: 0.008723
2021-12-13 00:36:11,631 iteration 3581 : loss : 0.018726, loss_ce: 0.007149
2021-12-13 00:36:13,087 iteration 3582 : loss : 0.026914, loss_ce: 0.009419
2021-12-13 00:36:14,513 iteration 3583 : loss : 0.027888, loss_ce: 0.005667
2021-12-13 00:36:15,898 iteration 3584 : loss : 0.017723, loss_ce: 0.006318
2021-12-13 00:36:17,335 iteration 3585 : loss : 0.013724, loss_ce: 0.005469
2021-12-13 00:36:18,734 iteration 3586 : loss : 0.013334, loss_ce: 0.003873
2021-12-13 00:36:20,185 iteration 3587 : loss : 0.021792, loss_ce: 0.009949
 53%|██████████████▏            | 211/400 [1:34:29<1:25:31, 27.15s/it]2021-12-13 00:36:21,725 iteration 3588 : loss : 0.016648, loss_ce: 0.006566
2021-12-13 00:36:23,227 iteration 3589 : loss : 0.022008, loss_ce: 0.006333
2021-12-13 00:36:24,677 iteration 3590 : loss : 0.026099, loss_ce: 0.007228
2021-12-13 00:36:26,090 iteration 3591 : loss : 0.018599, loss_ce: 0.006607
2021-12-13 00:36:27,544 iteration 3592 : loss : 0.016376, loss_ce: 0.006333
2021-12-13 00:36:29,033 iteration 3593 : loss : 0.020214, loss_ce: 0.009179
2021-12-13 00:36:30,480 iteration 3594 : loss : 0.023891, loss_ce: 0.007412
2021-12-13 00:36:31,912 iteration 3595 : loss : 0.033703, loss_ce: 0.008940
2021-12-13 00:36:33,310 iteration 3596 : loss : 0.019114, loss_ce: 0.008409
2021-12-13 00:36:34,753 iteration 3597 : loss : 0.016384, loss_ce: 0.006171
2021-12-13 00:36:36,222 iteration 3598 : loss : 0.019900, loss_ce: 0.009084
2021-12-13 00:36:37,688 iteration 3599 : loss : 0.023523, loss_ce: 0.007020
2021-12-13 00:36:39,073 iteration 3600 : loss : 0.019127, loss_ce: 0.009014
2021-12-13 00:36:40,535 iteration 3601 : loss : 0.021783, loss_ce: 0.009036
2021-12-13 00:36:42,013 iteration 3602 : loss : 0.031969, loss_ce: 0.011365
2021-12-13 00:36:43,437 iteration 3603 : loss : 0.025988, loss_ce: 0.012980
2021-12-13 00:36:44,883 iteration 3604 : loss : 0.023090, loss_ce: 0.005451
 53%|██████████████▎            | 212/400 [1:34:54<1:22:46, 26.42s/it]2021-12-13 00:36:46,480 iteration 3605 : loss : 0.040817, loss_ce: 0.020101
2021-12-13 00:36:47,864 iteration 3606 : loss : 0.019542, loss_ce: 0.004598
2021-12-13 00:36:49,220 iteration 3607 : loss : 0.013247, loss_ce: 0.004490
2021-12-13 00:36:50,718 iteration 3608 : loss : 0.034884, loss_ce: 0.010838
2021-12-13 00:36:52,208 iteration 3609 : loss : 0.041685, loss_ce: 0.019052
2021-12-13 00:36:53,591 iteration 3610 : loss : 0.016714, loss_ce: 0.005916
2021-12-13 00:36:55,025 iteration 3611 : loss : 0.023498, loss_ce: 0.009925
2021-12-13 00:36:56,415 iteration 3612 : loss : 0.020213, loss_ce: 0.008580
2021-12-13 00:36:57,871 iteration 3613 : loss : 0.017914, loss_ce: 0.006717
2021-12-13 00:36:59,285 iteration 3614 : loss : 0.019397, loss_ce: 0.007677
2021-12-13 00:37:00,729 iteration 3615 : loss : 0.034036, loss_ce: 0.012669
2021-12-13 00:37:02,164 iteration 3616 : loss : 0.017631, loss_ce: 0.008623
2021-12-13 00:37:03,629 iteration 3617 : loss : 0.016431, loss_ce: 0.007384
2021-12-13 00:37:05,090 iteration 3618 : loss : 0.024231, loss_ce: 0.008592
2021-12-13 00:37:06,505 iteration 3619 : loss : 0.021335, loss_ce: 0.007191
2021-12-13 00:37:07,957 iteration 3620 : loss : 0.019856, loss_ce: 0.006470
2021-12-13 00:37:09,385 iteration 3621 : loss : 0.018349, loss_ce: 0.009089
 53%|██████████████▍            | 213/400 [1:35:18<1:20:32, 25.84s/it]2021-12-13 00:37:10,890 iteration 3622 : loss : 0.019491, loss_ce: 0.005964
2021-12-13 00:37:12,342 iteration 3623 : loss : 0.040162, loss_ce: 0.023895
2021-12-13 00:37:13,794 iteration 3624 : loss : 0.028091, loss_ce: 0.010944
2021-12-13 00:37:15,156 iteration 3625 : loss : 0.020293, loss_ce: 0.007935
2021-12-13 00:37:16,600 iteration 3626 : loss : 0.029318, loss_ce: 0.008006
2021-12-13 00:37:18,069 iteration 3627 : loss : 0.025431, loss_ce: 0.010772
2021-12-13 00:37:19,543 iteration 3628 : loss : 0.043242, loss_ce: 0.012626
2021-12-13 00:37:21,041 iteration 3629 : loss : 0.024511, loss_ce: 0.010179
2021-12-13 00:37:22,482 iteration 3630 : loss : 0.019916, loss_ce: 0.008492
2021-12-13 00:37:23,917 iteration 3631 : loss : 0.030312, loss_ce: 0.009796
2021-12-13 00:37:25,422 iteration 3632 : loss : 0.021162, loss_ce: 0.010954
2021-12-13 00:37:26,894 iteration 3633 : loss : 0.025827, loss_ce: 0.007637
2021-12-13 00:37:28,292 iteration 3634 : loss : 0.017587, loss_ce: 0.005701
2021-12-13 00:37:29,826 iteration 3635 : loss : 0.020541, loss_ce: 0.009623
2021-12-13 00:37:31,189 iteration 3636 : loss : 0.016173, loss_ce: 0.007443
2021-12-13 00:37:32,634 iteration 3637 : loss : 0.016480, loss_ce: 0.006216
2021-12-13 00:37:34,102 iteration 3638 : loss : 0.024404, loss_ce: 0.007214
 54%|██████████████▍            | 214/400 [1:35:43<1:19:03, 25.51s/it]2021-12-13 00:37:35,589 iteration 3639 : loss : 0.028998, loss_ce: 0.010104
2021-12-13 00:37:37,068 iteration 3640 : loss : 0.022512, loss_ce: 0.005733
2021-12-13 00:37:38,544 iteration 3641 : loss : 0.017855, loss_ce: 0.006547
2021-12-13 00:37:39,954 iteration 3642 : loss : 0.020573, loss_ce: 0.008781
2021-12-13 00:37:41,412 iteration 3643 : loss : 0.042948, loss_ce: 0.013116
2021-12-13 00:37:42,880 iteration 3644 : loss : 0.017951, loss_ce: 0.006360
2021-12-13 00:37:44,393 iteration 3645 : loss : 0.035981, loss_ce: 0.009848
2021-12-13 00:37:45,948 iteration 3646 : loss : 0.018660, loss_ce: 0.008484
2021-12-13 00:37:47,354 iteration 3647 : loss : 0.017437, loss_ce: 0.006984
2021-12-13 00:37:48,811 iteration 3648 : loss : 0.023886, loss_ce: 0.011221
2021-12-13 00:37:50,144 iteration 3649 : loss : 0.017258, loss_ce: 0.007024
2021-12-13 00:37:51,588 iteration 3650 : loss : 0.017178, loss_ce: 0.007260
2021-12-13 00:37:52,980 iteration 3651 : loss : 0.018940, loss_ce: 0.006779
2021-12-13 00:37:54,365 iteration 3652 : loss : 0.024271, loss_ce: 0.009994
2021-12-13 00:37:55,866 iteration 3653 : loss : 0.023330, loss_ce: 0.009527
2021-12-13 00:37:57,287 iteration 3654 : loss : 0.016769, loss_ce: 0.006864
2021-12-13 00:37:57,287 Training Data Eval:
2021-12-13 00:38:04,724   Average segmentation loss on training set: 0.0183
2021-12-13 00:38:04,724 Validation Data Eval:
2021-12-13 00:38:07,297   Average segmentation loss on validation set: 0.1670
2021-12-13 00:38:08,882 iteration 3655 : loss : 0.032432, loss_ce: 0.009703
 54%|██████████████▌            | 215/400 [1:36:18<1:27:12, 28.28s/it]2021-12-13 00:38:10,352 iteration 3656 : loss : 0.021047, loss_ce: 0.006752
2021-12-13 00:38:11,830 iteration 3657 : loss : 0.018817, loss_ce: 0.008144
2021-12-13 00:38:13,267 iteration 3658 : loss : 0.020738, loss_ce: 0.008832
2021-12-13 00:38:14,647 iteration 3659 : loss : 0.035477, loss_ce: 0.015618
2021-12-13 00:38:16,160 iteration 3660 : loss : 0.030964, loss_ce: 0.012413
2021-12-13 00:38:17,587 iteration 3661 : loss : 0.025878, loss_ce: 0.009742
2021-12-13 00:38:18,962 iteration 3662 : loss : 0.019327, loss_ce: 0.008985
2021-12-13 00:38:20,399 iteration 3663 : loss : 0.015712, loss_ce: 0.006338
2021-12-13 00:38:21,874 iteration 3664 : loss : 0.015698, loss_ce: 0.004336
2021-12-13 00:38:23,424 iteration 3665 : loss : 0.029526, loss_ce: 0.009249
2021-12-13 00:38:24,908 iteration 3666 : loss : 0.017539, loss_ce: 0.007657
2021-12-13 00:38:26,325 iteration 3667 : loss : 0.018566, loss_ce: 0.007105
2021-12-13 00:38:27,755 iteration 3668 : loss : 0.023961, loss_ce: 0.008328
2021-12-13 00:38:29,210 iteration 3669 : loss : 0.028735, loss_ce: 0.009646
2021-12-13 00:38:30,590 iteration 3670 : loss : 0.021944, loss_ce: 0.010273
2021-12-13 00:38:32,017 iteration 3671 : loss : 0.032021, loss_ce: 0.009405
2021-12-13 00:38:33,442 iteration 3672 : loss : 0.027345, loss_ce: 0.007439
 54%|██████████████▌            | 216/400 [1:36:42<1:23:19, 27.17s/it]2021-12-13 00:38:34,902 iteration 3673 : loss : 0.018189, loss_ce: 0.007801
2021-12-13 00:38:36,403 iteration 3674 : loss : 0.016851, loss_ce: 0.007567
2021-12-13 00:38:37,897 iteration 3675 : loss : 0.030236, loss_ce: 0.010421
2021-12-13 00:38:39,379 iteration 3676 : loss : 0.024202, loss_ce: 0.007712
2021-12-13 00:38:40,844 iteration 3677 : loss : 0.018474, loss_ce: 0.008040
2021-12-13 00:38:42,357 iteration 3678 : loss : 0.027888, loss_ce: 0.008717
2021-12-13 00:38:43,723 iteration 3679 : loss : 0.017078, loss_ce: 0.006397
2021-12-13 00:38:45,126 iteration 3680 : loss : 0.017732, loss_ce: 0.007216
2021-12-13 00:38:46,574 iteration 3681 : loss : 0.025222, loss_ce: 0.009623
2021-12-13 00:38:47,934 iteration 3682 : loss : 0.016439, loss_ce: 0.005197
2021-12-13 00:38:49,366 iteration 3683 : loss : 0.021823, loss_ce: 0.012348
2021-12-13 00:38:50,746 iteration 3684 : loss : 0.019029, loss_ce: 0.005930
2021-12-13 00:38:52,168 iteration 3685 : loss : 0.018574, loss_ce: 0.008053
2021-12-13 00:38:53,683 iteration 3686 : loss : 0.022219, loss_ce: 0.009637
2021-12-13 00:38:55,186 iteration 3687 : loss : 0.026277, loss_ce: 0.010830
2021-12-13 00:38:56,644 iteration 3688 : loss : 0.020633, loss_ce: 0.008263
2021-12-13 00:38:58,112 iteration 3689 : loss : 0.020692, loss_ce: 0.006011
 54%|██████████████▋            | 217/400 [1:37:07<1:20:34, 26.42s/it]2021-12-13 00:38:59,694 iteration 3690 : loss : 0.037875, loss_ce: 0.017928
2021-12-13 00:39:01,115 iteration 3691 : loss : 0.022705, loss_ce: 0.006633
2021-12-13 00:39:02,588 iteration 3692 : loss : 0.047972, loss_ce: 0.021203
2021-12-13 00:39:03,982 iteration 3693 : loss : 0.016905, loss_ce: 0.005085
2021-12-13 00:39:05,447 iteration 3694 : loss : 0.030457, loss_ce: 0.010264
2021-12-13 00:39:06,896 iteration 3695 : loss : 0.018173, loss_ce: 0.007246
2021-12-13 00:39:08,294 iteration 3696 : loss : 0.012812, loss_ce: 0.005410
2021-12-13 00:39:09,701 iteration 3697 : loss : 0.024878, loss_ce: 0.008629
2021-12-13 00:39:11,228 iteration 3698 : loss : 0.024971, loss_ce: 0.008681
2021-12-13 00:39:12,668 iteration 3699 : loss : 0.023137, loss_ce: 0.011511
2021-12-13 00:39:14,102 iteration 3700 : loss : 0.019310, loss_ce: 0.006308
2021-12-13 00:39:15,481 iteration 3701 : loss : 0.021665, loss_ce: 0.011972
2021-12-13 00:39:16,964 iteration 3702 : loss : 0.025636, loss_ce: 0.009434
2021-12-13 00:39:18,415 iteration 3703 : loss : 0.018851, loss_ce: 0.007084
2021-12-13 00:39:19,856 iteration 3704 : loss : 0.021024, loss_ce: 0.008484
2021-12-13 00:39:21,307 iteration 3705 : loss : 0.022010, loss_ce: 0.011179
2021-12-13 00:39:22,680 iteration 3706 : loss : 0.025348, loss_ce: 0.007799
 55%|██████████████▋            | 218/400 [1:37:31<1:18:27, 25.86s/it]2021-12-13 00:39:24,178 iteration 3707 : loss : 0.033161, loss_ce: 0.007168
2021-12-13 00:39:25,731 iteration 3708 : loss : 0.035252, loss_ce: 0.011062
2021-12-13 00:39:27,161 iteration 3709 : loss : 0.018998, loss_ce: 0.005727
2021-12-13 00:39:28,517 iteration 3710 : loss : 0.017312, loss_ce: 0.006396
2021-12-13 00:39:30,064 iteration 3711 : loss : 0.023689, loss_ce: 0.009554
2021-12-13 00:39:31,467 iteration 3712 : loss : 0.020010, loss_ce: 0.006730
2021-12-13 00:39:32,862 iteration 3713 : loss : 0.014188, loss_ce: 0.005329
2021-12-13 00:39:34,345 iteration 3714 : loss : 0.023664, loss_ce: 0.010741
2021-12-13 00:39:35,760 iteration 3715 : loss : 0.025734, loss_ce: 0.009607
2021-12-13 00:39:37,204 iteration 3716 : loss : 0.024511, loss_ce: 0.009755
2021-12-13 00:39:38,661 iteration 3717 : loss : 0.019002, loss_ce: 0.009637
2021-12-13 00:39:40,152 iteration 3718 : loss : 0.024543, loss_ce: 0.008950
2021-12-13 00:39:41,701 iteration 3719 : loss : 0.023469, loss_ce: 0.007947
2021-12-13 00:39:43,226 iteration 3720 : loss : 0.022448, loss_ce: 0.009163
2021-12-13 00:39:44,664 iteration 3721 : loss : 0.022717, loss_ce: 0.010610
2021-12-13 00:39:46,163 iteration 3722 : loss : 0.038962, loss_ce: 0.010592
2021-12-13 00:39:47,587 iteration 3723 : loss : 0.019589, loss_ce: 0.008271
 55%|██████████████▊            | 219/400 [1:37:56<1:17:08, 25.57s/it]2021-12-13 00:39:49,058 iteration 3724 : loss : 0.022255, loss_ce: 0.011351
2021-12-13 00:39:50,544 iteration 3725 : loss : 0.025627, loss_ce: 0.008404
2021-12-13 00:39:51,971 iteration 3726 : loss : 0.016253, loss_ce: 0.006718
2021-12-13 00:39:53,416 iteration 3727 : loss : 0.013889, loss_ce: 0.004825
2021-12-13 00:39:54,780 iteration 3728 : loss : 0.016425, loss_ce: 0.007541
2021-12-13 00:39:56,261 iteration 3729 : loss : 0.021768, loss_ce: 0.006775
2021-12-13 00:39:57,679 iteration 3730 : loss : 0.016756, loss_ce: 0.006109
2021-12-13 00:39:59,192 iteration 3731 : loss : 0.037308, loss_ce: 0.010488
2021-12-13 00:40:00,638 iteration 3732 : loss : 0.019076, loss_ce: 0.009320
2021-12-13 00:40:02,014 iteration 3733 : loss : 0.015788, loss_ce: 0.004642
2021-12-13 00:40:03,493 iteration 3734 : loss : 0.021533, loss_ce: 0.006923
2021-12-13 00:40:04,999 iteration 3735 : loss : 0.025176, loss_ce: 0.008732
2021-12-13 00:40:06,471 iteration 3736 : loss : 0.022865, loss_ce: 0.009846
2021-12-13 00:40:07,989 iteration 3737 : loss : 0.027841, loss_ce: 0.012477
2021-12-13 00:40:09,428 iteration 3738 : loss : 0.038382, loss_ce: 0.010907
2021-12-13 00:40:10,859 iteration 3739 : loss : 0.023608, loss_ce: 0.006386
2021-12-13 00:40:10,860 Training Data Eval:
2021-12-13 00:40:18,241   Average segmentation loss on training set: 0.0247
2021-12-13 00:40:18,241 Validation Data Eval:
2021-12-13 00:40:20,811   Average segmentation loss on validation set: 0.1709
2021-12-13 00:40:22,225 iteration 3740 : loss : 0.018192, loss_ce: 0.005522
 55%|██████████████▊            | 220/400 [1:38:31<1:24:53, 28.30s/it]2021-12-13 00:40:23,734 iteration 3741 : loss : 0.032939, loss_ce: 0.019981
2021-12-13 00:40:25,173 iteration 3742 : loss : 0.018872, loss_ce: 0.006495
2021-12-13 00:40:26,591 iteration 3743 : loss : 0.013923, loss_ce: 0.004091
2021-12-13 00:40:28,056 iteration 3744 : loss : 0.014387, loss_ce: 0.004901
2021-12-13 00:40:29,575 iteration 3745 : loss : 0.020311, loss_ce: 0.010685
2021-12-13 00:40:30,998 iteration 3746 : loss : 0.022481, loss_ce: 0.006432
2021-12-13 00:40:32,479 iteration 3747 : loss : 0.025857, loss_ce: 0.012315
2021-12-13 00:40:33,972 iteration 3748 : loss : 0.023899, loss_ce: 0.008244
2021-12-13 00:40:35,405 iteration 3749 : loss : 0.018800, loss_ce: 0.005413
2021-12-13 00:40:36,939 iteration 3750 : loss : 0.037375, loss_ce: 0.013707
2021-12-13 00:40:38,373 iteration 3751 : loss : 0.021416, loss_ce: 0.010290
2021-12-13 00:40:39,790 iteration 3752 : loss : 0.019075, loss_ce: 0.007067
2021-12-13 00:40:41,206 iteration 3753 : loss : 0.018696, loss_ce: 0.006585
2021-12-13 00:40:42,569 iteration 3754 : loss : 0.017986, loss_ce: 0.008550
2021-12-13 00:40:44,011 iteration 3755 : loss : 0.016151, loss_ce: 0.005622
2021-12-13 00:40:45,420 iteration 3756 : loss : 0.017933, loss_ce: 0.006268
2021-12-13 00:40:46,864 iteration 3757 : loss : 0.022929, loss_ce: 0.008975
 55%|██████████████▉            | 221/400 [1:38:56<1:21:08, 27.20s/it]2021-12-13 00:40:48,389 iteration 3758 : loss : 0.020536, loss_ce: 0.009041
2021-12-13 00:40:49,870 iteration 3759 : loss : 0.019604, loss_ce: 0.008330
2021-12-13 00:40:51,348 iteration 3760 : loss : 0.033950, loss_ce: 0.016906
2021-12-13 00:40:52,796 iteration 3761 : loss : 0.017516, loss_ce: 0.008265
2021-12-13 00:40:54,286 iteration 3762 : loss : 0.025332, loss_ce: 0.010539
2021-12-13 00:40:55,776 iteration 3763 : loss : 0.029792, loss_ce: 0.012478
2021-12-13 00:40:57,183 iteration 3764 : loss : 0.023894, loss_ce: 0.005504
2021-12-13 00:40:58,561 iteration 3765 : loss : 0.025484, loss_ce: 0.010846
2021-12-13 00:40:59,972 iteration 3766 : loss : 0.017787, loss_ce: 0.005867
2021-12-13 00:41:01,420 iteration 3767 : loss : 0.018314, loss_ce: 0.007237
2021-12-13 00:41:02,929 iteration 3768 : loss : 0.022267, loss_ce: 0.008999
2021-12-13 00:41:04,371 iteration 3769 : loss : 0.023941, loss_ce: 0.008694
2021-12-13 00:41:05,861 iteration 3770 : loss : 0.018719, loss_ce: 0.006628
2021-12-13 00:41:07,327 iteration 3771 : loss : 0.018853, loss_ce: 0.008175
2021-12-13 00:41:08,811 iteration 3772 : loss : 0.041568, loss_ce: 0.009473
2021-12-13 00:41:10,257 iteration 3773 : loss : 0.024701, loss_ce: 0.009056
2021-12-13 00:41:11,717 iteration 3774 : loss : 0.023397, loss_ce: 0.011201
 56%|██████████████▉            | 222/400 [1:39:20<1:18:36, 26.50s/it]2021-12-13 00:41:13,238 iteration 3775 : loss : 0.024537, loss_ce: 0.010448
2021-12-13 00:41:14,692 iteration 3776 : loss : 0.017303, loss_ce: 0.006314
2021-12-13 00:41:16,138 iteration 3777 : loss : 0.022750, loss_ce: 0.007359
2021-12-13 00:41:17,628 iteration 3778 : loss : 0.027796, loss_ce: 0.011018
2021-12-13 00:41:19,028 iteration 3779 : loss : 0.022682, loss_ce: 0.008446
2021-12-13 00:41:20,532 iteration 3780 : loss : 0.025682, loss_ce: 0.012732
2021-12-13 00:41:22,018 iteration 3781 : loss : 0.024900, loss_ce: 0.009024
2021-12-13 00:41:23,530 iteration 3782 : loss : 0.022478, loss_ce: 0.007678
2021-12-13 00:41:25,027 iteration 3783 : loss : 0.022567, loss_ce: 0.010744
2021-12-13 00:41:26,416 iteration 3784 : loss : 0.018348, loss_ce: 0.004443
2021-12-13 00:41:27,858 iteration 3785 : loss : 0.026974, loss_ce: 0.007017
2021-12-13 00:41:29,291 iteration 3786 : loss : 0.022555, loss_ce: 0.010734
2021-12-13 00:41:30,679 iteration 3787 : loss : 0.023108, loss_ce: 0.011214
2021-12-13 00:41:32,134 iteration 3788 : loss : 0.025362, loss_ce: 0.008372
2021-12-13 00:41:33,572 iteration 3789 : loss : 0.022719, loss_ce: 0.009411
2021-12-13 00:41:34,986 iteration 3790 : loss : 0.022574, loss_ce: 0.009366
2021-12-13 00:41:36,487 iteration 3791 : loss : 0.021616, loss_ce: 0.008193
 56%|███████████████            | 223/400 [1:39:45<1:16:37, 25.98s/it]2021-12-13 00:41:37,932 iteration 3792 : loss : 0.022380, loss_ce: 0.009178
2021-12-13 00:41:39,305 iteration 3793 : loss : 0.012784, loss_ce: 0.003243
2021-12-13 00:41:40,733 iteration 3794 : loss : 0.021344, loss_ce: 0.009319
2021-12-13 00:41:42,154 iteration 3795 : loss : 0.016512, loss_ce: 0.005102
2021-12-13 00:41:43,668 iteration 3796 : loss : 0.021564, loss_ce: 0.006656
2021-12-13 00:41:45,133 iteration 3797 : loss : 0.015339, loss_ce: 0.004490
2021-12-13 00:41:46,529 iteration 3798 : loss : 0.017482, loss_ce: 0.006656
2021-12-13 00:41:48,056 iteration 3799 : loss : 0.021914, loss_ce: 0.007443
2021-12-13 00:41:49,621 iteration 3800 : loss : 0.039133, loss_ce: 0.019012
2021-12-13 00:41:51,124 iteration 3801 : loss : 0.031177, loss_ce: 0.010467
2021-12-13 00:41:52,616 iteration 3802 : loss : 0.021787, loss_ce: 0.008048
2021-12-13 00:41:54,047 iteration 3803 : loss : 0.023233, loss_ce: 0.008225
2021-12-13 00:41:55,488 iteration 3804 : loss : 0.022707, loss_ce: 0.008729
2021-12-13 00:41:56,928 iteration 3805 : loss : 0.031173, loss_ce: 0.012546
2021-12-13 00:41:58,305 iteration 3806 : loss : 0.017030, loss_ce: 0.007496
2021-12-13 00:41:59,789 iteration 3807 : loss : 0.024414, loss_ce: 0.007704
2021-12-13 00:42:01,210 iteration 3808 : loss : 0.028284, loss_ce: 0.012923
 56%|███████████████            | 224/400 [1:40:10<1:15:05, 25.60s/it]2021-12-13 00:42:02,716 iteration 3809 : loss : 0.019247, loss_ce: 0.007678
2021-12-13 00:42:04,201 iteration 3810 : loss : 0.025650, loss_ce: 0.008999
2021-12-13 00:42:05,624 iteration 3811 : loss : 0.018776, loss_ce: 0.006295
2021-12-13 00:42:07,086 iteration 3812 : loss : 0.021098, loss_ce: 0.006767
2021-12-13 00:42:08,447 iteration 3813 : loss : 0.018586, loss_ce: 0.008798
2021-12-13 00:42:09,952 iteration 3814 : loss : 0.020532, loss_ce: 0.009122
2021-12-13 00:42:11,496 iteration 3815 : loss : 0.022987, loss_ce: 0.008707
2021-12-13 00:42:12,895 iteration 3816 : loss : 0.014510, loss_ce: 0.005279
2021-12-13 00:42:14,239 iteration 3817 : loss : 0.015394, loss_ce: 0.005342
2021-12-13 00:42:15,665 iteration 3818 : loss : 0.020296, loss_ce: 0.006336
2021-12-13 00:42:17,144 iteration 3819 : loss : 0.025092, loss_ce: 0.009588
2021-12-13 00:42:18,513 iteration 3820 : loss : 0.014739, loss_ce: 0.006368
2021-12-13 00:42:20,012 iteration 3821 : loss : 0.025936, loss_ce: 0.013661
2021-12-13 00:42:21,454 iteration 3822 : loss : 0.016640, loss_ce: 0.004831
2021-12-13 00:42:22,880 iteration 3823 : loss : 0.021253, loss_ce: 0.007100
2021-12-13 00:42:24,360 iteration 3824 : loss : 0.023170, loss_ce: 0.009863
2021-12-13 00:42:24,360 Training Data Eval:
2021-12-13 00:42:31,776   Average segmentation loss on training set: 0.0143
2021-12-13 00:42:31,777 Validation Data Eval:
2021-12-13 00:42:34,335   Average segmentation loss on validation set: 0.1182
2021-12-13 00:42:35,709 iteration 3825 : loss : 0.016457, loss_ce: 0.005768
 56%|███████████████▏           | 225/400 [1:40:44<1:22:27, 28.27s/it]2021-12-13 00:42:37,260 iteration 3826 : loss : 0.028364, loss_ce: 0.014222
2021-12-13 00:42:38,774 iteration 3827 : loss : 0.032767, loss_ce: 0.012828
2021-12-13 00:42:40,175 iteration 3828 : loss : 0.015276, loss_ce: 0.008539
2021-12-13 00:42:41,576 iteration 3829 : loss : 0.013610, loss_ce: 0.005151
2021-12-13 00:42:43,093 iteration 3830 : loss : 0.042198, loss_ce: 0.011639
2021-12-13 00:42:44,596 iteration 3831 : loss : 0.030518, loss_ce: 0.010857
2021-12-13 00:42:46,062 iteration 3832 : loss : 0.019628, loss_ce: 0.009589
2021-12-13 00:42:47,521 iteration 3833 : loss : 0.025399, loss_ce: 0.007202
2021-12-13 00:42:48,916 iteration 3834 : loss : 0.018798, loss_ce: 0.004967
2021-12-13 00:42:50,381 iteration 3835 : loss : 0.033498, loss_ce: 0.007964
2021-12-13 00:42:51,768 iteration 3836 : loss : 0.017608, loss_ce: 0.006822
2021-12-13 00:42:53,145 iteration 3837 : loss : 0.018148, loss_ce: 0.007924
2021-12-13 00:42:54,633 iteration 3838 : loss : 0.016370, loss_ce: 0.006745
2021-12-13 00:42:56,033 iteration 3839 : loss : 0.021788, loss_ce: 0.005570
2021-12-13 00:42:57,491 iteration 3840 : loss : 0.019266, loss_ce: 0.009100
2021-12-13 00:42:58,866 iteration 3841 : loss : 0.015940, loss_ce: 0.005851
2021-12-13 00:43:00,350 iteration 3842 : loss : 0.035962, loss_ce: 0.009201
 56%|███████████████▎           | 226/400 [1:41:09<1:18:49, 27.18s/it]2021-12-13 00:43:01,833 iteration 3843 : loss : 0.016666, loss_ce: 0.005401
2021-12-13 00:43:03,334 iteration 3844 : loss : 0.022252, loss_ce: 0.007628
2021-12-13 00:43:04,688 iteration 3845 : loss : 0.016419, loss_ce: 0.006014
2021-12-13 00:43:06,118 iteration 3846 : loss : 0.027716, loss_ce: 0.011803
2021-12-13 00:43:07,666 iteration 3847 : loss : 0.025657, loss_ce: 0.010431
2021-12-13 00:43:09,078 iteration 3848 : loss : 0.017994, loss_ce: 0.006652
2021-12-13 00:43:10,485 iteration 3849 : loss : 0.016230, loss_ce: 0.005934
2021-12-13 00:43:11,997 iteration 3850 : loss : 0.027116, loss_ce: 0.009149
2021-12-13 00:43:13,530 iteration 3851 : loss : 0.028299, loss_ce: 0.010962
2021-12-13 00:43:15,010 iteration 3852 : loss : 0.025711, loss_ce: 0.008676
2021-12-13 00:43:16,443 iteration 3853 : loss : 0.018492, loss_ce: 0.006940
2021-12-13 00:43:17,809 iteration 3854 : loss : 0.016327, loss_ce: 0.006193
2021-12-13 00:43:19,238 iteration 3855 : loss : 0.019384, loss_ce: 0.006016
2021-12-13 00:43:20,798 iteration 3856 : loss : 0.020508, loss_ce: 0.008631
2021-12-13 00:43:22,234 iteration 3857 : loss : 0.027584, loss_ce: 0.007982
2021-12-13 00:43:23,679 iteration 3858 : loss : 0.033084, loss_ce: 0.016841
2021-12-13 00:43:25,082 iteration 3859 : loss : 0.018391, loss_ce: 0.007681
 57%|███████████████▎           | 227/400 [1:41:34<1:16:15, 26.45s/it]2021-12-13 00:43:26,526 iteration 3860 : loss : 0.015896, loss_ce: 0.007448
2021-12-13 00:43:27,940 iteration 3861 : loss : 0.023680, loss_ce: 0.009426
2021-12-13 00:43:29,331 iteration 3862 : loss : 0.023781, loss_ce: 0.006869
2021-12-13 00:43:30,787 iteration 3863 : loss : 0.022838, loss_ce: 0.010106
2021-12-13 00:43:32,157 iteration 3864 : loss : 0.016594, loss_ce: 0.006319
2021-12-13 00:43:33,626 iteration 3865 : loss : 0.020892, loss_ce: 0.008704
2021-12-13 00:43:35,056 iteration 3866 : loss : 0.018122, loss_ce: 0.009224
2021-12-13 00:43:36,531 iteration 3867 : loss : 0.026673, loss_ce: 0.010712
2021-12-13 00:43:37,909 iteration 3868 : loss : 0.017035, loss_ce: 0.006789
2021-12-13 00:43:39,424 iteration 3869 : loss : 0.019402, loss_ce: 0.005132
2021-12-13 00:43:40,846 iteration 3870 : loss : 0.018964, loss_ce: 0.006846
2021-12-13 00:43:42,341 iteration 3871 : loss : 0.030526, loss_ce: 0.012279
2021-12-13 00:43:43,789 iteration 3872 : loss : 0.020953, loss_ce: 0.007446
2021-12-13 00:43:45,219 iteration 3873 : loss : 0.025365, loss_ce: 0.006651
2021-12-13 00:43:46,716 iteration 3874 : loss : 0.017173, loss_ce: 0.005192
2021-12-13 00:43:48,186 iteration 3875 : loss : 0.030584, loss_ce: 0.008590
2021-12-13 00:43:49,702 iteration 3876 : loss : 0.020064, loss_ce: 0.007354
 57%|███████████████▍           | 228/400 [1:41:58<1:14:14, 25.90s/it]2021-12-13 00:43:51,157 iteration 3877 : loss : 0.015961, loss_ce: 0.006284
2021-12-13 00:43:52,639 iteration 3878 : loss : 0.021138, loss_ce: 0.007435
2021-12-13 00:43:54,138 iteration 3879 : loss : 0.022546, loss_ce: 0.013101
2021-12-13 00:43:55,565 iteration 3880 : loss : 0.017678, loss_ce: 0.006406
2021-12-13 00:43:57,020 iteration 3881 : loss : 0.021717, loss_ce: 0.006915
2021-12-13 00:43:58,504 iteration 3882 : loss : 0.019835, loss_ce: 0.008707
2021-12-13 00:43:59,962 iteration 3883 : loss : 0.014765, loss_ce: 0.004657
2021-12-13 00:44:01,421 iteration 3884 : loss : 0.014928, loss_ce: 0.004971
2021-12-13 00:44:02,832 iteration 3885 : loss : 0.015940, loss_ce: 0.004833
2021-12-13 00:44:04,312 iteration 3886 : loss : 0.020647, loss_ce: 0.008092
2021-12-13 00:44:05,765 iteration 3887 : loss : 0.020497, loss_ce: 0.007162
2021-12-13 00:44:07,265 iteration 3888 : loss : 0.018244, loss_ce: 0.008886
2021-12-13 00:44:08,681 iteration 3889 : loss : 0.019359, loss_ce: 0.006706
2021-12-13 00:44:10,105 iteration 3890 : loss : 0.014345, loss_ce: 0.004679
2021-12-13 00:44:11,592 iteration 3891 : loss : 0.025780, loss_ce: 0.013350
2021-12-13 00:44:13,046 iteration 3892 : loss : 0.021996, loss_ce: 0.007503
2021-12-13 00:44:14,466 iteration 3893 : loss : 0.021442, loss_ce: 0.005431
 57%|███████████████▍           | 229/400 [1:42:23<1:12:50, 25.56s/it]2021-12-13 00:44:15,947 iteration 3894 : loss : 0.028721, loss_ce: 0.011989
2021-12-13 00:44:17,429 iteration 3895 : loss : 0.018419, loss_ce: 0.008825
2021-12-13 00:44:18,818 iteration 3896 : loss : 0.014857, loss_ce: 0.005198
2021-12-13 00:44:20,316 iteration 3897 : loss : 0.019963, loss_ce: 0.006046
2021-12-13 00:44:21,789 iteration 3898 : loss : 0.022505, loss_ce: 0.006358
2021-12-13 00:44:23,253 iteration 3899 : loss : 0.020186, loss_ce: 0.007111
2021-12-13 00:44:24,707 iteration 3900 : loss : 0.021289, loss_ce: 0.009905
2021-12-13 00:44:26,051 iteration 3901 : loss : 0.016970, loss_ce: 0.007992
2021-12-13 00:44:27,486 iteration 3902 : loss : 0.015266, loss_ce: 0.004856
2021-12-13 00:44:28,886 iteration 3903 : loss : 0.018161, loss_ce: 0.005637
2021-12-13 00:44:30,351 iteration 3904 : loss : 0.018540, loss_ce: 0.007686
2021-12-13 00:44:31,805 iteration 3905 : loss : 0.028175, loss_ce: 0.014081
2021-12-13 00:44:33,250 iteration 3906 : loss : 0.022481, loss_ce: 0.007139
2021-12-13 00:44:34,687 iteration 3907 : loss : 0.022508, loss_ce: 0.006597
2021-12-13 00:44:36,053 iteration 3908 : loss : 0.021461, loss_ce: 0.006766
2021-12-13 00:44:37,436 iteration 3909 : loss : 0.020050, loss_ce: 0.008066
2021-12-13 00:44:37,437 Training Data Eval:
2021-12-13 00:44:44,870   Average segmentation loss on training set: 0.0135
2021-12-13 00:44:44,870 Validation Data Eval:
2021-12-13 00:44:47,460   Average segmentation loss on validation set: 0.1149
2021-12-13 00:44:48,929 iteration 3910 : loss : 0.021257, loss_ce: 0.008332
 57%|███████████████▌           | 230/400 [1:42:58<1:19:58, 28.23s/it]2021-12-13 00:44:50,356 iteration 3911 : loss : 0.017439, loss_ce: 0.007025
2021-12-13 00:44:51,797 iteration 3912 : loss : 0.042025, loss_ce: 0.012691
2021-12-13 00:44:53,266 iteration 3913 : loss : 0.024725, loss_ce: 0.010535
2021-12-13 00:44:54,630 iteration 3914 : loss : 0.014455, loss_ce: 0.006095
2021-12-13 00:44:56,117 iteration 3915 : loss : 0.029792, loss_ce: 0.008561
2021-12-13 00:44:57,583 iteration 3916 : loss : 0.020403, loss_ce: 0.007724
2021-12-13 00:44:59,052 iteration 3917 : loss : 0.020920, loss_ce: 0.007041
2021-12-13 00:45:00,481 iteration 3918 : loss : 0.016287, loss_ce: 0.005111
2021-12-13 00:45:01,920 iteration 3919 : loss : 0.024008, loss_ce: 0.007105
2021-12-13 00:45:03,396 iteration 3920 : loss : 0.056191, loss_ce: 0.007478
2021-12-13 00:45:04,840 iteration 3921 : loss : 0.024234, loss_ce: 0.007804
2021-12-13 00:45:06,312 iteration 3922 : loss : 0.046788, loss_ce: 0.009864
2021-12-13 00:45:07,849 iteration 3923 : loss : 0.030438, loss_ce: 0.015757
2021-12-13 00:45:09,265 iteration 3924 : loss : 0.018038, loss_ce: 0.006340
2021-12-13 00:45:10,641 iteration 3925 : loss : 0.016536, loss_ce: 0.007009
2021-12-13 00:45:12,212 iteration 3926 : loss : 0.034326, loss_ce: 0.011848
2021-12-13 00:45:13,680 iteration 3927 : loss : 0.023201, loss_ce: 0.010973
 58%|███████████████▌           | 231/400 [1:43:22<1:16:34, 27.19s/it]2021-12-13 00:45:15,143 iteration 3928 : loss : 0.017836, loss_ce: 0.006742
2021-12-13 00:45:16,546 iteration 3929 : loss : 0.018724, loss_ce: 0.011104
2021-12-13 00:45:17,998 iteration 3930 : loss : 0.021035, loss_ce: 0.005832
2021-12-13 00:45:19,383 iteration 3931 : loss : 0.020806, loss_ce: 0.004747
2021-12-13 00:45:20,846 iteration 3932 : loss : 0.026002, loss_ce: 0.008622
2021-12-13 00:45:22,278 iteration 3933 : loss : 0.022830, loss_ce: 0.009499
2021-12-13 00:45:23,742 iteration 3934 : loss : 0.034250, loss_ce: 0.010370
2021-12-13 00:45:25,178 iteration 3935 : loss : 0.018239, loss_ce: 0.007132
2021-12-13 00:45:26,582 iteration 3936 : loss : 0.017892, loss_ce: 0.005359
2021-12-13 00:45:28,024 iteration 3937 : loss : 0.024432, loss_ce: 0.006517
2021-12-13 00:45:29,466 iteration 3938 : loss : 0.021244, loss_ce: 0.005821
2021-12-13 00:45:30,960 iteration 3939 : loss : 0.052222, loss_ce: 0.010287
2021-12-13 00:45:32,391 iteration 3940 : loss : 0.018931, loss_ce: 0.008582
2021-12-13 00:45:33,828 iteration 3941 : loss : 0.015933, loss_ce: 0.004413
2021-12-13 00:45:35,242 iteration 3942 : loss : 0.015033, loss_ce: 0.007666
2021-12-13 00:45:36,659 iteration 3943 : loss : 0.022607, loss_ce: 0.008648
2021-12-13 00:45:38,089 iteration 3944 : loss : 0.030639, loss_ce: 0.009385
 58%|███████████████▋           | 232/400 [1:43:47<1:13:47, 26.35s/it]2021-12-13 00:45:39,628 iteration 3945 : loss : 0.032278, loss_ce: 0.011301
2021-12-13 00:45:41,047 iteration 3946 : loss : 0.017893, loss_ce: 0.006806
2021-12-13 00:45:42,455 iteration 3947 : loss : 0.032336, loss_ce: 0.014114
2021-12-13 00:45:43,949 iteration 3948 : loss : 0.029746, loss_ce: 0.013625
2021-12-13 00:45:45,455 iteration 3949 : loss : 0.019303, loss_ce: 0.005555
2021-12-13 00:45:46,876 iteration 3950 : loss : 0.020991, loss_ce: 0.010047
2021-12-13 00:45:48,281 iteration 3951 : loss : 0.017955, loss_ce: 0.003636
2021-12-13 00:45:49,839 iteration 3952 : loss : 0.021761, loss_ce: 0.010345
2021-12-13 00:45:51,288 iteration 3953 : loss : 0.019787, loss_ce: 0.008190
2021-12-13 00:45:52,678 iteration 3954 : loss : 0.014741, loss_ce: 0.005420
2021-12-13 00:45:54,141 iteration 3955 : loss : 0.032421, loss_ce: 0.013183
2021-12-13 00:45:55,620 iteration 3956 : loss : 0.030657, loss_ce: 0.019180
2021-12-13 00:45:57,113 iteration 3957 : loss : 0.043899, loss_ce: 0.017277
2021-12-13 00:45:58,609 iteration 3958 : loss : 0.023071, loss_ce: 0.011403
2021-12-13 00:45:59,974 iteration 3959 : loss : 0.026057, loss_ce: 0.006949
2021-12-13 00:46:01,456 iteration 3960 : loss : 0.025148, loss_ce: 0.009589
2021-12-13 00:46:02,881 iteration 3961 : loss : 0.017377, loss_ce: 0.005357
 58%|███████████████▋           | 233/400 [1:44:12<1:12:02, 25.88s/it]2021-12-13 00:46:04,388 iteration 3962 : loss : 0.045077, loss_ce: 0.018497
2021-12-13 00:46:05,889 iteration 3963 : loss : 0.026751, loss_ce: 0.012359
2021-12-13 00:46:07,288 iteration 3964 : loss : 0.018529, loss_ce: 0.005771
2021-12-13 00:46:08,756 iteration 3965 : loss : 0.016094, loss_ce: 0.007299
2021-12-13 00:46:10,301 iteration 3966 : loss : 0.027282, loss_ce: 0.012895
2021-12-13 00:46:11,741 iteration 3967 : loss : 0.023210, loss_ce: 0.005164
2021-12-13 00:46:13,167 iteration 3968 : loss : 0.015097, loss_ce: 0.005000
2021-12-13 00:46:14,564 iteration 3969 : loss : 0.018415, loss_ce: 0.005669
2021-12-13 00:46:16,004 iteration 3970 : loss : 0.022352, loss_ce: 0.005936
2021-12-13 00:46:17,440 iteration 3971 : loss : 0.031631, loss_ce: 0.009004
2021-12-13 00:46:18,888 iteration 3972 : loss : 0.026887, loss_ce: 0.010670
2021-12-13 00:46:20,394 iteration 3973 : loss : 0.021658, loss_ce: 0.008442
2021-12-13 00:46:21,895 iteration 3974 : loss : 0.019916, loss_ce: 0.010169
2021-12-13 00:46:23,333 iteration 3975 : loss : 0.023172, loss_ce: 0.006401
2021-12-13 00:46:24,764 iteration 3976 : loss : 0.019201, loss_ce: 0.006663
2021-12-13 00:46:26,235 iteration 3977 : loss : 0.024108, loss_ce: 0.009956
2021-12-13 00:46:27,689 iteration 3978 : loss : 0.022194, loss_ce: 0.008508
 58%|███████████████▊           | 234/400 [1:44:36<1:10:43, 25.56s/it]2021-12-13 00:46:29,241 iteration 3979 : loss : 0.020604, loss_ce: 0.009666
2021-12-13 00:46:30,618 iteration 3980 : loss : 0.018116, loss_ce: 0.006854
2021-12-13 00:46:32,057 iteration 3981 : loss : 0.028057, loss_ce: 0.006456
2021-12-13 00:46:33,512 iteration 3982 : loss : 0.015633, loss_ce: 0.006952
2021-12-13 00:46:34,977 iteration 3983 : loss : 0.026426, loss_ce: 0.006121
2021-12-13 00:46:36,454 iteration 3984 : loss : 0.033549, loss_ce: 0.016836
2021-12-13 00:46:37,941 iteration 3985 : loss : 0.017458, loss_ce: 0.005220
2021-12-13 00:46:39,439 iteration 3986 : loss : 0.024562, loss_ce: 0.008333
2021-12-13 00:46:40,837 iteration 3987 : loss : 0.019265, loss_ce: 0.007871
2021-12-13 00:46:42,257 iteration 3988 : loss : 0.021676, loss_ce: 0.009338
2021-12-13 00:46:43,713 iteration 3989 : loss : 0.019808, loss_ce: 0.007859
2021-12-13 00:46:45,173 iteration 3990 : loss : 0.022160, loss_ce: 0.008539
2021-12-13 00:46:46,652 iteration 3991 : loss : 0.021661, loss_ce: 0.010579
2021-12-13 00:46:48,132 iteration 3992 : loss : 0.026438, loss_ce: 0.010870
2021-12-13 00:46:49,583 iteration 3993 : loss : 0.019349, loss_ce: 0.007646
2021-12-13 00:46:51,067 iteration 3994 : loss : 0.018520, loss_ce: 0.006064
2021-12-13 00:46:51,067 Training Data Eval:
2021-12-13 00:46:58,472   Average segmentation loss on training set: 0.0133
2021-12-13 00:46:58,473 Validation Data Eval:
2021-12-13 00:47:01,063   Average segmentation loss on validation set: 0.1008
2021-12-13 00:47:02,623 iteration 3995 : loss : 0.022248, loss_ce: 0.007951
 59%|███████████████▊           | 235/400 [1:45:11<1:18:01, 28.37s/it]2021-12-13 00:47:04,114 iteration 3996 : loss : 0.021449, loss_ce: 0.009434
2021-12-13 00:47:05,517 iteration 3997 : loss : 0.019960, loss_ce: 0.009164
2021-12-13 00:47:06,905 iteration 3998 : loss : 0.016571, loss_ce: 0.005049
2021-12-13 00:47:08,416 iteration 3999 : loss : 0.021730, loss_ce: 0.005699
2021-12-13 00:47:09,871 iteration 4000 : loss : 0.020760, loss_ce: 0.008679
2021-12-13 00:47:11,366 iteration 4001 : loss : 0.027942, loss_ce: 0.015100
2021-12-13 00:47:12,732 iteration 4002 : loss : 0.020560, loss_ce: 0.007048
2021-12-13 00:47:14,231 iteration 4003 : loss : 0.028690, loss_ce: 0.008831
2021-12-13 00:47:15,729 iteration 4004 : loss : 0.023055, loss_ce: 0.010277
2021-12-13 00:47:17,202 iteration 4005 : loss : 0.019399, loss_ce: 0.007472
2021-12-13 00:47:18,603 iteration 4006 : loss : 0.044297, loss_ce: 0.011060
2021-12-13 00:47:20,064 iteration 4007 : loss : 0.023299, loss_ce: 0.008773
2021-12-13 00:47:21,503 iteration 4008 : loss : 0.014226, loss_ce: 0.006396
2021-12-13 00:47:22,950 iteration 4009 : loss : 0.014183, loss_ce: 0.004351
2021-12-13 00:47:24,412 iteration 4010 : loss : 0.020045, loss_ce: 0.008508
2021-12-13 00:47:25,835 iteration 4011 : loss : 0.023333, loss_ce: 0.007840
2021-12-13 00:47:27,288 iteration 4012 : loss : 0.026056, loss_ce: 0.012041
 59%|███████████████▉           | 236/400 [1:45:36<1:14:30, 27.26s/it]2021-12-13 00:47:28,656 iteration 4013 : loss : 0.013425, loss_ce: 0.006349
2021-12-13 00:47:30,150 iteration 4014 : loss : 0.019175, loss_ce: 0.008137
2021-12-13 00:47:31,547 iteration 4015 : loss : 0.015086, loss_ce: 0.006724
2021-12-13 00:47:33,056 iteration 4016 : loss : 0.019914, loss_ce: 0.007388
2021-12-13 00:47:34,515 iteration 4017 : loss : 0.028707, loss_ce: 0.007169
2021-12-13 00:47:35,884 iteration 4018 : loss : 0.018931, loss_ce: 0.006399
2021-12-13 00:47:37,326 iteration 4019 : loss : 0.040324, loss_ce: 0.013854
2021-12-13 00:47:38,733 iteration 4020 : loss : 0.016153, loss_ce: 0.005281
2021-12-13 00:47:40,186 iteration 4021 : loss : 0.023749, loss_ce: 0.006887
2021-12-13 00:47:41,704 iteration 4022 : loss : 0.022811, loss_ce: 0.007005
2021-12-13 00:47:43,099 iteration 4023 : loss : 0.014832, loss_ce: 0.006929
2021-12-13 00:47:44,594 iteration 4024 : loss : 0.018369, loss_ce: 0.004924
2021-12-13 00:47:46,050 iteration 4025 : loss : 0.029525, loss_ce: 0.010450
2021-12-13 00:47:47,549 iteration 4026 : loss : 0.018547, loss_ce: 0.005319
2021-12-13 00:47:48,919 iteration 4027 : loss : 0.014874, loss_ce: 0.004779
2021-12-13 00:47:50,489 iteration 4028 : loss : 0.025895, loss_ce: 0.013181
2021-12-13 00:47:52,020 iteration 4029 : loss : 0.023662, loss_ce: 0.010102
 59%|███████████████▉           | 237/400 [1:46:01<1:12:00, 26.50s/it]2021-12-13 00:47:53,476 iteration 4030 : loss : 0.020219, loss_ce: 0.007253
2021-12-13 00:47:54,900 iteration 4031 : loss : 0.019125, loss_ce: 0.008118
2021-12-13 00:47:56,273 iteration 4032 : loss : 0.014559, loss_ce: 0.004316
2021-12-13 00:47:57,685 iteration 4033 : loss : 0.015148, loss_ce: 0.006283
2021-12-13 00:47:59,162 iteration 4034 : loss : 0.020572, loss_ce: 0.008646
2021-12-13 00:48:00,635 iteration 4035 : loss : 0.022571, loss_ce: 0.006771
2021-12-13 00:48:02,081 iteration 4036 : loss : 0.019653, loss_ce: 0.009008
2021-12-13 00:48:03,484 iteration 4037 : loss : 0.014535, loss_ce: 0.007314
2021-12-13 00:48:04,926 iteration 4038 : loss : 0.027176, loss_ce: 0.011186
2021-12-13 00:48:06,376 iteration 4039 : loss : 0.021271, loss_ce: 0.008018
2021-12-13 00:48:07,801 iteration 4040 : loss : 0.016884, loss_ce: 0.005555
2021-12-13 00:48:09,287 iteration 4041 : loss : 0.018614, loss_ce: 0.007245
2021-12-13 00:48:10,752 iteration 4042 : loss : 0.018595, loss_ce: 0.007250
2021-12-13 00:48:12,197 iteration 4043 : loss : 0.017646, loss_ce: 0.006916
2021-12-13 00:48:13,632 iteration 4044 : loss : 0.021286, loss_ce: 0.009031
2021-12-13 00:48:15,078 iteration 4045 : loss : 0.017801, loss_ce: 0.005220
2021-12-13 00:48:16,567 iteration 4046 : loss : 0.024476, loss_ce: 0.008441
 60%|████████████████           | 238/400 [1:46:25<1:09:58, 25.91s/it]2021-12-13 00:48:18,076 iteration 4047 : loss : 0.019969, loss_ce: 0.008147
2021-12-13 00:48:19,500 iteration 4048 : loss : 0.020712, loss_ce: 0.006390
2021-12-13 00:48:20,923 iteration 4049 : loss : 0.013558, loss_ce: 0.003696
2021-12-13 00:48:22,318 iteration 4050 : loss : 0.023901, loss_ce: 0.008033
2021-12-13 00:48:23,776 iteration 4051 : loss : 0.021537, loss_ce: 0.008360
2021-12-13 00:48:25,178 iteration 4052 : loss : 0.014847, loss_ce: 0.005749
2021-12-13 00:48:26,637 iteration 4053 : loss : 0.027582, loss_ce: 0.006359
2021-12-13 00:48:28,114 iteration 4054 : loss : 0.018190, loss_ce: 0.007294
2021-12-13 00:48:29,562 iteration 4055 : loss : 0.017466, loss_ce: 0.007486
2021-12-13 00:48:30,994 iteration 4056 : loss : 0.019054, loss_ce: 0.008574
2021-12-13 00:48:32,378 iteration 4057 : loss : 0.014651, loss_ce: 0.004277
2021-12-13 00:48:33,789 iteration 4058 : loss : 0.018939, loss_ce: 0.006140
2021-12-13 00:48:35,262 iteration 4059 : loss : 0.028167, loss_ce: 0.010662
2021-12-13 00:48:36,663 iteration 4060 : loss : 0.015403, loss_ce: 0.006389
2021-12-13 00:48:38,030 iteration 4061 : loss : 0.014912, loss_ce: 0.006665
2021-12-13 00:48:39,450 iteration 4062 : loss : 0.013332, loss_ce: 0.006021
2021-12-13 00:48:40,943 iteration 4063 : loss : 0.020065, loss_ce: 0.007836
 60%|████████████████▏          | 239/400 [1:46:50<1:08:17, 25.45s/it]2021-12-13 00:48:42,427 iteration 4064 : loss : 0.015591, loss_ce: 0.005655
2021-12-13 00:48:43,843 iteration 4065 : loss : 0.015096, loss_ce: 0.003787
2021-12-13 00:48:45,289 iteration 4066 : loss : 0.018529, loss_ce: 0.006438
2021-12-13 00:48:46,726 iteration 4067 : loss : 0.016028, loss_ce: 0.005163
2021-12-13 00:48:48,199 iteration 4068 : loss : 0.046976, loss_ce: 0.022929
2021-12-13 00:48:49,667 iteration 4069 : loss : 0.024567, loss_ce: 0.011330
2021-12-13 00:48:51,061 iteration 4070 : loss : 0.014461, loss_ce: 0.004168
2021-12-13 00:48:52,491 iteration 4071 : loss : 0.019005, loss_ce: 0.006694
2021-12-13 00:48:53,928 iteration 4072 : loss : 0.014951, loss_ce: 0.006104
2021-12-13 00:48:55,392 iteration 4073 : loss : 0.031907, loss_ce: 0.011351
2021-12-13 00:48:56,828 iteration 4074 : loss : 0.020261, loss_ce: 0.008565
2021-12-13 00:48:58,345 iteration 4075 : loss : 0.023707, loss_ce: 0.007214
2021-12-13 00:48:59,810 iteration 4076 : loss : 0.015392, loss_ce: 0.006595
2021-12-13 00:49:01,311 iteration 4077 : loss : 0.023090, loss_ce: 0.009038
2021-12-13 00:49:02,814 iteration 4078 : loss : 0.026803, loss_ce: 0.008753
2021-12-13 00:49:04,234 iteration 4079 : loss : 0.014255, loss_ce: 0.005455
2021-12-13 00:49:04,234 Training Data Eval:
2021-12-13 00:49:11,638   Average segmentation loss on training set: 0.0138
2021-12-13 00:49:11,639 Validation Data Eval:
2021-12-13 00:49:14,220   Average segmentation loss on validation set: 0.0737
2021-12-13 00:49:20,521 Found new lowest validation loss at iteration 4079! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 00:49:21,977 iteration 4080 : loss : 0.022839, loss_ce: 0.009268
 60%|████████████████▏          | 240/400 [1:47:31<1:20:20, 30.13s/it]2021-12-13 00:49:23,348 iteration 4081 : loss : 0.016965, loss_ce: 0.006904
2021-12-13 00:49:24,700 iteration 4082 : loss : 0.017618, loss_ce: 0.006342
2021-12-13 00:49:26,047 iteration 4083 : loss : 0.014314, loss_ce: 0.006221
2021-12-13 00:49:27,449 iteration 4084 : loss : 0.024563, loss_ce: 0.009905
2021-12-13 00:49:28,895 iteration 4085 : loss : 0.028742, loss_ce: 0.008013
2021-12-13 00:49:30,324 iteration 4086 : loss : 0.019198, loss_ce: 0.008838
2021-12-13 00:49:31,681 iteration 4087 : loss : 0.016718, loss_ce: 0.004975
2021-12-13 00:49:33,043 iteration 4088 : loss : 0.018230, loss_ce: 0.007576
2021-12-13 00:49:34,441 iteration 4089 : loss : 0.023474, loss_ce: 0.008387
2021-12-13 00:49:35,842 iteration 4090 : loss : 0.016932, loss_ce: 0.007456
2021-12-13 00:49:37,195 iteration 4091 : loss : 0.020342, loss_ce: 0.006565
2021-12-13 00:49:38,581 iteration 4092 : loss : 0.017634, loss_ce: 0.006238
2021-12-13 00:49:39,977 iteration 4093 : loss : 0.018971, loss_ce: 0.008279
2021-12-13 00:49:41,394 iteration 4094 : loss : 0.017961, loss_ce: 0.005548
2021-12-13 00:49:42,855 iteration 4095 : loss : 0.018505, loss_ce: 0.007222
2021-12-13 00:49:44,318 iteration 4096 : loss : 0.017139, loss_ce: 0.007129
2021-12-13 00:49:45,794 iteration 4097 : loss : 0.034884, loss_ce: 0.013452
 60%|████████████████▎          | 241/400 [1:47:55<1:14:48, 28.23s/it]2021-12-13 00:49:47,332 iteration 4098 : loss : 0.020905, loss_ce: 0.007673
2021-12-13 00:49:48,774 iteration 4099 : loss : 0.028655, loss_ce: 0.005982
2021-12-13 00:49:50,192 iteration 4100 : loss : 0.015538, loss_ce: 0.006943
2021-12-13 00:49:51,624 iteration 4101 : loss : 0.014937, loss_ce: 0.005746
2021-12-13 00:49:53,097 iteration 4102 : loss : 0.018644, loss_ce: 0.007265
2021-12-13 00:49:54,534 iteration 4103 : loss : 0.014167, loss_ce: 0.005535
2021-12-13 00:49:55,943 iteration 4104 : loss : 0.016117, loss_ce: 0.007109
2021-12-13 00:49:57,414 iteration 4105 : loss : 0.016411, loss_ce: 0.006173
2021-12-13 00:49:58,819 iteration 4106 : loss : 0.021603, loss_ce: 0.004638
2021-12-13 00:50:00,364 iteration 4107 : loss : 0.019691, loss_ce: 0.009776
2021-12-13 00:50:01,862 iteration 4108 : loss : 0.024407, loss_ce: 0.008386
2021-12-13 00:50:03,266 iteration 4109 : loss : 0.018131, loss_ce: 0.004644
2021-12-13 00:50:04,740 iteration 4110 : loss : 0.034164, loss_ce: 0.014069
2021-12-13 00:50:06,254 iteration 4111 : loss : 0.021677, loss_ce: 0.008103
2021-12-13 00:50:07,674 iteration 4112 : loss : 0.020342, loss_ce: 0.006906
2021-12-13 00:50:09,135 iteration 4113 : loss : 0.019785, loss_ce: 0.008195
2021-12-13 00:50:10,660 iteration 4114 : loss : 0.021120, loss_ce: 0.007520
 60%|████████████████▎          | 242/400 [1:48:19<1:11:41, 27.23s/it]2021-12-13 00:50:12,123 iteration 4115 : loss : 0.017230, loss_ce: 0.004680
2021-12-13 00:50:13,530 iteration 4116 : loss : 0.016422, loss_ce: 0.006619
2021-12-13 00:50:15,115 iteration 4117 : loss : 0.026861, loss_ce: 0.010282
2021-12-13 00:50:16,674 iteration 4118 : loss : 0.022840, loss_ce: 0.010470
2021-12-13 00:50:18,155 iteration 4119 : loss : 0.021526, loss_ce: 0.009748
2021-12-13 00:50:19,622 iteration 4120 : loss : 0.034403, loss_ce: 0.007753
2021-12-13 00:50:21,104 iteration 4121 : loss : 0.018729, loss_ce: 0.008810
2021-12-13 00:50:22,552 iteration 4122 : loss : 0.024728, loss_ce: 0.007711
2021-12-13 00:50:24,084 iteration 4123 : loss : 0.025356, loss_ce: 0.008805
2021-12-13 00:50:25,470 iteration 4124 : loss : 0.021093, loss_ce: 0.008312
2021-12-13 00:50:26,978 iteration 4125 : loss : 0.020612, loss_ce: 0.005369
2021-12-13 00:50:28,453 iteration 4126 : loss : 0.017890, loss_ce: 0.008246
2021-12-13 00:50:29,952 iteration 4127 : loss : 0.023118, loss_ce: 0.008349
2021-12-13 00:50:31,386 iteration 4128 : loss : 0.021070, loss_ce: 0.011283
2021-12-13 00:50:32,905 iteration 4129 : loss : 0.022293, loss_ce: 0.008401
2021-12-13 00:50:34,359 iteration 4130 : loss : 0.015786, loss_ce: 0.008511
2021-12-13 00:50:35,725 iteration 4131 : loss : 0.011483, loss_ce: 0.003274
 61%|████████████████▍          | 243/400 [1:48:44<1:09:32, 26.58s/it]2021-12-13 00:50:37,252 iteration 4132 : loss : 0.022071, loss_ce: 0.007521
2021-12-13 00:50:38,754 iteration 4133 : loss : 0.019820, loss_ce: 0.009207
2021-12-13 00:50:40,138 iteration 4134 : loss : 0.015630, loss_ce: 0.006704
2021-12-13 00:50:41,661 iteration 4135 : loss : 0.016921, loss_ce: 0.007036
2021-12-13 00:50:43,122 iteration 4136 : loss : 0.019537, loss_ce: 0.008972
2021-12-13 00:50:44,545 iteration 4137 : loss : 0.021947, loss_ce: 0.010574
2021-12-13 00:50:45,955 iteration 4138 : loss : 0.016573, loss_ce: 0.007328
2021-12-13 00:50:47,451 iteration 4139 : loss : 0.031510, loss_ce: 0.009088
2021-12-13 00:50:48,971 iteration 4140 : loss : 0.019026, loss_ce: 0.005945
2021-12-13 00:50:50,420 iteration 4141 : loss : 0.021425, loss_ce: 0.004553
2021-12-13 00:50:51,895 iteration 4142 : loss : 0.036503, loss_ce: 0.009588
2021-12-13 00:50:53,403 iteration 4143 : loss : 0.018576, loss_ce: 0.004748
2021-12-13 00:50:54,851 iteration 4144 : loss : 0.018412, loss_ce: 0.007176
2021-12-13 00:50:56,291 iteration 4145 : loss : 0.018767, loss_ce: 0.004779
2021-12-13 00:50:57,755 iteration 4146 : loss : 0.027990, loss_ce: 0.008591
2021-12-13 00:50:59,198 iteration 4147 : loss : 0.018474, loss_ce: 0.006878
2021-12-13 00:51:00,573 iteration 4148 : loss : 0.014059, loss_ce: 0.004773
 61%|████████████████▍          | 244/400 [1:49:09<1:07:45, 26.06s/it]2021-12-13 00:51:02,167 iteration 4149 : loss : 0.036134, loss_ce: 0.016130
2021-12-13 00:51:03,522 iteration 4150 : loss : 0.015311, loss_ce: 0.004431
2021-12-13 00:51:04,993 iteration 4151 : loss : 0.028796, loss_ce: 0.014701
2021-12-13 00:51:06,360 iteration 4152 : loss : 0.021715, loss_ce: 0.008122
2021-12-13 00:51:07,842 iteration 4153 : loss : 0.030595, loss_ce: 0.008212
2021-12-13 00:51:09,304 iteration 4154 : loss : 0.025222, loss_ce: 0.009297
2021-12-13 00:51:10,806 iteration 4155 : loss : 0.023546, loss_ce: 0.008605
2021-12-13 00:51:12,167 iteration 4156 : loss : 0.012687, loss_ce: 0.004974
2021-12-13 00:51:13,648 iteration 4157 : loss : 0.022810, loss_ce: 0.007333
2021-12-13 00:51:15,099 iteration 4158 : loss : 0.019504, loss_ce: 0.007407
2021-12-13 00:51:16,581 iteration 4159 : loss : 0.015997, loss_ce: 0.006353
2021-12-13 00:51:18,036 iteration 4160 : loss : 0.033367, loss_ce: 0.022329
2021-12-13 00:51:19,494 iteration 4161 : loss : 0.023907, loss_ce: 0.008624
2021-12-13 00:51:20,922 iteration 4162 : loss : 0.023416, loss_ce: 0.008469
2021-12-13 00:51:22,406 iteration 4163 : loss : 0.029039, loss_ce: 0.008302
2021-12-13 00:51:23,890 iteration 4164 : loss : 0.017147, loss_ce: 0.007480
2021-12-13 00:51:23,890 Training Data Eval:
2021-12-13 00:51:31,334   Average segmentation loss on training set: 0.0115
2021-12-13 00:51:31,335 Validation Data Eval:
2021-12-13 00:51:33,923   Average segmentation loss on validation set: 0.0681
2021-12-13 00:51:40,359 Found new lowest validation loss at iteration 4164! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 00:51:41,751 iteration 4165 : loss : 0.017498, loss_ce: 0.008040
 61%|████████████████▌          | 245/400 [1:49:50<1:19:02, 30.59s/it]2021-12-13 00:51:43,109 iteration 4166 : loss : 0.014602, loss_ce: 0.005836
2021-12-13 00:51:44,505 iteration 4167 : loss : 0.027861, loss_ce: 0.007997
2021-12-13 00:51:45,918 iteration 4168 : loss : 0.016444, loss_ce: 0.006587
2021-12-13 00:51:47,309 iteration 4169 : loss : 0.020852, loss_ce: 0.007797
2021-12-13 00:51:48,721 iteration 4170 : loss : 0.020618, loss_ce: 0.008973
2021-12-13 00:51:50,059 iteration 4171 : loss : 0.018638, loss_ce: 0.008307
2021-12-13 00:51:51,415 iteration 4172 : loss : 0.017639, loss_ce: 0.006869
2021-12-13 00:51:52,708 iteration 4173 : loss : 0.016040, loss_ce: 0.005004
2021-12-13 00:51:54,117 iteration 4174 : loss : 0.031302, loss_ce: 0.009408
2021-12-13 00:51:55,507 iteration 4175 : loss : 0.017473, loss_ce: 0.004591
2021-12-13 00:51:56,923 iteration 4176 : loss : 0.025453, loss_ce: 0.007418
2021-12-13 00:51:58,262 iteration 4177 : loss : 0.016629, loss_ce: 0.007939
2021-12-13 00:51:59,696 iteration 4178 : loss : 0.013884, loss_ce: 0.005468
2021-12-13 00:52:01,200 iteration 4179 : loss : 0.021685, loss_ce: 0.007736
2021-12-13 00:52:02,743 iteration 4180 : loss : 0.031283, loss_ce: 0.009138
2021-12-13 00:52:04,229 iteration 4181 : loss : 0.028947, loss_ce: 0.012079
2021-12-13 00:52:05,745 iteration 4182 : loss : 0.030649, loss_ce: 0.011774
 62%|████████████████▌          | 246/400 [1:50:14<1:13:26, 28.61s/it]2021-12-13 00:52:07,243 iteration 4183 : loss : 0.027997, loss_ce: 0.008136
2021-12-13 00:52:08,686 iteration 4184 : loss : 0.025175, loss_ce: 0.008006
2021-12-13 00:52:10,163 iteration 4185 : loss : 0.020283, loss_ce: 0.007407
2021-12-13 00:52:11,583 iteration 4186 : loss : 0.015913, loss_ce: 0.005616
2021-12-13 00:52:12,993 iteration 4187 : loss : 0.024496, loss_ce: 0.009811
2021-12-13 00:52:14,432 iteration 4188 : loss : 0.022074, loss_ce: 0.009980
2021-12-13 00:52:15,829 iteration 4189 : loss : 0.018740, loss_ce: 0.006515
2021-12-13 00:52:17,384 iteration 4190 : loss : 0.023598, loss_ce: 0.009657
2021-12-13 00:52:18,880 iteration 4191 : loss : 0.017899, loss_ce: 0.003585
2021-12-13 00:52:20,280 iteration 4192 : loss : 0.017905, loss_ce: 0.008965
2021-12-13 00:52:21,670 iteration 4193 : loss : 0.016418, loss_ce: 0.004833
2021-12-13 00:52:23,141 iteration 4194 : loss : 0.022173, loss_ce: 0.007691
2021-12-13 00:52:24,577 iteration 4195 : loss : 0.019563, loss_ce: 0.008029
2021-12-13 00:52:26,004 iteration 4196 : loss : 0.017239, loss_ce: 0.006467
2021-12-13 00:52:27,422 iteration 4197 : loss : 0.015183, loss_ce: 0.006548
2021-12-13 00:52:28,820 iteration 4198 : loss : 0.018043, loss_ce: 0.004517
2021-12-13 00:52:30,316 iteration 4199 : loss : 0.021971, loss_ce: 0.008484
 62%|████████████████▋          | 247/400 [1:50:39<1:09:52, 27.40s/it]2021-12-13 00:52:31,810 iteration 4200 : loss : 0.020650, loss_ce: 0.006717
2021-12-13 00:52:33,299 iteration 4201 : loss : 0.026080, loss_ce: 0.012229
2021-12-13 00:52:34,818 iteration 4202 : loss : 0.019803, loss_ce: 0.008557
2021-12-13 00:52:36,338 iteration 4203 : loss : 0.023790, loss_ce: 0.009163
2021-12-13 00:52:37,826 iteration 4204 : loss : 0.016503, loss_ce: 0.006186
2021-12-13 00:52:39,142 iteration 4205 : loss : 0.012281, loss_ce: 0.004260
2021-12-13 00:52:40,581 iteration 4206 : loss : 0.021336, loss_ce: 0.006348
2021-12-13 00:52:42,007 iteration 4207 : loss : 0.013001, loss_ce: 0.006143
2021-12-13 00:52:43,493 iteration 4208 : loss : 0.020788, loss_ce: 0.006722
2021-12-13 00:52:44,916 iteration 4209 : loss : 0.020878, loss_ce: 0.006572
2021-12-13 00:52:46,345 iteration 4210 : loss : 0.015277, loss_ce: 0.005730
2021-12-13 00:52:47,809 iteration 4211 : loss : 0.016260, loss_ce: 0.006323
2021-12-13 00:52:49,228 iteration 4212 : loss : 0.013553, loss_ce: 0.005762
2021-12-13 00:52:50,738 iteration 4213 : loss : 0.016789, loss_ce: 0.005479
2021-12-13 00:52:52,235 iteration 4214 : loss : 0.018780, loss_ce: 0.008630
2021-12-13 00:52:53,717 iteration 4215 : loss : 0.026258, loss_ce: 0.006411
2021-12-13 00:52:55,159 iteration 4216 : loss : 0.022495, loss_ce: 0.008136
 62%|████████████████▋          | 248/400 [1:51:04<1:07:28, 26.63s/it]2021-12-13 00:52:56,712 iteration 4217 : loss : 0.034773, loss_ce: 0.013102
2021-12-13 00:52:58,241 iteration 4218 : loss : 0.026307, loss_ce: 0.014763
2021-12-13 00:52:59,713 iteration 4219 : loss : 0.023437, loss_ce: 0.010734
2021-12-13 00:53:01,163 iteration 4220 : loss : 0.017671, loss_ce: 0.005876
2021-12-13 00:53:02,646 iteration 4221 : loss : 0.021306, loss_ce: 0.007456
2021-12-13 00:53:04,151 iteration 4222 : loss : 0.015228, loss_ce: 0.006801
2021-12-13 00:53:05,728 iteration 4223 : loss : 0.041800, loss_ce: 0.010260
2021-12-13 00:53:07,171 iteration 4224 : loss : 0.031502, loss_ce: 0.010764
2021-12-13 00:53:08,665 iteration 4225 : loss : 0.021492, loss_ce: 0.011379
2021-12-13 00:53:10,204 iteration 4226 : loss : 0.024413, loss_ce: 0.009844
2021-12-13 00:53:11,642 iteration 4227 : loss : 0.017611, loss_ce: 0.005672
2021-12-13 00:53:13,128 iteration 4228 : loss : 0.023721, loss_ce: 0.011717
2021-12-13 00:53:14,538 iteration 4229 : loss : 0.019551, loss_ce: 0.007481
2021-12-13 00:53:16,038 iteration 4230 : loss : 0.018227, loss_ce: 0.005230
2021-12-13 00:53:17,513 iteration 4231 : loss : 0.018431, loss_ce: 0.006947
2021-12-13 00:53:19,017 iteration 4232 : loss : 0.028292, loss_ce: 0.011095
2021-12-13 00:53:20,422 iteration 4233 : loss : 0.020077, loss_ce: 0.007582
 62%|████████████████▊          | 249/400 [1:51:29<1:05:59, 26.22s/it]2021-12-13 00:53:21,956 iteration 4234 : loss : 0.020383, loss_ce: 0.008993
2021-12-13 00:53:23,369 iteration 4235 : loss : 0.017989, loss_ce: 0.007068
2021-12-13 00:53:24,875 iteration 4236 : loss : 0.026915, loss_ce: 0.013322
2021-12-13 00:53:26,318 iteration 4237 : loss : 0.024679, loss_ce: 0.013168
2021-12-13 00:53:27,838 iteration 4238 : loss : 0.031809, loss_ce: 0.011003
2021-12-13 00:53:29,229 iteration 4239 : loss : 0.016930, loss_ce: 0.004848
2021-12-13 00:53:30,754 iteration 4240 : loss : 0.018700, loss_ce: 0.006181
2021-12-13 00:53:32,187 iteration 4241 : loss : 0.015883, loss_ce: 0.005277
2021-12-13 00:53:33,613 iteration 4242 : loss : 0.025315, loss_ce: 0.008242
2021-12-13 00:53:35,061 iteration 4243 : loss : 0.019496, loss_ce: 0.006960
2021-12-13 00:53:36,562 iteration 4244 : loss : 0.024850, loss_ce: 0.009879
2021-12-13 00:53:38,028 iteration 4245 : loss : 0.031915, loss_ce: 0.006751
2021-12-13 00:53:39,459 iteration 4246 : loss : 0.022900, loss_ce: 0.011418
2021-12-13 00:53:40,883 iteration 4247 : loss : 0.024984, loss_ce: 0.005600
2021-12-13 00:53:42,365 iteration 4248 : loss : 0.022930, loss_ce: 0.009030
2021-12-13 00:53:43,827 iteration 4249 : loss : 0.029047, loss_ce: 0.012876
2021-12-13 00:53:43,827 Training Data Eval:
2021-12-13 00:53:51,307   Average segmentation loss on training set: 0.0155
2021-12-13 00:53:51,307 Validation Data Eval:
2021-12-13 00:53:53,901   Average segmentation loss on validation set: 0.0716
2021-12-13 00:53:55,395 iteration 4250 : loss : 0.016656, loss_ce: 0.006350
 62%|████████████████▉          | 250/400 [1:52:04<1:12:07, 28.85s/it]2021-12-13 00:53:56,945 iteration 4251 : loss : 0.020414, loss_ce: 0.008229
2021-12-13 00:53:58,439 iteration 4252 : loss : 0.021785, loss_ce: 0.009378
2021-12-13 00:53:59,922 iteration 4253 : loss : 0.027491, loss_ce: 0.011878
2021-12-13 00:54:01,460 iteration 4254 : loss : 0.022061, loss_ce: 0.009134
2021-12-13 00:54:02,835 iteration 4255 : loss : 0.013582, loss_ce: 0.005099
2021-12-13 00:54:04,296 iteration 4256 : loss : 0.017074, loss_ce: 0.004478
2021-12-13 00:54:05,827 iteration 4257 : loss : 0.020805, loss_ce: 0.008020
2021-12-13 00:54:07,247 iteration 4258 : loss : 0.015596, loss_ce: 0.005300
2021-12-13 00:54:08,703 iteration 4259 : loss : 0.019357, loss_ce: 0.007245
2021-12-13 00:54:10,161 iteration 4260 : loss : 0.016977, loss_ce: 0.005467
2021-12-13 00:54:11,638 iteration 4261 : loss : 0.014232, loss_ce: 0.005207
2021-12-13 00:54:13,175 iteration 4262 : loss : 0.018227, loss_ce: 0.007921
2021-12-13 00:54:14,619 iteration 4263 : loss : 0.016232, loss_ce: 0.005953
2021-12-13 00:54:16,007 iteration 4264 : loss : 0.017797, loss_ce: 0.005786
2021-12-13 00:54:17,441 iteration 4265 : loss : 0.019224, loss_ce: 0.007254
2021-12-13 00:54:18,897 iteration 4266 : loss : 0.023149, loss_ce: 0.009038
2021-12-13 00:54:20,359 iteration 4267 : loss : 0.015160, loss_ce: 0.006986
 63%|████████████████▉          | 251/400 [1:52:29<1:08:44, 27.68s/it]2021-12-13 00:54:21,850 iteration 4268 : loss : 0.016646, loss_ce: 0.007138
2021-12-13 00:54:23,248 iteration 4269 : loss : 0.024666, loss_ce: 0.007328
2021-12-13 00:54:24,661 iteration 4270 : loss : 0.015285, loss_ce: 0.002192
2021-12-13 00:54:26,068 iteration 4271 : loss : 0.017103, loss_ce: 0.008642
2021-12-13 00:54:27,565 iteration 4272 : loss : 0.016493, loss_ce: 0.005747
2021-12-13 00:54:29,032 iteration 4273 : loss : 0.020069, loss_ce: 0.008267
2021-12-13 00:54:30,519 iteration 4274 : loss : 0.020281, loss_ce: 0.009163
2021-12-13 00:54:31,862 iteration 4275 : loss : 0.012904, loss_ce: 0.005273
2021-12-13 00:54:33,265 iteration 4276 : loss : 0.021097, loss_ce: 0.006791
2021-12-13 00:54:34,677 iteration 4277 : loss : 0.013083, loss_ce: 0.004994
2021-12-13 00:54:36,108 iteration 4278 : loss : 0.020439, loss_ce: 0.005065
2021-12-13 00:54:37,502 iteration 4279 : loss : 0.012852, loss_ce: 0.003949
2021-12-13 00:54:38,912 iteration 4280 : loss : 0.016777, loss_ce: 0.004944
2021-12-13 00:54:40,473 iteration 4281 : loss : 0.016702, loss_ce: 0.007374
2021-12-13 00:54:41,928 iteration 4282 : loss : 0.016408, loss_ce: 0.006607
2021-12-13 00:54:43,282 iteration 4283 : loss : 0.016332, loss_ce: 0.007162
2021-12-13 00:54:44,714 iteration 4284 : loss : 0.028903, loss_ce: 0.014091
 63%|█████████████████          | 252/400 [1:52:53<1:05:49, 26.68s/it]2021-12-13 00:54:46,246 iteration 4285 : loss : 0.021885, loss_ce: 0.008802
2021-12-13 00:54:47,724 iteration 4286 : loss : 0.014204, loss_ce: 0.003713
2021-12-13 00:54:49,217 iteration 4287 : loss : 0.021872, loss_ce: 0.008533
2021-12-13 00:54:50,651 iteration 4288 : loss : 0.015671, loss_ce: 0.005050
2021-12-13 00:54:52,114 iteration 4289 : loss : 0.020127, loss_ce: 0.006700
2021-12-13 00:54:53,615 iteration 4290 : loss : 0.023810, loss_ce: 0.009072
2021-12-13 00:54:54,995 iteration 4291 : loss : 0.017012, loss_ce: 0.005681
2021-12-13 00:54:56,506 iteration 4292 : loss : 0.016395, loss_ce: 0.005870
2021-12-13 00:54:57,976 iteration 4293 : loss : 0.023313, loss_ce: 0.010074
2021-12-13 00:54:59,438 iteration 4294 : loss : 0.023082, loss_ce: 0.011136
2021-12-13 00:55:00,935 iteration 4295 : loss : 0.017622, loss_ce: 0.007755
2021-12-13 00:55:02,311 iteration 4296 : loss : 0.014533, loss_ce: 0.005936
2021-12-13 00:55:03,765 iteration 4297 : loss : 0.016247, loss_ce: 0.006665
2021-12-13 00:55:05,194 iteration 4298 : loss : 0.014630, loss_ce: 0.004476
2021-12-13 00:55:06,721 iteration 4299 : loss : 0.027925, loss_ce: 0.013339
2021-12-13 00:55:08,211 iteration 4300 : loss : 0.020447, loss_ce: 0.006275
2021-12-13 00:55:09,654 iteration 4301 : loss : 0.015808, loss_ce: 0.006590
 63%|█████████████████          | 253/400 [1:53:18<1:04:05, 26.16s/it]2021-12-13 00:55:11,163 iteration 4302 : loss : 0.017569, loss_ce: 0.007720
2021-12-13 00:55:12,656 iteration 4303 : loss : 0.023168, loss_ce: 0.008727
2021-12-13 00:55:14,031 iteration 4304 : loss : 0.017286, loss_ce: 0.006721
2021-12-13 00:55:15,492 iteration 4305 : loss : 0.020035, loss_ce: 0.006070
2021-12-13 00:55:16,909 iteration 4306 : loss : 0.015480, loss_ce: 0.005670
2021-12-13 00:55:18,333 iteration 4307 : loss : 0.016899, loss_ce: 0.006458
2021-12-13 00:55:19,834 iteration 4308 : loss : 0.023561, loss_ce: 0.008637
2021-12-13 00:55:21,258 iteration 4309 : loss : 0.034407, loss_ce: 0.011214
2021-12-13 00:55:22,738 iteration 4310 : loss : 0.032345, loss_ce: 0.016260
2021-12-13 00:55:24,213 iteration 4311 : loss : 0.019030, loss_ce: 0.008092
2021-12-13 00:55:25,766 iteration 4312 : loss : 0.023671, loss_ce: 0.008151
2021-12-13 00:55:27,220 iteration 4313 : loss : 0.024537, loss_ce: 0.009375
2021-12-13 00:55:28,670 iteration 4314 : loss : 0.019158, loss_ce: 0.005944
2021-12-13 00:55:30,089 iteration 4315 : loss : 0.016691, loss_ce: 0.007046
2021-12-13 00:55:31,591 iteration 4316 : loss : 0.017365, loss_ce: 0.006239
2021-12-13 00:55:33,027 iteration 4317 : loss : 0.037415, loss_ce: 0.011163
2021-12-13 00:55:34,456 iteration 4318 : loss : 0.018567, loss_ce: 0.009247
 64%|█████████████████▏         | 254/400 [1:53:43<1:02:39, 25.75s/it]2021-12-13 00:55:35,996 iteration 4319 : loss : 0.028890, loss_ce: 0.011033
2021-12-13 00:55:37,492 iteration 4320 : loss : 0.026241, loss_ce: 0.012715
2021-12-13 00:55:38,994 iteration 4321 : loss : 0.020434, loss_ce: 0.008654
2021-12-13 00:55:40,464 iteration 4322 : loss : 0.020428, loss_ce: 0.005967
2021-12-13 00:55:41,883 iteration 4323 : loss : 0.013374, loss_ce: 0.004181
2021-12-13 00:55:43,355 iteration 4324 : loss : 0.026012, loss_ce: 0.010091
2021-12-13 00:55:44,910 iteration 4325 : loss : 0.024435, loss_ce: 0.006161
2021-12-13 00:55:46,363 iteration 4326 : loss : 0.021071, loss_ce: 0.011752
2021-12-13 00:55:47,777 iteration 4327 : loss : 0.016014, loss_ce: 0.006474
2021-12-13 00:55:49,217 iteration 4328 : loss : 0.042200, loss_ce: 0.014798
2021-12-13 00:55:50,708 iteration 4329 : loss : 0.019511, loss_ce: 0.008133
2021-12-13 00:55:52,119 iteration 4330 : loss : 0.014939, loss_ce: 0.005681
2021-12-13 00:55:53,693 iteration 4331 : loss : 0.022967, loss_ce: 0.006304
2021-12-13 00:55:55,195 iteration 4332 : loss : 0.024906, loss_ce: 0.010808
2021-12-13 00:55:56,583 iteration 4333 : loss : 0.018506, loss_ce: 0.008063
2021-12-13 00:55:57,998 iteration 4334 : loss : 0.015546, loss_ce: 0.006362
2021-12-13 00:55:57,998 Training Data Eval:
2021-12-13 00:56:05,471   Average segmentation loss on training set: 0.0455
2021-12-13 00:56:05,472 Validation Data Eval:
2021-12-13 00:56:08,059   Average segmentation loss on validation set: 0.0832
2021-12-13 00:56:09,584 iteration 4335 : loss : 0.019169, loss_ce: 0.009370
 64%|█████████████████▏         | 255/400 [1:54:18<1:09:02, 28.57s/it]2021-12-13 00:56:11,074 iteration 4336 : loss : 0.021047, loss_ce: 0.008785
2021-12-13 00:56:12,547 iteration 4337 : loss : 0.018432, loss_ce: 0.007136
2021-12-13 00:56:14,089 iteration 4338 : loss : 0.017610, loss_ce: 0.006192
2021-12-13 00:56:15,528 iteration 4339 : loss : 0.019967, loss_ce: 0.006517
2021-12-13 00:56:17,002 iteration 4340 : loss : 0.016913, loss_ce: 0.006587
2021-12-13 00:56:18,480 iteration 4341 : loss : 0.020768, loss_ce: 0.008955
2021-12-13 00:56:19,921 iteration 4342 : loss : 0.035282, loss_ce: 0.011372
2021-12-13 00:56:21,383 iteration 4343 : loss : 0.014197, loss_ce: 0.004186
2021-12-13 00:56:22,804 iteration 4344 : loss : 0.019055, loss_ce: 0.006174
2021-12-13 00:56:24,247 iteration 4345 : loss : 0.015454, loss_ce: 0.004617
2021-12-13 00:56:25,669 iteration 4346 : loss : 0.015154, loss_ce: 0.006775
2021-12-13 00:56:27,165 iteration 4347 : loss : 0.022362, loss_ce: 0.007625
2021-12-13 00:56:28,631 iteration 4348 : loss : 0.015816, loss_ce: 0.008045
2021-12-13 00:56:30,085 iteration 4349 : loss : 0.018589, loss_ce: 0.006046
2021-12-13 00:56:31,506 iteration 4350 : loss : 0.015493, loss_ce: 0.005796
2021-12-13 00:56:32,898 iteration 4351 : loss : 0.012741, loss_ce: 0.006162
2021-12-13 00:56:34,322 iteration 4352 : loss : 0.013191, loss_ce: 0.005191
 64%|█████████████████▎         | 256/400 [1:54:43<1:05:48, 27.42s/it]2021-12-13 00:56:35,833 iteration 4353 : loss : 0.013469, loss_ce: 0.004461
2021-12-13 00:56:37,362 iteration 4354 : loss : 0.022307, loss_ce: 0.007156
2021-12-13 00:56:38,769 iteration 4355 : loss : 0.014708, loss_ce: 0.005068
2021-12-13 00:56:40,253 iteration 4356 : loss : 0.023783, loss_ce: 0.012234
2021-12-13 00:56:41,707 iteration 4357 : loss : 0.022229, loss_ce: 0.008859
2021-12-13 00:56:43,126 iteration 4358 : loss : 0.014560, loss_ce: 0.006062
2021-12-13 00:56:44,565 iteration 4359 : loss : 0.011674, loss_ce: 0.004166
2021-12-13 00:56:46,005 iteration 4360 : loss : 0.051957, loss_ce: 0.024186
2021-12-13 00:56:47,502 iteration 4361 : loss : 0.023564, loss_ce: 0.010664
2021-12-13 00:56:48,925 iteration 4362 : loss : 0.014430, loss_ce: 0.004436
2021-12-13 00:56:50,305 iteration 4363 : loss : 0.014846, loss_ce: 0.006831
2021-12-13 00:56:51,796 iteration 4364 : loss : 0.020562, loss_ce: 0.009083
2021-12-13 00:56:53,241 iteration 4365 : loss : 0.022469, loss_ce: 0.009023
2021-12-13 00:56:54,589 iteration 4366 : loss : 0.012961, loss_ce: 0.005385
2021-12-13 00:56:56,028 iteration 4367 : loss : 0.016271, loss_ce: 0.005118
2021-12-13 00:56:57,553 iteration 4368 : loss : 0.021556, loss_ce: 0.007451
2021-12-13 00:56:58,956 iteration 4369 : loss : 0.017575, loss_ce: 0.004551
 64%|█████████████████▎         | 257/400 [1:55:08<1:03:21, 26.58s/it]2021-12-13 00:57:00,466 iteration 4370 : loss : 0.023571, loss_ce: 0.006090
2021-12-13 00:57:01,932 iteration 4371 : loss : 0.018749, loss_ce: 0.008335
2021-12-13 00:57:03,323 iteration 4372 : loss : 0.014155, loss_ce: 0.006194
2021-12-13 00:57:04,820 iteration 4373 : loss : 0.018716, loss_ce: 0.007489
2021-12-13 00:57:06,256 iteration 4374 : loss : 0.015602, loss_ce: 0.006552
2021-12-13 00:57:07,650 iteration 4375 : loss : 0.018778, loss_ce: 0.008123
2021-12-13 00:57:09,089 iteration 4376 : loss : 0.023437, loss_ce: 0.008646
2021-12-13 00:57:10,631 iteration 4377 : loss : 0.018194, loss_ce: 0.006650
2021-12-13 00:57:12,117 iteration 4378 : loss : 0.022223, loss_ce: 0.007691
2021-12-13 00:57:13,658 iteration 4379 : loss : 0.019833, loss_ce: 0.008613
2021-12-13 00:57:15,117 iteration 4380 : loss : 0.013061, loss_ce: 0.005704
2021-12-13 00:57:16,599 iteration 4381 : loss : 0.020590, loss_ce: 0.008056
2021-12-13 00:57:18,039 iteration 4382 : loss : 0.017902, loss_ce: 0.007921
2021-12-13 00:57:19,495 iteration 4383 : loss : 0.016574, loss_ce: 0.004454
2021-12-13 00:57:20,952 iteration 4384 : loss : 0.017310, loss_ce: 0.005687
2021-12-13 00:57:22,317 iteration 4385 : loss : 0.014971, loss_ce: 0.006666
2021-12-13 00:57:23,796 iteration 4386 : loss : 0.018197, loss_ce: 0.007320
 64%|█████████████████▍         | 258/400 [1:55:33<1:01:40, 26.06s/it]2021-12-13 00:57:25,287 iteration 4387 : loss : 0.013289, loss_ce: 0.004643
2021-12-13 00:57:26,768 iteration 4388 : loss : 0.017438, loss_ce: 0.007530
2021-12-13 00:57:28,164 iteration 4389 : loss : 0.015734, loss_ce: 0.006857
2021-12-13 00:57:29,568 iteration 4390 : loss : 0.016472, loss_ce: 0.006011
2021-12-13 00:57:31,011 iteration 4391 : loss : 0.020864, loss_ce: 0.008810
2021-12-13 00:57:32,489 iteration 4392 : loss : 0.021864, loss_ce: 0.011507
2021-12-13 00:57:33,862 iteration 4393 : loss : 0.017974, loss_ce: 0.006397
2021-12-13 00:57:35,387 iteration 4394 : loss : 0.019882, loss_ce: 0.009366
2021-12-13 00:57:36,877 iteration 4395 : loss : 0.016232, loss_ce: 0.005962
2021-12-13 00:57:38,411 iteration 4396 : loss : 0.016737, loss_ce: 0.006088
2021-12-13 00:57:39,860 iteration 4397 : loss : 0.028350, loss_ce: 0.010556
2021-12-13 00:57:41,281 iteration 4398 : loss : 0.019412, loss_ce: 0.005508
2021-12-13 00:57:42,726 iteration 4399 : loss : 0.014180, loss_ce: 0.004806
2021-12-13 00:57:44,144 iteration 4400 : loss : 0.012730, loss_ce: 0.005138
2021-12-13 00:57:45,572 iteration 4401 : loss : 0.016914, loss_ce: 0.007911
2021-12-13 00:57:46,966 iteration 4402 : loss : 0.015121, loss_ce: 0.004616
2021-12-13 00:57:48,419 iteration 4403 : loss : 0.024594, loss_ce: 0.006969
 65%|█████████████████▍         | 259/400 [1:55:57<1:00:13, 25.63s/it]2021-12-13 00:57:49,862 iteration 4404 : loss : 0.012708, loss_ce: 0.005866
2021-12-13 00:57:51,345 iteration 4405 : loss : 0.014508, loss_ce: 0.004251
2021-12-13 00:57:52,802 iteration 4406 : loss : 0.016607, loss_ce: 0.005704
2021-12-13 00:57:54,185 iteration 4407 : loss : 0.015703, loss_ce: 0.005462
2021-12-13 00:57:55,554 iteration 4408 : loss : 0.019596, loss_ce: 0.004874
2021-12-13 00:57:57,010 iteration 4409 : loss : 0.012950, loss_ce: 0.004827
2021-12-13 00:57:58,471 iteration 4410 : loss : 0.037989, loss_ce: 0.012142
2021-12-13 00:57:59,981 iteration 4411 : loss : 0.013162, loss_ce: 0.005871
2021-12-13 00:58:01,371 iteration 4412 : loss : 0.023690, loss_ce: 0.008995
2021-12-13 00:58:02,883 iteration 4413 : loss : 0.022137, loss_ce: 0.006120
2021-12-13 00:58:04,249 iteration 4414 : loss : 0.020571, loss_ce: 0.006604
2021-12-13 00:58:05,714 iteration 4415 : loss : 0.017138, loss_ce: 0.007226
2021-12-13 00:58:07,130 iteration 4416 : loss : 0.016666, loss_ce: 0.004170
2021-12-13 00:58:08,579 iteration 4417 : loss : 0.017360, loss_ce: 0.005376
2021-12-13 00:58:10,031 iteration 4418 : loss : 0.016192, loss_ce: 0.007197
2021-12-13 00:58:11,489 iteration 4419 : loss : 0.018148, loss_ce: 0.005772
2021-12-13 00:58:11,489 Training Data Eval:
2021-12-13 00:58:18,918   Average segmentation loss on training set: 0.0129
2021-12-13 00:58:18,919 Validation Data Eval:
2021-12-13 00:58:21,506   Average segmentation loss on validation set: 0.1194
2021-12-13 00:58:22,922 iteration 4420 : loss : 0.011698, loss_ce: 0.004721
 65%|█████████████████▌         | 260/400 [1:56:32<1:06:00, 28.29s/it]2021-12-13 00:58:24,433 iteration 4421 : loss : 0.013262, loss_ce: 0.004012
2021-12-13 00:58:25,931 iteration 4422 : loss : 0.016118, loss_ce: 0.005791
2021-12-13 00:58:27,472 iteration 4423 : loss : 0.019934, loss_ce: 0.007666
2021-12-13 00:58:28,969 iteration 4424 : loss : 0.023787, loss_ce: 0.008179
2021-12-13 00:58:30,360 iteration 4425 : loss : 0.013965, loss_ce: 0.004755
2021-12-13 00:58:31,855 iteration 4426 : loss : 0.015565, loss_ce: 0.005496
2021-12-13 00:58:33,331 iteration 4427 : loss : 0.024484, loss_ce: 0.006913
2021-12-13 00:58:34,824 iteration 4428 : loss : 0.017300, loss_ce: 0.006141
2021-12-13 00:58:36,335 iteration 4429 : loss : 0.027054, loss_ce: 0.009258
2021-12-13 00:58:37,764 iteration 4430 : loss : 0.021951, loss_ce: 0.007141
2021-12-13 00:58:39,195 iteration 4431 : loss : 0.018691, loss_ce: 0.007370
2021-12-13 00:58:40,631 iteration 4432 : loss : 0.014012, loss_ce: 0.005275
2021-12-13 00:58:42,069 iteration 4433 : loss : 0.016017, loss_ce: 0.006245
2021-12-13 00:58:43,505 iteration 4434 : loss : 0.015411, loss_ce: 0.005307
2021-12-13 00:58:44,991 iteration 4435 : loss : 0.019646, loss_ce: 0.007453
2021-12-13 00:58:46,549 iteration 4436 : loss : 0.027811, loss_ce: 0.012728
2021-12-13 00:58:47,944 iteration 4437 : loss : 0.016548, loss_ce: 0.006037
 65%|█████████████████▌         | 261/400 [1:56:57<1:03:15, 27.31s/it]2021-12-13 00:58:49,486 iteration 4438 : loss : 0.015136, loss_ce: 0.004488
2021-12-13 00:58:50,886 iteration 4439 : loss : 0.028142, loss_ce: 0.010262
2021-12-13 00:58:52,365 iteration 4440 : loss : 0.024200, loss_ce: 0.007885
2021-12-13 00:58:53,840 iteration 4441 : loss : 0.017252, loss_ce: 0.008091
2021-12-13 00:58:55,227 iteration 4442 : loss : 0.014275, loss_ce: 0.006198
2021-12-13 00:58:56,669 iteration 4443 : loss : 0.016368, loss_ce: 0.006852
2021-12-13 00:58:58,082 iteration 4444 : loss : 0.019323, loss_ce: 0.006267
2021-12-13 00:58:59,547 iteration 4445 : loss : 0.019264, loss_ce: 0.006587
2021-12-13 00:59:01,038 iteration 4446 : loss : 0.014947, loss_ce: 0.005762
2021-12-13 00:59:02,521 iteration 4447 : loss : 0.025400, loss_ce: 0.009287
2021-12-13 00:59:03,971 iteration 4448 : loss : 0.017260, loss_ce: 0.004150
2021-12-13 00:59:05,442 iteration 4449 : loss : 0.019457, loss_ce: 0.008827
2021-12-13 00:59:06,954 iteration 4450 : loss : 0.017407, loss_ce: 0.006349
2021-12-13 00:59:08,345 iteration 4451 : loss : 0.017819, loss_ce: 0.006277
2021-12-13 00:59:09,810 iteration 4452 : loss : 0.016910, loss_ce: 0.006500
2021-12-13 00:59:11,348 iteration 4453 : loss : 0.020768, loss_ce: 0.008956
2021-12-13 00:59:12,830 iteration 4454 : loss : 0.020188, loss_ce: 0.007980
 66%|█████████████████▋         | 262/400 [1:57:22<1:01:08, 26.58s/it]2021-12-13 00:59:14,394 iteration 4455 : loss : 0.017225, loss_ce: 0.005742
2021-12-13 00:59:15,849 iteration 4456 : loss : 0.016651, loss_ce: 0.007560
2021-12-13 00:59:17,223 iteration 4457 : loss : 0.012839, loss_ce: 0.006185
2021-12-13 00:59:18,708 iteration 4458 : loss : 0.021124, loss_ce: 0.009380
2021-12-13 00:59:20,106 iteration 4459 : loss : 0.013081, loss_ce: 0.005338
2021-12-13 00:59:21,553 iteration 4460 : loss : 0.014610, loss_ce: 0.005081
2021-12-13 00:59:22,961 iteration 4461 : loss : 0.015682, loss_ce: 0.007171
2021-12-13 00:59:24,384 iteration 4462 : loss : 0.012601, loss_ce: 0.005034
2021-12-13 00:59:25,782 iteration 4463 : loss : 0.015300, loss_ce: 0.004970
2021-12-13 00:59:27,181 iteration 4464 : loss : 0.018340, loss_ce: 0.007995
2021-12-13 00:59:28,653 iteration 4465 : loss : 0.018076, loss_ce: 0.007125
2021-12-13 00:59:30,122 iteration 4466 : loss : 0.029306, loss_ce: 0.007418
2021-12-13 00:59:31,571 iteration 4467 : loss : 0.013569, loss_ce: 0.004859
2021-12-13 00:59:33,010 iteration 4468 : loss : 0.020060, loss_ce: 0.007014
2021-12-13 00:59:34,412 iteration 4469 : loss : 0.018540, loss_ce: 0.004545
2021-12-13 00:59:35,887 iteration 4470 : loss : 0.019876, loss_ce: 0.006260
2021-12-13 00:59:37,378 iteration 4471 : loss : 0.014512, loss_ce: 0.004396
 66%|███████████████████          | 263/400 [1:57:46<59:18, 25.97s/it]2021-12-13 00:59:38,827 iteration 4472 : loss : 0.019020, loss_ce: 0.007865
2021-12-13 00:59:40,254 iteration 4473 : loss : 0.013984, loss_ce: 0.005394
2021-12-13 00:59:41,723 iteration 4474 : loss : 0.014586, loss_ce: 0.005168
2021-12-13 00:59:43,129 iteration 4475 : loss : 0.012799, loss_ce: 0.005267
2021-12-13 00:59:44,488 iteration 4476 : loss : 0.012495, loss_ce: 0.004198
2021-12-13 00:59:45,945 iteration 4477 : loss : 0.016527, loss_ce: 0.006031
2021-12-13 00:59:47,403 iteration 4478 : loss : 0.023433, loss_ce: 0.006701
2021-12-13 00:59:48,852 iteration 4479 : loss : 0.016806, loss_ce: 0.003957
2021-12-13 00:59:50,249 iteration 4480 : loss : 0.012163, loss_ce: 0.005188
2021-12-13 00:59:51,645 iteration 4481 : loss : 0.011990, loss_ce: 0.004845
2021-12-13 00:59:53,143 iteration 4482 : loss : 0.020581, loss_ce: 0.007474
2021-12-13 00:59:54,674 iteration 4483 : loss : 0.020477, loss_ce: 0.007140
2021-12-13 00:59:56,170 iteration 4484 : loss : 0.016369, loss_ce: 0.005105
2021-12-13 00:59:57,596 iteration 4485 : loss : 0.012477, loss_ce: 0.003827
2021-12-13 00:59:59,148 iteration 4486 : loss : 0.019122, loss_ce: 0.008077
2021-12-13 01:00:00,549 iteration 4487 : loss : 0.015245, loss_ce: 0.006559
2021-12-13 01:00:01,970 iteration 4488 : loss : 0.013899, loss_ce: 0.006016
 66%|███████████████████▏         | 264/400 [1:58:11<57:56, 25.56s/it]2021-12-13 01:00:03,485 iteration 4489 : loss : 0.018483, loss_ce: 0.006913
2021-12-13 01:00:04,939 iteration 4490 : loss : 0.013342, loss_ce: 0.004933
2021-12-13 01:00:06,456 iteration 4491 : loss : 0.028401, loss_ce: 0.010786
2021-12-13 01:00:07,920 iteration 4492 : loss : 0.016277, loss_ce: 0.005509
2021-12-13 01:00:09,426 iteration 4493 : loss : 0.023214, loss_ce: 0.006606
2021-12-13 01:00:10,790 iteration 4494 : loss : 0.016044, loss_ce: 0.006147
2021-12-13 01:00:12,264 iteration 4495 : loss : 0.019684, loss_ce: 0.009163
2021-12-13 01:00:13,743 iteration 4496 : loss : 0.020069, loss_ce: 0.005485
2021-12-13 01:00:15,138 iteration 4497 : loss : 0.014586, loss_ce: 0.003981
2021-12-13 01:00:16,663 iteration 4498 : loss : 0.026027, loss_ce: 0.012215
2021-12-13 01:00:18,221 iteration 4499 : loss : 0.020191, loss_ce: 0.009340
2021-12-13 01:00:19,650 iteration 4500 : loss : 0.016548, loss_ce: 0.007348
2021-12-13 01:00:21,040 iteration 4501 : loss : 0.019805, loss_ce: 0.006591
2021-12-13 01:00:22,433 iteration 4502 : loss : 0.015140, loss_ce: 0.006315
2021-12-13 01:00:23,940 iteration 4503 : loss : 0.016640, loss_ce: 0.006989
2021-12-13 01:00:25,375 iteration 4504 : loss : 0.014043, loss_ce: 0.004182
2021-12-13 01:00:25,375 Training Data Eval:
2021-12-13 01:00:32,801   Average segmentation loss on training set: 0.0309
2021-12-13 01:00:32,802 Validation Data Eval:
2021-12-13 01:00:35,405   Average segmentation loss on validation set: 0.0843
2021-12-13 01:00:36,794 iteration 4505 : loss : 0.013439, loss_ce: 0.005166
 66%|█████████████████▉         | 265/400 [1:58:46<1:03:45, 28.34s/it]2021-12-13 01:00:38,331 iteration 4506 : loss : 0.023650, loss_ce: 0.007229
2021-12-13 01:00:39,743 iteration 4507 : loss : 0.015820, loss_ce: 0.005111
2021-12-13 01:00:41,236 iteration 4508 : loss : 0.025395, loss_ce: 0.006338
2021-12-13 01:00:42,699 iteration 4509 : loss : 0.018961, loss_ce: 0.005813
2021-12-13 01:00:44,152 iteration 4510 : loss : 0.014376, loss_ce: 0.005364
2021-12-13 01:00:45,566 iteration 4511 : loss : 0.016848, loss_ce: 0.005833
2021-12-13 01:00:46,999 iteration 4512 : loss : 0.012188, loss_ce: 0.004965
2021-12-13 01:00:48,458 iteration 4513 : loss : 0.014531, loss_ce: 0.006790
2021-12-13 01:00:49,848 iteration 4514 : loss : 0.016682, loss_ce: 0.005980
2021-12-13 01:00:51,280 iteration 4515 : loss : 0.019805, loss_ce: 0.007086
2021-12-13 01:00:52,828 iteration 4516 : loss : 0.022360, loss_ce: 0.008586
2021-12-13 01:00:54,256 iteration 4517 : loss : 0.017602, loss_ce: 0.005820
2021-12-13 01:00:55,730 iteration 4518 : loss : 0.019148, loss_ce: 0.005195
2021-12-13 01:00:57,180 iteration 4519 : loss : 0.020212, loss_ce: 0.008701
2021-12-13 01:00:58,580 iteration 4520 : loss : 0.016313, loss_ce: 0.005199
2021-12-13 01:01:00,034 iteration 4521 : loss : 0.019084, loss_ce: 0.006162
2021-12-13 01:01:01,436 iteration 4522 : loss : 0.013674, loss_ce: 0.006452
 66%|█████████████████▉         | 266/400 [1:59:10<1:00:48, 27.23s/it]2021-12-13 01:01:02,979 iteration 4523 : loss : 0.014759, loss_ce: 0.005230
2021-12-13 01:01:04,355 iteration 4524 : loss : 0.010412, loss_ce: 0.004181
2021-12-13 01:01:05,862 iteration 4525 : loss : 0.027088, loss_ce: 0.007989
2021-12-13 01:01:07,314 iteration 4526 : loss : 0.013898, loss_ce: 0.005416
2021-12-13 01:01:08,756 iteration 4527 : loss : 0.028797, loss_ce: 0.013346
2021-12-13 01:01:10,249 iteration 4528 : loss : 0.020375, loss_ce: 0.007336
2021-12-13 01:01:11,680 iteration 4529 : loss : 0.021512, loss_ce: 0.007766
2021-12-13 01:01:13,150 iteration 4530 : loss : 0.018028, loss_ce: 0.007126
2021-12-13 01:01:14,551 iteration 4531 : loss : 0.014282, loss_ce: 0.006198
2021-12-13 01:01:16,036 iteration 4532 : loss : 0.018854, loss_ce: 0.008888
2021-12-13 01:01:17,544 iteration 4533 : loss : 0.039035, loss_ce: 0.016117
2021-12-13 01:01:19,101 iteration 4534 : loss : 0.020754, loss_ce: 0.006969
2021-12-13 01:01:20,477 iteration 4535 : loss : 0.017180, loss_ce: 0.005586
2021-12-13 01:01:21,953 iteration 4536 : loss : 0.015025, loss_ce: 0.006785
2021-12-13 01:01:23,475 iteration 4537 : loss : 0.026201, loss_ce: 0.010150
2021-12-13 01:01:24,895 iteration 4538 : loss : 0.014833, loss_ce: 0.005538
2021-12-13 01:01:26,363 iteration 4539 : loss : 0.021794, loss_ce: 0.008572
 67%|███████████████████▎         | 267/400 [1:59:35<58:49, 26.54s/it]2021-12-13 01:01:27,884 iteration 4540 : loss : 0.017533, loss_ce: 0.004902
2021-12-13 01:01:29,264 iteration 4541 : loss : 0.012712, loss_ce: 0.004548
2021-12-13 01:01:30,715 iteration 4542 : loss : 0.013508, loss_ce: 0.003911
2021-12-13 01:01:32,080 iteration 4543 : loss : 0.014279, loss_ce: 0.005170
2021-12-13 01:01:33,566 iteration 4544 : loss : 0.024019, loss_ce: 0.009673
2021-12-13 01:01:35,073 iteration 4545 : loss : 0.023982, loss_ce: 0.011257
2021-12-13 01:01:36,542 iteration 4546 : loss : 0.018991, loss_ce: 0.006866
2021-12-13 01:01:38,000 iteration 4547 : loss : 0.014459, loss_ce: 0.007277
2021-12-13 01:01:39,441 iteration 4548 : loss : 0.025366, loss_ce: 0.010117
2021-12-13 01:01:40,969 iteration 4549 : loss : 0.035693, loss_ce: 0.012555
2021-12-13 01:01:42,475 iteration 4550 : loss : 0.028200, loss_ce: 0.008317
2021-12-13 01:01:43,953 iteration 4551 : loss : 0.020953, loss_ce: 0.004943
2021-12-13 01:01:45,322 iteration 4552 : loss : 0.013401, loss_ce: 0.005391
2021-12-13 01:01:46,739 iteration 4553 : loss : 0.019046, loss_ce: 0.007410
2021-12-13 01:01:48,179 iteration 4554 : loss : 0.016332, loss_ce: 0.006038
2021-12-13 01:01:49,671 iteration 4555 : loss : 0.020294, loss_ce: 0.007435
2021-12-13 01:01:51,102 iteration 4556 : loss : 0.014816, loss_ce: 0.006984
 67%|███████████████████▍         | 268/400 [2:00:00<57:11, 26.00s/it]2021-12-13 01:01:52,609 iteration 4557 : loss : 0.017060, loss_ce: 0.007584
2021-12-13 01:01:54,113 iteration 4558 : loss : 0.025511, loss_ce: 0.010360
2021-12-13 01:01:55,548 iteration 4559 : loss : 0.044660, loss_ce: 0.010499
2021-12-13 01:01:56,979 iteration 4560 : loss : 0.018559, loss_ce: 0.005622
2021-12-13 01:01:58,428 iteration 4561 : loss : 0.016054, loss_ce: 0.003468
2021-12-13 01:01:59,881 iteration 4562 : loss : 0.025988, loss_ce: 0.009707
2021-12-13 01:02:01,297 iteration 4563 : loss : 0.016591, loss_ce: 0.005628
2021-12-13 01:02:02,755 iteration 4564 : loss : 0.018503, loss_ce: 0.005121
2021-12-13 01:02:04,165 iteration 4565 : loss : 0.021088, loss_ce: 0.008206
2021-12-13 01:02:05,546 iteration 4566 : loss : 0.015779, loss_ce: 0.007133
2021-12-13 01:02:06,998 iteration 4567 : loss : 0.032179, loss_ce: 0.012508
2021-12-13 01:02:08,429 iteration 4568 : loss : 0.019987, loss_ce: 0.006952
2021-12-13 01:02:09,867 iteration 4569 : loss : 0.015807, loss_ce: 0.006432
2021-12-13 01:02:11,263 iteration 4570 : loss : 0.019834, loss_ce: 0.008080
2021-12-13 01:02:12,672 iteration 4571 : loss : 0.020423, loss_ce: 0.010381
2021-12-13 01:02:14,090 iteration 4572 : loss : 0.016098, loss_ce: 0.004924
2021-12-13 01:02:15,530 iteration 4573 : loss : 0.019315, loss_ce: 0.008287
 67%|███████████████████▌         | 269/400 [2:00:24<55:44, 25.53s/it]2021-12-13 01:02:17,004 iteration 4574 : loss : 0.018054, loss_ce: 0.005666
2021-12-13 01:02:18,406 iteration 4575 : loss : 0.012802, loss_ce: 0.005157
2021-12-13 01:02:19,884 iteration 4576 : loss : 0.016776, loss_ce: 0.010323
2021-12-13 01:02:21,380 iteration 4577 : loss : 0.019415, loss_ce: 0.007030
2021-12-13 01:02:22,831 iteration 4578 : loss : 0.017612, loss_ce: 0.006886
2021-12-13 01:02:24,261 iteration 4579 : loss : 0.014684, loss_ce: 0.006871
2021-12-13 01:02:25,690 iteration 4580 : loss : 0.017271, loss_ce: 0.007192
2021-12-13 01:02:27,222 iteration 4581 : loss : 0.018800, loss_ce: 0.006117
2021-12-13 01:02:28,668 iteration 4582 : loss : 0.014097, loss_ce: 0.006341
2021-12-13 01:02:30,110 iteration 4583 : loss : 0.017354, loss_ce: 0.005881
2021-12-13 01:02:31,515 iteration 4584 : loss : 0.019827, loss_ce: 0.007371
2021-12-13 01:02:32,970 iteration 4585 : loss : 0.024219, loss_ce: 0.007537
2021-12-13 01:02:34,376 iteration 4586 : loss : 0.014813, loss_ce: 0.006629
2021-12-13 01:02:35,897 iteration 4587 : loss : 0.035994, loss_ce: 0.012103
2021-12-13 01:02:37,320 iteration 4588 : loss : 0.014575, loss_ce: 0.003683
2021-12-13 01:02:38,763 iteration 4589 : loss : 0.017770, loss_ce: 0.007798
2021-12-13 01:02:38,763 Training Data Eval:
2021-12-13 01:02:46,173   Average segmentation loss on training set: 0.0240
2021-12-13 01:02:46,174 Validation Data Eval:
2021-12-13 01:02:48,755   Average segmentation loss on validation set: 0.0786
2021-12-13 01:02:50,319 iteration 4590 : loss : 0.019547, loss_ce: 0.006588
 68%|██████████████████▏        | 270/400 [2:00:59<1:01:19, 28.30s/it]2021-12-13 01:02:51,739 iteration 4591 : loss : 0.011180, loss_ce: 0.003369
2021-12-13 01:02:53,179 iteration 4592 : loss : 0.019053, loss_ce: 0.005998
2021-12-13 01:02:54,555 iteration 4593 : loss : 0.014866, loss_ce: 0.004383
2021-12-13 01:02:55,985 iteration 4594 : loss : 0.014925, loss_ce: 0.006652
2021-12-13 01:02:57,448 iteration 4595 : loss : 0.026797, loss_ce: 0.005983
2021-12-13 01:02:58,972 iteration 4596 : loss : 0.029149, loss_ce: 0.010214
2021-12-13 01:03:00,396 iteration 4597 : loss : 0.016195, loss_ce: 0.007095
2021-12-13 01:03:01,762 iteration 4598 : loss : 0.017243, loss_ce: 0.007833
2021-12-13 01:03:03,186 iteration 4599 : loss : 0.025255, loss_ce: 0.008198
2021-12-13 01:03:04,693 iteration 4600 : loss : 0.018978, loss_ce: 0.009038
2021-12-13 01:03:06,227 iteration 4601 : loss : 0.020261, loss_ce: 0.010325
2021-12-13 01:03:07,577 iteration 4602 : loss : 0.014276, loss_ce: 0.005393
2021-12-13 01:03:08,960 iteration 4603 : loss : 0.015123, loss_ce: 0.006899
2021-12-13 01:03:10,436 iteration 4604 : loss : 0.021657, loss_ce: 0.007179
2021-12-13 01:03:11,908 iteration 4605 : loss : 0.021713, loss_ce: 0.005732
2021-12-13 01:03:13,419 iteration 4606 : loss : 0.021609, loss_ce: 0.006382
2021-12-13 01:03:14,796 iteration 4607 : loss : 0.013667, loss_ce: 0.007346
 68%|███████████████████▋         | 271/400 [2:01:24<58:23, 27.16s/it]2021-12-13 01:03:16,307 iteration 4608 : loss : 0.021919, loss_ce: 0.007365
2021-12-13 01:03:17,810 iteration 4609 : loss : 0.026475, loss_ce: 0.012793
2021-12-13 01:03:19,292 iteration 4610 : loss : 0.021699, loss_ce: 0.005473
2021-12-13 01:03:20,731 iteration 4611 : loss : 0.020310, loss_ce: 0.008582
2021-12-13 01:03:22,097 iteration 4612 : loss : 0.013032, loss_ce: 0.004636
2021-12-13 01:03:23,563 iteration 4613 : loss : 0.018425, loss_ce: 0.008372
2021-12-13 01:03:25,033 iteration 4614 : loss : 0.036323, loss_ce: 0.016747
2021-12-13 01:03:26,517 iteration 4615 : loss : 0.028425, loss_ce: 0.009487
2021-12-13 01:03:28,033 iteration 4616 : loss : 0.018327, loss_ce: 0.006305
2021-12-13 01:03:29,420 iteration 4617 : loss : 0.016253, loss_ce: 0.006602
2021-12-13 01:03:30,915 iteration 4618 : loss : 0.021679, loss_ce: 0.007602
2021-12-13 01:03:32,414 iteration 4619 : loss : 0.020297, loss_ce: 0.007896
2021-12-13 01:03:33,906 iteration 4620 : loss : 0.020575, loss_ce: 0.006355
2021-12-13 01:03:35,417 iteration 4621 : loss : 0.020685, loss_ce: 0.007317
2021-12-13 01:03:36,859 iteration 4622 : loss : 0.014641, loss_ce: 0.004724
2021-12-13 01:03:38,277 iteration 4623 : loss : 0.029405, loss_ce: 0.010320
2021-12-13 01:03:39,721 iteration 4624 : loss : 0.018142, loss_ce: 0.008191
 68%|███████████████████▋         | 272/400 [2:01:48<56:30, 26.49s/it]2021-12-13 01:03:41,203 iteration 4625 : loss : 0.018657, loss_ce: 0.007701
2021-12-13 01:03:42,626 iteration 4626 : loss : 0.012886, loss_ce: 0.004361
2021-12-13 01:03:44,081 iteration 4627 : loss : 0.037169, loss_ce: 0.012992
2021-12-13 01:03:45,488 iteration 4628 : loss : 0.019556, loss_ce: 0.006698
2021-12-13 01:03:46,887 iteration 4629 : loss : 0.017788, loss_ce: 0.007383
2021-12-13 01:03:48,308 iteration 4630 : loss : 0.024296, loss_ce: 0.009188
2021-12-13 01:03:49,825 iteration 4631 : loss : 0.031880, loss_ce: 0.013609
2021-12-13 01:03:51,292 iteration 4632 : loss : 0.042634, loss_ce: 0.019043
2021-12-13 01:03:52,749 iteration 4633 : loss : 0.028405, loss_ce: 0.009454
2021-12-13 01:03:54,109 iteration 4634 : loss : 0.015987, loss_ce: 0.007611
2021-12-13 01:03:55,581 iteration 4635 : loss : 0.032845, loss_ce: 0.010541
2021-12-13 01:03:57,041 iteration 4636 : loss : 0.031917, loss_ce: 0.010451
2021-12-13 01:03:58,485 iteration 4637 : loss : 0.019875, loss_ce: 0.006888
2021-12-13 01:03:59,957 iteration 4638 : loss : 0.029949, loss_ce: 0.014297
2021-12-13 01:04:01,478 iteration 4639 : loss : 0.032305, loss_ce: 0.012794
2021-12-13 01:04:02,953 iteration 4640 : loss : 0.029840, loss_ce: 0.011718
2021-12-13 01:04:04,378 iteration 4641 : loss : 0.015703, loss_ce: 0.007131
 68%|███████████████████▊         | 273/400 [2:02:13<54:54, 25.94s/it]2021-12-13 01:04:05,902 iteration 4642 : loss : 0.035447, loss_ce: 0.011152
2021-12-13 01:04:07,366 iteration 4643 : loss : 0.043181, loss_ce: 0.022646
2021-12-13 01:04:08,836 iteration 4644 : loss : 0.022504, loss_ce: 0.009635
2021-12-13 01:04:10,436 iteration 4645 : loss : 0.028569, loss_ce: 0.013291
2021-12-13 01:04:11,847 iteration 4646 : loss : 0.016810, loss_ce: 0.007127
2021-12-13 01:04:13,263 iteration 4647 : loss : 0.021298, loss_ce: 0.008298
2021-12-13 01:04:14,627 iteration 4648 : loss : 0.016204, loss_ce: 0.006350
2021-12-13 01:04:16,101 iteration 4649 : loss : 0.025974, loss_ce: 0.011048
2021-12-13 01:04:17,536 iteration 4650 : loss : 0.022042, loss_ce: 0.007998
2021-12-13 01:04:18,994 iteration 4651 : loss : 0.024992, loss_ce: 0.010545
2021-12-13 01:04:20,457 iteration 4652 : loss : 0.022675, loss_ce: 0.009075
2021-12-13 01:04:21,899 iteration 4653 : loss : 0.020648, loss_ce: 0.008124
2021-12-13 01:04:23,350 iteration 4654 : loss : 0.018296, loss_ce: 0.008459
2021-12-13 01:04:24,811 iteration 4655 : loss : 0.021331, loss_ce: 0.006940
2021-12-13 01:04:26,333 iteration 4656 : loss : 0.052274, loss_ce: 0.009816
2021-12-13 01:04:27,771 iteration 4657 : loss : 0.055581, loss_ce: 0.007688
2021-12-13 01:04:29,182 iteration 4658 : loss : 0.025463, loss_ce: 0.005966
 68%|███████████████████▊         | 274/400 [2:02:38<53:45, 25.60s/it]2021-12-13 01:04:30,666 iteration 4659 : loss : 0.018727, loss_ce: 0.006530
2021-12-13 01:04:32,148 iteration 4660 : loss : 0.023599, loss_ce: 0.004964
2021-12-13 01:04:33,605 iteration 4661 : loss : 0.038952, loss_ce: 0.019855
2021-12-13 01:04:35,170 iteration 4662 : loss : 0.026206, loss_ce: 0.013892
2021-12-13 01:04:36,573 iteration 4663 : loss : 0.026016, loss_ce: 0.007388
2021-12-13 01:04:38,041 iteration 4664 : loss : 0.023319, loss_ce: 0.007182
2021-12-13 01:04:39,638 iteration 4665 : loss : 0.035269, loss_ce: 0.014364
2021-12-13 01:04:41,033 iteration 4666 : loss : 0.017598, loss_ce: 0.006724
2021-12-13 01:04:42,481 iteration 4667 : loss : 0.035951, loss_ce: 0.024177
2021-12-13 01:04:43,923 iteration 4668 : loss : 0.028665, loss_ce: 0.006769
2021-12-13 01:04:45,434 iteration 4669 : loss : 0.023182, loss_ce: 0.010987
2021-12-13 01:04:46,940 iteration 4670 : loss : 0.020646, loss_ce: 0.008722
2021-12-13 01:04:48,323 iteration 4671 : loss : 0.021511, loss_ce: 0.006463
2021-12-13 01:04:49,886 iteration 4672 : loss : 0.031852, loss_ce: 0.014625
2021-12-13 01:04:51,360 iteration 4673 : loss : 0.025043, loss_ce: 0.008933
2021-12-13 01:04:52,877 iteration 4674 : loss : 0.021593, loss_ce: 0.011533
2021-12-13 01:04:52,877 Training Data Eval:
2021-12-13 01:05:00,264   Average segmentation loss on training set: 0.3056
2021-12-13 01:05:00,264 Validation Data Eval:
2021-12-13 01:05:02,853   Average segmentation loss on validation set: 0.2923
2021-12-13 01:05:04,289 iteration 4675 : loss : 0.020822, loss_ce: 0.009228
 69%|███████████████████▉         | 275/400 [2:03:13<59:16, 28.45s/it]2021-12-13 01:05:05,845 iteration 4676 : loss : 0.023429, loss_ce: 0.008334
2021-12-13 01:05:07,276 iteration 4677 : loss : 0.019024, loss_ce: 0.009123
2021-12-13 01:05:08,724 iteration 4678 : loss : 0.024950, loss_ce: 0.008498
2021-12-13 01:05:10,176 iteration 4679 : loss : 0.019914, loss_ce: 0.011483
2021-12-13 01:05:11,591 iteration 4680 : loss : 0.017508, loss_ce: 0.006364
2021-12-13 01:05:13,054 iteration 4681 : loss : 0.033021, loss_ce: 0.009885
2021-12-13 01:05:14,451 iteration 4682 : loss : 0.023723, loss_ce: 0.005540
2021-12-13 01:05:15,901 iteration 4683 : loss : 0.022966, loss_ce: 0.009638
2021-12-13 01:05:17,396 iteration 4684 : loss : 0.020918, loss_ce: 0.009951
2021-12-13 01:05:18,854 iteration 4685 : loss : 0.015439, loss_ce: 0.006918
2021-12-13 01:05:20,232 iteration 4686 : loss : 0.018539, loss_ce: 0.006667
2021-12-13 01:05:21,740 iteration 4687 : loss : 0.017255, loss_ce: 0.007079
2021-12-13 01:05:23,257 iteration 4688 : loss : 0.023486, loss_ce: 0.007304
2021-12-13 01:05:24,789 iteration 4689 : loss : 0.024750, loss_ce: 0.009232
2021-12-13 01:05:26,225 iteration 4690 : loss : 0.013744, loss_ce: 0.003440
2021-12-13 01:05:27,623 iteration 4691 : loss : 0.021900, loss_ce: 0.007398
2021-12-13 01:05:29,053 iteration 4692 : loss : 0.021934, loss_ce: 0.008338
 69%|████████████████████         | 276/400 [2:03:38<56:30, 27.35s/it]2021-12-13 01:05:30,571 iteration 4693 : loss : 0.015846, loss_ce: 0.006016
2021-12-13 01:05:31,992 iteration 4694 : loss : 0.023467, loss_ce: 0.006948
2021-12-13 01:05:33,502 iteration 4695 : loss : 0.025571, loss_ce: 0.009749
2021-12-13 01:05:34,982 iteration 4696 : loss : 0.018166, loss_ce: 0.007255
2021-12-13 01:05:36,491 iteration 4697 : loss : 0.029383, loss_ce: 0.011778
2021-12-13 01:05:37,851 iteration 4698 : loss : 0.017154, loss_ce: 0.006948
2021-12-13 01:05:39,291 iteration 4699 : loss : 0.018077, loss_ce: 0.006441
2021-12-13 01:05:40,741 iteration 4700 : loss : 0.029308, loss_ce: 0.009330
2021-12-13 01:05:42,187 iteration 4701 : loss : 0.018597, loss_ce: 0.008031
2021-12-13 01:05:43,550 iteration 4702 : loss : 0.018043, loss_ce: 0.006425
2021-12-13 01:05:45,030 iteration 4703 : loss : 0.017829, loss_ce: 0.005969
2021-12-13 01:05:46,482 iteration 4704 : loss : 0.024225, loss_ce: 0.006629
2021-12-13 01:05:47,871 iteration 4705 : loss : 0.015809, loss_ce: 0.005762
2021-12-13 01:05:49,284 iteration 4706 : loss : 0.018095, loss_ce: 0.007476
2021-12-13 01:05:50,797 iteration 4707 : loss : 0.017902, loss_ce: 0.007529
2021-12-13 01:05:52,233 iteration 4708 : loss : 0.032278, loss_ce: 0.006644
2021-12-13 01:05:53,647 iteration 4709 : loss : 0.015047, loss_ce: 0.005400
 69%|████████████████████         | 277/400 [2:04:02<54:21, 26.52s/it]2021-12-13 01:05:55,192 iteration 4710 : loss : 0.024269, loss_ce: 0.007464
2021-12-13 01:05:56,608 iteration 4711 : loss : 0.020169, loss_ce: 0.008640
2021-12-13 01:05:58,067 iteration 4712 : loss : 0.015751, loss_ce: 0.005876
2021-12-13 01:05:59,495 iteration 4713 : loss : 0.012897, loss_ce: 0.004726
2021-12-13 01:06:00,910 iteration 4714 : loss : 0.013428, loss_ce: 0.005713
2021-12-13 01:06:02,430 iteration 4715 : loss : 0.022455, loss_ce: 0.006977
2021-12-13 01:06:03,870 iteration 4716 : loss : 0.013051, loss_ce: 0.005268
2021-12-13 01:06:05,309 iteration 4717 : loss : 0.022230, loss_ce: 0.007265
2021-12-13 01:06:06,730 iteration 4718 : loss : 0.014031, loss_ce: 0.004872
2021-12-13 01:06:08,148 iteration 4719 : loss : 0.015761, loss_ce: 0.005336
2021-12-13 01:06:09,654 iteration 4720 : loss : 0.019487, loss_ce: 0.007632
2021-12-13 01:06:11,102 iteration 4721 : loss : 0.013664, loss_ce: 0.004108
2021-12-13 01:06:12,543 iteration 4722 : loss : 0.017116, loss_ce: 0.006828
2021-12-13 01:06:14,017 iteration 4723 : loss : 0.020145, loss_ce: 0.005113
2021-12-13 01:06:15,413 iteration 4724 : loss : 0.014667, loss_ce: 0.007185
2021-12-13 01:06:16,842 iteration 4725 : loss : 0.018789, loss_ce: 0.007431
2021-12-13 01:06:18,244 iteration 4726 : loss : 0.018046, loss_ce: 0.005912
 70%|████████████████████▏        | 278/400 [2:04:27<52:45, 25.94s/it]2021-12-13 01:06:19,727 iteration 4727 : loss : 0.017301, loss_ce: 0.006136
2021-12-13 01:06:21,198 iteration 4728 : loss : 0.018550, loss_ce: 0.006928
2021-12-13 01:06:22,678 iteration 4729 : loss : 0.013648, loss_ce: 0.004015
2021-12-13 01:06:24,135 iteration 4730 : loss : 0.016502, loss_ce: 0.006493
2021-12-13 01:06:25,579 iteration 4731 : loss : 0.022442, loss_ce: 0.006651
2021-12-13 01:06:26,964 iteration 4732 : loss : 0.014617, loss_ce: 0.006091
2021-12-13 01:06:28,495 iteration 4733 : loss : 0.025094, loss_ce: 0.011632
2021-12-13 01:06:29,927 iteration 4734 : loss : 0.014368, loss_ce: 0.005232
2021-12-13 01:06:31,298 iteration 4735 : loss : 0.013793, loss_ce: 0.005421
2021-12-13 01:06:32,778 iteration 4736 : loss : 0.021263, loss_ce: 0.008100
2021-12-13 01:06:34,235 iteration 4737 : loss : 0.014918, loss_ce: 0.006986
2021-12-13 01:06:35,786 iteration 4738 : loss : 0.023344, loss_ce: 0.007388
2021-12-13 01:06:37,257 iteration 4739 : loss : 0.010452, loss_ce: 0.003802
2021-12-13 01:06:38,711 iteration 4740 : loss : 0.013891, loss_ce: 0.003230
2021-12-13 01:06:40,146 iteration 4741 : loss : 0.019967, loss_ce: 0.009529
2021-12-13 01:06:41,607 iteration 4742 : loss : 0.018471, loss_ce: 0.007882
2021-12-13 01:06:43,215 iteration 4743 : loss : 0.035567, loss_ce: 0.017682
 70%|████████████████████▏        | 279/400 [2:04:52<51:43, 25.65s/it]2021-12-13 01:06:44,746 iteration 4744 : loss : 0.015304, loss_ce: 0.005333
2021-12-13 01:06:46,201 iteration 4745 : loss : 0.016789, loss_ce: 0.006982
2021-12-13 01:06:47,645 iteration 4746 : loss : 0.015902, loss_ce: 0.004241
2021-12-13 01:06:49,037 iteration 4747 : loss : 0.010812, loss_ce: 0.005137
2021-12-13 01:06:50,588 iteration 4748 : loss : 0.019553, loss_ce: 0.007220
2021-12-13 01:06:51,983 iteration 4749 : loss : 0.017616, loss_ce: 0.007631
2021-12-13 01:06:53,452 iteration 4750 : loss : 0.020673, loss_ce: 0.005882
2021-12-13 01:06:54,926 iteration 4751 : loss : 0.021737, loss_ce: 0.010243
2021-12-13 01:06:56,368 iteration 4752 : loss : 0.017114, loss_ce: 0.004050
2021-12-13 01:06:57,789 iteration 4753 : loss : 0.011492, loss_ce: 0.003648
2021-12-13 01:06:59,251 iteration 4754 : loss : 0.020764, loss_ce: 0.009191
2021-12-13 01:07:00,778 iteration 4755 : loss : 0.024962, loss_ce: 0.005727
2021-12-13 01:07:02,254 iteration 4756 : loss : 0.033147, loss_ce: 0.013131
2021-12-13 01:07:03,708 iteration 4757 : loss : 0.014464, loss_ce: 0.007358
2021-12-13 01:07:05,228 iteration 4758 : loss : 0.018078, loss_ce: 0.005649
2021-12-13 01:07:06,682 iteration 4759 : loss : 0.020824, loss_ce: 0.011352
2021-12-13 01:07:06,683 Training Data Eval:
2021-12-13 01:07:14,129   Average segmentation loss on training set: 0.0125
2021-12-13 01:07:14,130 Validation Data Eval:
2021-12-13 01:07:16,716   Average segmentation loss on validation set: 0.0744
2021-12-13 01:07:18,201 iteration 4760 : loss : 0.018906, loss_ce: 0.005708
 70%|████████████████████▎        | 280/400 [2:05:27<56:54, 28.45s/it]2021-12-13 01:07:19,642 iteration 4761 : loss : 0.015189, loss_ce: 0.004962
2021-12-13 01:07:21,178 iteration 4762 : loss : 0.034379, loss_ce: 0.011135
2021-12-13 01:07:22,648 iteration 4763 : loss : 0.019256, loss_ce: 0.008334
2021-12-13 01:07:24,047 iteration 4764 : loss : 0.015801, loss_ce: 0.005755
2021-12-13 01:07:25,475 iteration 4765 : loss : 0.018272, loss_ce: 0.008949
2021-12-13 01:07:26,891 iteration 4766 : loss : 0.017251, loss_ce: 0.005120
2021-12-13 01:07:28,377 iteration 4767 : loss : 0.021453, loss_ce: 0.007952
2021-12-13 01:07:29,913 iteration 4768 : loss : 0.021978, loss_ce: 0.009746
2021-12-13 01:07:31,430 iteration 4769 : loss : 0.019986, loss_ce: 0.005519
2021-12-13 01:07:32,887 iteration 4770 : loss : 0.015846, loss_ce: 0.008181
2021-12-13 01:07:34,311 iteration 4771 : loss : 0.016820, loss_ce: 0.006887
2021-12-13 01:07:35,748 iteration 4772 : loss : 0.011934, loss_ce: 0.003600
2021-12-13 01:07:37,176 iteration 4773 : loss : 0.015002, loss_ce: 0.005992
2021-12-13 01:07:38,604 iteration 4774 : loss : 0.013598, loss_ce: 0.005814
2021-12-13 01:07:40,069 iteration 4775 : loss : 0.025569, loss_ce: 0.009807
2021-12-13 01:07:41,512 iteration 4776 : loss : 0.018687, loss_ce: 0.006278
2021-12-13 01:07:42,950 iteration 4777 : loss : 0.013980, loss_ce: 0.004784
 70%|████████████████████▎        | 281/400 [2:05:52<54:13, 27.34s/it]2021-12-13 01:07:44,495 iteration 4778 : loss : 0.018439, loss_ce: 0.007194
2021-12-13 01:07:45,901 iteration 4779 : loss : 0.013713, loss_ce: 0.004815
2021-12-13 01:07:47,316 iteration 4780 : loss : 0.024335, loss_ce: 0.006797
2021-12-13 01:07:48,746 iteration 4781 : loss : 0.013504, loss_ce: 0.006519
2021-12-13 01:07:50,259 iteration 4782 : loss : 0.021034, loss_ce: 0.007279
2021-12-13 01:07:51,647 iteration 4783 : loss : 0.015311, loss_ce: 0.004257
2021-12-13 01:07:53,153 iteration 4784 : loss : 0.015928, loss_ce: 0.006200
2021-12-13 01:07:54,680 iteration 4785 : loss : 0.022727, loss_ce: 0.010966
2021-12-13 01:07:56,121 iteration 4786 : loss : 0.015321, loss_ce: 0.005800
2021-12-13 01:07:57,602 iteration 4787 : loss : 0.018342, loss_ce: 0.006097
2021-12-13 01:07:59,075 iteration 4788 : loss : 0.017768, loss_ce: 0.008054
2021-12-13 01:08:00,554 iteration 4789 : loss : 0.015579, loss_ce: 0.006269
2021-12-13 01:08:02,014 iteration 4790 : loss : 0.019525, loss_ce: 0.007800
2021-12-13 01:08:03,452 iteration 4791 : loss : 0.013340, loss_ce: 0.004664
2021-12-13 01:08:04,897 iteration 4792 : loss : 0.033484, loss_ce: 0.015450
2021-12-13 01:08:06,385 iteration 4793 : loss : 0.017050, loss_ce: 0.007365
2021-12-13 01:08:07,830 iteration 4794 : loss : 0.027078, loss_ce: 0.004239
 70%|████████████████████▍        | 282/400 [2:06:17<52:18, 26.60s/it]2021-12-13 01:08:09,268 iteration 4795 : loss : 0.012901, loss_ce: 0.003999
2021-12-13 01:08:10,663 iteration 4796 : loss : 0.016633, loss_ce: 0.006314
2021-12-13 01:08:12,066 iteration 4797 : loss : 0.019171, loss_ce: 0.007015
2021-12-13 01:08:13,572 iteration 4798 : loss : 0.021998, loss_ce: 0.011148
2021-12-13 01:08:15,017 iteration 4799 : loss : 0.037814, loss_ce: 0.007411
2021-12-13 01:08:16,487 iteration 4800 : loss : 0.026474, loss_ce: 0.012830
2021-12-13 01:08:17,954 iteration 4801 : loss : 0.013637, loss_ce: 0.005734
2021-12-13 01:08:19,319 iteration 4802 : loss : 0.013476, loss_ce: 0.004174
2021-12-13 01:08:20,779 iteration 4803 : loss : 0.018870, loss_ce: 0.009087
2021-12-13 01:08:22,200 iteration 4804 : loss : 0.024777, loss_ce: 0.007360
2021-12-13 01:08:23,670 iteration 4805 : loss : 0.020952, loss_ce: 0.007370
2021-12-13 01:08:25,085 iteration 4806 : loss : 0.020529, loss_ce: 0.004955
2021-12-13 01:08:26,606 iteration 4807 : loss : 0.019019, loss_ce: 0.007173
2021-12-13 01:08:28,239 iteration 4808 : loss : 0.035119, loss_ce: 0.013771
2021-12-13 01:08:29,586 iteration 4809 : loss : 0.015289, loss_ce: 0.006441
2021-12-13 01:08:31,072 iteration 4810 : loss : 0.026041, loss_ce: 0.009901
2021-12-13 01:08:32,500 iteration 4811 : loss : 0.017563, loss_ce: 0.007533
 71%|████████████████████▌        | 283/400 [2:06:41<50:44, 26.02s/it]2021-12-13 01:08:33,956 iteration 4812 : loss : 0.019575, loss_ce: 0.006668
2021-12-13 01:08:35,419 iteration 4813 : loss : 0.019360, loss_ce: 0.006135
2021-12-13 01:08:36,813 iteration 4814 : loss : 0.015332, loss_ce: 0.007718
2021-12-13 01:08:38,257 iteration 4815 : loss : 0.018079, loss_ce: 0.006140
2021-12-13 01:08:39,672 iteration 4816 : loss : 0.018039, loss_ce: 0.006063
2021-12-13 01:08:41,013 iteration 4817 : loss : 0.013555, loss_ce: 0.004620
2021-12-13 01:08:42,505 iteration 4818 : loss : 0.028704, loss_ce: 0.011981
2021-12-13 01:08:43,975 iteration 4819 : loss : 0.016858, loss_ce: 0.005218
2021-12-13 01:08:45,476 iteration 4820 : loss : 0.020850, loss_ce: 0.008970
2021-12-13 01:08:46,902 iteration 4821 : loss : 0.015832, loss_ce: 0.007170
2021-12-13 01:08:48,372 iteration 4822 : loss : 0.015487, loss_ce: 0.004977
2021-12-13 01:08:49,787 iteration 4823 : loss : 0.017507, loss_ce: 0.006409
2021-12-13 01:08:51,291 iteration 4824 : loss : 0.014680, loss_ce: 0.005258
2021-12-13 01:08:52,725 iteration 4825 : loss : 0.011009, loss_ce: 0.003312
2021-12-13 01:08:54,151 iteration 4826 : loss : 0.019413, loss_ce: 0.005820
2021-12-13 01:08:55,703 iteration 4827 : loss : 0.037166, loss_ce: 0.013718
2021-12-13 01:08:57,209 iteration 4828 : loss : 0.023505, loss_ce: 0.009663
 71%|████████████████████▌        | 284/400 [2:07:06<49:33, 25.63s/it]2021-12-13 01:08:58,719 iteration 4829 : loss : 0.024179, loss_ce: 0.007255
2021-12-13 01:09:00,115 iteration 4830 : loss : 0.014700, loss_ce: 0.004933
2021-12-13 01:09:01,645 iteration 4831 : loss : 0.033140, loss_ce: 0.012452
2021-12-13 01:09:03,077 iteration 4832 : loss : 0.016963, loss_ce: 0.006732
2021-12-13 01:09:04,577 iteration 4833 : loss : 0.014030, loss_ce: 0.004238
2021-12-13 01:09:06,108 iteration 4834 : loss : 0.016488, loss_ce: 0.005351
2021-12-13 01:09:07,542 iteration 4835 : loss : 0.022145, loss_ce: 0.008911
2021-12-13 01:09:08,993 iteration 4836 : loss : 0.017709, loss_ce: 0.005647
2021-12-13 01:09:10,404 iteration 4837 : loss : 0.016410, loss_ce: 0.003462
2021-12-13 01:09:11,889 iteration 4838 : loss : 0.019597, loss_ce: 0.008496
2021-12-13 01:09:13,358 iteration 4839 : loss : 0.020398, loss_ce: 0.009741
2021-12-13 01:09:14,822 iteration 4840 : loss : 0.020430, loss_ce: 0.007788
2021-12-13 01:09:16,337 iteration 4841 : loss : 0.016021, loss_ce: 0.005092
2021-12-13 01:09:17,804 iteration 4842 : loss : 0.017295, loss_ce: 0.007139
2021-12-13 01:09:19,243 iteration 4843 : loss : 0.028876, loss_ce: 0.012132
2021-12-13 01:09:20,631 iteration 4844 : loss : 0.014325, loss_ce: 0.006633
2021-12-13 01:09:20,631 Training Data Eval:
2021-12-13 01:09:28,049   Average segmentation loss on training set: 0.0354
2021-12-13 01:09:28,050 Validation Data Eval:
2021-12-13 01:09:30,639   Average segmentation loss on validation set: 0.1841
2021-12-13 01:09:32,066 iteration 4845 : loss : 0.019050, loss_ce: 0.005989
 71%|████████████████████▋        | 285/400 [2:07:41<54:25, 28.40s/it]2021-12-13 01:09:33,592 iteration 4846 : loss : 0.017271, loss_ce: 0.005696
2021-12-13 01:09:35,019 iteration 4847 : loss : 0.017766, loss_ce: 0.004857
2021-12-13 01:09:36,549 iteration 4848 : loss : 0.020086, loss_ce: 0.008328
2021-12-13 01:09:37,976 iteration 4849 : loss : 0.016456, loss_ce: 0.007028
2021-12-13 01:09:39,460 iteration 4850 : loss : 0.037580, loss_ce: 0.008542
2021-12-13 01:09:40,942 iteration 4851 : loss : 0.013060, loss_ce: 0.005949
2021-12-13 01:09:42,364 iteration 4852 : loss : 0.015525, loss_ce: 0.005916
2021-12-13 01:09:43,783 iteration 4853 : loss : 0.016644, loss_ce: 0.006717
2021-12-13 01:09:45,168 iteration 4854 : loss : 0.014303, loss_ce: 0.005031
2021-12-13 01:09:46,624 iteration 4855 : loss : 0.014025, loss_ce: 0.005035
2021-12-13 01:09:48,094 iteration 4856 : loss : 0.017821, loss_ce: 0.006470
2021-12-13 01:09:49,579 iteration 4857 : loss : 0.019705, loss_ce: 0.010400
2021-12-13 01:09:51,033 iteration 4858 : loss : 0.016137, loss_ce: 0.006328
2021-12-13 01:09:52,422 iteration 4859 : loss : 0.013068, loss_ce: 0.005176
2021-12-13 01:09:53,843 iteration 4860 : loss : 0.014466, loss_ce: 0.003557
2021-12-13 01:09:55,225 iteration 4861 : loss : 0.015579, loss_ce: 0.004417
2021-12-13 01:09:56,755 iteration 4862 : loss : 0.027906, loss_ce: 0.011225
 72%|████████████████████▋        | 286/400 [2:08:05<51:50, 27.28s/it]2021-12-13 01:09:58,258 iteration 4863 : loss : 0.018096, loss_ce: 0.004973
2021-12-13 01:09:59,720 iteration 4864 : loss : 0.020787, loss_ce: 0.007217
2021-12-13 01:10:01,179 iteration 4865 : loss : 0.017958, loss_ce: 0.006532
2021-12-13 01:10:02,635 iteration 4866 : loss : 0.021951, loss_ce: 0.009416
2021-12-13 01:10:04,117 iteration 4867 : loss : 0.028061, loss_ce: 0.011914
2021-12-13 01:10:05,579 iteration 4868 : loss : 0.017706, loss_ce: 0.008309
2021-12-13 01:10:06,993 iteration 4869 : loss : 0.016018, loss_ce: 0.005030
2021-12-13 01:10:08,350 iteration 4870 : loss : 0.014145, loss_ce: 0.005126
2021-12-13 01:10:09,785 iteration 4871 : loss : 0.014689, loss_ce: 0.004519
2021-12-13 01:10:11,242 iteration 4872 : loss : 0.016061, loss_ce: 0.007211
2021-12-13 01:10:12,691 iteration 4873 : loss : 0.017115, loss_ce: 0.005781
2021-12-13 01:10:14,138 iteration 4874 : loss : 0.014912, loss_ce: 0.005153
2021-12-13 01:10:15,553 iteration 4875 : loss : 0.018820, loss_ce: 0.005431
2021-12-13 01:10:16,921 iteration 4876 : loss : 0.014328, loss_ce: 0.006071
2021-12-13 01:10:18,357 iteration 4877 : loss : 0.013044, loss_ce: 0.004583
2021-12-13 01:10:19,811 iteration 4878 : loss : 0.021872, loss_ce: 0.007541
2021-12-13 01:10:21,306 iteration 4879 : loss : 0.026719, loss_ce: 0.008644
 72%|████████████████████▊        | 287/400 [2:08:30<49:50, 26.47s/it]2021-12-13 01:10:22,825 iteration 4880 : loss : 0.017126, loss_ce: 0.005546
2021-12-13 01:10:24,209 iteration 4881 : loss : 0.012644, loss_ce: 0.003927
2021-12-13 01:10:25,592 iteration 4882 : loss : 0.013492, loss_ce: 0.003476
2021-12-13 01:10:27,054 iteration 4883 : loss : 0.018458, loss_ce: 0.007958
2021-12-13 01:10:28,447 iteration 4884 : loss : 0.026003, loss_ce: 0.010585
2021-12-13 01:10:29,889 iteration 4885 : loss : 0.016805, loss_ce: 0.004739
2021-12-13 01:10:31,364 iteration 4886 : loss : 0.015616, loss_ce: 0.005524
2021-12-13 01:10:32,779 iteration 4887 : loss : 0.018573, loss_ce: 0.007501
2021-12-13 01:10:34,225 iteration 4888 : loss : 0.021530, loss_ce: 0.004877
2021-12-13 01:10:35,648 iteration 4889 : loss : 0.016778, loss_ce: 0.006469
2021-12-13 01:10:37,103 iteration 4890 : loss : 0.020779, loss_ce: 0.008047
2021-12-13 01:10:38,550 iteration 4891 : loss : 0.018498, loss_ce: 0.008068
2021-12-13 01:10:39,996 iteration 4892 : loss : 0.015086, loss_ce: 0.006620
2021-12-13 01:10:41,581 iteration 4893 : loss : 0.018930, loss_ce: 0.006474
2021-12-13 01:10:43,014 iteration 4894 : loss : 0.015967, loss_ce: 0.006216
2021-12-13 01:10:44,442 iteration 4895 : loss : 0.019670, loss_ce: 0.010363
2021-12-13 01:10:45,872 iteration 4896 : loss : 0.014536, loss_ce: 0.005150
 72%|████████████████████▉        | 288/400 [2:08:55<48:20, 25.90s/it]2021-12-13 01:10:47,290 iteration 4897 : loss : 0.012044, loss_ce: 0.005305
2021-12-13 01:10:48,716 iteration 4898 : loss : 0.011216, loss_ce: 0.003967
2021-12-13 01:10:50,118 iteration 4899 : loss : 0.012534, loss_ce: 0.005451
2021-12-13 01:10:51,631 iteration 4900 : loss : 0.032226, loss_ce: 0.013632
2021-12-13 01:10:53,081 iteration 4901 : loss : 0.013754, loss_ce: 0.004055
2021-12-13 01:10:54,474 iteration 4902 : loss : 0.014557, loss_ce: 0.002925
2021-12-13 01:10:55,919 iteration 4903 : loss : 0.014634, loss_ce: 0.005669
2021-12-13 01:10:57,353 iteration 4904 : loss : 0.017517, loss_ce: 0.008403
2021-12-13 01:10:58,775 iteration 4905 : loss : 0.012723, loss_ce: 0.005438
2021-12-13 01:11:00,198 iteration 4906 : loss : 0.014073, loss_ce: 0.004771
2021-12-13 01:11:01,644 iteration 4907 : loss : 0.016220, loss_ce: 0.005943
2021-12-13 01:11:03,003 iteration 4908 : loss : 0.016006, loss_ce: 0.004176
2021-12-13 01:11:04,456 iteration 4909 : loss : 0.017579, loss_ce: 0.005497
2021-12-13 01:11:05,889 iteration 4910 : loss : 0.016915, loss_ce: 0.003614
2021-12-13 01:11:07,414 iteration 4911 : loss : 0.017973, loss_ce: 0.007459
2021-12-13 01:11:08,904 iteration 4912 : loss : 0.022104, loss_ce: 0.008483
2021-12-13 01:11:10,309 iteration 4913 : loss : 0.018066, loss_ce: 0.006116
 72%|████████████████████▉        | 289/400 [2:09:19<47:05, 25.46s/it]2021-12-13 01:11:11,715 iteration 4914 : loss : 0.012969, loss_ce: 0.003783
2021-12-13 01:11:13,178 iteration 4915 : loss : 0.017309, loss_ce: 0.007258
2021-12-13 01:11:14,646 iteration 4916 : loss : 0.016157, loss_ce: 0.005003
2021-12-13 01:11:16,095 iteration 4917 : loss : 0.015881, loss_ce: 0.006334
2021-12-13 01:11:17,505 iteration 4918 : loss : 0.012624, loss_ce: 0.005805
2021-12-13 01:11:18,906 iteration 4919 : loss : 0.023772, loss_ce: 0.008478
2021-12-13 01:11:20,374 iteration 4920 : loss : 0.016385, loss_ce: 0.007373
2021-12-13 01:11:21,804 iteration 4921 : loss : 0.012756, loss_ce: 0.002948
2021-12-13 01:11:23,249 iteration 4922 : loss : 0.042178, loss_ce: 0.006422
2021-12-13 01:11:24,701 iteration 4923 : loss : 0.017006, loss_ce: 0.007245
2021-12-13 01:11:26,170 iteration 4924 : loss : 0.017602, loss_ce: 0.006121
2021-12-13 01:11:27,728 iteration 4925 : loss : 0.020165, loss_ce: 0.008550
2021-12-13 01:11:29,139 iteration 4926 : loss : 0.016236, loss_ce: 0.005908
2021-12-13 01:11:30,632 iteration 4927 : loss : 0.018272, loss_ce: 0.007347
2021-12-13 01:11:32,139 iteration 4928 : loss : 0.022466, loss_ce: 0.010757
2021-12-13 01:11:33,629 iteration 4929 : loss : 0.023483, loss_ce: 0.007927
2021-12-13 01:11:33,629 Training Data Eval:
2021-12-13 01:11:41,055   Average segmentation loss on training set: 0.0101
2021-12-13 01:11:41,055 Validation Data Eval:
2021-12-13 01:11:43,642   Average segmentation loss on validation set: 0.0649
2021-12-13 01:11:49,948 Found new lowest validation loss at iteration 4929! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 01:11:51,337 iteration 4930 : loss : 0.013720, loss_ce: 0.006329
 72%|█████████████████████        | 290/400 [2:10:00<55:14, 30.13s/it]2021-12-13 01:11:52,785 iteration 4931 : loss : 0.014938, loss_ce: 0.006452
2021-12-13 01:11:54,122 iteration 4932 : loss : 0.015314, loss_ce: 0.005571
2021-12-13 01:11:55,447 iteration 4933 : loss : 0.015734, loss_ce: 0.005563
2021-12-13 01:11:56,837 iteration 4934 : loss : 0.018943, loss_ce: 0.009683
2021-12-13 01:11:58,254 iteration 4935 : loss : 0.021561, loss_ce: 0.006087
2021-12-13 01:11:59,645 iteration 4936 : loss : 0.013171, loss_ce: 0.005335
2021-12-13 01:12:01,043 iteration 4937 : loss : 0.024034, loss_ce: 0.006708
2021-12-13 01:12:02,415 iteration 4938 : loss : 0.017936, loss_ce: 0.006430
2021-12-13 01:12:03,849 iteration 4939 : loss : 0.020744, loss_ce: 0.009137
2021-12-13 01:12:05,183 iteration 4940 : loss : 0.018102, loss_ce: 0.004958
2021-12-13 01:12:06,551 iteration 4941 : loss : 0.013355, loss_ce: 0.004618
2021-12-13 01:12:07,968 iteration 4942 : loss : 0.019687, loss_ce: 0.007931
2021-12-13 01:12:09,330 iteration 4943 : loss : 0.012854, loss_ce: 0.003789
2021-12-13 01:12:10,781 iteration 4944 : loss : 0.042331, loss_ce: 0.036608
2021-12-13 01:12:12,337 iteration 4945 : loss : 0.021813, loss_ce: 0.006859
2021-12-13 01:12:13,857 iteration 4946 : loss : 0.031699, loss_ce: 0.012775
2021-12-13 01:12:15,425 iteration 4947 : loss : 0.023182, loss_ce: 0.008562
 73%|█████████████████████        | 291/400 [2:10:24<51:26, 28.32s/it]2021-12-13 01:12:16,980 iteration 4948 : loss : 0.018615, loss_ce: 0.007139
2021-12-13 01:12:18,421 iteration 4949 : loss : 0.015352, loss_ce: 0.005839
2021-12-13 01:12:19,845 iteration 4950 : loss : 0.016853, loss_ce: 0.006096
2021-12-13 01:12:21,290 iteration 4951 : loss : 0.017842, loss_ce: 0.006379
2021-12-13 01:12:22,680 iteration 4952 : loss : 0.018008, loss_ce: 0.007446
2021-12-13 01:12:24,181 iteration 4953 : loss : 0.015418, loss_ce: 0.005791
2021-12-13 01:12:25,582 iteration 4954 : loss : 0.016015, loss_ce: 0.005903
2021-12-13 01:12:27,028 iteration 4955 : loss : 0.013613, loss_ce: 0.005582
2021-12-13 01:12:28,480 iteration 4956 : loss : 0.017650, loss_ce: 0.005740
2021-12-13 01:12:29,935 iteration 4957 : loss : 0.016308, loss_ce: 0.006542
2021-12-13 01:12:31,391 iteration 4958 : loss : 0.016656, loss_ce: 0.007342
2021-12-13 01:12:32,775 iteration 4959 : loss : 0.012859, loss_ce: 0.004250
2021-12-13 01:12:34,236 iteration 4960 : loss : 0.015504, loss_ce: 0.005583
2021-12-13 01:12:35,638 iteration 4961 : loss : 0.013751, loss_ce: 0.005472
2021-12-13 01:12:37,125 iteration 4962 : loss : 0.019488, loss_ce: 0.008248
2021-12-13 01:12:38,518 iteration 4963 : loss : 0.013672, loss_ce: 0.005539
2021-12-13 01:12:40,055 iteration 4964 : loss : 0.018054, loss_ce: 0.007108
 73%|█████████████████████▏       | 292/400 [2:10:49<48:58, 27.21s/it]2021-12-13 01:12:41,622 iteration 4965 : loss : 0.019633, loss_ce: 0.006004
2021-12-13 01:12:43,176 iteration 4966 : loss : 0.029147, loss_ce: 0.008462
2021-12-13 01:12:44,577 iteration 4967 : loss : 0.016054, loss_ce: 0.006869
2021-12-13 01:12:46,040 iteration 4968 : loss : 0.018375, loss_ce: 0.006417
2021-12-13 01:12:47,479 iteration 4969 : loss : 0.025975, loss_ce: 0.005432
2021-12-13 01:12:48,905 iteration 4970 : loss : 0.011484, loss_ce: 0.004313
2021-12-13 01:12:50,411 iteration 4971 : loss : 0.017784, loss_ce: 0.007136
2021-12-13 01:12:51,922 iteration 4972 : loss : 0.018266, loss_ce: 0.005553
2021-12-13 01:12:53,361 iteration 4973 : loss : 0.017173, loss_ce: 0.006490
2021-12-13 01:12:54,791 iteration 4974 : loss : 0.019370, loss_ce: 0.006770
2021-12-13 01:12:56,224 iteration 4975 : loss : 0.017323, loss_ce: 0.005553
2021-12-13 01:12:57,656 iteration 4976 : loss : 0.019278, loss_ce: 0.007057
2021-12-13 01:12:59,195 iteration 4977 : loss : 0.021666, loss_ce: 0.010551
2021-12-13 01:13:00,639 iteration 4978 : loss : 0.041496, loss_ce: 0.012382
2021-12-13 01:13:02,101 iteration 4979 : loss : 0.020942, loss_ce: 0.010249
2021-12-13 01:13:03,467 iteration 4980 : loss : 0.010689, loss_ce: 0.003710
2021-12-13 01:13:04,932 iteration 4981 : loss : 0.034081, loss_ce: 0.011658
 73%|█████████████████████▏       | 293/400 [2:11:14<47:16, 26.51s/it]2021-12-13 01:13:06,427 iteration 4982 : loss : 0.015240, loss_ce: 0.006166
2021-12-13 01:13:07,849 iteration 4983 : loss : 0.014385, loss_ce: 0.005912
2021-12-13 01:13:09,361 iteration 4984 : loss : 0.018194, loss_ce: 0.006242
2021-12-13 01:13:10,841 iteration 4985 : loss : 0.014999, loss_ce: 0.004767
2021-12-13 01:13:12,380 iteration 4986 : loss : 0.017917, loss_ce: 0.007659
2021-12-13 01:13:13,798 iteration 4987 : loss : 0.017084, loss_ce: 0.007554
2021-12-13 01:13:15,233 iteration 4988 : loss : 0.017067, loss_ce: 0.008052
2021-12-13 01:13:16,664 iteration 4989 : loss : 0.018868, loss_ce: 0.006298
2021-12-13 01:13:18,200 iteration 4990 : loss : 0.019351, loss_ce: 0.007725
2021-12-13 01:13:19,661 iteration 4991 : loss : 0.019331, loss_ce: 0.005410
2021-12-13 01:13:21,114 iteration 4992 : loss : 0.015087, loss_ce: 0.006504
2021-12-13 01:13:22,622 iteration 4993 : loss : 0.032664, loss_ce: 0.021055
2021-12-13 01:13:24,153 iteration 4994 : loss : 0.026046, loss_ce: 0.005759
2021-12-13 01:13:25,595 iteration 4995 : loss : 0.026524, loss_ce: 0.008831
2021-12-13 01:13:27,033 iteration 4996 : loss : 0.018514, loss_ce: 0.007032
2021-12-13 01:13:28,556 iteration 4997 : loss : 0.021337, loss_ce: 0.007892
2021-12-13 01:13:29,967 iteration 4998 : loss : 0.014757, loss_ce: 0.005187
 74%|█████████████████████▎       | 294/400 [2:11:39<46:03, 26.07s/it]2021-12-13 01:13:31,503 iteration 4999 : loss : 0.018123, loss_ce: 0.008269
2021-12-13 01:13:32,908 iteration 5000 : loss : 0.013157, loss_ce: 0.004534
2021-12-13 01:13:34,354 iteration 5001 : loss : 0.022261, loss_ce: 0.008611
2021-12-13 01:13:35,848 iteration 5002 : loss : 0.019954, loss_ce: 0.008775
2021-12-13 01:13:37,281 iteration 5003 : loss : 0.020903, loss_ce: 0.006627
2021-12-13 01:13:38,810 iteration 5004 : loss : 0.025311, loss_ce: 0.008527
2021-12-13 01:13:40,244 iteration 5005 : loss : 0.018038, loss_ce: 0.006080
2021-12-13 01:13:41,740 iteration 5006 : loss : 0.023865, loss_ce: 0.006591
2021-12-13 01:13:43,181 iteration 5007 : loss : 0.014043, loss_ce: 0.005522
2021-12-13 01:13:44,589 iteration 5008 : loss : 0.018206, loss_ce: 0.007508
2021-12-13 01:13:46,048 iteration 5009 : loss : 0.019032, loss_ce: 0.006166
2021-12-13 01:13:47,608 iteration 5010 : loss : 0.026170, loss_ce: 0.009929
2021-12-13 01:13:49,076 iteration 5011 : loss : 0.016369, loss_ce: 0.009974
2021-12-13 01:13:50,594 iteration 5012 : loss : 0.020298, loss_ce: 0.008859
2021-12-13 01:13:52,201 iteration 5013 : loss : 0.044402, loss_ce: 0.019428
2021-12-13 01:13:53,562 iteration 5014 : loss : 0.013693, loss_ce: 0.004903
2021-12-13 01:13:53,562 Training Data Eval:
2021-12-13 01:14:01,009   Average segmentation loss on training set: 0.0324
2021-12-13 01:14:01,009 Validation Data Eval:
2021-12-13 01:14:03,605   Average segmentation loss on validation set: 0.0807
2021-12-13 01:14:05,054 iteration 5015 : loss : 0.011993, loss_ce: 0.002533
 74%|█████████████████████▍       | 295/400 [2:12:14<50:21, 28.77s/it]2021-12-13 01:14:06,523 iteration 5016 : loss : 0.022007, loss_ce: 0.007967
2021-12-13 01:14:07,968 iteration 5017 : loss : 0.014519, loss_ce: 0.004232
2021-12-13 01:14:09,580 iteration 5018 : loss : 0.021028, loss_ce: 0.007004
2021-12-13 01:14:11,003 iteration 5019 : loss : 0.029342, loss_ce: 0.010970
2021-12-13 01:14:12,487 iteration 5020 : loss : 0.015515, loss_ce: 0.008355
2021-12-13 01:14:14,016 iteration 5021 : loss : 0.013725, loss_ce: 0.004354
2021-12-13 01:14:15,514 iteration 5022 : loss : 0.022988, loss_ce: 0.011177
2021-12-13 01:14:16,986 iteration 5023 : loss : 0.021223, loss_ce: 0.008576
2021-12-13 01:14:18,408 iteration 5024 : loss : 0.012889, loss_ce: 0.004696
2021-12-13 01:14:19,826 iteration 5025 : loss : 0.014784, loss_ce: 0.005793
2021-12-13 01:14:21,287 iteration 5026 : loss : 0.021869, loss_ce: 0.009551
2021-12-13 01:14:22,735 iteration 5027 : loss : 0.012693, loss_ce: 0.004246
2021-12-13 01:14:24,198 iteration 5028 : loss : 0.026264, loss_ce: 0.009169
2021-12-13 01:14:25,612 iteration 5029 : loss : 0.015072, loss_ce: 0.005858
2021-12-13 01:14:27,083 iteration 5030 : loss : 0.019745, loss_ce: 0.006329
2021-12-13 01:14:28,600 iteration 5031 : loss : 0.019958, loss_ce: 0.008952
2021-12-13 01:14:30,126 iteration 5032 : loss : 0.027289, loss_ce: 0.008794
 74%|█████████████████████▍       | 296/400 [2:12:39<47:57, 27.67s/it]2021-12-13 01:14:31,626 iteration 5033 : loss : 0.019573, loss_ce: 0.009932
2021-12-13 01:14:33,071 iteration 5034 : loss : 0.023375, loss_ce: 0.006778
2021-12-13 01:14:34,502 iteration 5035 : loss : 0.020292, loss_ce: 0.007619
2021-12-13 01:14:35,885 iteration 5036 : loss : 0.011342, loss_ce: 0.004006
2021-12-13 01:14:37,303 iteration 5037 : loss : 0.013049, loss_ce: 0.005148
2021-12-13 01:14:38,880 iteration 5038 : loss : 0.023130, loss_ce: 0.010021
2021-12-13 01:14:40,315 iteration 5039 : loss : 0.013629, loss_ce: 0.004555
2021-12-13 01:14:41,818 iteration 5040 : loss : 0.022013, loss_ce: 0.009578
2021-12-13 01:14:43,277 iteration 5041 : loss : 0.015288, loss_ce: 0.004769
2021-12-13 01:14:44,726 iteration 5042 : loss : 0.011785, loss_ce: 0.004640
2021-12-13 01:14:46,145 iteration 5043 : loss : 0.013817, loss_ce: 0.004684
2021-12-13 01:14:47,612 iteration 5044 : loss : 0.016466, loss_ce: 0.005291
2021-12-13 01:14:48,980 iteration 5045 : loss : 0.012095, loss_ce: 0.003667
2021-12-13 01:14:50,445 iteration 5046 : loss : 0.014196, loss_ce: 0.004426
2021-12-13 01:14:51,869 iteration 5047 : loss : 0.013975, loss_ce: 0.005483
2021-12-13 01:14:53,271 iteration 5048 : loss : 0.013476, loss_ce: 0.005311
2021-12-13 01:14:54,795 iteration 5049 : loss : 0.025709, loss_ce: 0.011214
 74%|█████████████████████▌       | 297/400 [2:13:04<45:56, 26.76s/it]2021-12-13 01:14:56,275 iteration 5050 : loss : 0.015035, loss_ce: 0.004148
2021-12-13 01:14:57,674 iteration 5051 : loss : 0.014504, loss_ce: 0.006336
2021-12-13 01:14:59,156 iteration 5052 : loss : 0.014477, loss_ce: 0.006738
2021-12-13 01:15:00,558 iteration 5053 : loss : 0.014207, loss_ce: 0.005180
2021-12-13 01:15:02,043 iteration 5054 : loss : 0.015111, loss_ce: 0.007277
2021-12-13 01:15:03,468 iteration 5055 : loss : 0.011472, loss_ce: 0.004124
2021-12-13 01:15:04,895 iteration 5056 : loss : 0.016976, loss_ce: 0.005727
2021-12-13 01:15:06,330 iteration 5057 : loss : 0.013369, loss_ce: 0.006069
2021-12-13 01:15:07,752 iteration 5058 : loss : 0.015642, loss_ce: 0.005153
2021-12-13 01:15:09,202 iteration 5059 : loss : 0.013171, loss_ce: 0.006129
2021-12-13 01:15:10,701 iteration 5060 : loss : 0.021034, loss_ce: 0.004943
2021-12-13 01:15:12,151 iteration 5061 : loss : 0.019337, loss_ce: 0.011480
2021-12-13 01:15:13,657 iteration 5062 : loss : 0.013890, loss_ce: 0.004621
2021-12-13 01:15:15,072 iteration 5063 : loss : 0.012617, loss_ce: 0.004960
2021-12-13 01:15:16,538 iteration 5064 : loss : 0.019712, loss_ce: 0.004699
2021-12-13 01:15:18,048 iteration 5065 : loss : 0.027757, loss_ce: 0.008215
2021-12-13 01:15:19,390 iteration 5066 : loss : 0.011692, loss_ce: 0.005066
 74%|█████████████████████▌       | 298/400 [2:13:28<44:23, 26.11s/it]2021-12-13 01:15:20,973 iteration 5067 : loss : 0.017189, loss_ce: 0.005575
2021-12-13 01:15:22,394 iteration 5068 : loss : 0.016944, loss_ce: 0.006903
2021-12-13 01:15:23,859 iteration 5069 : loss : 0.018033, loss_ce: 0.006064
2021-12-13 01:15:25,291 iteration 5070 : loss : 0.015265, loss_ce: 0.007246
2021-12-13 01:15:26,790 iteration 5071 : loss : 0.016061, loss_ce: 0.007122
2021-12-13 01:15:28,258 iteration 5072 : loss : 0.015013, loss_ce: 0.004868
2021-12-13 01:15:29,763 iteration 5073 : loss : 0.023507, loss_ce: 0.005509
2021-12-13 01:15:31,253 iteration 5074 : loss : 0.016568, loss_ce: 0.005986
2021-12-13 01:15:32,625 iteration 5075 : loss : 0.015948, loss_ce: 0.007358
2021-12-13 01:15:33,997 iteration 5076 : loss : 0.012662, loss_ce: 0.005000
2021-12-13 01:15:35,496 iteration 5077 : loss : 0.017422, loss_ce: 0.006063
2021-12-13 01:15:36,955 iteration 5078 : loss : 0.016454, loss_ce: 0.005489
2021-12-13 01:15:38,384 iteration 5079 : loss : 0.010320, loss_ce: 0.003668
2021-12-13 01:15:39,856 iteration 5080 : loss : 0.013201, loss_ce: 0.005370
2021-12-13 01:15:41,334 iteration 5081 : loss : 0.015837, loss_ce: 0.006859
2021-12-13 01:15:42,766 iteration 5082 : loss : 0.018062, loss_ce: 0.004445
2021-12-13 01:15:44,195 iteration 5083 : loss : 0.020413, loss_ce: 0.007379
 75%|█████████████████████▋       | 299/400 [2:13:53<43:17, 25.72s/it]2021-12-13 01:15:45,694 iteration 5084 : loss : 0.020229, loss_ce: 0.008425
2021-12-13 01:15:47,237 iteration 5085 : loss : 0.019802, loss_ce: 0.007725
2021-12-13 01:15:48,610 iteration 5086 : loss : 0.012248, loss_ce: 0.003696
2021-12-13 01:15:50,066 iteration 5087 : loss : 0.018072, loss_ce: 0.006430
2021-12-13 01:15:51,451 iteration 5088 : loss : 0.010613, loss_ce: 0.004988
2021-12-13 01:15:52,878 iteration 5089 : loss : 0.017289, loss_ce: 0.007114
2021-12-13 01:15:54,347 iteration 5090 : loss : 0.021106, loss_ce: 0.009247
2021-12-13 01:15:55,828 iteration 5091 : loss : 0.025936, loss_ce: 0.010720
2021-12-13 01:15:57,272 iteration 5092 : loss : 0.016085, loss_ce: 0.004067
2021-12-13 01:15:58,724 iteration 5093 : loss : 0.016592, loss_ce: 0.005750
2021-12-13 01:16:00,186 iteration 5094 : loss : 0.018965, loss_ce: 0.006507
2021-12-13 01:16:01,650 iteration 5095 : loss : 0.016221, loss_ce: 0.008506
2021-12-13 01:16:03,167 iteration 5096 : loss : 0.026776, loss_ce: 0.006958
2021-12-13 01:16:04,655 iteration 5097 : loss : 0.023293, loss_ce: 0.013750
2021-12-13 01:16:06,110 iteration 5098 : loss : 0.015511, loss_ce: 0.006447
2021-12-13 01:16:07,602 iteration 5099 : loss : 0.015869, loss_ce: 0.006593
2021-12-13 01:16:07,603 Training Data Eval:
2021-12-13 01:16:14,996   Average segmentation loss on training set: 0.0101
2021-12-13 01:16:14,997 Validation Data Eval:
2021-12-13 01:16:17,581   Average segmentation loss on validation set: 0.0730
2021-12-13 01:16:19,020 iteration 5100 : loss : 0.016103, loss_ce: 0.004630
 75%|█████████████████████▊       | 300/400 [2:14:28<47:25, 28.45s/it]2021-12-13 01:16:20,542 iteration 5101 : loss : 0.023115, loss_ce: 0.006241
2021-12-13 01:16:22,061 iteration 5102 : loss : 0.020788, loss_ce: 0.010504
2021-12-13 01:16:23,477 iteration 5103 : loss : 0.013533, loss_ce: 0.004620
2021-12-13 01:16:24,935 iteration 5104 : loss : 0.016906, loss_ce: 0.006109
2021-12-13 01:16:26,370 iteration 5105 : loss : 0.017068, loss_ce: 0.006439
2021-12-13 01:16:27,836 iteration 5106 : loss : 0.023096, loss_ce: 0.008803
2021-12-13 01:16:29,313 iteration 5107 : loss : 0.015319, loss_ce: 0.006148
2021-12-13 01:16:30,793 iteration 5108 : loss : 0.015443, loss_ce: 0.006396
2021-12-13 01:16:32,239 iteration 5109 : loss : 0.018324, loss_ce: 0.007088
2021-12-13 01:16:33,594 iteration 5110 : loss : 0.013011, loss_ce: 0.005088
2021-12-13 01:16:35,068 iteration 5111 : loss : 0.015665, loss_ce: 0.004811
2021-12-13 01:16:36,476 iteration 5112 : loss : 0.013413, loss_ce: 0.005339
2021-12-13 01:16:38,001 iteration 5113 : loss : 0.021479, loss_ce: 0.007878
2021-12-13 01:16:39,395 iteration 5114 : loss : 0.012618, loss_ce: 0.004729
2021-12-13 01:16:40,795 iteration 5115 : loss : 0.014866, loss_ce: 0.006307
2021-12-13 01:16:42,241 iteration 5116 : loss : 0.019692, loss_ce: 0.007169
2021-12-13 01:16:43,691 iteration 5117 : loss : 0.015272, loss_ce: 0.005690
 75%|█████████████████████▊       | 301/400 [2:14:52<45:04, 27.32s/it]2021-12-13 01:16:45,188 iteration 5118 : loss : 0.015437, loss_ce: 0.006216
2021-12-13 01:16:46,639 iteration 5119 : loss : 0.020615, loss_ce: 0.007172
2021-12-13 01:16:48,183 iteration 5120 : loss : 0.018495, loss_ce: 0.004358
2021-12-13 01:16:49,601 iteration 5121 : loss : 0.012544, loss_ce: 0.004678
2021-12-13 01:16:51,028 iteration 5122 : loss : 0.017829, loss_ce: 0.004929
2021-12-13 01:16:52,475 iteration 5123 : loss : 0.017840, loss_ce: 0.009467
2021-12-13 01:16:53,882 iteration 5124 : loss : 0.017884, loss_ce: 0.003236
2021-12-13 01:16:55,349 iteration 5125 : loss : 0.016942, loss_ce: 0.006892
2021-12-13 01:16:56,774 iteration 5126 : loss : 0.013263, loss_ce: 0.005235
2021-12-13 01:16:58,241 iteration 5127 : loss : 0.021236, loss_ce: 0.007505
2021-12-13 01:16:59,781 iteration 5128 : loss : 0.020629, loss_ce: 0.006496
2021-12-13 01:17:01,293 iteration 5129 : loss : 0.029183, loss_ce: 0.009725
2021-12-13 01:17:02,677 iteration 5130 : loss : 0.012816, loss_ce: 0.004940
2021-12-13 01:17:04,150 iteration 5131 : loss : 0.016133, loss_ce: 0.004666
2021-12-13 01:17:05,616 iteration 5132 : loss : 0.016661, loss_ce: 0.007911
2021-12-13 01:17:07,020 iteration 5133 : loss : 0.016688, loss_ce: 0.007504
2021-12-13 01:17:08,418 iteration 5134 : loss : 0.009715, loss_ce: 0.003262
 76%|█████████████████████▉       | 302/400 [2:15:17<43:21, 26.54s/it]2021-12-13 01:17:09,891 iteration 5135 : loss : 0.014566, loss_ce: 0.004889
2021-12-13 01:17:11,426 iteration 5136 : loss : 0.021191, loss_ce: 0.009263
2021-12-13 01:17:12,953 iteration 5137 : loss : 0.017950, loss_ce: 0.006209
2021-12-13 01:17:14,489 iteration 5138 : loss : 0.020610, loss_ce: 0.010798
2021-12-13 01:17:15,871 iteration 5139 : loss : 0.009356, loss_ce: 0.002769
2021-12-13 01:17:17,372 iteration 5140 : loss : 0.018562, loss_ce: 0.008066
2021-12-13 01:17:18,773 iteration 5141 : loss : 0.012871, loss_ce: 0.006371
2021-12-13 01:17:20,313 iteration 5142 : loss : 0.022964, loss_ce: 0.007666
2021-12-13 01:17:21,701 iteration 5143 : loss : 0.012364, loss_ce: 0.004665
2021-12-13 01:17:23,093 iteration 5144 : loss : 0.013980, loss_ce: 0.006330
2021-12-13 01:17:24,566 iteration 5145 : loss : 0.018733, loss_ce: 0.007429
2021-12-13 01:17:26,140 iteration 5146 : loss : 0.029726, loss_ce: 0.007009
2021-12-13 01:17:27,583 iteration 5147 : loss : 0.017602, loss_ce: 0.008097
2021-12-13 01:17:29,066 iteration 5148 : loss : 0.014538, loss_ce: 0.004610
2021-12-13 01:17:30,486 iteration 5149 : loss : 0.015622, loss_ce: 0.005405
2021-12-13 01:17:31,905 iteration 5150 : loss : 0.012310, loss_ce: 0.004749
2021-12-13 01:17:33,293 iteration 5151 : loss : 0.011594, loss_ce: 0.004001
 76%|█████████████████████▉       | 303/400 [2:15:42<42:05, 26.04s/it]2021-12-13 01:17:34,811 iteration 5152 : loss : 0.016592, loss_ce: 0.004612
2021-12-13 01:17:36,195 iteration 5153 : loss : 0.010262, loss_ce: 0.004778
2021-12-13 01:17:37,692 iteration 5154 : loss : 0.019989, loss_ce: 0.007172
2021-12-13 01:17:39,084 iteration 5155 : loss : 0.010953, loss_ce: 0.004177
2021-12-13 01:17:40,522 iteration 5156 : loss : 0.016878, loss_ce: 0.006440
2021-12-13 01:17:42,033 iteration 5157 : loss : 0.014170, loss_ce: 0.005402
2021-12-13 01:17:43,495 iteration 5158 : loss : 0.017765, loss_ce: 0.005554
2021-12-13 01:17:44,988 iteration 5159 : loss : 0.020882, loss_ce: 0.006693
2021-12-13 01:17:46,495 iteration 5160 : loss : 0.018749, loss_ce: 0.007482
2021-12-13 01:17:47,995 iteration 5161 : loss : 0.013875, loss_ce: 0.005242
2021-12-13 01:17:49,403 iteration 5162 : loss : 0.016635, loss_ce: 0.004736
2021-12-13 01:17:50,828 iteration 5163 : loss : 0.018457, loss_ce: 0.005932
2021-12-13 01:17:52,215 iteration 5164 : loss : 0.015174, loss_ce: 0.007998
2021-12-13 01:17:53,673 iteration 5165 : loss : 0.011434, loss_ce: 0.003279
2021-12-13 01:17:55,134 iteration 5166 : loss : 0.013833, loss_ce: 0.005996
2021-12-13 01:17:56,542 iteration 5167 : loss : 0.014383, loss_ce: 0.005927
2021-12-13 01:17:58,043 iteration 5168 : loss : 0.024820, loss_ce: 0.008782
 76%|██████████████████████       | 304/400 [2:16:07<41:02, 25.65s/it]2021-12-13 01:17:59,486 iteration 5169 : loss : 0.015329, loss_ce: 0.005995
2021-12-13 01:18:00,933 iteration 5170 : loss : 0.014110, loss_ce: 0.006454
2021-12-13 01:18:02,345 iteration 5171 : loss : 0.021087, loss_ce: 0.006323
2021-12-13 01:18:03,796 iteration 5172 : loss : 0.014353, loss_ce: 0.004486
2021-12-13 01:18:05,203 iteration 5173 : loss : 0.016736, loss_ce: 0.009033
2021-12-13 01:18:06,678 iteration 5174 : loss : 0.020452, loss_ce: 0.007424
2021-12-13 01:18:08,211 iteration 5175 : loss : 0.018463, loss_ce: 0.006185
2021-12-13 01:18:09,657 iteration 5176 : loss : 0.015206, loss_ce: 0.004640
2021-12-13 01:18:11,220 iteration 5177 : loss : 0.029810, loss_ce: 0.014874
2021-12-13 01:18:12,649 iteration 5178 : loss : 0.014692, loss_ce: 0.003331
2021-12-13 01:18:14,148 iteration 5179 : loss : 0.017045, loss_ce: 0.006982
2021-12-13 01:18:15,595 iteration 5180 : loss : 0.014130, loss_ce: 0.005606
2021-12-13 01:18:17,083 iteration 5181 : loss : 0.015794, loss_ce: 0.006160
2021-12-13 01:18:18,578 iteration 5182 : loss : 0.024335, loss_ce: 0.010015
2021-12-13 01:18:20,076 iteration 5183 : loss : 0.018124, loss_ce: 0.005187
2021-12-13 01:18:21,613 iteration 5184 : loss : 0.017043, loss_ce: 0.006873
2021-12-13 01:18:21,613 Training Data Eval:
2021-12-13 01:18:29,015   Average segmentation loss on training set: 0.0408
2021-12-13 01:18:29,016 Validation Data Eval:
2021-12-13 01:18:31,607   Average segmentation loss on validation set: 0.2087
2021-12-13 01:18:33,090 iteration 5185 : loss : 0.012708, loss_ce: 0.005538
 76%|██████████████████████       | 305/400 [2:16:42<45:04, 28.47s/it]2021-12-13 01:18:34,598 iteration 5186 : loss : 0.015095, loss_ce: 0.006838
2021-12-13 01:18:36,110 iteration 5187 : loss : 0.015415, loss_ce: 0.005496
2021-12-13 01:18:37,500 iteration 5188 : loss : 0.015343, loss_ce: 0.004678
2021-12-13 01:18:38,955 iteration 5189 : loss : 0.020386, loss_ce: 0.007918
2021-12-13 01:18:40,341 iteration 5190 : loss : 0.014539, loss_ce: 0.006342
2021-12-13 01:18:41,760 iteration 5191 : loss : 0.015230, loss_ce: 0.005815
2021-12-13 01:18:43,260 iteration 5192 : loss : 0.012798, loss_ce: 0.004687
2021-12-13 01:18:44,726 iteration 5193 : loss : 0.022714, loss_ce: 0.010116
2021-12-13 01:18:46,169 iteration 5194 : loss : 0.017917, loss_ce: 0.007669
2021-12-13 01:18:47,640 iteration 5195 : loss : 0.026093, loss_ce: 0.010217
2021-12-13 01:18:49,210 iteration 5196 : loss : 0.030642, loss_ce: 0.008491
2021-12-13 01:18:50,574 iteration 5197 : loss : 0.015478, loss_ce: 0.004137
2021-12-13 01:18:52,079 iteration 5198 : loss : 0.021386, loss_ce: 0.008201
2021-12-13 01:18:53,574 iteration 5199 : loss : 0.013890, loss_ce: 0.004826
2021-12-13 01:18:55,061 iteration 5200 : loss : 0.011792, loss_ce: 0.003617
2021-12-13 01:18:56,502 iteration 5201 : loss : 0.013475, loss_ce: 0.003498
2021-12-13 01:18:57,957 iteration 5202 : loss : 0.017726, loss_ce: 0.006571
 76%|██████████████████████▏      | 306/400 [2:17:07<42:54, 27.39s/it]2021-12-13 01:18:59,358 iteration 5203 : loss : 0.014994, loss_ce: 0.003974
2021-12-13 01:19:00,837 iteration 5204 : loss : 0.022015, loss_ce: 0.007530
2021-12-13 01:19:02,295 iteration 5205 : loss : 0.014131, loss_ce: 0.005169
2021-12-13 01:19:03,688 iteration 5206 : loss : 0.010999, loss_ce: 0.004370
2021-12-13 01:19:05,137 iteration 5207 : loss : 0.011982, loss_ce: 0.004648
2021-12-13 01:19:06,665 iteration 5208 : loss : 0.020728, loss_ce: 0.008475
2021-12-13 01:19:08,128 iteration 5209 : loss : 0.015884, loss_ce: 0.006203
2021-12-13 01:19:09,551 iteration 5210 : loss : 0.012441, loss_ce: 0.004064
2021-12-13 01:19:10,945 iteration 5211 : loss : 0.012727, loss_ce: 0.003689
2021-12-13 01:19:12,389 iteration 5212 : loss : 0.014100, loss_ce: 0.004067
2021-12-13 01:19:13,872 iteration 5213 : loss : 0.026099, loss_ce: 0.006612
2021-12-13 01:19:15,322 iteration 5214 : loss : 0.015038, loss_ce: 0.008669
2021-12-13 01:19:16,753 iteration 5215 : loss : 0.023092, loss_ce: 0.008203
2021-12-13 01:19:18,190 iteration 5216 : loss : 0.013724, loss_ce: 0.005430
2021-12-13 01:19:19,585 iteration 5217 : loss : 0.012672, loss_ce: 0.004082
2021-12-13 01:19:21,014 iteration 5218 : loss : 0.033754, loss_ce: 0.010196
2021-12-13 01:19:22,486 iteration 5219 : loss : 0.017856, loss_ce: 0.007469
 77%|██████████████████████▎      | 307/400 [2:17:31<41:07, 26.53s/it]2021-12-13 01:19:24,054 iteration 5220 : loss : 0.030032, loss_ce: 0.011014
2021-12-13 01:19:25,466 iteration 5221 : loss : 0.011005, loss_ce: 0.004091
2021-12-13 01:19:26,828 iteration 5222 : loss : 0.039842, loss_ce: 0.006327
2021-12-13 01:19:28,265 iteration 5223 : loss : 0.019111, loss_ce: 0.007099
2021-12-13 01:19:29,791 iteration 5224 : loss : 0.019577, loss_ce: 0.005862
2021-12-13 01:19:31,177 iteration 5225 : loss : 0.013174, loss_ce: 0.003577
2021-12-13 01:19:32,748 iteration 5226 : loss : 0.017144, loss_ce: 0.006438
2021-12-13 01:19:34,110 iteration 5227 : loss : 0.013057, loss_ce: 0.004656
2021-12-13 01:19:35,477 iteration 5228 : loss : 0.012062, loss_ce: 0.005113
2021-12-13 01:19:36,885 iteration 5229 : loss : 0.022914, loss_ce: 0.012254
2021-12-13 01:19:38,358 iteration 5230 : loss : 0.022822, loss_ce: 0.011110
2021-12-13 01:19:39,832 iteration 5231 : loss : 0.018330, loss_ce: 0.005448
2021-12-13 01:19:41,238 iteration 5232 : loss : 0.015522, loss_ce: 0.006833
2021-12-13 01:19:42,725 iteration 5233 : loss : 0.024133, loss_ce: 0.011160
2021-12-13 01:19:44,083 iteration 5234 : loss : 0.011736, loss_ce: 0.004050
2021-12-13 01:19:45,613 iteration 5235 : loss : 0.035774, loss_ce: 0.013083
2021-12-13 01:19:47,053 iteration 5236 : loss : 0.016444, loss_ce: 0.006331
 77%|██████████████████████▎      | 308/400 [2:17:56<39:46, 25.94s/it]2021-12-13 01:19:48,565 iteration 5237 : loss : 0.015278, loss_ce: 0.004727
2021-12-13 01:19:50,016 iteration 5238 : loss : 0.015465, loss_ce: 0.007182
2021-12-13 01:19:51,467 iteration 5239 : loss : 0.012288, loss_ce: 0.003510
2021-12-13 01:19:53,014 iteration 5240 : loss : 0.014742, loss_ce: 0.004660
2021-12-13 01:19:54,506 iteration 5241 : loss : 0.027535, loss_ce: 0.011348
2021-12-13 01:19:55,993 iteration 5242 : loss : 0.018177, loss_ce: 0.006914
2021-12-13 01:19:57,453 iteration 5243 : loss : 0.017173, loss_ce: 0.005515
2021-12-13 01:19:58,931 iteration 5244 : loss : 0.020742, loss_ce: 0.007747
2021-12-13 01:20:00,398 iteration 5245 : loss : 0.024028, loss_ce: 0.009547
2021-12-13 01:20:01,765 iteration 5246 : loss : 0.010665, loss_ce: 0.004491
2021-12-13 01:20:03,222 iteration 5247 : loss : 0.013688, loss_ce: 0.004336
2021-12-13 01:20:04,710 iteration 5248 : loss : 0.016308, loss_ce: 0.005731
2021-12-13 01:20:06,146 iteration 5249 : loss : 0.020730, loss_ce: 0.008071
2021-12-13 01:20:07,598 iteration 5250 : loss : 0.016277, loss_ce: 0.007437
2021-12-13 01:20:09,105 iteration 5251 : loss : 0.013210, loss_ce: 0.005049
2021-12-13 01:20:10,546 iteration 5252 : loss : 0.017173, loss_ce: 0.004634
2021-12-13 01:20:12,034 iteration 5253 : loss : 0.012948, loss_ce: 0.005037
 77%|██████████████████████▍      | 309/400 [2:18:21<38:54, 25.65s/it]2021-12-13 01:20:13,455 iteration 5254 : loss : 0.013735, loss_ce: 0.004754
2021-12-13 01:20:14,958 iteration 5255 : loss : 0.018854, loss_ce: 0.006076
2021-12-13 01:20:16,421 iteration 5256 : loss : 0.014849, loss_ce: 0.006419
2021-12-13 01:20:17,952 iteration 5257 : loss : 0.021226, loss_ce: 0.005744
2021-12-13 01:20:19,354 iteration 5258 : loss : 0.018695, loss_ce: 0.007563
2021-12-13 01:20:20,833 iteration 5259 : loss : 0.020966, loss_ce: 0.005578
2021-12-13 01:20:22,267 iteration 5260 : loss : 0.015801, loss_ce: 0.006280
2021-12-13 01:20:23,724 iteration 5261 : loss : 0.014138, loss_ce: 0.006153
2021-12-13 01:20:25,131 iteration 5262 : loss : 0.009691, loss_ce: 0.004127
2021-12-13 01:20:26,603 iteration 5263 : loss : 0.018299, loss_ce: 0.007007
2021-12-13 01:20:28,034 iteration 5264 : loss : 0.014007, loss_ce: 0.004552
2021-12-13 01:20:29,417 iteration 5265 : loss : 0.011200, loss_ce: 0.004035
2021-12-13 01:20:30,879 iteration 5266 : loss : 0.016417, loss_ce: 0.007083
2021-12-13 01:20:32,280 iteration 5267 : loss : 0.015844, loss_ce: 0.006516
2021-12-13 01:20:33,787 iteration 5268 : loss : 0.016153, loss_ce: 0.005841
2021-12-13 01:20:35,306 iteration 5269 : loss : 0.016957, loss_ce: 0.007799
2021-12-13 01:20:35,306 Training Data Eval:
2021-12-13 01:20:42,718   Average segmentation loss on training set: 0.0095
2021-12-13 01:20:42,718 Validation Data Eval:
2021-12-13 01:20:45,303   Average segmentation loss on validation set: 0.0732
2021-12-13 01:20:46,813 iteration 5270 : loss : 0.022690, loss_ce: 0.009892
 78%|██████████████████████▍      | 310/400 [2:18:56<42:35, 28.39s/it]2021-12-13 01:20:48,342 iteration 5271 : loss : 0.015403, loss_ce: 0.006454
2021-12-13 01:20:49,793 iteration 5272 : loss : 0.015722, loss_ce: 0.005935
2021-12-13 01:20:51,238 iteration 5273 : loss : 0.020336, loss_ce: 0.007608
2021-12-13 01:20:52,645 iteration 5274 : loss : 0.013197, loss_ce: 0.004335
2021-12-13 01:20:54,116 iteration 5275 : loss : 0.021375, loss_ce: 0.007020
2021-12-13 01:20:55,587 iteration 5276 : loss : 0.014053, loss_ce: 0.003961
2021-12-13 01:20:56,973 iteration 5277 : loss : 0.016460, loss_ce: 0.004498
2021-12-13 01:20:58,549 iteration 5278 : loss : 0.020246, loss_ce: 0.008958
2021-12-13 01:20:59,991 iteration 5279 : loss : 0.020031, loss_ce: 0.005194
2021-12-13 01:21:01,500 iteration 5280 : loss : 0.016216, loss_ce: 0.005698
2021-12-13 01:21:02,945 iteration 5281 : loss : 0.014762, loss_ce: 0.007777
2021-12-13 01:21:04,420 iteration 5282 : loss : 0.018081, loss_ce: 0.006134
2021-12-13 01:21:05,858 iteration 5283 : loss : 0.019720, loss_ce: 0.006066
2021-12-13 01:21:07,327 iteration 5284 : loss : 0.013069, loss_ce: 0.005930
2021-12-13 01:21:08,806 iteration 5285 : loss : 0.015677, loss_ce: 0.007274
2021-12-13 01:21:10,316 iteration 5286 : loss : 0.013471, loss_ce: 0.004950
2021-12-13 01:21:11,863 iteration 5287 : loss : 0.020156, loss_ce: 0.008507
 78%|██████████████████████▌      | 311/400 [2:19:21<40:37, 27.39s/it]2021-12-13 01:21:13,296 iteration 5288 : loss : 0.026204, loss_ce: 0.009729
2021-12-13 01:21:14,760 iteration 5289 : loss : 0.015461, loss_ce: 0.005199
2021-12-13 01:21:16,267 iteration 5290 : loss : 0.016886, loss_ce: 0.006824
2021-12-13 01:21:17,761 iteration 5291 : loss : 0.014414, loss_ce: 0.006046
2021-12-13 01:21:19,241 iteration 5292 : loss : 0.012814, loss_ce: 0.004525
2021-12-13 01:21:20,669 iteration 5293 : loss : 0.015235, loss_ce: 0.005218
2021-12-13 01:21:22,180 iteration 5294 : loss : 0.018970, loss_ce: 0.008534
2021-12-13 01:21:23,584 iteration 5295 : loss : 0.014085, loss_ce: 0.005260
2021-12-13 01:21:25,030 iteration 5296 : loss : 0.018892, loss_ce: 0.005966
2021-12-13 01:21:26,553 iteration 5297 : loss : 0.019648, loss_ce: 0.005795
2021-12-13 01:21:27,956 iteration 5298 : loss : 0.011591, loss_ce: 0.005157
2021-12-13 01:21:29,481 iteration 5299 : loss : 0.016503, loss_ce: 0.006669
2021-12-13 01:21:30,876 iteration 5300 : loss : 0.014897, loss_ce: 0.005680
2021-12-13 01:21:32,337 iteration 5301 : loss : 0.023655, loss_ce: 0.008833
2021-12-13 01:21:33,757 iteration 5302 : loss : 0.011770, loss_ce: 0.005065
2021-12-13 01:21:35,100 iteration 5303 : loss : 0.012172, loss_ce: 0.004365
2021-12-13 01:21:36,596 iteration 5304 : loss : 0.024503, loss_ce: 0.009322
 78%|██████████████████████▌      | 312/400 [2:19:45<39:00, 26.59s/it]2021-12-13 01:21:38,094 iteration 5305 : loss : 0.027119, loss_ce: 0.008919
2021-12-13 01:21:39,579 iteration 5306 : loss : 0.040323, loss_ce: 0.014274
2021-12-13 01:21:41,030 iteration 5307 : loss : 0.012198, loss_ce: 0.004477
2021-12-13 01:21:42,518 iteration 5308 : loss : 0.017672, loss_ce: 0.007382
2021-12-13 01:21:43,962 iteration 5309 : loss : 0.012624, loss_ce: 0.003803
2021-12-13 01:21:45,412 iteration 5310 : loss : 0.013212, loss_ce: 0.005811
2021-12-13 01:21:46,881 iteration 5311 : loss : 0.018550, loss_ce: 0.006519
2021-12-13 01:21:48,342 iteration 5312 : loss : 0.016897, loss_ce: 0.005131
2021-12-13 01:21:49,838 iteration 5313 : loss : 0.020133, loss_ce: 0.005251
2021-12-13 01:21:51,241 iteration 5314 : loss : 0.012966, loss_ce: 0.005395
2021-12-13 01:21:52,713 iteration 5315 : loss : 0.016826, loss_ce: 0.006826
2021-12-13 01:21:54,053 iteration 5316 : loss : 0.010994, loss_ce: 0.005071
2021-12-13 01:21:55,519 iteration 5317 : loss : 0.014833, loss_ce: 0.005188
2021-12-13 01:21:57,004 iteration 5318 : loss : 0.020023, loss_ce: 0.005862
2021-12-13 01:21:58,501 iteration 5319 : loss : 0.021273, loss_ce: 0.007112
2021-12-13 01:21:59,990 iteration 5320 : loss : 0.016842, loss_ce: 0.006725
2021-12-13 01:22:01,388 iteration 5321 : loss : 0.018371, loss_ce: 0.004059
 78%|██████████████████████▋      | 313/400 [2:20:10<37:46, 26.05s/it]2021-12-13 01:22:02,926 iteration 5322 : loss : 0.022854, loss_ce: 0.013727
2021-12-13 01:22:04,447 iteration 5323 : loss : 0.014655, loss_ce: 0.005016
2021-12-13 01:22:05,905 iteration 5324 : loss : 0.014561, loss_ce: 0.006725
2021-12-13 01:22:07,367 iteration 5325 : loss : 0.016824, loss_ce: 0.006038
2021-12-13 01:22:08,909 iteration 5326 : loss : 0.020405, loss_ce: 0.005467
2021-12-13 01:22:10,383 iteration 5327 : loss : 0.019532, loss_ce: 0.007511
2021-12-13 01:22:11,824 iteration 5328 : loss : 0.018432, loss_ce: 0.006778
2021-12-13 01:22:13,287 iteration 5329 : loss : 0.017643, loss_ce: 0.006741
2021-12-13 01:22:14,751 iteration 5330 : loss : 0.019016, loss_ce: 0.007158
2021-12-13 01:22:16,153 iteration 5331 : loss : 0.012079, loss_ce: 0.004672
2021-12-13 01:22:17,792 iteration 5332 : loss : 0.023220, loss_ce: 0.010151
2021-12-13 01:22:19,243 iteration 5333 : loss : 0.019574, loss_ce: 0.007562
2021-12-13 01:22:20,603 iteration 5334 : loss : 0.015125, loss_ce: 0.004223
2021-12-13 01:22:22,064 iteration 5335 : loss : 0.022908, loss_ce: 0.007511
2021-12-13 01:22:23,486 iteration 5336 : loss : 0.013444, loss_ce: 0.004700
2021-12-13 01:22:24,928 iteration 5337 : loss : 0.013755, loss_ce: 0.005328
2021-12-13 01:22:26,399 iteration 5338 : loss : 0.017008, loss_ce: 0.006489
 78%|██████████████████████▊      | 314/400 [2:20:35<36:53, 25.74s/it]2021-12-13 01:22:27,880 iteration 5339 : loss : 0.015908, loss_ce: 0.006165
2021-12-13 01:22:29,308 iteration 5340 : loss : 0.015533, loss_ce: 0.005775
2021-12-13 01:22:30,824 iteration 5341 : loss : 0.019828, loss_ce: 0.004990
2021-12-13 01:22:32,303 iteration 5342 : loss : 0.014865, loss_ce: 0.004711
2021-12-13 01:22:33,767 iteration 5343 : loss : 0.015580, loss_ce: 0.005705
2021-12-13 01:22:35,178 iteration 5344 : loss : 0.015012, loss_ce: 0.005954
2021-12-13 01:22:36,605 iteration 5345 : loss : 0.013823, loss_ce: 0.005519
2021-12-13 01:22:38,029 iteration 5346 : loss : 0.016763, loss_ce: 0.006543
2021-12-13 01:22:39,503 iteration 5347 : loss : 0.011305, loss_ce: 0.004642
2021-12-13 01:22:40,902 iteration 5348 : loss : 0.015033, loss_ce: 0.005808
2021-12-13 01:22:42,311 iteration 5349 : loss : 0.013018, loss_ce: 0.004428
2021-12-13 01:22:43,732 iteration 5350 : loss : 0.013615, loss_ce: 0.004523
2021-12-13 01:22:45,117 iteration 5351 : loss : 0.010047, loss_ce: 0.003424
2021-12-13 01:22:46,625 iteration 5352 : loss : 0.025615, loss_ce: 0.009228
2021-12-13 01:22:48,086 iteration 5353 : loss : 0.019044, loss_ce: 0.007273
2021-12-13 01:22:49,492 iteration 5354 : loss : 0.012305, loss_ce: 0.004989
2021-12-13 01:22:49,493 Training Data Eval:
2021-12-13 01:22:56,897   Average segmentation loss on training set: 0.1825
2021-12-13 01:22:56,898 Validation Data Eval:
2021-12-13 01:22:59,478   Average segmentation loss on validation set: 0.1937
2021-12-13 01:23:00,940 iteration 5355 : loss : 0.015226, loss_ce: 0.006786
 79%|██████████████████████▊      | 315/400 [2:21:10<40:12, 28.38s/it]2021-12-13 01:23:02,475 iteration 5356 : loss : 0.019176, loss_ce: 0.008229
2021-12-13 01:23:03,892 iteration 5357 : loss : 0.010525, loss_ce: 0.004054
2021-12-13 01:23:05,298 iteration 5358 : loss : 0.015016, loss_ce: 0.006287
2021-12-13 01:23:06,700 iteration 5359 : loss : 0.012804, loss_ce: 0.004003
2021-12-13 01:23:08,196 iteration 5360 : loss : 0.022957, loss_ce: 0.007936
2021-12-13 01:23:09,637 iteration 5361 : loss : 0.014565, loss_ce: 0.006373
2021-12-13 01:23:11,108 iteration 5362 : loss : 0.012607, loss_ce: 0.004401
2021-12-13 01:23:12,689 iteration 5363 : loss : 0.018112, loss_ce: 0.007177
2021-12-13 01:23:14,129 iteration 5364 : loss : 0.022298, loss_ce: 0.005277
2021-12-13 01:23:15,589 iteration 5365 : loss : 0.019367, loss_ce: 0.006411
2021-12-13 01:23:17,016 iteration 5366 : loss : 0.021642, loss_ce: 0.007263
2021-12-13 01:23:18,378 iteration 5367 : loss : 0.012144, loss_ce: 0.004244
2021-12-13 01:23:19,919 iteration 5368 : loss : 0.020602, loss_ce: 0.006706
2021-12-13 01:23:21,339 iteration 5369 : loss : 0.009724, loss_ce: 0.003755
2021-12-13 01:23:22,762 iteration 5370 : loss : 0.014893, loss_ce: 0.006550
2021-12-13 01:23:24,190 iteration 5371 : loss : 0.010959, loss_ce: 0.002876
2021-12-13 01:23:25,556 iteration 5372 : loss : 0.012789, loss_ce: 0.004803
 79%|██████████████████████▉      | 316/400 [2:21:34<38:09, 27.25s/it]2021-12-13 01:23:27,022 iteration 5373 : loss : 0.015581, loss_ce: 0.005618
2021-12-13 01:23:28,440 iteration 5374 : loss : 0.020176, loss_ce: 0.004877
2021-12-13 01:23:29,889 iteration 5375 : loss : 0.014993, loss_ce: 0.006242
2021-12-13 01:23:31,350 iteration 5376 : loss : 0.017519, loss_ce: 0.006316
2021-12-13 01:23:32,820 iteration 5377 : loss : 0.015564, loss_ce: 0.004550
2021-12-13 01:23:34,277 iteration 5378 : loss : 0.022770, loss_ce: 0.006750
2021-12-13 01:23:35,695 iteration 5379 : loss : 0.016723, loss_ce: 0.007071
2021-12-13 01:23:37,070 iteration 5380 : loss : 0.013345, loss_ce: 0.005435
2021-12-13 01:23:38,582 iteration 5381 : loss : 0.015605, loss_ce: 0.006663
2021-12-13 01:23:40,014 iteration 5382 : loss : 0.019542, loss_ce: 0.007143
2021-12-13 01:23:41,434 iteration 5383 : loss : 0.016445, loss_ce: 0.008100
2021-12-13 01:23:42,851 iteration 5384 : loss : 0.012189, loss_ce: 0.005136
2021-12-13 01:23:44,310 iteration 5385 : loss : 0.017442, loss_ce: 0.006127
2021-12-13 01:23:45,718 iteration 5386 : loss : 0.016077, loss_ce: 0.006039
2021-12-13 01:23:47,254 iteration 5387 : loss : 0.017654, loss_ce: 0.006459
2021-12-13 01:23:48,729 iteration 5388 : loss : 0.011451, loss_ce: 0.003459
2021-12-13 01:23:50,244 iteration 5389 : loss : 0.018293, loss_ce: 0.007859
 79%|██████████████████████▉      | 317/400 [2:21:59<36:38, 26.48s/it]2021-12-13 01:23:51,687 iteration 5390 : loss : 0.012091, loss_ce: 0.004129
2021-12-13 01:23:53,200 iteration 5391 : loss : 0.022753, loss_ce: 0.006855
2021-12-13 01:23:54,624 iteration 5392 : loss : 0.019357, loss_ce: 0.005706
2021-12-13 01:23:56,015 iteration 5393 : loss : 0.016848, loss_ce: 0.006168
2021-12-13 01:23:57,440 iteration 5394 : loss : 0.013963, loss_ce: 0.004246
2021-12-13 01:23:58,869 iteration 5395 : loss : 0.023591, loss_ce: 0.007963
2021-12-13 01:24:00,278 iteration 5396 : loss : 0.012889, loss_ce: 0.004585
2021-12-13 01:24:01,768 iteration 5397 : loss : 0.017649, loss_ce: 0.006794
2021-12-13 01:24:03,350 iteration 5398 : loss : 0.024772, loss_ce: 0.007617
2021-12-13 01:24:04,832 iteration 5399 : loss : 0.016899, loss_ce: 0.004909
2021-12-13 01:24:06,241 iteration 5400 : loss : 0.014011, loss_ce: 0.005501
2021-12-13 01:24:07,705 iteration 5401 : loss : 0.016305, loss_ce: 0.008723
2021-12-13 01:24:09,129 iteration 5402 : loss : 0.013408, loss_ce: 0.006866
2021-12-13 01:24:10,579 iteration 5403 : loss : 0.017294, loss_ce: 0.006494
2021-12-13 01:24:12,052 iteration 5404 : loss : 0.013703, loss_ce: 0.006478
2021-12-13 01:24:13,592 iteration 5405 : loss : 0.019418, loss_ce: 0.005970
2021-12-13 01:24:14,992 iteration 5406 : loss : 0.010536, loss_ce: 0.004603
 80%|███████████████████████      | 318/400 [2:22:24<35:28, 25.96s/it]2021-12-13 01:24:16,461 iteration 5407 : loss : 0.017126, loss_ce: 0.007184
2021-12-13 01:24:17,892 iteration 5408 : loss : 0.014960, loss_ce: 0.005748
2021-12-13 01:24:19,269 iteration 5409 : loss : 0.011035, loss_ce: 0.003575
2021-12-13 01:24:20,731 iteration 5410 : loss : 0.019173, loss_ce: 0.007548
2021-12-13 01:24:22,136 iteration 5411 : loss : 0.010566, loss_ce: 0.004005
2021-12-13 01:24:23,605 iteration 5412 : loss : 0.023437, loss_ce: 0.009949
2021-12-13 01:24:25,026 iteration 5413 : loss : 0.013102, loss_ce: 0.005291
2021-12-13 01:24:26,482 iteration 5414 : loss : 0.021474, loss_ce: 0.009131
2021-12-13 01:24:28,033 iteration 5415 : loss : 0.019733, loss_ce: 0.006292
2021-12-13 01:24:29,435 iteration 5416 : loss : 0.014393, loss_ce: 0.004516
2021-12-13 01:24:30,874 iteration 5417 : loss : 0.011038, loss_ce: 0.003442
2021-12-13 01:24:32,395 iteration 5418 : loss : 0.016926, loss_ce: 0.007225
2021-12-13 01:24:33,786 iteration 5419 : loss : 0.013415, loss_ce: 0.005433
2021-12-13 01:24:35,194 iteration 5420 : loss : 0.011819, loss_ce: 0.004597
2021-12-13 01:24:36,697 iteration 5421 : loss : 0.024612, loss_ce: 0.010705
2021-12-13 01:24:38,208 iteration 5422 : loss : 0.018111, loss_ce: 0.003997
2021-12-13 01:24:39,704 iteration 5423 : loss : 0.021232, loss_ce: 0.009386
 80%|███████████████████████▏     | 319/400 [2:22:48<34:32, 25.59s/it]2021-12-13 01:24:41,183 iteration 5424 : loss : 0.018502, loss_ce: 0.006021
2021-12-13 01:24:42,602 iteration 5425 : loss : 0.022535, loss_ce: 0.005827
2021-12-13 01:24:44,112 iteration 5426 : loss : 0.017138, loss_ce: 0.007697
2021-12-13 01:24:45,480 iteration 5427 : loss : 0.014200, loss_ce: 0.004200
2021-12-13 01:24:46,898 iteration 5428 : loss : 0.011913, loss_ce: 0.004744
2021-12-13 01:24:48,312 iteration 5429 : loss : 0.016587, loss_ce: 0.006741
2021-12-13 01:24:49,851 iteration 5430 : loss : 0.017201, loss_ce: 0.005124
2021-12-13 01:24:51,261 iteration 5431 : loss : 0.019076, loss_ce: 0.007302
2021-12-13 01:24:52,675 iteration 5432 : loss : 0.016309, loss_ce: 0.006670
2021-12-13 01:24:54,175 iteration 5433 : loss : 0.015775, loss_ce: 0.006956
2021-12-13 01:24:55,603 iteration 5434 : loss : 0.016301, loss_ce: 0.005748
2021-12-13 01:24:57,145 iteration 5435 : loss : 0.018108, loss_ce: 0.008326
2021-12-13 01:24:58,586 iteration 5436 : loss : 0.013082, loss_ce: 0.005289
2021-12-13 01:24:59,917 iteration 5437 : loss : 0.010457, loss_ce: 0.004142
2021-12-13 01:25:01,444 iteration 5438 : loss : 0.024562, loss_ce: 0.008721
2021-12-13 01:25:02,845 iteration 5439 : loss : 0.010008, loss_ce: 0.003262
2021-12-13 01:25:02,845 Training Data Eval:
2021-12-13 01:25:10,227   Average segmentation loss on training set: 0.0224
2021-12-13 01:25:10,227 Validation Data Eval:
2021-12-13 01:25:12,795   Average segmentation loss on validation set: 0.1828
2021-12-13 01:25:14,297 iteration 5440 : loss : 0.021981, loss_ce: 0.005357
 80%|███████████████████████▏     | 320/400 [2:23:23<37:43, 28.29s/it]2021-12-13 01:25:15,678 iteration 5441 : loss : 0.011969, loss_ce: 0.003687
2021-12-13 01:25:17,117 iteration 5442 : loss : 0.017931, loss_ce: 0.005976
2021-12-13 01:25:18,588 iteration 5443 : loss : 0.012140, loss_ce: 0.003983
2021-12-13 01:25:20,044 iteration 5444 : loss : 0.012941, loss_ce: 0.004896
2021-12-13 01:25:21,557 iteration 5445 : loss : 0.019914, loss_ce: 0.010271
2021-12-13 01:25:22,965 iteration 5446 : loss : 0.019997, loss_ce: 0.009349
2021-12-13 01:25:24,408 iteration 5447 : loss : 0.017833, loss_ce: 0.007062
2021-12-13 01:25:25,870 iteration 5448 : loss : 0.021984, loss_ce: 0.007153
2021-12-13 01:25:27,301 iteration 5449 : loss : 0.016189, loss_ce: 0.005262
2021-12-13 01:25:28,803 iteration 5450 : loss : 0.020113, loss_ce: 0.009208
2021-12-13 01:25:30,230 iteration 5451 : loss : 0.018637, loss_ce: 0.008507
2021-12-13 01:25:31,725 iteration 5452 : loss : 0.017036, loss_ce: 0.006443
2021-12-13 01:25:33,187 iteration 5453 : loss : 0.015069, loss_ce: 0.005977
2021-12-13 01:25:34,538 iteration 5454 : loss : 0.009390, loss_ce: 0.004287
2021-12-13 01:25:36,075 iteration 5455 : loss : 0.027208, loss_ce: 0.009439
2021-12-13 01:25:37,565 iteration 5456 : loss : 0.016232, loss_ce: 0.005985
2021-12-13 01:25:38,991 iteration 5457 : loss : 0.017309, loss_ce: 0.005936
 80%|███████████████████████▎     | 321/400 [2:23:48<35:49, 27.21s/it]2021-12-13 01:25:40,441 iteration 5458 : loss : 0.014725, loss_ce: 0.005303
2021-12-13 01:25:41,842 iteration 5459 : loss : 0.011735, loss_ce: 0.004220
2021-12-13 01:25:43,314 iteration 5460 : loss : 0.021562, loss_ce: 0.009098
2021-12-13 01:25:44,792 iteration 5461 : loss : 0.017658, loss_ce: 0.007466
2021-12-13 01:25:46,243 iteration 5462 : loss : 0.010871, loss_ce: 0.002963
2021-12-13 01:25:47,663 iteration 5463 : loss : 0.013911, loss_ce: 0.005617
2021-12-13 01:25:49,085 iteration 5464 : loss : 0.014976, loss_ce: 0.005389
2021-12-13 01:25:50,465 iteration 5465 : loss : 0.014648, loss_ce: 0.004690
2021-12-13 01:25:51,980 iteration 5466 : loss : 0.014089, loss_ce: 0.005348
2021-12-13 01:25:53,400 iteration 5467 : loss : 0.011537, loss_ce: 0.005471
2021-12-13 01:25:54,850 iteration 5468 : loss : 0.020428, loss_ce: 0.010051
2021-12-13 01:25:56,238 iteration 5469 : loss : 0.009863, loss_ce: 0.003320
2021-12-13 01:25:57,721 iteration 5470 : loss : 0.017054, loss_ce: 0.006793
2021-12-13 01:25:59,162 iteration 5471 : loss : 0.013414, loss_ce: 0.004736
2021-12-13 01:26:00,660 iteration 5472 : loss : 0.012615, loss_ce: 0.004388
2021-12-13 01:26:02,146 iteration 5473 : loss : 0.017195, loss_ce: 0.005307
2021-12-13 01:26:03,640 iteration 5474 : loss : 0.017778, loss_ce: 0.007466
 80%|███████████████████████▎     | 322/400 [2:24:12<34:22, 26.44s/it]2021-12-13 01:26:05,111 iteration 5475 : loss : 0.010202, loss_ce: 0.002738
2021-12-13 01:26:06,524 iteration 5476 : loss : 0.016627, loss_ce: 0.004966
2021-12-13 01:26:07,931 iteration 5477 : loss : 0.011420, loss_ce: 0.004673
2021-12-13 01:26:09,369 iteration 5478 : loss : 0.016077, loss_ce: 0.006849
2021-12-13 01:26:10,907 iteration 5479 : loss : 0.013809, loss_ce: 0.005699
2021-12-13 01:26:12,418 iteration 5480 : loss : 0.018328, loss_ce: 0.007334
2021-12-13 01:26:13,848 iteration 5481 : loss : 0.014701, loss_ce: 0.004445
2021-12-13 01:26:15,285 iteration 5482 : loss : 0.010953, loss_ce: 0.003738
2021-12-13 01:26:16,736 iteration 5483 : loss : 0.015903, loss_ce: 0.006002
2021-12-13 01:26:18,149 iteration 5484 : loss : 0.014843, loss_ce: 0.006070
2021-12-13 01:26:19,508 iteration 5485 : loss : 0.016864, loss_ce: 0.006762
2021-12-13 01:26:21,053 iteration 5486 : loss : 0.016354, loss_ce: 0.006134
2021-12-13 01:26:22,638 iteration 5487 : loss : 0.022531, loss_ce: 0.007918
2021-12-13 01:26:24,069 iteration 5488 : loss : 0.020482, loss_ce: 0.008479
2021-12-13 01:26:25,501 iteration 5489 : loss : 0.014174, loss_ce: 0.005488
2021-12-13 01:26:26,916 iteration 5490 : loss : 0.023688, loss_ce: 0.008638
2021-12-13 01:26:28,347 iteration 5491 : loss : 0.011875, loss_ce: 0.004540
 81%|███████████████████████▍     | 323/400 [2:24:37<33:15, 25.92s/it]2021-12-13 01:26:29,824 iteration 5492 : loss : 0.016148, loss_ce: 0.005981
2021-12-13 01:26:31,232 iteration 5493 : loss : 0.013894, loss_ce: 0.005960
2021-12-13 01:26:32,622 iteration 5494 : loss : 0.015192, loss_ce: 0.003997
2021-12-13 01:26:34,129 iteration 5495 : loss : 0.022785, loss_ce: 0.003120
2021-12-13 01:26:35,533 iteration 5496 : loss : 0.017635, loss_ce: 0.006709
2021-12-13 01:26:36,977 iteration 5497 : loss : 0.012526, loss_ce: 0.003901
2021-12-13 01:26:38,444 iteration 5498 : loss : 0.020046, loss_ce: 0.010853
2021-12-13 01:26:39,874 iteration 5499 : loss : 0.017443, loss_ce: 0.006504
2021-12-13 01:26:41,336 iteration 5500 : loss : 0.024127, loss_ce: 0.009588
2021-12-13 01:26:42,856 iteration 5501 : loss : 0.017499, loss_ce: 0.007880
2021-12-13 01:26:44,336 iteration 5502 : loss : 0.020909, loss_ce: 0.010736
2021-12-13 01:26:45,756 iteration 5503 : loss : 0.014189, loss_ce: 0.004089
2021-12-13 01:26:47,229 iteration 5504 : loss : 0.016672, loss_ce: 0.007695
2021-12-13 01:26:48,691 iteration 5505 : loss : 0.017927, loss_ce: 0.009375
2021-12-13 01:26:50,092 iteration 5506 : loss : 0.015529, loss_ce: 0.005778
2021-12-13 01:26:51,555 iteration 5507 : loss : 0.015102, loss_ce: 0.004482
2021-12-13 01:26:53,003 iteration 5508 : loss : 0.016867, loss_ce: 0.007673
 81%|███████████████████████▍     | 324/400 [2:25:02<32:21, 25.54s/it]2021-12-13 01:26:54,471 iteration 5509 : loss : 0.015344, loss_ce: 0.005300
2021-12-13 01:26:56,039 iteration 5510 : loss : 0.021403, loss_ce: 0.006929
2021-12-13 01:26:57,487 iteration 5511 : loss : 0.016745, loss_ce: 0.007989
2021-12-13 01:26:58,985 iteration 5512 : loss : 0.014381, loss_ce: 0.002417
2021-12-13 01:27:00,403 iteration 5513 : loss : 0.015432, loss_ce: 0.003162
2021-12-13 01:27:01,887 iteration 5514 : loss : 0.019407, loss_ce: 0.008472
2021-12-13 01:27:03,401 iteration 5515 : loss : 0.022838, loss_ce: 0.007791
2021-12-13 01:27:04,762 iteration 5516 : loss : 0.010236, loss_ce: 0.004049
2021-12-13 01:27:06,240 iteration 5517 : loss : 0.018162, loss_ce: 0.005995
2021-12-13 01:27:07,672 iteration 5518 : loss : 0.015042, loss_ce: 0.006360
2021-12-13 01:27:09,092 iteration 5519 : loss : 0.024824, loss_ce: 0.008094
2021-12-13 01:27:10,563 iteration 5520 : loss : 0.018956, loss_ce: 0.006954
2021-12-13 01:27:12,122 iteration 5521 : loss : 0.015712, loss_ce: 0.005223
2021-12-13 01:27:13,496 iteration 5522 : loss : 0.010361, loss_ce: 0.004556
2021-12-13 01:27:14,945 iteration 5523 : loss : 0.015885, loss_ce: 0.006436
2021-12-13 01:27:16,410 iteration 5524 : loss : 0.019092, loss_ce: 0.009359
2021-12-13 01:27:16,410 Training Data Eval:
2021-12-13 01:27:23,822   Average segmentation loss on training set: 0.0103
2021-12-13 01:27:23,823 Validation Data Eval:
2021-12-13 01:27:26,391   Average segmentation loss on validation set: 0.0885
2021-12-13 01:27:27,888 iteration 5525 : loss : 0.019750, loss_ce: 0.008427
 81%|███████████████████████▌     | 325/400 [2:25:37<35:25, 28.35s/it]2021-12-13 01:27:29,461 iteration 5526 : loss : 0.022384, loss_ce: 0.008941
2021-12-13 01:27:30,867 iteration 5527 : loss : 0.013983, loss_ce: 0.004465
2021-12-13 01:27:32,332 iteration 5528 : loss : 0.017117, loss_ce: 0.006501
2021-12-13 01:27:33,745 iteration 5529 : loss : 0.012566, loss_ce: 0.004359
2021-12-13 01:27:35,140 iteration 5530 : loss : 0.013494, loss_ce: 0.003559
2021-12-13 01:27:36,599 iteration 5531 : loss : 0.013128, loss_ce: 0.004596
2021-12-13 01:27:37,967 iteration 5532 : loss : 0.011736, loss_ce: 0.003857
2021-12-13 01:27:39,447 iteration 5533 : loss : 0.013728, loss_ce: 0.005428
2021-12-13 01:27:40,906 iteration 5534 : loss : 0.019611, loss_ce: 0.006835
2021-12-13 01:27:42,365 iteration 5535 : loss : 0.014514, loss_ce: 0.005490
2021-12-13 01:27:43,794 iteration 5536 : loss : 0.020377, loss_ce: 0.006327
2021-12-13 01:27:45,224 iteration 5537 : loss : 0.013660, loss_ce: 0.004216
2021-12-13 01:27:46,648 iteration 5538 : loss : 0.013500, loss_ce: 0.006875
2021-12-13 01:27:48,106 iteration 5539 : loss : 0.015070, loss_ce: 0.006569
2021-12-13 01:27:49,578 iteration 5540 : loss : 0.011516, loss_ce: 0.004017
2021-12-13 01:27:50,967 iteration 5541 : loss : 0.014084, loss_ce: 0.005422
2021-12-13 01:27:52,382 iteration 5542 : loss : 0.012796, loss_ce: 0.005082
 82%|███████████████████████▋     | 326/400 [2:26:01<33:31, 27.19s/it]2021-12-13 01:27:53,912 iteration 5543 : loss : 0.021291, loss_ce: 0.009038
2021-12-13 01:27:55,451 iteration 5544 : loss : 0.015693, loss_ce: 0.005024
2021-12-13 01:27:56,950 iteration 5545 : loss : 0.017479, loss_ce: 0.006584
2021-12-13 01:27:58,327 iteration 5546 : loss : 0.009681, loss_ce: 0.004395
2021-12-13 01:27:59,802 iteration 5547 : loss : 0.011982, loss_ce: 0.004989
2021-12-13 01:28:01,216 iteration 5548 : loss : 0.019550, loss_ce: 0.006344
2021-12-13 01:28:02,644 iteration 5549 : loss : 0.013966, loss_ce: 0.005629
2021-12-13 01:28:04,102 iteration 5550 : loss : 0.018048, loss_ce: 0.006766
2021-12-13 01:28:05,568 iteration 5551 : loss : 0.012235, loss_ce: 0.002852
2021-12-13 01:28:07,097 iteration 5552 : loss : 0.023505, loss_ce: 0.007031
2021-12-13 01:28:08,557 iteration 5553 : loss : 0.011797, loss_ce: 0.004319
2021-12-13 01:28:10,081 iteration 5554 : loss : 0.018264, loss_ce: 0.004854
2021-12-13 01:28:11,590 iteration 5555 : loss : 0.013959, loss_ce: 0.005573
2021-12-13 01:28:13,072 iteration 5556 : loss : 0.016911, loss_ce: 0.007266
2021-12-13 01:28:14,546 iteration 5557 : loss : 0.015248, loss_ce: 0.004293
2021-12-13 01:28:15,979 iteration 5558 : loss : 0.020658, loss_ce: 0.006428
2021-12-13 01:28:17,362 iteration 5559 : loss : 0.013342, loss_ce: 0.004212
 82%|███████████████████████▋     | 327/400 [2:26:26<32:16, 26.53s/it]2021-12-13 01:28:18,847 iteration 5560 : loss : 0.014413, loss_ce: 0.005120
2021-12-13 01:28:20,367 iteration 5561 : loss : 0.015057, loss_ce: 0.003929
2021-12-13 01:28:21,825 iteration 5562 : loss : 0.013409, loss_ce: 0.004008
2021-12-13 01:28:23,320 iteration 5563 : loss : 0.017613, loss_ce: 0.006200
2021-12-13 01:28:24,695 iteration 5564 : loss : 0.015832, loss_ce: 0.005249
2021-12-13 01:28:26,164 iteration 5565 : loss : 0.023016, loss_ce: 0.005477
2021-12-13 01:28:27,575 iteration 5566 : loss : 0.011674, loss_ce: 0.003868
2021-12-13 01:28:29,073 iteration 5567 : loss : 0.013043, loss_ce: 0.005888
2021-12-13 01:28:30,568 iteration 5568 : loss : 0.017190, loss_ce: 0.008228
2021-12-13 01:28:32,068 iteration 5569 : loss : 0.017054, loss_ce: 0.007909
2021-12-13 01:28:33,514 iteration 5570 : loss : 0.012475, loss_ce: 0.005494
2021-12-13 01:28:34,950 iteration 5571 : loss : 0.024586, loss_ce: 0.006623
2021-12-13 01:28:36,302 iteration 5572 : loss : 0.009853, loss_ce: 0.003405
2021-12-13 01:28:37,783 iteration 5573 : loss : 0.016493, loss_ce: 0.006446
2021-12-13 01:28:39,188 iteration 5574 : loss : 0.011321, loss_ce: 0.004333
2021-12-13 01:28:40,575 iteration 5575 : loss : 0.010419, loss_ce: 0.003752
2021-12-13 01:28:41,933 iteration 5576 : loss : 0.015665, loss_ce: 0.004555
 82%|███████████████████████▊     | 328/400 [2:26:51<31:07, 25.94s/it]2021-12-13 01:28:43,472 iteration 5577 : loss : 0.028412, loss_ce: 0.008810
2021-12-13 01:28:44,928 iteration 5578 : loss : 0.015843, loss_ce: 0.006375
2021-12-13 01:28:46,478 iteration 5579 : loss : 0.019372, loss_ce: 0.005058
2021-12-13 01:28:47,975 iteration 5580 : loss : 0.015185, loss_ce: 0.005072
2021-12-13 01:28:49,438 iteration 5581 : loss : 0.018230, loss_ce: 0.008832
2021-12-13 01:28:50,869 iteration 5582 : loss : 0.013277, loss_ce: 0.004680
2021-12-13 01:28:52,271 iteration 5583 : loss : 0.010818, loss_ce: 0.003077
2021-12-13 01:28:53,698 iteration 5584 : loss : 0.012758, loss_ce: 0.004820
2021-12-13 01:28:55,085 iteration 5585 : loss : 0.011515, loss_ce: 0.003798
2021-12-13 01:28:56,490 iteration 5586 : loss : 0.011654, loss_ce: 0.004706
2021-12-13 01:28:58,006 iteration 5587 : loss : 0.020344, loss_ce: 0.008001
2021-12-13 01:28:59,447 iteration 5588 : loss : 0.023075, loss_ce: 0.008469
2021-12-13 01:29:00,951 iteration 5589 : loss : 0.015079, loss_ce: 0.005347
2021-12-13 01:29:02,336 iteration 5590 : loss : 0.012089, loss_ce: 0.005088
2021-12-13 01:29:03,810 iteration 5591 : loss : 0.024781, loss_ce: 0.008921
2021-12-13 01:29:05,278 iteration 5592 : loss : 0.014378, loss_ce: 0.005309
2021-12-13 01:29:06,649 iteration 5593 : loss : 0.011680, loss_ce: 0.005605
 82%|███████████████████████▊     | 329/400 [2:27:15<30:15, 25.57s/it]2021-12-13 01:29:08,134 iteration 5594 : loss : 0.010454, loss_ce: 0.003805
2021-12-13 01:29:09,522 iteration 5595 : loss : 0.010647, loss_ce: 0.003953
2021-12-13 01:29:11,031 iteration 5596 : loss : 0.019762, loss_ce: 0.006419
2021-12-13 01:29:12,491 iteration 5597 : loss : 0.016612, loss_ce: 0.007274
2021-12-13 01:29:14,039 iteration 5598 : loss : 0.018183, loss_ce: 0.008823
2021-12-13 01:29:15,555 iteration 5599 : loss : 0.020086, loss_ce: 0.006680
2021-12-13 01:29:16,932 iteration 5600 : loss : 0.011210, loss_ce: 0.004304
2021-12-13 01:29:18,389 iteration 5601 : loss : 0.015952, loss_ce: 0.004911
2021-12-13 01:29:19,835 iteration 5602 : loss : 0.019025, loss_ce: 0.006398
2021-12-13 01:29:21,282 iteration 5603 : loss : 0.017956, loss_ce: 0.009122
2021-12-13 01:29:22,742 iteration 5604 : loss : 0.017354, loss_ce: 0.005161
2021-12-13 01:29:24,161 iteration 5605 : loss : 0.011530, loss_ce: 0.005036
2021-12-13 01:29:25,652 iteration 5606 : loss : 0.020558, loss_ce: 0.007385
2021-12-13 01:29:27,065 iteration 5607 : loss : 0.013374, loss_ce: 0.005712
2021-12-13 01:29:28,539 iteration 5608 : loss : 0.013501, loss_ce: 0.006432
2021-12-13 01:29:29,956 iteration 5609 : loss : 0.012458, loss_ce: 0.004137
2021-12-13 01:29:29,956 Training Data Eval:
2021-12-13 01:29:37,395   Average segmentation loss on training set: 0.0085
2021-12-13 01:29:37,395 Validation Data Eval:
2021-12-13 01:29:39,976   Average segmentation loss on validation set: 0.0793
2021-12-13 01:29:41,459 iteration 5610 : loss : 0.012912, loss_ce: 0.005181
 82%|███████████████████████▉     | 330/400 [2:27:50<33:04, 28.35s/it]2021-12-13 01:29:42,891 iteration 5611 : loss : 0.008888, loss_ce: 0.003347
2021-12-13 01:29:44,388 iteration 5612 : loss : 0.026664, loss_ce: 0.007929
2021-12-13 01:29:45,805 iteration 5613 : loss : 0.012382, loss_ce: 0.002615
2021-12-13 01:29:47,230 iteration 5614 : loss : 0.013973, loss_ce: 0.005029
2021-12-13 01:29:48,674 iteration 5615 : loss : 0.019081, loss_ce: 0.008908
2021-12-13 01:29:50,127 iteration 5616 : loss : 0.012232, loss_ce: 0.003411
2021-12-13 01:29:51,720 iteration 5617 : loss : 0.018815, loss_ce: 0.005415
2021-12-13 01:29:53,211 iteration 5618 : loss : 0.014859, loss_ce: 0.004858
2021-12-13 01:29:54,660 iteration 5619 : loss : 0.013163, loss_ce: 0.005999
2021-12-13 01:29:56,047 iteration 5620 : loss : 0.014575, loss_ce: 0.005452
2021-12-13 01:29:57,435 iteration 5621 : loss : 0.014974, loss_ce: 0.006616
2021-12-13 01:29:58,806 iteration 5622 : loss : 0.013407, loss_ce: 0.005583
2021-12-13 01:30:00,331 iteration 5623 : loss : 0.011896, loss_ce: 0.004532
2021-12-13 01:30:01,779 iteration 5624 : loss : 0.013464, loss_ce: 0.005138
2021-12-13 01:30:03,220 iteration 5625 : loss : 0.016673, loss_ce: 0.007857
2021-12-13 01:30:04,696 iteration 5626 : loss : 0.015273, loss_ce: 0.005397
2021-12-13 01:30:06,147 iteration 5627 : loss : 0.012927, loss_ce: 0.005350
 83%|███████████████████████▉     | 331/400 [2:28:15<31:20, 27.25s/it]2021-12-13 01:30:07,640 iteration 5628 : loss : 0.013548, loss_ce: 0.005397
2021-12-13 01:30:09,108 iteration 5629 : loss : 0.018704, loss_ce: 0.008273
2021-12-13 01:30:10,577 iteration 5630 : loss : 0.011574, loss_ce: 0.004564
2021-12-13 01:30:12,052 iteration 5631 : loss : 0.014564, loss_ce: 0.007425
2021-12-13 01:30:13,577 iteration 5632 : loss : 0.024951, loss_ce: 0.010489
2021-12-13 01:30:14,942 iteration 5633 : loss : 0.017494, loss_ce: 0.004076
2021-12-13 01:30:16,459 iteration 5634 : loss : 0.018565, loss_ce: 0.004741
2021-12-13 01:30:17,913 iteration 5635 : loss : 0.013958, loss_ce: 0.005273
2021-12-13 01:30:19,304 iteration 5636 : loss : 0.016786, loss_ce: 0.004420
2021-12-13 01:30:20,845 iteration 5637 : loss : 0.013617, loss_ce: 0.005260
2021-12-13 01:30:22,282 iteration 5638 : loss : 0.013495, loss_ce: 0.006136
2021-12-13 01:30:23,739 iteration 5639 : loss : 0.016424, loss_ce: 0.005101
2021-12-13 01:30:25,180 iteration 5640 : loss : 0.014102, loss_ce: 0.004496
2021-12-13 01:30:26,579 iteration 5641 : loss : 0.017430, loss_ce: 0.006264
2021-12-13 01:30:28,130 iteration 5642 : loss : 0.019971, loss_ce: 0.008912
2021-12-13 01:30:29,506 iteration 5643 : loss : 0.013901, loss_ce: 0.006778
2021-12-13 01:30:30,949 iteration 5644 : loss : 0.014632, loss_ce: 0.006322
 83%|████████████████████████     | 332/400 [2:28:40<30:03, 26.52s/it]2021-12-13 01:30:32,388 iteration 5645 : loss : 0.017827, loss_ce: 0.005106
2021-12-13 01:30:33,814 iteration 5646 : loss : 0.010068, loss_ce: 0.002733
2021-12-13 01:30:35,201 iteration 5647 : loss : 0.010040, loss_ce: 0.003272
2021-12-13 01:30:36,645 iteration 5648 : loss : 0.012304, loss_ce: 0.005711
2021-12-13 01:30:38,046 iteration 5649 : loss : 0.014452, loss_ce: 0.003826
2021-12-13 01:30:39,542 iteration 5650 : loss : 0.019475, loss_ce: 0.007998
2021-12-13 01:30:40,983 iteration 5651 : loss : 0.013253, loss_ce: 0.006264
2021-12-13 01:30:42,450 iteration 5652 : loss : 0.013800, loss_ce: 0.004247
2021-12-13 01:30:43,908 iteration 5653 : loss : 0.013707, loss_ce: 0.004513
2021-12-13 01:30:45,352 iteration 5654 : loss : 0.013022, loss_ce: 0.004849
2021-12-13 01:30:46,724 iteration 5655 : loss : 0.012602, loss_ce: 0.005965
2021-12-13 01:30:48,266 iteration 5656 : loss : 0.023015, loss_ce: 0.007230
2021-12-13 01:30:49,765 iteration 5657 : loss : 0.020777, loss_ce: 0.007721
2021-12-13 01:30:51,245 iteration 5658 : loss : 0.018859, loss_ce: 0.009176
2021-12-13 01:30:52,648 iteration 5659 : loss : 0.013261, loss_ce: 0.004889
2021-12-13 01:30:54,126 iteration 5660 : loss : 0.015542, loss_ce: 0.005342
2021-12-13 01:30:55,579 iteration 5661 : loss : 0.015556, loss_ce: 0.006439
 83%|████████████████████████▏    | 333/400 [2:29:04<28:58, 25.95s/it]2021-12-13 01:30:57,060 iteration 5662 : loss : 0.015790, loss_ce: 0.005791
2021-12-13 01:30:58,458 iteration 5663 : loss : 0.016950, loss_ce: 0.005422
2021-12-13 01:30:59,904 iteration 5664 : loss : 0.019450, loss_ce: 0.008437
2021-12-13 01:31:01,305 iteration 5665 : loss : 0.009676, loss_ce: 0.003582
2021-12-13 01:31:02,774 iteration 5666 : loss : 0.017393, loss_ce: 0.004384
2021-12-13 01:31:04,268 iteration 5667 : loss : 0.015378, loss_ce: 0.005008
2021-12-13 01:31:05,718 iteration 5668 : loss : 0.016547, loss_ce: 0.005841
2021-12-13 01:31:07,099 iteration 5669 : loss : 0.011439, loss_ce: 0.004121
2021-12-13 01:31:08,521 iteration 5670 : loss : 0.016953, loss_ce: 0.005325
2021-12-13 01:31:09,931 iteration 5671 : loss : 0.011033, loss_ce: 0.004086
2021-12-13 01:31:11,473 iteration 5672 : loss : 0.018813, loss_ce: 0.008389
2021-12-13 01:31:12,900 iteration 5673 : loss : 0.019071, loss_ce: 0.006413
2021-12-13 01:31:14,343 iteration 5674 : loss : 0.015265, loss_ce: 0.004563
2021-12-13 01:31:15,750 iteration 5675 : loss : 0.012531, loss_ce: 0.006488
2021-12-13 01:31:17,256 iteration 5676 : loss : 0.020402, loss_ce: 0.008022
2021-12-13 01:31:18,707 iteration 5677 : loss : 0.022433, loss_ce: 0.005152
2021-12-13 01:31:20,237 iteration 5678 : loss : 0.017033, loss_ce: 0.006891
 84%|████████████████████████▏    | 334/400 [2:29:29<28:06, 25.56s/it]2021-12-13 01:31:21,742 iteration 5679 : loss : 0.014827, loss_ce: 0.005562
2021-12-13 01:31:23,139 iteration 5680 : loss : 0.017134, loss_ce: 0.006683
2021-12-13 01:31:24,593 iteration 5681 : loss : 0.012054, loss_ce: 0.004877
2021-12-13 01:31:26,028 iteration 5682 : loss : 0.019482, loss_ce: 0.006752
2021-12-13 01:31:27,503 iteration 5683 : loss : 0.019060, loss_ce: 0.007399
2021-12-13 01:31:29,013 iteration 5684 : loss : 0.017146, loss_ce: 0.006291
2021-12-13 01:31:30,495 iteration 5685 : loss : 0.011064, loss_ce: 0.002573
2021-12-13 01:31:31,931 iteration 5686 : loss : 0.014163, loss_ce: 0.006016
2021-12-13 01:31:33,335 iteration 5687 : loss : 0.011071, loss_ce: 0.002897
2021-12-13 01:31:34,762 iteration 5688 : loss : 0.012718, loss_ce: 0.004495
2021-12-13 01:31:36,192 iteration 5689 : loss : 0.016186, loss_ce: 0.007129
2021-12-13 01:31:37,667 iteration 5690 : loss : 0.017079, loss_ce: 0.008670
2021-12-13 01:31:39,089 iteration 5691 : loss : 0.011313, loss_ce: 0.002814
2021-12-13 01:31:40,497 iteration 5692 : loss : 0.011317, loss_ce: 0.003831
2021-12-13 01:31:41,971 iteration 5693 : loss : 0.019570, loss_ce: 0.008669
2021-12-13 01:31:43,463 iteration 5694 : loss : 0.018292, loss_ce: 0.006701
2021-12-13 01:31:43,463 Training Data Eval:
2021-12-13 01:31:50,910   Average segmentation loss on training set: 0.0078
2021-12-13 01:31:50,910 Validation Data Eval:
2021-12-13 01:31:53,504   Average segmentation loss on validation set: 0.0638
2021-12-13 01:31:59,891 Found new lowest validation loss at iteration 5694! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 01:32:01,241 iteration 5695 : loss : 0.012530, loss_ce: 0.003830
 84%|████████████████████████▎    | 335/400 [2:30:10<32:42, 30.19s/it]2021-12-13 01:32:02,629 iteration 5696 : loss : 0.013532, loss_ce: 0.004525
2021-12-13 01:32:04,056 iteration 5697 : loss : 0.017150, loss_ce: 0.006205
2021-12-13 01:32:05,432 iteration 5698 : loss : 0.013937, loss_ce: 0.005273
2021-12-13 01:32:06,882 iteration 5699 : loss : 0.017265, loss_ce: 0.006284
2021-12-13 01:32:08,264 iteration 5700 : loss : 0.013344, loss_ce: 0.004625
2021-12-13 01:32:09,625 iteration 5701 : loss : 0.012269, loss_ce: 0.005991
2021-12-13 01:32:11,022 iteration 5702 : loss : 0.009800, loss_ce: 0.003483
2021-12-13 01:32:12,397 iteration 5703 : loss : 0.012698, loss_ce: 0.005973
2021-12-13 01:32:13,809 iteration 5704 : loss : 0.014943, loss_ce: 0.006221
2021-12-13 01:32:15,210 iteration 5705 : loss : 0.012615, loss_ce: 0.004620
2021-12-13 01:32:16,554 iteration 5706 : loss : 0.027155, loss_ce: 0.010258
2021-12-13 01:32:18,055 iteration 5707 : loss : 0.022305, loss_ce: 0.007996
2021-12-13 01:32:19,465 iteration 5708 : loss : 0.020869, loss_ce: 0.008716
2021-12-13 01:32:20,946 iteration 5709 : loss : 0.013960, loss_ce: 0.005671
2021-12-13 01:32:22,508 iteration 5710 : loss : 0.013512, loss_ce: 0.005466
2021-12-13 01:32:23,958 iteration 5711 : loss : 0.017736, loss_ce: 0.008819
2021-12-13 01:32:25,416 iteration 5712 : loss : 0.014682, loss_ce: 0.006209
 84%|████████████████████████▎    | 336/400 [2:30:34<30:16, 28.39s/it]2021-12-13 01:32:26,887 iteration 5713 : loss : 0.014218, loss_ce: 0.003770
2021-12-13 01:32:28,336 iteration 5714 : loss : 0.013501, loss_ce: 0.004774
2021-12-13 01:32:29,783 iteration 5715 : loss : 0.012641, loss_ce: 0.004790
2021-12-13 01:32:31,261 iteration 5716 : loss : 0.013175, loss_ce: 0.006187
2021-12-13 01:32:32,759 iteration 5717 : loss : 0.018570, loss_ce: 0.006179
2021-12-13 01:32:34,151 iteration 5718 : loss : 0.020753, loss_ce: 0.006413
2021-12-13 01:32:35,643 iteration 5719 : loss : 0.010621, loss_ce: 0.004016
2021-12-13 01:32:37,070 iteration 5720 : loss : 0.014130, loss_ce: 0.006747
2021-12-13 01:32:38,445 iteration 5721 : loss : 0.010885, loss_ce: 0.002985
2021-12-13 01:32:39,899 iteration 5722 : loss : 0.010633, loss_ce: 0.003553
2021-12-13 01:32:41,354 iteration 5723 : loss : 0.013296, loss_ce: 0.004929
2021-12-13 01:32:42,731 iteration 5724 : loss : 0.011505, loss_ce: 0.003906
2021-12-13 01:32:44,224 iteration 5725 : loss : 0.014283, loss_ce: 0.007167
2021-12-13 01:32:45,626 iteration 5726 : loss : 0.012838, loss_ce: 0.005347
2021-12-13 01:32:47,067 iteration 5727 : loss : 0.013310, loss_ce: 0.004050
2021-12-13 01:32:48,500 iteration 5728 : loss : 0.021231, loss_ce: 0.012569
2021-12-13 01:32:49,993 iteration 5729 : loss : 0.014926, loss_ce: 0.005613
 84%|████████████████████████▍    | 337/400 [2:30:59<28:36, 27.24s/it]2021-12-13 01:32:51,502 iteration 5730 : loss : 0.020768, loss_ce: 0.006954
2021-12-13 01:32:52,997 iteration 5731 : loss : 0.012949, loss_ce: 0.005384
2021-12-13 01:32:54,430 iteration 5732 : loss : 0.014420, loss_ce: 0.004178
2021-12-13 01:32:55,839 iteration 5733 : loss : 0.012514, loss_ce: 0.003286
2021-12-13 01:32:57,297 iteration 5734 : loss : 0.017757, loss_ce: 0.006023
2021-12-13 01:32:58,765 iteration 5735 : loss : 0.013828, loss_ce: 0.006482
2021-12-13 01:33:00,210 iteration 5736 : loss : 0.013886, loss_ce: 0.006784
2021-12-13 01:33:01,649 iteration 5737 : loss : 0.021415, loss_ce: 0.009363
2021-12-13 01:33:03,080 iteration 5738 : loss : 0.009567, loss_ce: 0.004159
2021-12-13 01:33:04,476 iteration 5739 : loss : 0.012995, loss_ce: 0.005093
2021-12-13 01:33:05,956 iteration 5740 : loss : 0.019344, loss_ce: 0.006202
2021-12-13 01:33:07,424 iteration 5741 : loss : 0.015717, loss_ce: 0.008218
2021-12-13 01:33:08,898 iteration 5742 : loss : 0.015168, loss_ce: 0.006334
2021-12-13 01:33:10,335 iteration 5743 : loss : 0.014519, loss_ce: 0.006826
2021-12-13 01:33:11,846 iteration 5744 : loss : 0.011972, loss_ce: 0.004997
2021-12-13 01:33:13,293 iteration 5745 : loss : 0.012578, loss_ce: 0.003471
2021-12-13 01:33:14,678 iteration 5746 : loss : 0.010819, loss_ce: 0.003165
 84%|████████████████████████▌    | 338/400 [2:31:23<27:21, 26.48s/it]2021-12-13 01:33:16,206 iteration 5747 : loss : 0.011659, loss_ce: 0.003717
2021-12-13 01:33:17,691 iteration 5748 : loss : 0.013717, loss_ce: 0.004102
2021-12-13 01:33:19,200 iteration 5749 : loss : 0.014838, loss_ce: 0.006660
2021-12-13 01:33:20,741 iteration 5750 : loss : 0.015702, loss_ce: 0.004674
2021-12-13 01:33:22,141 iteration 5751 : loss : 0.013685, loss_ce: 0.005104
2021-12-13 01:33:23,623 iteration 5752 : loss : 0.014023, loss_ce: 0.004340
2021-12-13 01:33:25,074 iteration 5753 : loss : 0.015813, loss_ce: 0.005847
2021-12-13 01:33:26,478 iteration 5754 : loss : 0.010495, loss_ce: 0.003865
2021-12-13 01:33:27,928 iteration 5755 : loss : 0.016264, loss_ce: 0.008095
2021-12-13 01:33:29,391 iteration 5756 : loss : 0.014422, loss_ce: 0.004417
2021-12-13 01:33:30,827 iteration 5757 : loss : 0.012122, loss_ce: 0.006018
2021-12-13 01:33:32,282 iteration 5758 : loss : 0.014452, loss_ce: 0.003679
2021-12-13 01:33:33,749 iteration 5759 : loss : 0.012117, loss_ce: 0.005532
2021-12-13 01:33:35,282 iteration 5760 : loss : 0.016898, loss_ce: 0.006492
2021-12-13 01:33:36,665 iteration 5761 : loss : 0.010490, loss_ce: 0.003803
2021-12-13 01:33:38,282 iteration 5762 : loss : 0.021619, loss_ce: 0.010605
2021-12-13 01:33:39,719 iteration 5763 : loss : 0.014107, loss_ce: 0.005364
 85%|████████████████████████▌    | 339/400 [2:31:48<26:28, 26.05s/it]2021-12-13 01:33:41,216 iteration 5764 : loss : 0.016825, loss_ce: 0.005810
2021-12-13 01:33:42,713 iteration 5765 : loss : 0.021458, loss_ce: 0.005996
2021-12-13 01:33:44,189 iteration 5766 : loss : 0.017343, loss_ce: 0.007308
2021-12-13 01:33:45,670 iteration 5767 : loss : 0.017764, loss_ce: 0.006678
2021-12-13 01:33:47,233 iteration 5768 : loss : 0.020594, loss_ce: 0.006697
2021-12-13 01:33:48,678 iteration 5769 : loss : 0.017682, loss_ce: 0.007532
2021-12-13 01:33:50,126 iteration 5770 : loss : 0.012330, loss_ce: 0.005254
2021-12-13 01:33:51,575 iteration 5771 : loss : 0.015834, loss_ce: 0.006589
2021-12-13 01:33:53,038 iteration 5772 : loss : 0.014701, loss_ce: 0.005106
2021-12-13 01:33:54,570 iteration 5773 : loss : 0.013179, loss_ce: 0.005797
2021-12-13 01:33:56,096 iteration 5774 : loss : 0.014991, loss_ce: 0.006161
2021-12-13 01:33:57,628 iteration 5775 : loss : 0.011915, loss_ce: 0.003752
2021-12-13 01:33:59,045 iteration 5776 : loss : 0.013450, loss_ce: 0.004144
2021-12-13 01:34:00,484 iteration 5777 : loss : 0.012590, loss_ce: 0.005052
2021-12-13 01:34:01,993 iteration 5778 : loss : 0.014927, loss_ce: 0.004350
2021-12-13 01:34:03,440 iteration 5779 : loss : 0.014862, loss_ce: 0.006544
2021-12-13 01:34:03,441 Training Data Eval:
2021-12-13 01:34:10,898   Average segmentation loss on training set: 0.0078
2021-12-13 01:34:10,899 Validation Data Eval:
2021-12-13 01:34:13,490   Average segmentation loss on validation set: 0.0768
2021-12-13 01:34:14,993 iteration 5780 : loss : 0.012017, loss_ce: 0.004279
 85%|████████████████████████▋    | 340/400 [2:32:24<28:48, 28.81s/it]2021-12-13 01:34:16,592 iteration 5781 : loss : 0.031860, loss_ce: 0.008349
2021-12-13 01:34:17,955 iteration 5782 : loss : 0.009724, loss_ce: 0.004590
2021-12-13 01:34:19,377 iteration 5783 : loss : 0.013813, loss_ce: 0.005715
2021-12-13 01:34:20,807 iteration 5784 : loss : 0.011397, loss_ce: 0.003966
2021-12-13 01:34:22,199 iteration 5785 : loss : 0.012051, loss_ce: 0.005214
2021-12-13 01:34:23,667 iteration 5786 : loss : 0.021210, loss_ce: 0.004513
2021-12-13 01:34:25,107 iteration 5787 : loss : 0.014081, loss_ce: 0.005569
2021-12-13 01:34:26,474 iteration 5788 : loss : 0.009958, loss_ce: 0.003729
2021-12-13 01:34:27,859 iteration 5789 : loss : 0.008619, loss_ce: 0.003385
2021-12-13 01:34:29,331 iteration 5790 : loss : 0.009948, loss_ce: 0.003634
2021-12-13 01:34:30,781 iteration 5791 : loss : 0.015055, loss_ce: 0.008168
2021-12-13 01:34:32,191 iteration 5792 : loss : 0.010444, loss_ce: 0.003852
2021-12-13 01:34:33,682 iteration 5793 : loss : 0.014093, loss_ce: 0.004861
2021-12-13 01:34:35,191 iteration 5794 : loss : 0.014567, loss_ce: 0.006258
2021-12-13 01:34:36,579 iteration 5795 : loss : 0.008774, loss_ce: 0.003908
2021-12-13 01:34:38,032 iteration 5796 : loss : 0.011834, loss_ce: 0.005599
2021-12-13 01:34:39,482 iteration 5797 : loss : 0.016550, loss_ce: 0.005373
 85%|████████████████████████▋    | 341/400 [2:32:48<27:03, 27.52s/it]2021-12-13 01:34:41,056 iteration 5798 : loss : 0.017692, loss_ce: 0.004694
2021-12-13 01:34:42,502 iteration 5799 : loss : 0.016866, loss_ce: 0.005247
2021-12-13 01:34:43,943 iteration 5800 : loss : 0.021267, loss_ce: 0.005392
2021-12-13 01:34:45,316 iteration 5801 : loss : 0.008888, loss_ce: 0.003011
2021-12-13 01:34:46,787 iteration 5802 : loss : 0.012383, loss_ce: 0.006207
2021-12-13 01:34:48,177 iteration 5803 : loss : 0.009831, loss_ce: 0.003260
2021-12-13 01:34:49,709 iteration 5804 : loss : 0.016464, loss_ce: 0.006147
2021-12-13 01:34:51,117 iteration 5805 : loss : 0.015435, loss_ce: 0.007284
2021-12-13 01:34:52,522 iteration 5806 : loss : 0.013324, loss_ce: 0.005406
2021-12-13 01:34:54,000 iteration 5807 : loss : 0.010694, loss_ce: 0.004042
2021-12-13 01:34:55,437 iteration 5808 : loss : 0.015707, loss_ce: 0.006558
2021-12-13 01:34:56,967 iteration 5809 : loss : 0.023132, loss_ce: 0.007270
2021-12-13 01:34:58,331 iteration 5810 : loss : 0.014872, loss_ce: 0.003871
2021-12-13 01:34:59,757 iteration 5811 : loss : 0.012056, loss_ce: 0.004789
2021-12-13 01:35:01,229 iteration 5812 : loss : 0.015960, loss_ce: 0.007045
2021-12-13 01:35:02,635 iteration 5813 : loss : 0.014850, loss_ce: 0.004587
2021-12-13 01:35:04,079 iteration 5814 : loss : 0.017752, loss_ce: 0.006832
 86%|████████████████████████▊    | 342/400 [2:33:13<25:45, 26.64s/it]2021-12-13 01:35:05,663 iteration 5815 : loss : 0.015374, loss_ce: 0.006712
2021-12-13 01:35:07,054 iteration 5816 : loss : 0.013190, loss_ce: 0.003826
2021-12-13 01:35:08,529 iteration 5817 : loss : 0.012151, loss_ce: 0.003475
2021-12-13 01:35:09,967 iteration 5818 : loss : 0.013857, loss_ce: 0.005073
2021-12-13 01:35:11,504 iteration 5819 : loss : 0.014887, loss_ce: 0.006251
2021-12-13 01:35:12,932 iteration 5820 : loss : 0.011555, loss_ce: 0.005064
2021-12-13 01:35:14,352 iteration 5821 : loss : 0.019899, loss_ce: 0.006399
2021-12-13 01:35:15,856 iteration 5822 : loss : 0.014607, loss_ce: 0.004747
2021-12-13 01:35:17,332 iteration 5823 : loss : 0.009430, loss_ce: 0.003031
2021-12-13 01:35:18,788 iteration 5824 : loss : 0.013523, loss_ce: 0.004684
2021-12-13 01:35:20,235 iteration 5825 : loss : 0.016372, loss_ce: 0.006754
2021-12-13 01:35:21,661 iteration 5826 : loss : 0.017246, loss_ce: 0.005304
2021-12-13 01:35:23,068 iteration 5827 : loss : 0.015547, loss_ce: 0.004239
2021-12-13 01:35:24,451 iteration 5828 : loss : 0.009104, loss_ce: 0.003894
2021-12-13 01:35:25,914 iteration 5829 : loss : 0.011366, loss_ce: 0.004254
2021-12-13 01:35:27,385 iteration 5830 : loss : 0.016111, loss_ce: 0.006745
2021-12-13 01:35:28,885 iteration 5831 : loss : 0.013579, loss_ce: 0.005037
 86%|████████████████████████▊    | 343/400 [2:33:38<24:47, 26.09s/it]2021-12-13 01:35:30,440 iteration 5832 : loss : 0.012445, loss_ce: 0.004775
2021-12-13 01:35:31,864 iteration 5833 : loss : 0.009029, loss_ce: 0.003128
2021-12-13 01:35:33,392 iteration 5834 : loss : 0.014859, loss_ce: 0.005288
2021-12-13 01:35:34,976 iteration 5835 : loss : 0.028489, loss_ce: 0.011938
2021-12-13 01:35:36,401 iteration 5836 : loss : 0.012517, loss_ce: 0.005096
2021-12-13 01:35:37,927 iteration 5837 : loss : 0.015390, loss_ce: 0.005806
2021-12-13 01:35:39,445 iteration 5838 : loss : 0.018644, loss_ce: 0.005782
2021-12-13 01:35:40,826 iteration 5839 : loss : 0.013523, loss_ce: 0.004425
2021-12-13 01:35:42,463 iteration 5840 : loss : 0.014610, loss_ce: 0.006716
2021-12-13 01:35:43,910 iteration 5841 : loss : 0.009179, loss_ce: 0.003783
2021-12-13 01:35:45,427 iteration 5842 : loss : 0.019251, loss_ce: 0.007809
2021-12-13 01:35:46,948 iteration 5843 : loss : 0.018688, loss_ce: 0.005880
2021-12-13 01:35:48,420 iteration 5844 : loss : 0.025983, loss_ce: 0.010640
2021-12-13 01:35:49,918 iteration 5845 : loss : 0.016858, loss_ce: 0.005278
2021-12-13 01:35:51,374 iteration 5846 : loss : 0.013972, loss_ce: 0.006311
2021-12-13 01:35:52,802 iteration 5847 : loss : 0.010244, loss_ce: 0.003529
2021-12-13 01:35:54,181 iteration 5848 : loss : 0.010178, loss_ce: 0.003065
 86%|████████████████████████▉    | 344/400 [2:34:03<24:07, 25.85s/it]2021-12-13 01:35:55,629 iteration 5849 : loss : 0.012064, loss_ce: 0.003962
2021-12-13 01:35:57,146 iteration 5850 : loss : 0.018120, loss_ce: 0.004819
2021-12-13 01:35:58,552 iteration 5851 : loss : 0.010357, loss_ce: 0.004357
2021-12-13 01:35:59,969 iteration 5852 : loss : 0.011303, loss_ce: 0.003647
2021-12-13 01:36:01,360 iteration 5853 : loss : 0.014636, loss_ce: 0.004305
2021-12-13 01:36:02,809 iteration 5854 : loss : 0.016738, loss_ce: 0.006378
2021-12-13 01:36:04,251 iteration 5855 : loss : 0.014509, loss_ce: 0.003689
2021-12-13 01:36:05,656 iteration 5856 : loss : 0.010837, loss_ce: 0.004653
2021-12-13 01:36:07,138 iteration 5857 : loss : 0.014812, loss_ce: 0.006880
2021-12-13 01:36:08,570 iteration 5858 : loss : 0.016530, loss_ce: 0.004777
2021-12-13 01:36:10,050 iteration 5859 : loss : 0.012894, loss_ce: 0.006325
2021-12-13 01:36:11,530 iteration 5860 : loss : 0.010213, loss_ce: 0.003976
2021-12-13 01:36:13,011 iteration 5861 : loss : 0.018120, loss_ce: 0.007190
2021-12-13 01:36:14,459 iteration 5862 : loss : 0.011133, loss_ce: 0.004196
2021-12-13 01:36:15,899 iteration 5863 : loss : 0.012872, loss_ce: 0.005005
2021-12-13 01:36:17,334 iteration 5864 : loss : 0.015991, loss_ce: 0.005948
2021-12-13 01:36:17,334 Training Data Eval:
2021-12-13 01:36:24,759   Average segmentation loss on training set: 0.0077
2021-12-13 01:36:24,759 Validation Data Eval:
2021-12-13 01:36:27,352   Average segmentation loss on validation set: 0.0668
2021-12-13 01:36:28,793 iteration 5865 : loss : 0.011487, loss_ce: 0.004056
 86%|█████████████████████████    | 345/400 [2:34:38<26:06, 28.48s/it]2021-12-13 01:36:30,296 iteration 5866 : loss : 0.014418, loss_ce: 0.005156
2021-12-13 01:36:31,754 iteration 5867 : loss : 0.011901, loss_ce: 0.004889
2021-12-13 01:36:33,132 iteration 5868 : loss : 0.010649, loss_ce: 0.003950
2021-12-13 01:36:34,552 iteration 5869 : loss : 0.009403, loss_ce: 0.003303
2021-12-13 01:36:35,928 iteration 5870 : loss : 0.010959, loss_ce: 0.003886
2021-12-13 01:36:37,361 iteration 5871 : loss : 0.010767, loss_ce: 0.004558
2021-12-13 01:36:38,793 iteration 5872 : loss : 0.010430, loss_ce: 0.004566
2021-12-13 01:36:40,178 iteration 5873 : loss : 0.010519, loss_ce: 0.004588
2021-12-13 01:36:41,558 iteration 5874 : loss : 0.042187, loss_ce: 0.010184
2021-12-13 01:36:43,066 iteration 5875 : loss : 0.016871, loss_ce: 0.009139
2021-12-13 01:36:44,590 iteration 5876 : loss : 0.016760, loss_ce: 0.006994
2021-12-13 01:36:46,059 iteration 5877 : loss : 0.025691, loss_ce: 0.008743
2021-12-13 01:36:47,555 iteration 5878 : loss : 0.012911, loss_ce: 0.003225
2021-12-13 01:36:48,969 iteration 5879 : loss : 0.014238, loss_ce: 0.004110
2021-12-13 01:36:50,403 iteration 5880 : loss : 0.012265, loss_ce: 0.004247
2021-12-13 01:36:51,886 iteration 5881 : loss : 0.027397, loss_ce: 0.007072
2021-12-13 01:36:53,317 iteration 5882 : loss : 0.011521, loss_ce: 0.003614
 86%|█████████████████████████    | 346/400 [2:35:02<24:33, 27.29s/it]2021-12-13 01:36:54,900 iteration 5883 : loss : 0.019403, loss_ce: 0.007053
2021-12-13 01:36:56,297 iteration 5884 : loss : 0.012206, loss_ce: 0.004844
2021-12-13 01:36:57,793 iteration 5885 : loss : 0.017893, loss_ce: 0.004172
2021-12-13 01:36:59,188 iteration 5886 : loss : 0.012633, loss_ce: 0.003552
2021-12-13 01:37:00,594 iteration 5887 : loss : 0.013364, loss_ce: 0.004151
2021-12-13 01:37:01,951 iteration 5888 : loss : 0.010378, loss_ce: 0.004433
2021-12-13 01:37:03,394 iteration 5889 : loss : 0.016039, loss_ce: 0.006402
2021-12-13 01:37:04,883 iteration 5890 : loss : 0.014610, loss_ce: 0.005987
2021-12-13 01:37:06,367 iteration 5891 : loss : 0.017039, loss_ce: 0.005305
2021-12-13 01:37:07,872 iteration 5892 : loss : 0.014723, loss_ce: 0.006735
2021-12-13 01:37:09,240 iteration 5893 : loss : 0.010139, loss_ce: 0.002636
2021-12-13 01:37:10,646 iteration 5894 : loss : 0.010586, loss_ce: 0.002940
2021-12-13 01:37:12,125 iteration 5895 : loss : 0.014329, loss_ce: 0.005664
2021-12-13 01:37:13,490 iteration 5896 : loss : 0.011026, loss_ce: 0.003702
2021-12-13 01:37:14,949 iteration 5897 : loss : 0.034597, loss_ce: 0.012753
2021-12-13 01:37:16,449 iteration 5898 : loss : 0.017354, loss_ce: 0.006579
2021-12-13 01:37:17,877 iteration 5899 : loss : 0.014432, loss_ce: 0.004546
 87%|█████████████████████████▏   | 347/400 [2:35:27<23:23, 26.47s/it]2021-12-13 01:37:19,259 iteration 5900 : loss : 0.009222, loss_ce: 0.003939
2021-12-13 01:37:20,660 iteration 5901 : loss : 0.009745, loss_ce: 0.004117
2021-12-13 01:37:22,034 iteration 5902 : loss : 0.009445, loss_ce: 0.003631
2021-12-13 01:37:23,464 iteration 5903 : loss : 0.014515, loss_ce: 0.005467
2021-12-13 01:37:24,920 iteration 5904 : loss : 0.020761, loss_ce: 0.006061
2021-12-13 01:37:26,399 iteration 5905 : loss : 0.015177, loss_ce: 0.006688
2021-12-13 01:37:27,893 iteration 5906 : loss : 0.015132, loss_ce: 0.003928
2021-12-13 01:37:29,268 iteration 5907 : loss : 0.009445, loss_ce: 0.004206
2021-12-13 01:37:30,707 iteration 5908 : loss : 0.016717, loss_ce: 0.005441
2021-12-13 01:37:32,193 iteration 5909 : loss : 0.011843, loss_ce: 0.005911
2021-12-13 01:37:33,641 iteration 5910 : loss : 0.010033, loss_ce: 0.003257
2021-12-13 01:37:35,126 iteration 5911 : loss : 0.020020, loss_ce: 0.005030
2021-12-13 01:37:36,587 iteration 5912 : loss : 0.024551, loss_ce: 0.005710
2021-12-13 01:37:38,021 iteration 5913 : loss : 0.013918, loss_ce: 0.005907
2021-12-13 01:37:39,450 iteration 5914 : loss : 0.013104, loss_ce: 0.006512
2021-12-13 01:37:40,921 iteration 5915 : loss : 0.013319, loss_ce: 0.007284
2021-12-13 01:37:42,325 iteration 5916 : loss : 0.010395, loss_ce: 0.003599
 87%|█████████████████████████▏   | 348/400 [2:35:51<22:24, 25.87s/it]2021-12-13 01:37:43,766 iteration 5917 : loss : 0.011882, loss_ce: 0.004936
2021-12-13 01:37:45,283 iteration 5918 : loss : 0.018649, loss_ce: 0.008257
2021-12-13 01:37:46,791 iteration 5919 : loss : 0.014113, loss_ce: 0.005007
2021-12-13 01:37:48,299 iteration 5920 : loss : 0.015588, loss_ce: 0.005367
2021-12-13 01:37:49,714 iteration 5921 : loss : 0.014151, loss_ce: 0.004877
2021-12-13 01:37:51,181 iteration 5922 : loss : 0.016934, loss_ce: 0.008435
2021-12-13 01:37:52,632 iteration 5923 : loss : 0.014664, loss_ce: 0.006227
2021-12-13 01:37:54,003 iteration 5924 : loss : 0.011723, loss_ce: 0.004225
2021-12-13 01:37:55,497 iteration 5925 : loss : 0.012438, loss_ce: 0.004040
2021-12-13 01:37:56,994 iteration 5926 : loss : 0.016074, loss_ce: 0.004531
2021-12-13 01:37:58,392 iteration 5927 : loss : 0.009363, loss_ce: 0.003808
2021-12-13 01:37:59,897 iteration 5928 : loss : 0.010647, loss_ce: 0.004360
2021-12-13 01:38:01,380 iteration 5929 : loss : 0.013256, loss_ce: 0.005302
2021-12-13 01:38:02,901 iteration 5930 : loss : 0.013441, loss_ce: 0.005784
2021-12-13 01:38:04,291 iteration 5931 : loss : 0.012209, loss_ce: 0.005152
2021-12-13 01:38:05,745 iteration 5932 : loss : 0.015978, loss_ce: 0.006061
2021-12-13 01:38:07,227 iteration 5933 : loss : 0.016523, loss_ce: 0.004805
 87%|█████████████████████████▎   | 349/400 [2:36:16<21:44, 25.58s/it]2021-12-13 01:38:08,729 iteration 5934 : loss : 0.009287, loss_ce: 0.003203
2021-12-13 01:38:10,196 iteration 5935 : loss : 0.013026, loss_ce: 0.003216
2021-12-13 01:38:11,760 iteration 5936 : loss : 0.018723, loss_ce: 0.005552
2021-12-13 01:38:13,282 iteration 5937 : loss : 0.014598, loss_ce: 0.005936
2021-12-13 01:38:14,745 iteration 5938 : loss : 0.013154, loss_ce: 0.004764
2021-12-13 01:38:16,160 iteration 5939 : loss : 0.015017, loss_ce: 0.006195
2021-12-13 01:38:17,626 iteration 5940 : loss : 0.013165, loss_ce: 0.005841
2021-12-13 01:38:18,996 iteration 5941 : loss : 0.011377, loss_ce: 0.005248
2021-12-13 01:38:20,506 iteration 5942 : loss : 0.019155, loss_ce: 0.006311
2021-12-13 01:38:21,899 iteration 5943 : loss : 0.008908, loss_ce: 0.003164
2021-12-13 01:38:23,351 iteration 5944 : loss : 0.019371, loss_ce: 0.005757
2021-12-13 01:38:24,777 iteration 5945 : loss : 0.011339, loss_ce: 0.003972
2021-12-13 01:38:26,182 iteration 5946 : loss : 0.016825, loss_ce: 0.005906
2021-12-13 01:38:27,587 iteration 5947 : loss : 0.011369, loss_ce: 0.004592
2021-12-13 01:38:29,097 iteration 5948 : loss : 0.027943, loss_ce: 0.011071
2021-12-13 01:38:30,485 iteration 5949 : loss : 0.012869, loss_ce: 0.005608
2021-12-13 01:38:30,486 Training Data Eval:
2021-12-13 01:38:37,929   Average segmentation loss on training set: 0.0078
2021-12-13 01:38:37,929 Validation Data Eval:
2021-12-13 01:38:40,502   Average segmentation loss on validation set: 0.0666
2021-12-13 01:38:42,034 iteration 5950 : loss : 0.016644, loss_ce: 0.005008
 88%|█████████████████████████▍   | 350/400 [2:36:51<23:37, 28.34s/it]2021-12-13 01:38:43,491 iteration 5951 : loss : 0.011260, loss_ce: 0.002936
2021-12-13 01:38:44,952 iteration 5952 : loss : 0.012694, loss_ce: 0.006132
2021-12-13 01:38:46,420 iteration 5953 : loss : 0.021358, loss_ce: 0.009148
2021-12-13 01:38:47,945 iteration 5954 : loss : 0.014666, loss_ce: 0.004604
2021-12-13 01:38:49,378 iteration 5955 : loss : 0.010075, loss_ce: 0.003340
2021-12-13 01:38:50,891 iteration 5956 : loss : 0.015676, loss_ce: 0.005082
2021-12-13 01:38:52,316 iteration 5957 : loss : 0.017097, loss_ce: 0.005466
2021-12-13 01:38:53,714 iteration 5958 : loss : 0.010418, loss_ce: 0.004521
2021-12-13 01:38:55,151 iteration 5959 : loss : 0.013030, loss_ce: 0.004193
2021-12-13 01:38:56,551 iteration 5960 : loss : 0.009678, loss_ce: 0.002882
2021-12-13 01:38:58,012 iteration 5961 : loss : 0.011357, loss_ce: 0.004478
2021-12-13 01:38:59,514 iteration 5962 : loss : 0.013113, loss_ce: 0.005147
2021-12-13 01:39:00,904 iteration 5963 : loss : 0.010345, loss_ce: 0.004702
2021-12-13 01:39:02,512 iteration 5964 : loss : 0.023960, loss_ce: 0.009932
2021-12-13 01:39:03,922 iteration 5965 : loss : 0.013436, loss_ce: 0.004551
2021-12-13 01:39:05,406 iteration 5966 : loss : 0.014196, loss_ce: 0.005253
2021-12-13 01:39:06,821 iteration 5967 : loss : 0.014315, loss_ce: 0.004686
 88%|█████████████████████████▍   | 351/400 [2:37:16<22:16, 27.28s/it]2021-12-13 01:39:08,289 iteration 5968 : loss : 0.011549, loss_ce: 0.004883
2021-12-13 01:39:09,776 iteration 5969 : loss : 0.020655, loss_ce: 0.006508
2021-12-13 01:39:11,240 iteration 5970 : loss : 0.013417, loss_ce: 0.004646
2021-12-13 01:39:12,610 iteration 5971 : loss : 0.010374, loss_ce: 0.004133
2021-12-13 01:39:14,038 iteration 5972 : loss : 0.013810, loss_ce: 0.005069
2021-12-13 01:39:15,515 iteration 5973 : loss : 0.010006, loss_ce: 0.004250
2021-12-13 01:39:16,925 iteration 5974 : loss : 0.017476, loss_ce: 0.006228
2021-12-13 01:39:18,411 iteration 5975 : loss : 0.017173, loss_ce: 0.004730
2021-12-13 01:39:19,868 iteration 5976 : loss : 0.020721, loss_ce: 0.004915
2021-12-13 01:39:21,325 iteration 5977 : loss : 0.010888, loss_ce: 0.003608
2021-12-13 01:39:22,760 iteration 5978 : loss : 0.012520, loss_ce: 0.005118
2021-12-13 01:39:24,155 iteration 5979 : loss : 0.010472, loss_ce: 0.003638
2021-12-13 01:39:25,632 iteration 5980 : loss : 0.008913, loss_ce: 0.002784
2021-12-13 01:39:27,101 iteration 5981 : loss : 0.020226, loss_ce: 0.007268
2021-12-13 01:39:28,610 iteration 5982 : loss : 0.023327, loss_ce: 0.009323
2021-12-13 01:39:29,999 iteration 5983 : loss : 0.009662, loss_ce: 0.004366
2021-12-13 01:39:31,402 iteration 5984 : loss : 0.014022, loss_ce: 0.004472
 88%|█████████████████████████▌   | 352/400 [2:37:40<21:10, 26.47s/it]2021-12-13 01:39:32,986 iteration 5985 : loss : 0.026614, loss_ce: 0.011123
2021-12-13 01:39:34,392 iteration 5986 : loss : 0.014151, loss_ce: 0.005754
2021-12-13 01:39:35,885 iteration 5987 : loss : 0.035042, loss_ce: 0.006507
2021-12-13 01:39:37,404 iteration 5988 : loss : 0.013347, loss_ce: 0.005987
2021-12-13 01:39:38,843 iteration 5989 : loss : 0.013655, loss_ce: 0.005960
2021-12-13 01:39:40,324 iteration 5990 : loss : 0.016327, loss_ce: 0.009098
2021-12-13 01:39:41,694 iteration 5991 : loss : 0.010338, loss_ce: 0.003602
2021-12-13 01:39:43,176 iteration 5992 : loss : 0.014923, loss_ce: 0.004429
2021-12-13 01:39:44,579 iteration 5993 : loss : 0.008237, loss_ce: 0.002558
2021-12-13 01:39:46,018 iteration 5994 : loss : 0.015500, loss_ce: 0.004948
2021-12-13 01:39:47,487 iteration 5995 : loss : 0.016028, loss_ce: 0.005897
2021-12-13 01:39:49,005 iteration 5996 : loss : 0.020111, loss_ce: 0.009003
2021-12-13 01:39:50,503 iteration 5997 : loss : 0.015210, loss_ce: 0.007125
2021-12-13 01:39:51,911 iteration 5998 : loss : 0.011281, loss_ce: 0.003911
2021-12-13 01:39:53,397 iteration 5999 : loss : 0.022913, loss_ce: 0.006864
2021-12-13 01:39:54,870 iteration 6000 : loss : 0.017946, loss_ce: 0.008238
2021-12-13 01:39:56,378 iteration 6001 : loss : 0.019500, loss_ce: 0.006877
 88%|█████████████████████████▌   | 353/400 [2:38:05<20:22, 26.02s/it]2021-12-13 01:39:57,874 iteration 6002 : loss : 0.013030, loss_ce: 0.005497
2021-12-13 01:39:59,377 iteration 6003 : loss : 0.013861, loss_ce: 0.004805
2021-12-13 01:40:00,819 iteration 6004 : loss : 0.019184, loss_ce: 0.010803
2021-12-13 01:40:02,292 iteration 6005 : loss : 0.012109, loss_ce: 0.005225
2021-12-13 01:40:03,682 iteration 6006 : loss : 0.012453, loss_ce: 0.006158
2021-12-13 01:40:05,130 iteration 6007 : loss : 0.015960, loss_ce: 0.006325
2021-12-13 01:40:06,576 iteration 6008 : loss : 0.015990, loss_ce: 0.006483
2021-12-13 01:40:08,101 iteration 6009 : loss : 0.019402, loss_ce: 0.007280
2021-12-13 01:40:09,457 iteration 6010 : loss : 0.010539, loss_ce: 0.004185
2021-12-13 01:40:10,926 iteration 6011 : loss : 0.019828, loss_ce: 0.006572
2021-12-13 01:40:12,385 iteration 6012 : loss : 0.022134, loss_ce: 0.007185
2021-12-13 01:40:13,940 iteration 6013 : loss : 0.020344, loss_ce: 0.006936
2021-12-13 01:40:15,376 iteration 6014 : loss : 0.012173, loss_ce: 0.005062
2021-12-13 01:40:16,788 iteration 6015 : loss : 0.013807, loss_ce: 0.004380
2021-12-13 01:40:18,244 iteration 6016 : loss : 0.011747, loss_ce: 0.003583
2021-12-13 01:40:19,645 iteration 6017 : loss : 0.012640, loss_ce: 0.003446
2021-12-13 01:40:21,186 iteration 6018 : loss : 0.012491, loss_ce: 0.004486
 88%|█████████████████████████▋   | 354/400 [2:38:30<19:40, 25.66s/it]2021-12-13 01:40:22,721 iteration 6019 : loss : 0.016069, loss_ce: 0.006000
2021-12-13 01:40:24,153 iteration 6020 : loss : 0.017625, loss_ce: 0.007042
2021-12-13 01:40:25,584 iteration 6021 : loss : 0.012608, loss_ce: 0.004520
2021-12-13 01:40:27,045 iteration 6022 : loss : 0.009402, loss_ce: 0.003623
2021-12-13 01:40:28,419 iteration 6023 : loss : 0.009419, loss_ce: 0.003282
2021-12-13 01:40:29,930 iteration 6024 : loss : 0.021942, loss_ce: 0.008449
2021-12-13 01:40:31,431 iteration 6025 : loss : 0.017643, loss_ce: 0.008058
2021-12-13 01:40:32,925 iteration 6026 : loss : 0.015310, loss_ce: 0.004982
2021-12-13 01:40:34,352 iteration 6027 : loss : 0.012607, loss_ce: 0.005076
2021-12-13 01:40:35,765 iteration 6028 : loss : 0.013321, loss_ce: 0.005193
2021-12-13 01:40:37,259 iteration 6029 : loss : 0.022149, loss_ce: 0.011217
2021-12-13 01:40:38,660 iteration 6030 : loss : 0.012223, loss_ce: 0.004378
2021-12-13 01:40:40,206 iteration 6031 : loss : 0.022171, loss_ce: 0.006005
2021-12-13 01:40:41,695 iteration 6032 : loss : 0.013646, loss_ce: 0.004148
2021-12-13 01:40:43,181 iteration 6033 : loss : 0.015305, loss_ce: 0.006971
2021-12-13 01:40:44,714 iteration 6034 : loss : 0.010091, loss_ce: 0.002939
2021-12-13 01:40:44,714 Training Data Eval:
2021-12-13 01:40:52,138   Average segmentation loss on training set: 0.0084
2021-12-13 01:40:52,139 Validation Data Eval:
2021-12-13 01:40:54,731   Average segmentation loss on validation set: 0.0625
2021-12-13 01:41:01,045 Found new lowest validation loss at iteration 6034! Save model to /scratch_net/biwidl217_second/arismu/Master_Thesis_Codes/project_TransUNet/model/TU_3seeds/TU_ADAM_best_val_loss_seed100.pth
2021-12-13 01:41:02,357 iteration 6035 : loss : 0.013268, loss_ce: 0.003176
 89%|█████████████████████████▋   | 355/400 [2:39:11<22:44, 30.31s/it]2021-12-13 01:41:03,804 iteration 6036 : loss : 0.017417, loss_ce: 0.006963
2021-12-13 01:41:05,247 iteration 6037 : loss : 0.017036, loss_ce: 0.006544
2021-12-13 01:41:06,594 iteration 6038 : loss : 0.014493, loss_ce: 0.006961
2021-12-13 01:41:07,989 iteration 6039 : loss : 0.015766, loss_ce: 0.008099
2021-12-13 01:41:09,360 iteration 6040 : loss : 0.010853, loss_ce: 0.004538
2021-12-13 01:41:10,851 iteration 6041 : loss : 0.024082, loss_ce: 0.009088
2021-12-13 01:41:12,292 iteration 6042 : loss : 0.019288, loss_ce: 0.007581
2021-12-13 01:41:13,675 iteration 6043 : loss : 0.011588, loss_ce: 0.005539
2021-12-13 01:41:15,036 iteration 6044 : loss : 0.012460, loss_ce: 0.004058
2021-12-13 01:41:16,463 iteration 6045 : loss : 0.014277, loss_ce: 0.005348
2021-12-13 01:41:17,842 iteration 6046 : loss : 0.018106, loss_ce: 0.005948
2021-12-13 01:41:19,193 iteration 6047 : loss : 0.017989, loss_ce: 0.006766
2021-12-13 01:41:20,720 iteration 6048 : loss : 0.023020, loss_ce: 0.003821
2021-12-13 01:41:22,226 iteration 6049 : loss : 0.017838, loss_ce: 0.008348
2021-12-13 01:41:23,677 iteration 6050 : loss : 0.012020, loss_ce: 0.004991
2021-12-13 01:41:25,210 iteration 6051 : loss : 0.013300, loss_ce: 0.005611
2021-12-13 01:41:26,604 iteration 6052 : loss : 0.011118, loss_ce: 0.002763
 89%|█████████████████████████▊   | 356/400 [2:39:35<20:53, 28.49s/it]2021-12-13 01:41:28,086 iteration 6053 : loss : 0.012260, loss_ce: 0.005682
2021-12-13 01:41:29,643 iteration 6054 : loss : 0.016186, loss_ce: 0.006491
2021-12-13 01:41:31,089 iteration 6055 : loss : 0.012330, loss_ce: 0.003824
2021-12-13 01:41:32,521 iteration 6056 : loss : 0.011382, loss_ce: 0.004475
2021-12-13 01:41:33,952 iteration 6057 : loss : 0.012007, loss_ce: 0.004172
2021-12-13 01:41:35,470 iteration 6058 : loss : 0.010674, loss_ce: 0.004523
2021-12-13 01:41:36,864 iteration 6059 : loss : 0.010975, loss_ce: 0.004207
2021-12-13 01:41:38,372 iteration 6060 : loss : 0.009830, loss_ce: 0.004108
2021-12-13 01:41:39,776 iteration 6061 : loss : 0.013527, loss_ce: 0.005728
2021-12-13 01:41:41,320 iteration 6062 : loss : 0.014698, loss_ce: 0.006332
2021-12-13 01:41:42,854 iteration 6063 : loss : 0.021241, loss_ce: 0.006595
2021-12-13 01:41:44,317 iteration 6064 : loss : 0.031369, loss_ce: 0.007826
2021-12-13 01:41:45,851 iteration 6065 : loss : 0.028349, loss_ce: 0.012578
2021-12-13 01:41:47,298 iteration 6066 : loss : 0.012683, loss_ce: 0.005606
2021-12-13 01:41:48,722 iteration 6067 : loss : 0.020970, loss_ce: 0.004129
2021-12-13 01:41:50,279 iteration 6068 : loss : 0.028067, loss_ce: 0.009158
2021-12-13 01:41:51,707 iteration 6069 : loss : 0.013844, loss_ce: 0.002391
 89%|█████████████████████████▉   | 357/400 [2:40:00<19:41, 27.48s/it]2021-12-13 01:41:53,248 iteration 6070 : loss : 0.017691, loss_ce: 0.009012
2021-12-13 01:41:54,747 iteration 6071 : loss : 0.016114, loss_ce: 0.004838
2021-12-13 01:41:56,210 iteration 6072 : loss : 0.012184, loss_ce: 0.004211
2021-12-13 01:41:57,706 iteration 6073 : loss : 0.019645, loss_ce: 0.007240
2021-12-13 01:41:59,190 iteration 6074 : loss : 0.010446, loss_ce: 0.002969
2021-12-13 01:42:00,723 iteration 6075 : loss : 0.014587, loss_ce: 0.005729
2021-12-13 01:42:02,166 iteration 6076 : loss : 0.012371, loss_ce: 0.004863
2021-12-13 01:42:03,593 iteration 6077 : loss : 0.011901, loss_ce: 0.005604
2021-12-13 01:42:05,040 iteration 6078 : loss : 0.014313, loss_ce: 0.004242
2021-12-13 01:42:06,522 iteration 6079 : loss : 0.024242, loss_ce: 0.005020
2021-12-13 01:42:07,994 iteration 6080 : loss : 0.011921, loss_ce: 0.003437
2021-12-13 01:42:09,385 iteration 6081 : loss : 0.018027, loss_ce: 0.007589
2021-12-13 01:42:10,908 iteration 6082 : loss : 0.023543, loss_ce: 0.009914
2021-12-13 01:42:12,432 iteration 6083 : loss : 0.021442, loss_ce: 0.009169
2021-12-13 01:42:13,847 iteration 6084 : loss : 0.021444, loss_ce: 0.006076
2021-12-13 01:42:15,265 iteration 6085 : loss : 0.012382, loss_ce: 0.006138
2021-12-13 01:42:16,838 iteration 6086 : loss : 0.022968, loss_ce: 0.008765
 90%|█████████████████████████▉   | 358/400 [2:40:26<18:44, 26.77s/it]2021-12-13 01:42:18,327 iteration 6087 : loss : 0.020716, loss_ce: 0.005566
2021-12-13 01:42:19,790 iteration 6088 : loss : 0.012720, loss_ce: 0.004043
2021-12-13 01:42:21,310 iteration 6089 : loss : 0.014248, loss_ce: 0.006455
2021-12-13 01:42:22,747 iteration 6090 : loss : 0.010572, loss_ce: 0.003328
2021-12-13 01:42:24,165 iteration 6091 : loss : 0.007636, loss_ce: 0.002180
2021-12-13 01:42:25,699 iteration 6092 : loss : 0.018122, loss_ce: 0.006160
2021-12-13 01:42:27,243 iteration 6093 : loss : 0.013232, loss_ce: 0.005648
2021-12-13 01:42:28,758 iteration 6094 : loss : 0.017944, loss_ce: 0.008694
2021-12-13 01:42:30,143 iteration 6095 : loss : 0.022543, loss_ce: 0.005595
2021-12-13 01:42:31,671 iteration 6096 : loss : 0.022418, loss_ce: 0.005424
2021-12-13 01:42:33,078 iteration 6097 : loss : 0.012287, loss_ce: 0.006116
2021-12-13 01:42:34,553 iteration 6098 : loss : 0.014543, loss_ce: 0.007566
2021-12-13 01:42:36,013 iteration 6099 : loss : 0.014595, loss_ce: 0.006114
2021-12-13 01:42:37,499 iteration 6100 : loss : 0.019267, loss_ce: 0.005985
2021-12-13 01:42:39,030 iteration 6101 : loss : 0.017627, loss_ce: 0.007240
2021-12-13 01:42:40,431 iteration 6102 : loss : 0.012495, loss_ce: 0.005785
2021-12-13 01:42:41,909 iteration 6103 : loss : 0.017075, loss_ce: 0.004957
 90%|██████████████████████████   | 359/400 [2:40:51<17:56, 26.26s/it]2021-12-13 01:42:43,451 iteration 6104 : loss : 0.012043, loss_ce: 0.004547
2021-12-13 01:42:44,874 iteration 6105 : loss : 0.018702, loss_ce: 0.005089
2021-12-13 01:42:46,278 iteration 6106 : loss : 0.009039, loss_ce: 0.003636
2021-12-13 01:42:47,696 iteration 6107 : loss : 0.010241, loss_ce: 0.004168
2021-12-13 01:42:49,161 iteration 6108 : loss : 0.017893, loss_ce: 0.006523
2021-12-13 01:42:50,656 iteration 6109 : loss : 0.017712, loss_ce: 0.007904
2021-12-13 01:42:52,043 iteration 6110 : loss : 0.010853, loss_ce: 0.005048
2021-12-13 01:42:53,498 iteration 6111 : loss : 0.017836, loss_ce: 0.005867
2021-12-13 01:42:54,993 iteration 6112 : loss : 0.013765, loss_ce: 0.004171
2021-12-13 01:42:56,446 iteration 6113 : loss : 0.015303, loss_ce: 0.005627
2021-12-13 01:42:57,926 iteration 6114 : loss : 0.014499, loss_ce: 0.005170
2021-12-13 01:42:59,437 iteration 6115 : loss : 0.015626, loss_ce: 0.004441
2021-12-13 01:43:00,882 iteration 6116 : loss : 0.012901, loss_ce: 0.003668
2021-12-13 01:43:02,296 iteration 6117 : loss : 0.012008, loss_ce: 0.004284
2021-12-13 01:43:03,767 iteration 6118 : loss : 0.013294, loss_ce: 0.007461
2021-12-13 01:43:05,203 iteration 6119 : loss : 0.013328, loss_ce: 0.005642
2021-12-13 01:43:05,204 Training Data Eval:
2021-12-13 01:43:12,679   Average segmentation loss on training set: 0.0072
2021-12-13 01:43:12,679 Validation Data Eval:
2021-12-13 01:43:15,276   Average segmentation loss on validation set: 0.0686
2021-12-13 01:43:16,792 iteration 6120 : loss : 0.013837, loss_ce: 0.005117
 90%|██████████████████████████   | 360/400 [2:41:26<19:13, 28.85s/it]2021-12-13 01:43:18,341 iteration 6121 : loss : 0.010820, loss_ce: 0.003493
2021-12-13 01:43:19,815 iteration 6122 : loss : 0.017363, loss_ce: 0.007605
2021-12-13 01:43:21,267 iteration 6123 : loss : 0.012444, loss_ce: 0.004404
2021-12-13 01:43:22,809 iteration 6124 : loss : 0.026399, loss_ce: 0.011285
2021-12-13 01:43:24,270 iteration 6125 : loss : 0.013679, loss_ce: 0.004230
2021-12-13 01:43:25,833 iteration 6126 : loss : 0.016232, loss_ce: 0.007066
2021-12-13 01:43:27,383 iteration 6127 : loss : 0.016802, loss_ce: 0.008368
2021-12-13 01:43:28,836 iteration 6128 : loss : 0.012694, loss_ce: 0.004184
2021-12-13 01:43:30,263 iteration 6129 : loss : 0.015000, loss_ce: 0.004926
2021-12-13 01:43:31,746 iteration 6130 : loss : 0.017717, loss_ce: 0.006726
2021-12-13 01:43:33,159 iteration 6131 : loss : 0.013403, loss_ce: 0.003830
2021-12-13 01:43:34,655 iteration 6132 : loss : 0.015114, loss_ce: 0.004738
2021-12-13 01:43:36,136 iteration 6133 : loss : 0.013617, loss_ce: 0.005554
2021-12-13 01:43:37,569 iteration 6134 : loss : 0.021127, loss_ce: 0.011445
2021-12-13 01:43:38,969 iteration 6135 : loss : 0.012202, loss_ce: 0.005466
2021-12-13 01:43:40,390 iteration 6136 : loss : 0.007610, loss_ce: 0.002116
2021-12-13 01:43:41,810 iteration 6137 : loss : 0.014812, loss_ce: 0.006124
 90%|██████████████████████████▏  | 361/400 [2:41:51<18:00, 27.70s/it]2021-12-13 01:43:43,261 iteration 6138 : loss : 0.012622, loss_ce: 0.004360
2021-12-13 01:43:44,685 iteration 6139 : loss : 0.012273, loss_ce: 0.002907
2021-12-13 01:43:46,102 iteration 6140 : loss : 0.011329, loss_ce: 0.003637
2021-12-13 01:43:47,500 iteration 6141 : loss : 0.012768, loss_ce: 0.005862
2021-12-13 01:43:48,984 iteration 6142 : loss : 0.012902, loss_ce: 0.005033
2021-12-13 01:43:50,383 iteration 6143 : loss : 0.014099, loss_ce: 0.007128
2021-12-13 01:43:51,912 iteration 6144 : loss : 0.017244, loss_ce: 0.008137
2021-12-13 01:43:53,323 iteration 6145 : loss : 0.013184, loss_ce: 0.005169
2021-12-13 01:43:54,697 iteration 6146 : loss : 0.010511, loss_ce: 0.003427
2021-12-13 01:43:56,135 iteration 6147 : loss : 0.011508, loss_ce: 0.004253
2021-12-13 01:43:57,566 iteration 6148 : loss : 0.012851, loss_ce: 0.005128
2021-12-13 01:43:58,989 iteration 6149 : loss : 0.012358, loss_ce: 0.004347
2021-12-13 01:44:00,468 iteration 6150 : loss : 0.015514, loss_ce: 0.005504
2021-12-13 01:44:02,043 iteration 6151 : loss : 0.014079, loss_ce: 0.004044
2021-12-13 01:44:03,483 iteration 6152 : loss : 0.010865, loss_ce: 0.004241
2021-12-13 01:44:04,953 iteration 6153 : loss : 0.014241, loss_ce: 0.006148
2021-12-13 01:44:06,485 iteration 6154 : loss : 0.017681, loss_ce: 0.006390
 90%|██████████████████████████▏  | 362/400 [2:42:15<16:58, 26.79s/it]2021-12-13 01:44:08,042 iteration 6155 : loss : 0.019048, loss_ce: 0.007421
2021-12-13 01:44:09,434 iteration 6156 : loss : 0.009426, loss_ce: 0.003764
2021-12-13 01:44:10,856 iteration 6157 : loss : 0.010462, loss_ce: 0.003329
2021-12-13 01:44:12,312 iteration 6158 : loss : 0.013073, loss_ce: 0.004933
2021-12-13 01:44:13,710 iteration 6159 : loss : 0.014843, loss_ce: 0.005102
2021-12-13 01:44:15,153 iteration 6160 : loss : 0.012672, loss_ce: 0.005247
2021-12-13 01:44:16,613 iteration 6161 : loss : 0.012942, loss_ce: 0.003430
2021-12-13 01:44:18,103 iteration 6162 : loss : 0.016194, loss_ce: 0.003206
2021-12-13 01:44:19,567 iteration 6163 : loss : 0.012746, loss_ce: 0.005985
2021-12-13 01:44:21,068 iteration 6164 : loss : 0.020655, loss_ce: 0.009946
2021-12-13 01:44:22,521 iteration 6165 : loss : 0.017628, loss_ce: 0.006919
2021-12-13 01:44:23,969 iteration 6166 : loss : 0.013658, loss_ce: 0.006282
2021-12-13 01:44:25,390 iteration 6167 : loss : 0.014420, loss_ce: 0.005709
2021-12-13 01:44:26,880 iteration 6168 : loss : 0.014621, loss_ce: 0.005433
2021-12-13 01:44:28,348 iteration 6169 : loss : 0.024397, loss_ce: 0.008918
2021-12-13 01:44:29,765 iteration 6170 : loss : 0.013185, loss_ce: 0.004853
2021-12-13 01:44:31,166 iteration 6171 : loss : 0.010957, loss_ce: 0.004368
 91%|██████████████████████████▎  | 363/400 [2:42:40<16:07, 26.16s/it]2021-12-13 01:44:32,618 iteration 6172 : loss : 0.011019, loss_ce: 0.003878
2021-12-13 01:44:34,146 iteration 6173 : loss : 0.015266, loss_ce: 0.004821
2021-12-13 01:44:35,596 iteration 6174 : loss : 0.012094, loss_ce: 0.005108
2021-12-13 01:44:37,095 iteration 6175 : loss : 0.015824, loss_ce: 0.006934
2021-12-13 01:44:38,561 iteration 6176 : loss : 0.014649, loss_ce: 0.005016
2021-12-13 01:44:40,097 iteration 6177 : loss : 0.018530, loss_ce: 0.007324
2021-12-13 01:44:41,560 iteration 6178 : loss : 0.013171, loss_ce: 0.005102
2021-12-13 01:44:43,015 iteration 6179 : loss : 0.011014, loss_ce: 0.005183
2021-12-13 01:44:44,465 iteration 6180 : loss : 0.018343, loss_ce: 0.007027
2021-12-13 01:44:45,818 iteration 6181 : loss : 0.009337, loss_ce: 0.002990
2021-12-13 01:44:47,292 iteration 6182 : loss : 0.016320, loss_ce: 0.003898
2021-12-13 01:44:48,815 iteration 6183 : loss : 0.015067, loss_ce: 0.006202
2021-12-13 01:44:50,277 iteration 6184 : loss : 0.017273, loss_ce: 0.005263
2021-12-13 01:44:51,699 iteration 6185 : loss : 0.013557, loss_ce: 0.004537
2021-12-13 01:44:53,144 iteration 6186 : loss : 0.014370, loss_ce: 0.004828
2021-12-13 01:44:54,646 iteration 6187 : loss : 0.011276, loss_ce: 0.003868
2021-12-13 01:44:56,021 iteration 6188 : loss : 0.011441, loss_ce: 0.003783
 91%|██████████████████████████▍  | 364/400 [2:43:05<15:27, 25.77s/it]2021-12-13 01:44:57,456 iteration 6189 : loss : 0.009208, loss_ce: 0.002889
2021-12-13 01:44:58,819 iteration 6190 : loss : 0.011631, loss_ce: 0.004289
2021-12-13 01:45:00,393 iteration 6191 : loss : 0.029936, loss_ce: 0.011810
2021-12-13 01:45:01,890 iteration 6192 : loss : 0.010261, loss_ce: 0.003480
2021-12-13 01:45:03,234 iteration 6193 : loss : 0.009412, loss_ce: 0.003383
2021-12-13 01:45:04,686 iteration 6194 : loss : 0.014132, loss_ce: 0.005064
2021-12-13 01:45:06,167 iteration 6195 : loss : 0.012115, loss_ce: 0.004632
2021-12-13 01:45:07,656 iteration 6196 : loss : 0.010789, loss_ce: 0.004586
2021-12-13 01:45:09,126 iteration 6197 : loss : 0.012422, loss_ce: 0.006357
2021-12-13 01:45:10,580 iteration 6198 : loss : 0.010997, loss_ce: 0.004066
2021-12-13 01:45:12,037 iteration 6199 : loss : 0.013420, loss_ce: 0.003333
2021-12-13 01:45:13,410 iteration 6200 : loss : 0.008214, loss_ce: 0.003809
2021-12-13 01:45:14,871 iteration 6201 : loss : 0.021037, loss_ce: 0.007187
2021-12-13 01:45:16,277 iteration 6202 : loss : 0.012964, loss_ce: 0.006267
2021-12-13 01:45:17,686 iteration 6203 : loss : 0.010036, loss_ce: 0.002446
2021-12-13 01:45:19,150 iteration 6204 : loss : 0.011002, loss_ce: 0.004601
2021-12-13 01:45:19,150 Training Data Eval:
2021-12-13 01:45:26,582   Average segmentation loss on training set: 0.0092
2021-12-13 01:45:26,583 Validation Data Eval:
2021-12-13 01:45:29,170   Average segmentation loss on validation set: 0.0670
2021-12-13 01:45:30,650 iteration 6205 : loss : 0.018613, loss_ce: 0.006037
 91%|██████████████████████████▍  | 365/400 [2:43:39<16:35, 28.43s/it]2021-12-13 01:45:32,160 iteration 6206 : loss : 0.015682, loss_ce: 0.007495
2021-12-13 01:45:33,589 iteration 6207 : loss : 0.013503, loss_ce: 0.003884
2021-12-13 01:45:35,121 iteration 6208 : loss : 0.019594, loss_ce: 0.006095
2021-12-13 01:45:36,542 iteration 6209 : loss : 0.015421, loss_ce: 0.004562
2021-12-13 01:45:37,940 iteration 6210 : loss : 0.012653, loss_ce: 0.004584
2021-12-13 01:45:39,426 iteration 6211 : loss : 0.014289, loss_ce: 0.006483
2021-12-13 01:45:40,842 iteration 6212 : loss : 0.010111, loss_ce: 0.003227
2021-12-13 01:45:42,262 iteration 6213 : loss : 0.014818, loss_ce: 0.003786
2021-12-13 01:45:43,678 iteration 6214 : loss : 0.012208, loss_ce: 0.002465
2021-12-13 01:45:45,162 iteration 6215 : loss : 0.014606, loss_ce: 0.007157
2021-12-13 01:45:46,633 iteration 6216 : loss : 0.020563, loss_ce: 0.006254
2021-12-13 01:45:48,014 iteration 6217 : loss : 0.010488, loss_ce: 0.003568
2021-12-13 01:45:49,464 iteration 6218 : loss : 0.011589, loss_ce: 0.006440
2021-12-13 01:45:50,890 iteration 6219 : loss : 0.011915, loss_ce: 0.004255
2021-12-13 01:45:52,331 iteration 6220 : loss : 0.013212, loss_ce: 0.004012
2021-12-13 01:45:53,855 iteration 6221 : loss : 0.012904, loss_ce: 0.005460
2021-12-13 01:45:55,305 iteration 6222 : loss : 0.012160, loss_ce: 0.005282
 92%|██████████████████████████▌  | 366/400 [2:44:04<15:28, 27.30s/it]2021-12-13 01:45:56,826 iteration 6223 : loss : 0.027589, loss_ce: 0.008638
2021-12-13 01:45:58,248 iteration 6224 : loss : 0.012056, loss_ce: 0.003521
2021-12-13 01:45:59,681 iteration 6225 : loss : 0.012884, loss_ce: 0.005352
2021-12-13 01:46:01,197 iteration 6226 : loss : 0.017700, loss_ce: 0.006359
2021-12-13 01:46:02,643 iteration 6227 : loss : 0.011614, loss_ce: 0.002662
2021-12-13 01:46:04,110 iteration 6228 : loss : 0.015619, loss_ce: 0.006963
2021-12-13 01:46:05,500 iteration 6229 : loss : 0.010711, loss_ce: 0.004243
2021-12-13 01:46:06,920 iteration 6230 : loss : 0.014215, loss_ce: 0.005912
2021-12-13 01:46:08,387 iteration 6231 : loss : 0.012925, loss_ce: 0.005222
2021-12-13 01:46:09,846 iteration 6232 : loss : 0.012130, loss_ce: 0.005235
2021-12-13 01:46:11,263 iteration 6233 : loss : 0.012383, loss_ce: 0.005482
2021-12-13 01:46:12,720 iteration 6234 : loss : 0.015002, loss_ce: 0.005915
2021-12-13 01:46:14,245 iteration 6235 : loss : 0.025658, loss_ce: 0.005293
2021-12-13 01:46:15,617 iteration 6236 : loss : 0.009759, loss_ce: 0.003773
2021-12-13 01:46:17,059 iteration 6237 : loss : 0.011114, loss_ce: 0.004389
2021-12-13 01:46:18,453 iteration 6238 : loss : 0.010400, loss_ce: 0.004896
2021-12-13 01:46:19,861 iteration 6239 : loss : 0.009575, loss_ce: 0.004031
 92%|██████████████████████████▌  | 367/400 [2:44:29<14:33, 26.47s/it]2021-12-13 01:46:21,390 iteration 6240 : loss : 0.012251, loss_ce: 0.004857
2021-12-13 01:46:22,882 iteration 6241 : loss : 0.018643, loss_ce: 0.008336
2021-12-13 01:46:24,380 iteration 6242 : loss : 0.013943, loss_ce: 0.005627
2021-12-13 01:46:25,750 iteration 6243 : loss : 0.015322, loss_ce: 0.005094
2021-12-13 01:46:27,162 iteration 6244 : loss : 0.010038, loss_ce: 0.003040
2021-12-13 01:46:28,591 iteration 6245 : loss : 0.012568, loss_ce: 0.004615
2021-12-13 01:46:30,007 iteration 6246 : loss : 0.014865, loss_ce: 0.006209
2021-12-13 01:46:31,414 iteration 6247 : loss : 0.013527, loss_ce: 0.003598
2021-12-13 01:46:32,909 iteration 6248 : loss : 0.015222, loss_ce: 0.006421
2021-12-13 01:46:34,344 iteration 6249 : loss : 0.014830, loss_ce: 0.005907
2021-12-13 01:46:35,820 iteration 6250 : loss : 0.017940, loss_ce: 0.008276
2021-12-13 01:46:37,348 iteration 6251 : loss : 0.010412, loss_ce: 0.003888
2021-12-13 01:46:38,821 iteration 6252 : loss : 0.021626, loss_ce: 0.005428
2021-12-13 01:46:40,222 iteration 6253 : loss : 0.013374, loss_ce: 0.004561
2021-12-13 01:46:41,585 iteration 6254 : loss : 0.014379, loss_ce: 0.005255
2021-12-13 01:46:43,066 iteration 6255 : loss : 0.011266, loss_ce: 0.003627
2021-12-13 01:46:44,497 iteration 6256 : loss : 0.011240, loss_ce: 0.003783
 92%|██████████████████████████▋  | 368/400 [2:44:53<13:49, 25.92s/it]2021-12-13 01:46:46,004 iteration 6257 : loss : 0.010487, loss_ce: 0.003169
2021-12-13 01:46:47,404 iteration 6258 : loss : 0.011357, loss_ce: 0.003857
2021-12-13 01:46:48,901 iteration 6259 : loss : 0.011221, loss_ce: 0.004195
2021-12-13 01:46:50,467 iteration 6260 : loss : 0.024877, loss_ce: 0.006112
2021-12-13 01:46:51,917 iteration 6261 : loss : 0.012434, loss_ce: 0.006197
2021-12-13 01:46:53,406 iteration 6262 : loss : 0.015111, loss_ce: 0.005605
2021-12-13 01:46:54,832 iteration 6263 : loss : 0.012798, loss_ce: 0.004364
2021-12-13 01:46:56,230 iteration 6264 : loss : 0.013536, loss_ce: 0.005401
2021-12-13 01:46:57,674 iteration 6265 : loss : 0.015494, loss_ce: 0.005464
2021-12-13 01:46:59,090 iteration 6266 : loss : 0.009791, loss_ce: 0.003424
2021-12-13 01:47:00,702 iteration 6267 : loss : 0.018297, loss_ce: 0.007653
2021-12-13 01:47:02,131 iteration 6268 : loss : 0.012927, loss_ce: 0.004858
2021-12-13 01:47:03,574 iteration 6269 : loss : 0.011558, loss_ce: 0.004217
2021-12-13 01:47:04,986 iteration 6270 : loss : 0.011719, loss_ce: 0.005305
2021-12-13 01:47:06,501 iteration 6271 : loss : 0.012821, loss_ce: 0.005023
2021-12-13 01:47:07,906 iteration 6272 : loss : 0.013367, loss_ce: 0.004332
2021-12-13 01:47:09,427 iteration 6273 : loss : 0.016587, loss_ce: 0.006258
 92%|██████████████████████████▊  | 369/400 [2:45:18<13:14, 25.62s/it]2021-12-13 01:47:11,005 iteration 6274 : loss : 0.014874, loss_ce: 0.005111
2021-12-13 01:47:12,416 iteration 6275 : loss : 0.017915, loss_ce: 0.004575
2021-12-13 01:47:13,794 iteration 6276 : loss : 0.013599, loss_ce: 0.005722
2021-12-13 01:47:15,232 iteration 6277 : loss : 0.011687, loss_ce: 0.004167
2021-12-13 01:47:16,736 iteration 6278 : loss : 0.015585, loss_ce: 0.006277
2021-12-13 01:47:18,230 iteration 6279 : loss : 0.014724, loss_ce: 0.005454
2021-12-13 01:47:19,624 iteration 6280 : loss : 0.010826, loss_ce: 0.003321
2021-12-13 01:47:21,062 iteration 6281 : loss : 0.015404, loss_ce: 0.004356
2021-12-13 01:47:22,516 iteration 6282 : loss : 0.012115, loss_ce: 0.005625
2021-12-13 01:47:24,038 iteration 6283 : loss : 0.020501, loss_ce: 0.007599
2021-12-13 01:47:25,501 iteration 6284 : loss : 0.011099, loss_ce: 0.003469
2021-12-13 01:47:26,963 iteration 6285 : loss : 0.011808, loss_ce: 0.004666
2021-12-13 01:47:28,462 iteration 6286 : loss : 0.012629, loss_ce: 0.006172
2021-12-13 01:47:29,921 iteration 6287 : loss : 0.013029, loss_ce: 0.005662
2021-12-13 01:47:31,312 iteration 6288 : loss : 0.010681, loss_ce: 0.003647
2021-12-13 01:47:32,755 iteration 6289 : loss : 0.012389, loss_ce: 0.005609
2021-12-13 01:47:32,755 Training Data Eval:
2021-12-13 01:47:40,180   Average segmentation loss on training set: 0.0069
2021-12-13 01:47:40,180 Validation Data Eval:
2021-12-13 01:47:42,764   Average segmentation loss on validation set: 0.0767
2021-12-13 01:47:44,217 iteration 6290 : loss : 0.012747, loss_ce: 0.004744
 92%|██████████████████████████▊  | 370/400 [2:45:53<14:11, 28.37s/it]2021-12-13 01:47:45,691 iteration 6291 : loss : 0.019425, loss_ce: 0.005162
2021-12-13 01:47:47,062 iteration 6292 : loss : 0.010363, loss_ce: 0.003181
2021-12-13 01:47:48,478 iteration 6293 : loss : 0.010777, loss_ce: 0.003041
2021-12-13 01:47:50,007 iteration 6294 : loss : 0.017614, loss_ce: 0.004979
2021-12-13 01:47:51,447 iteration 6295 : loss : 0.014064, loss_ce: 0.007400
2021-12-13 01:47:52,823 iteration 6296 : loss : 0.010719, loss_ce: 0.004267
2021-12-13 01:47:54,337 iteration 6297 : loss : 0.014840, loss_ce: 0.005718
2021-12-13 01:47:55,782 iteration 6298 : loss : 0.013755, loss_ce: 0.006680
2021-12-13 01:47:57,225 iteration 6299 : loss : 0.011546, loss_ce: 0.004131
2021-12-13 01:47:58,723 iteration 6300 : loss : 0.013489, loss_ce: 0.004078
2021-12-13 01:48:00,206 iteration 6301 : loss : 0.011684, loss_ce: 0.006042
2021-12-13 01:48:01,729 iteration 6302 : loss : 0.019843, loss_ce: 0.006240
2021-12-13 01:48:03,145 iteration 6303 : loss : 0.010901, loss_ce: 0.003927
2021-12-13 01:48:04,610 iteration 6304 : loss : 0.016489, loss_ce: 0.006495
2021-12-13 01:48:06,017 iteration 6305 : loss : 0.011260, loss_ce: 0.003521
2021-12-13 01:48:07,451 iteration 6306 : loss : 0.015205, loss_ce: 0.008443
2021-12-13 01:48:08,860 iteration 6307 : loss : 0.013735, loss_ce: 0.005309
 93%|██████████████████████████▉  | 371/400 [2:46:18<13:10, 27.26s/it]2021-12-13 01:48:10,382 iteration 6308 : loss : 0.014321, loss_ce: 0.005545
2021-12-13 01:48:11,806 iteration 6309 : loss : 0.023012, loss_ce: 0.005033
2021-12-13 01:48:13,260 iteration 6310 : loss : 0.010129, loss_ce: 0.003807
2021-12-13 01:48:14,760 iteration 6311 : loss : 0.021471, loss_ce: 0.006534
2021-12-13 01:48:16,189 iteration 6312 : loss : 0.012513, loss_ce: 0.005376
2021-12-13 01:48:17,653 iteration 6313 : loss : 0.013594, loss_ce: 0.003827
2021-12-13 01:48:19,133 iteration 6314 : loss : 0.011371, loss_ce: 0.004235
2021-12-13 01:48:20,549 iteration 6315 : loss : 0.014254, loss_ce: 0.005897
2021-12-13 01:48:21,937 iteration 6316 : loss : 0.012326, loss_ce: 0.003427
2021-12-13 01:48:23,324 iteration 6317 : loss : 0.012802, loss_ce: 0.004092
2021-12-13 01:48:24,812 iteration 6318 : loss : 0.016313, loss_ce: 0.006665
2021-12-13 01:48:26,230 iteration 6319 : loss : 0.015146, loss_ce: 0.005543
2021-12-13 01:48:27,674 iteration 6320 : loss : 0.010297, loss_ce: 0.004171
2021-12-13 01:48:29,114 iteration 6321 : loss : 0.012244, loss_ce: 0.004513
2021-12-13 01:48:30,636 iteration 6322 : loss : 0.024669, loss_ce: 0.010002
2021-12-13 01:48:32,166 iteration 6323 : loss : 0.032502, loss_ce: 0.009634
2021-12-13 01:48:33,590 iteration 6324 : loss : 0.013317, loss_ce: 0.005304
 93%|██████████████████████████▉  | 372/400 [2:46:42<12:21, 26.50s/it]2021-12-13 01:48:35,034 iteration 6325 : loss : 0.011074, loss_ce: 0.004975
2021-12-13 01:48:36,425 iteration 6326 : loss : 0.008201, loss_ce: 0.003264
2021-12-13 01:48:37,911 iteration 6327 : loss : 0.014758, loss_ce: 0.005663
2021-12-13 01:48:39,341 iteration 6328 : loss : 0.024688, loss_ce: 0.007906
2021-12-13 01:48:40,744 iteration 6329 : loss : 0.012730, loss_ce: 0.003056
2021-12-13 01:48:42,192 iteration 6330 : loss : 0.009964, loss_ce: 0.003209
2021-12-13 01:48:43,814 iteration 6331 : loss : 0.025888, loss_ce: 0.008616
2021-12-13 01:48:45,217 iteration 6332 : loss : 0.012337, loss_ce: 0.005022
2021-12-13 01:48:46,692 iteration 6333 : loss : 0.010821, loss_ce: 0.003040
2021-12-13 01:48:48,142 iteration 6334 : loss : 0.012834, loss_ce: 0.005303
2021-12-13 01:48:49,676 iteration 6335 : loss : 0.014848, loss_ce: 0.005689
2021-12-13 01:48:51,042 iteration 6336 : loss : 0.007342, loss_ce: 0.002730
2021-12-13 01:48:52,495 iteration 6337 : loss : 0.017742, loss_ce: 0.007108
2021-12-13 01:48:54,023 iteration 6338 : loss : 0.023102, loss_ce: 0.003603
2021-12-13 01:48:55,433 iteration 6339 : loss : 0.013173, loss_ce: 0.005789
2021-12-13 01:48:56,836 iteration 6340 : loss : 0.010581, loss_ce: 0.005081
2021-12-13 01:48:58,284 iteration 6341 : loss : 0.010840, loss_ce: 0.003413
 93%|███████████████████████████  | 373/400 [2:47:07<11:40, 25.96s/it]2021-12-13 01:48:59,778 iteration 6342 : loss : 0.016969, loss_ce: 0.006257
2021-12-13 01:49:01,212 iteration 6343 : loss : 0.015368, loss_ce: 0.004401
2021-12-13 01:49:02,734 iteration 6344 : loss : 0.021503, loss_ce: 0.009507
2021-12-13 01:49:04,166 iteration 6345 : loss : 0.016605, loss_ce: 0.004857
2021-12-13 01:49:05,561 iteration 6346 : loss : 0.011579, loss_ce: 0.004602
2021-12-13 01:49:07,029 iteration 6347 : loss : 0.014752, loss_ce: 0.006725
2021-12-13 01:49:08,446 iteration 6348 : loss : 0.012715, loss_ce: 0.005470
2021-12-13 01:49:09,887 iteration 6349 : loss : 0.012541, loss_ce: 0.004195
2021-12-13 01:49:11,328 iteration 6350 : loss : 0.012347, loss_ce: 0.004361
2021-12-13 01:49:12,793 iteration 6351 : loss : 0.020718, loss_ce: 0.013000
2021-12-13 01:49:14,283 iteration 6352 : loss : 0.012450, loss_ce: 0.004768
2021-12-13 01:49:15,820 iteration 6353 : loss : 0.025873, loss_ce: 0.007298
2021-12-13 01:49:17,229 iteration 6354 : loss : 0.013046, loss_ce: 0.003078
2021-12-13 01:49:18,739 iteration 6355 : loss : 0.015382, loss_ce: 0.005210
2021-12-13 01:49:20,273 iteration 6356 : loss : 0.020471, loss_ce: 0.008124
2021-12-13 01:49:21,750 iteration 6357 : loss : 0.012887, loss_ce: 0.006321
2021-12-13 01:49:23,265 iteration 6358 : loss : 0.013562, loss_ce: 0.003735
 94%|███████████████████████████  | 374/400 [2:47:32<11:07, 25.66s/it]2021-12-13 01:49:24,749 iteration 6359 : loss : 0.012538, loss_ce: 0.004441
2021-12-13 01:49:26,087 iteration 6360 : loss : 0.007785, loss_ce: 0.002659
2021-12-13 01:49:27,610 iteration 6361 : loss : 0.013620, loss_ce: 0.005080
2021-12-13 01:49:29,073 iteration 6362 : loss : 0.010171, loss_ce: 0.003993
2021-12-13 01:49:30,616 iteration 6363 : loss : 0.021838, loss_ce: 0.007229
2021-12-13 01:49:32,094 iteration 6364 : loss : 0.009372, loss_ce: 0.002692
2021-12-13 01:49:33,524 iteration 6365 : loss : 0.014661, loss_ce: 0.006223
2021-12-13 01:49:34,959 iteration 6366 : loss : 0.011444, loss_ce: 0.004426
2021-12-13 01:49:36,463 iteration 6367 : loss : 0.016298, loss_ce: 0.009233
2021-12-13 01:49:37,934 iteration 6368 : loss : 0.016781, loss_ce: 0.004014
2021-12-13 01:49:39,369 iteration 6369 : loss : 0.012882, loss_ce: 0.003134
2021-12-13 01:49:40,837 iteration 6370 : loss : 0.012753, loss_ce: 0.005751
2021-12-13 01:49:42,234 iteration 6371 : loss : 0.009640, loss_ce: 0.003977
2021-12-13 01:49:43,704 iteration 6372 : loss : 0.013454, loss_ce: 0.004777
2021-12-13 01:49:45,098 iteration 6373 : loss : 0.009739, loss_ce: 0.004384
2021-12-13 01:49:46,452 iteration 6374 : loss : 0.008407, loss_ce: 0.003215
2021-12-13 01:49:46,452 Training Data Eval:
2021-12-13 01:49:53,891   Average segmentation loss on training set: 0.0071
2021-12-13 01:49:53,891 Validation Data Eval:
2021-12-13 01:49:56,487   Average segmentation loss on validation set: 0.0842
2021-12-13 01:49:57,995 iteration 6375 : loss : 0.012065, loss_ce: 0.005873
 94%|███████████████████████████▏ | 375/400 [2:48:07<11:49, 28.38s/it]2021-12-13 01:49:59,561 iteration 6376 : loss : 0.018170, loss_ce: 0.006952
2021-12-13 01:50:01,030 iteration 6377 : loss : 0.014074, loss_ce: 0.003546
2021-12-13 01:50:02,495 iteration 6378 : loss : 0.014769, loss_ce: 0.007410
2021-12-13 01:50:03,943 iteration 6379 : loss : 0.012307, loss_ce: 0.005089
2021-12-13 01:50:05,439 iteration 6380 : loss : 0.017064, loss_ce: 0.006484
2021-12-13 01:50:06,936 iteration 6381 : loss : 0.022999, loss_ce: 0.010769
2021-12-13 01:50:08,380 iteration 6382 : loss : 0.012866, loss_ce: 0.006147
2021-12-13 01:50:09,864 iteration 6383 : loss : 0.014269, loss_ce: 0.004579
2021-12-13 01:50:11,361 iteration 6384 : loss : 0.015557, loss_ce: 0.006441
2021-12-13 01:50:12,683 iteration 6385 : loss : 0.008094, loss_ce: 0.003062
2021-12-13 01:50:14,178 iteration 6386 : loss : 0.013603, loss_ce: 0.003874
2021-12-13 01:50:15,661 iteration 6387 : loss : 0.015646, loss_ce: 0.006903
2021-12-13 01:50:17,043 iteration 6388 : loss : 0.009024, loss_ce: 0.004260
2021-12-13 01:50:18,527 iteration 6389 : loss : 0.014090, loss_ce: 0.007032
2021-12-13 01:50:19,994 iteration 6390 : loss : 0.015750, loss_ce: 0.005632
2021-12-13 01:50:21,489 iteration 6391 : loss : 0.021497, loss_ce: 0.008469
2021-12-13 01:50:22,996 iteration 6392 : loss : 0.017588, loss_ce: 0.003809
 94%|███████████████████████████▎ | 376/400 [2:48:32<10:56, 27.37s/it]2021-12-13 01:50:24,447 iteration 6393 : loss : 0.009788, loss_ce: 0.004784
2021-12-13 01:50:25,876 iteration 6394 : loss : 0.009418, loss_ce: 0.004052
2021-12-13 01:50:27,288 iteration 6395 : loss : 0.008335, loss_ce: 0.002386
2021-12-13 01:50:28,769 iteration 6396 : loss : 0.014619, loss_ce: 0.005092
2021-12-13 01:50:30,272 iteration 6397 : loss : 0.015515, loss_ce: 0.004557
2021-12-13 01:50:31,770 iteration 6398 : loss : 0.013432, loss_ce: 0.005266
2021-12-13 01:50:33,158 iteration 6399 : loss : 0.012516, loss_ce: 0.003474
2021-12-13 01:50:34,590 iteration 6400 : loss : 0.008426, loss_ce: 0.003162
2021-12-13 01:50:35,979 iteration 6401 : loss : 0.008461, loss_ce: 0.003111
2021-12-13 01:50:37,475 iteration 6402 : loss : 0.014355, loss_ce: 0.006460
2021-12-13 01:50:38,891 iteration 6403 : loss : 0.010515, loss_ce: 0.004489
2021-12-13 01:50:40,290 iteration 6404 : loss : 0.011042, loss_ce: 0.005626
2021-12-13 01:50:41,871 iteration 6405 : loss : 0.016599, loss_ce: 0.006821
2021-12-13 01:50:43,247 iteration 6406 : loss : 0.008515, loss_ce: 0.003346
2021-12-13 01:50:44,704 iteration 6407 : loss : 0.022738, loss_ce: 0.009933
2021-12-13 01:50:46,173 iteration 6408 : loss : 0.017063, loss_ce: 0.007274
2021-12-13 01:50:47,562 iteration 6409 : loss : 0.008642, loss_ce: 0.002831
 94%|███████████████████████████▎ | 377/400 [2:48:56<10:10, 26.53s/it]2021-12-13 01:50:48,990 iteration 6410 : loss : 0.010287, loss_ce: 0.003801
2021-12-13 01:50:50,427 iteration 6411 : loss : 0.009843, loss_ce: 0.003825
2021-12-13 01:50:51,932 iteration 6412 : loss : 0.015426, loss_ce: 0.005141
2021-12-13 01:50:53,373 iteration 6413 : loss : 0.014304, loss_ce: 0.006170
2021-12-13 01:50:54,854 iteration 6414 : loss : 0.013233, loss_ce: 0.004974
2021-12-13 01:50:56,339 iteration 6415 : loss : 0.009614, loss_ce: 0.003368
2021-12-13 01:50:57,739 iteration 6416 : loss : 0.015493, loss_ce: 0.006121
2021-12-13 01:50:59,224 iteration 6417 : loss : 0.018426, loss_ce: 0.005474
2021-12-13 01:51:00,657 iteration 6418 : loss : 0.011378, loss_ce: 0.004827
2021-12-13 01:51:02,099 iteration 6419 : loss : 0.011997, loss_ce: 0.005018
2021-12-13 01:51:03,566 iteration 6420 : loss : 0.019445, loss_ce: 0.008794
2021-12-13 01:51:05,048 iteration 6421 : loss : 0.011879, loss_ce: 0.005056
2021-12-13 01:51:06,469 iteration 6422 : loss : 0.012736, loss_ce: 0.004857
2021-12-13 01:51:07,914 iteration 6423 : loss : 0.013684, loss_ce: 0.005662
2021-12-13 01:51:09,305 iteration 6424 : loss : 0.009244, loss_ce: 0.002970
2021-12-13 01:51:10,872 iteration 6425 : loss : 0.014335, loss_ce: 0.005230
2021-12-13 01:51:12,259 iteration 6426 : loss : 0.012722, loss_ce: 0.004105
 94%|███████████████████████████▍ | 378/400 [2:49:21<09:31, 25.98s/it]2021-12-13 01:51:13,771 iteration 6427 : loss : 0.014888, loss_ce: 0.006757
2021-12-13 01:51:15,264 iteration 6428 : loss : 0.018375, loss_ce: 0.005240
2021-12-13 01:51:16,693 iteration 6429 : loss : 0.009735, loss_ce: 0.003888
2021-12-13 01:51:18,187 iteration 6430 : loss : 0.012695, loss_ce: 0.005525
2021-12-13 01:51:19,628 iteration 6431 : loss : 0.021580, loss_ce: 0.006322
2021-12-13 01:51:21,080 iteration 6432 : loss : 0.012813, loss_ce: 0.004672
2021-12-13 01:51:22,533 iteration 6433 : loss : 0.011685, loss_ce: 0.003018
2021-12-13 01:51:23,990 iteration 6434 : loss : 0.020985, loss_ce: 0.008755
2021-12-13 01:51:25,353 iteration 6435 : loss : 0.008716, loss_ce: 0.002854
2021-12-13 01:51:26,750 iteration 6436 : loss : 0.012146, loss_ce: 0.006102
2021-12-13 01:51:28,119 iteration 6437 : loss : 0.012014, loss_ce: 0.004604
2021-12-13 01:51:29,485 iteration 6438 : loss : 0.008898, loss_ce: 0.004101
2021-12-13 01:51:30,990 iteration 6439 : loss : 0.022761, loss_ce: 0.007555
2021-12-13 01:51:32,442 iteration 6440 : loss : 0.014609, loss_ce: 0.005606
2021-12-13 01:51:33,900 iteration 6441 : loss : 0.010671, loss_ce: 0.004854
2021-12-13 01:51:35,337 iteration 6442 : loss : 0.009365, loss_ce: 0.003931
2021-12-13 01:51:36,751 iteration 6443 : loss : 0.011552, loss_ce: 0.004399
 95%|███████████████████████████▍ | 379/400 [2:49:45<08:56, 25.53s/it]2021-12-13 01:51:38,204 iteration 6444 : loss : 0.012501, loss_ce: 0.005899
2021-12-13 01:51:39,604 iteration 6445 : loss : 0.008874, loss_ce: 0.003303
2021-12-13 01:51:41,042 iteration 6446 : loss : 0.014252, loss_ce: 0.005243
2021-12-13 01:51:42,479 iteration 6447 : loss : 0.009539, loss_ce: 0.004088
2021-12-13 01:51:43,915 iteration 6448 : loss : 0.016207, loss_ce: 0.003757
2021-12-13 01:51:45,376 iteration 6449 : loss : 0.015959, loss_ce: 0.005055
2021-12-13 01:51:46,877 iteration 6450 : loss : 0.017209, loss_ce: 0.004426
2021-12-13 01:51:48,312 iteration 6451 : loss : 0.013668, loss_ce: 0.004875
2021-12-13 01:51:49,801 iteration 6452 : loss : 0.024670, loss_ce: 0.007124
2021-12-13 01:51:51,229 iteration 6453 : loss : 0.011194, loss_ce: 0.004787
2021-12-13 01:51:52,674 iteration 6454 : loss : 0.014091, loss_ce: 0.004414
2021-12-13 01:51:54,066 iteration 6455 : loss : 0.011721, loss_ce: 0.004463
2021-12-13 01:51:55,520 iteration 6456 : loss : 0.011512, loss_ce: 0.005248
2021-12-13 01:51:56,945 iteration 6457 : loss : 0.009069, loss_ce: 0.003684
2021-12-13 01:51:58,354 iteration 6458 : loss : 0.012443, loss_ce: 0.006806
2021-12-13 01:51:59,873 iteration 6459 : loss : 0.012729, loss_ce: 0.004761
2021-12-13 01:51:59,873 Training Data Eval:
2021-12-13 01:52:07,287   Average segmentation loss on training set: 0.0062
2021-12-13 01:52:07,287 Validation Data Eval:
2021-12-13 01:52:09,863   Average segmentation loss on validation set: 0.0746
2021-12-13 01:52:11,404 iteration 6460 : loss : 0.011180, loss_ce: 0.003447
 95%|███████████████████████████▌ | 380/400 [2:50:20<09:25, 28.27s/it]2021-12-13 01:52:12,870 iteration 6461 : loss : 0.009082, loss_ce: 0.002997
2021-12-13 01:52:14,329 iteration 6462 : loss : 0.009787, loss_ce: 0.003776
2021-12-13 01:52:15,727 iteration 6463 : loss : 0.009862, loss_ce: 0.004500
2021-12-13 01:52:17,150 iteration 6464 : loss : 0.011499, loss_ce: 0.004281
2021-12-13 01:52:18,588 iteration 6465 : loss : 0.008918, loss_ce: 0.003023
2021-12-13 01:52:20,028 iteration 6466 : loss : 0.011744, loss_ce: 0.004832
2021-12-13 01:52:21,469 iteration 6467 : loss : 0.014231, loss_ce: 0.006037
2021-12-13 01:52:22,858 iteration 6468 : loss : 0.012097, loss_ce: 0.003551
2021-12-13 01:52:24,349 iteration 6469 : loss : 0.015198, loss_ce: 0.003824
2021-12-13 01:52:25,815 iteration 6470 : loss : 0.009854, loss_ce: 0.004028
2021-12-13 01:52:27,262 iteration 6471 : loss : 0.013005, loss_ce: 0.005214
2021-12-13 01:52:28,658 iteration 6472 : loss : 0.014291, loss_ce: 0.004842
2021-12-13 01:52:30,137 iteration 6473 : loss : 0.011619, loss_ce: 0.004661
2021-12-13 01:52:31,604 iteration 6474 : loss : 0.010200, loss_ce: 0.003986
2021-12-13 01:52:33,083 iteration 6475 : loss : 0.014183, loss_ce: 0.004792
2021-12-13 01:52:34,547 iteration 6476 : loss : 0.015845, loss_ce: 0.006115
2021-12-13 01:52:35,996 iteration 6477 : loss : 0.012250, loss_ce: 0.004936
 95%|███████████████████████████▌ | 381/400 [2:50:45<08:36, 27.16s/it]2021-12-13 01:52:37,474 iteration 6478 : loss : 0.011845, loss_ce: 0.004654
2021-12-13 01:52:38,926 iteration 6479 : loss : 0.014669, loss_ce: 0.005290
2021-12-13 01:52:40,354 iteration 6480 : loss : 0.014257, loss_ce: 0.006557
2021-12-13 01:52:41,931 iteration 6481 : loss : 0.017168, loss_ce: 0.006311
2021-12-13 01:52:43,333 iteration 6482 : loss : 0.011552, loss_ce: 0.004441
2021-12-13 01:52:44,815 iteration 6483 : loss : 0.012694, loss_ce: 0.005008
2021-12-13 01:52:46,160 iteration 6484 : loss : 0.012214, loss_ce: 0.004039
2021-12-13 01:52:47,595 iteration 6485 : loss : 0.010897, loss_ce: 0.003490
2021-12-13 01:52:49,046 iteration 6486 : loss : 0.013935, loss_ce: 0.004564
2021-12-13 01:52:50,517 iteration 6487 : loss : 0.015124, loss_ce: 0.006395
2021-12-13 01:52:52,002 iteration 6488 : loss : 0.011087, loss_ce: 0.003663
2021-12-13 01:52:53,449 iteration 6489 : loss : 0.017583, loss_ce: 0.004725
2021-12-13 01:52:54,891 iteration 6490 : loss : 0.012375, loss_ce: 0.004361
2021-12-13 01:52:56,305 iteration 6491 : loss : 0.012825, loss_ce: 0.005867
2021-12-13 01:52:57,723 iteration 6492 : loss : 0.008408, loss_ce: 0.004403
2021-12-13 01:52:59,151 iteration 6493 : loss : 0.012970, loss_ce: 0.004754
2021-12-13 01:53:00,607 iteration 6494 : loss : 0.014333, loss_ce: 0.005608
 96%|███████████████████████████▋ | 382/400 [2:51:09<07:55, 26.40s/it]2021-12-13 01:53:02,027 iteration 6495 : loss : 0.010605, loss_ce: 0.004453
2021-12-13 01:53:03,454 iteration 6496 : loss : 0.012290, loss_ce: 0.004116
2021-12-13 01:53:04,928 iteration 6497 : loss : 0.007737, loss_ce: 0.003770
2021-12-13 01:53:06,334 iteration 6498 : loss : 0.010923, loss_ce: 0.002744
2021-12-13 01:53:07,766 iteration 6499 : loss : 0.024743, loss_ce: 0.005171
2021-12-13 01:53:09,287 iteration 6500 : loss : 0.023650, loss_ce: 0.007307
2021-12-13 01:53:10,799 iteration 6501 : loss : 0.015854, loss_ce: 0.007668
2021-12-13 01:53:12,266 iteration 6502 : loss : 0.011102, loss_ce: 0.003655
2021-12-13 01:53:13,721 iteration 6503 : loss : 0.012129, loss_ce: 0.004438
2021-12-13 01:53:15,191 iteration 6504 : loss : 0.012918, loss_ce: 0.006056
2021-12-13 01:53:16,583 iteration 6505 : loss : 0.009016, loss_ce: 0.003297
2021-12-13 01:53:18,047 iteration 6506 : loss : 0.012481, loss_ce: 0.003316
2021-12-13 01:53:19,463 iteration 6507 : loss : 0.010759, loss_ce: 0.004351
2021-12-13 01:53:20,839 iteration 6508 : loss : 0.015059, loss_ce: 0.005559
2021-12-13 01:53:22,270 iteration 6509 : loss : 0.010444, loss_ce: 0.003534
2021-12-13 01:53:23,606 iteration 6510 : loss : 0.007747, loss_ce: 0.002887
2021-12-13 01:53:25,071 iteration 6511 : loss : 0.012902, loss_ce: 0.005607
 96%|███████████████████████████▊ | 383/400 [2:51:34<07:18, 25.82s/it]2021-12-13 01:53:26,576 iteration 6512 : loss : 0.018323, loss_ce: 0.006883
2021-12-13 01:53:28,070 iteration 6513 : loss : 0.016758, loss_ce: 0.006114
2021-12-13 01:53:29,525 iteration 6514 : loss : 0.015016, loss_ce: 0.004530
2021-12-13 01:53:31,017 iteration 6515 : loss : 0.017775, loss_ce: 0.006028
2021-12-13 01:53:32,431 iteration 6516 : loss : 0.010465, loss_ce: 0.004009
2021-12-13 01:53:33,832 iteration 6517 : loss : 0.012664, loss_ce: 0.005477
2021-12-13 01:53:35,295 iteration 6518 : loss : 0.018957, loss_ce: 0.007336
2021-12-13 01:53:36,807 iteration 6519 : loss : 0.013827, loss_ce: 0.005131
2021-12-13 01:53:38,184 iteration 6520 : loss : 0.011509, loss_ce: 0.004397
2021-12-13 01:53:39,662 iteration 6521 : loss : 0.012098, loss_ce: 0.004972
2021-12-13 01:53:41,118 iteration 6522 : loss : 0.015559, loss_ce: 0.005636
2021-12-13 01:53:42,592 iteration 6523 : loss : 0.012043, loss_ce: 0.005035
2021-12-13 01:53:44,065 iteration 6524 : loss : 0.015959, loss_ce: 0.005151
2021-12-13 01:53:45,553 iteration 6525 : loss : 0.014809, loss_ce: 0.004782
2021-12-13 01:53:46,993 iteration 6526 : loss : 0.015385, loss_ce: 0.005646
2021-12-13 01:53:48,397 iteration 6527 : loss : 0.017598, loss_ce: 0.006046
2021-12-13 01:53:49,816 iteration 6528 : loss : 0.011505, loss_ce: 0.004553
 96%|███████████████████████████▊ | 384/400 [2:51:59<06:47, 25.50s/it]2021-12-13 01:53:51,461 iteration 6529 : loss : 0.018928, loss_ce: 0.007135
2021-12-13 01:53:52,893 iteration 6530 : loss : 0.012512, loss_ce: 0.005653
2021-12-13 01:53:54,432 iteration 6531 : loss : 0.022938, loss_ce: 0.006699
2021-12-13 01:53:55,895 iteration 6532 : loss : 0.021456, loss_ce: 0.007780
2021-12-13 01:53:57,392 iteration 6533 : loss : 0.020674, loss_ce: 0.003955
2021-12-13 01:53:58,982 iteration 6534 : loss : 0.025200, loss_ce: 0.006868
2021-12-13 01:54:00,356 iteration 6535 : loss : 0.011722, loss_ce: 0.001838
2021-12-13 01:54:01,792 iteration 6536 : loss : 0.020937, loss_ce: 0.009484
2021-12-13 01:54:03,244 iteration 6537 : loss : 0.010195, loss_ce: 0.003845
2021-12-13 01:54:04,711 iteration 6538 : loss : 0.015869, loss_ce: 0.007944
2021-12-13 01:54:06,262 iteration 6539 : loss : 0.014121, loss_ce: 0.005509
2021-12-13 01:54:07,704 iteration 6540 : loss : 0.013866, loss_ce: 0.006417
2021-12-13 01:54:09,124 iteration 6541 : loss : 0.010107, loss_ce: 0.004258
2021-12-13 01:54:10,619 iteration 6542 : loss : 0.019272, loss_ce: 0.008010
2021-12-13 01:54:12,093 iteration 6543 : loss : 0.015773, loss_ce: 0.006301
2021-12-13 01:54:13,475 iteration 6544 : loss : 0.008906, loss_ce: 0.002930
2021-12-13 01:54:13,475 Training Data Eval:
2021-12-13 01:54:20,872   Average segmentation loss on training set: 0.0062
2021-12-13 01:54:20,872 Validation Data Eval:
2021-12-13 01:54:23,442   Average segmentation loss on validation set: 0.0675
2021-12-13 01:54:24,802 iteration 6545 : loss : 0.008094, loss_ce: 0.001792
 96%|███████████████████████████▉ | 385/400 [2:52:34<07:05, 28.34s/it]2021-12-13 01:54:26,329 iteration 6546 : loss : 0.016494, loss_ce: 0.004722
2021-12-13 01:54:27,945 iteration 6547 : loss : 0.022980, loss_ce: 0.007919
2021-12-13 01:54:29,296 iteration 6548 : loss : 0.011194, loss_ce: 0.006475
2021-12-13 01:54:30,655 iteration 6549 : loss : 0.006774, loss_ce: 0.002297
2021-12-13 01:54:32,080 iteration 6550 : loss : 0.010578, loss_ce: 0.004061
2021-12-13 01:54:33,571 iteration 6551 : loss : 0.012943, loss_ce: 0.005811
2021-12-13 01:54:34,923 iteration 6552 : loss : 0.010066, loss_ce: 0.004638
2021-12-13 01:54:36,437 iteration 6553 : loss : 0.016195, loss_ce: 0.005916
2021-12-13 01:54:37,882 iteration 6554 : loss : 0.013011, loss_ce: 0.004155
2021-12-13 01:54:39,397 iteration 6555 : loss : 0.014350, loss_ce: 0.005052
2021-12-13 01:54:40,883 iteration 6556 : loss : 0.017545, loss_ce: 0.005083
2021-12-13 01:54:42,269 iteration 6557 : loss : 0.015115, loss_ce: 0.005403
2021-12-13 01:54:43,670 iteration 6558 : loss : 0.011059, loss_ce: 0.003182
2021-12-13 01:54:45,149 iteration 6559 : loss : 0.013705, loss_ce: 0.006601
2021-12-13 01:54:46,675 iteration 6560 : loss : 0.037327, loss_ce: 0.007084
2021-12-13 01:54:48,077 iteration 6561 : loss : 0.010941, loss_ce: 0.004179
2021-12-13 01:54:49,428 iteration 6562 : loss : 0.007865, loss_ce: 0.002507
 96%|███████████████████████████▉ | 386/400 [2:52:58<06:21, 27.23s/it]2021-12-13 01:54:50,899 iteration 6563 : loss : 0.009980, loss_ce: 0.004174
2021-12-13 01:54:52,300 iteration 6564 : loss : 0.011899, loss_ce: 0.003189
2021-12-13 01:54:53,678 iteration 6565 : loss : 0.008756, loss_ce: 0.002450
2021-12-13 01:54:55,103 iteration 6566 : loss : 0.008165, loss_ce: 0.003104
2021-12-13 01:54:56,576 iteration 6567 : loss : 0.016362, loss_ce: 0.006281
2021-12-13 01:54:58,036 iteration 6568 : loss : 0.014741, loss_ce: 0.005613
2021-12-13 01:54:59,542 iteration 6569 : loss : 0.017191, loss_ce: 0.004895
2021-12-13 01:55:00,985 iteration 6570 : loss : 0.012184, loss_ce: 0.003179
2021-12-13 01:55:02,544 iteration 6571 : loss : 0.017044, loss_ce: 0.007095
2021-12-13 01:55:03,918 iteration 6572 : loss : 0.009507, loss_ce: 0.004487
2021-12-13 01:55:05,424 iteration 6573 : loss : 0.020024, loss_ce: 0.006059
2021-12-13 01:55:06,845 iteration 6574 : loss : 0.008698, loss_ce: 0.002447
2021-12-13 01:55:08,352 iteration 6575 : loss : 0.026743, loss_ce: 0.008742
2021-12-13 01:55:09,795 iteration 6576 : loss : 0.014180, loss_ce: 0.005605
2021-12-13 01:55:11,198 iteration 6577 : loss : 0.013302, loss_ce: 0.004573
2021-12-13 01:55:12,665 iteration 6578 : loss : 0.009285, loss_ce: 0.003294
2021-12-13 01:55:14,083 iteration 6579 : loss : 0.013271, loss_ce: 0.005671
 97%|████████████████████████████ | 387/400 [2:53:23<05:43, 26.45s/it]2021-12-13 01:55:15,611 iteration 6580 : loss : 0.020132, loss_ce: 0.007786
2021-12-13 01:55:17,005 iteration 6581 : loss : 0.010187, loss_ce: 0.003045
2021-12-13 01:55:18,525 iteration 6582 : loss : 0.015192, loss_ce: 0.004956
2021-12-13 01:55:19,971 iteration 6583 : loss : 0.019532, loss_ce: 0.006561
2021-12-13 01:55:21,369 iteration 6584 : loss : 0.013734, loss_ce: 0.005039
2021-12-13 01:55:22,744 iteration 6585 : loss : 0.009203, loss_ce: 0.002810
2021-12-13 01:55:24,175 iteration 6586 : loss : 0.010672, loss_ce: 0.002298
2021-12-13 01:55:25,556 iteration 6587 : loss : 0.009799, loss_ce: 0.004645
2021-12-13 01:55:27,025 iteration 6588 : loss : 0.008449, loss_ce: 0.003748
2021-12-13 01:55:28,475 iteration 6589 : loss : 0.010718, loss_ce: 0.004389
2021-12-13 01:55:29,881 iteration 6590 : loss : 0.011038, loss_ce: 0.004776
2021-12-13 01:55:31,295 iteration 6591 : loss : 0.007932, loss_ce: 0.002869
2021-12-13 01:55:32,806 iteration 6592 : loss : 0.013399, loss_ce: 0.006319
2021-12-13 01:55:34,168 iteration 6593 : loss : 0.008980, loss_ce: 0.004703
2021-12-13 01:55:35,591 iteration 6594 : loss : 0.009071, loss_ce: 0.003206
2021-12-13 01:55:37,067 iteration 6595 : loss : 0.020679, loss_ce: 0.006349
2021-12-13 01:55:38,443 iteration 6596 : loss : 0.010158, loss_ce: 0.003135
 97%|████████████████████████████▏| 388/400 [2:53:47<05:09, 25.83s/it]2021-12-13 01:55:39,868 iteration 6597 : loss : 0.009110, loss_ce: 0.003733
2021-12-13 01:55:41,352 iteration 6598 : loss : 0.018278, loss_ce: 0.002908
2021-12-13 01:55:42,853 iteration 6599 : loss : 0.015252, loss_ce: 0.005791
2021-12-13 01:55:44,251 iteration 6600 : loss : 0.010751, loss_ce: 0.004593
2021-12-13 01:55:45,793 iteration 6601 : loss : 0.017440, loss_ce: 0.007504
2021-12-13 01:55:47,277 iteration 6602 : loss : 0.014082, loss_ce: 0.005423
2021-12-13 01:55:48,676 iteration 6603 : loss : 0.012223, loss_ce: 0.005704
2021-12-13 01:55:50,151 iteration 6604 : loss : 0.010409, loss_ce: 0.004702
2021-12-13 01:55:51,577 iteration 6605 : loss : 0.014530, loss_ce: 0.006801
2021-12-13 01:55:53,085 iteration 6606 : loss : 0.015680, loss_ce: 0.005735
2021-12-13 01:55:54,602 iteration 6607 : loss : 0.017864, loss_ce: 0.007470
2021-12-13 01:55:55,995 iteration 6608 : loss : 0.011434, loss_ce: 0.004909
2021-12-13 01:55:57,492 iteration 6609 : loss : 0.014554, loss_ce: 0.006532
2021-12-13 01:55:58,922 iteration 6610 : loss : 0.010163, loss_ce: 0.003695
2021-12-13 01:56:00,342 iteration 6611 : loss : 0.009700, loss_ce: 0.002525
2021-12-13 01:56:01,778 iteration 6612 : loss : 0.015012, loss_ce: 0.004584
2021-12-13 01:56:03,264 iteration 6613 : loss : 0.011446, loss_ce: 0.004235
 97%|████████████████████████████▏| 389/400 [2:54:12<04:40, 25.53s/it]2021-12-13 01:56:04,712 iteration 6614 : loss : 0.008260, loss_ce: 0.002835
2021-12-13 01:56:06,094 iteration 6615 : loss : 0.007600, loss_ce: 0.002755
2021-12-13 01:56:07,580 iteration 6616 : loss : 0.016396, loss_ce: 0.006160
2021-12-13 01:56:09,002 iteration 6617 : loss : 0.014383, loss_ce: 0.005780
2021-12-13 01:56:10,523 iteration 6618 : loss : 0.016074, loss_ce: 0.006292
2021-12-13 01:56:11,967 iteration 6619 : loss : 0.011962, loss_ce: 0.003901
2021-12-13 01:56:13,422 iteration 6620 : loss : 0.015818, loss_ce: 0.005035
2021-12-13 01:56:14,934 iteration 6621 : loss : 0.013910, loss_ce: 0.004847
2021-12-13 01:56:16,359 iteration 6622 : loss : 0.013921, loss_ce: 0.006099
2021-12-13 01:56:17,743 iteration 6623 : loss : 0.011389, loss_ce: 0.003896
2021-12-13 01:56:19,170 iteration 6624 : loss : 0.012445, loss_ce: 0.005099
2021-12-13 01:56:20,633 iteration 6625 : loss : 0.015555, loss_ce: 0.006035
2021-12-13 01:56:22,080 iteration 6626 : loss : 0.015137, loss_ce: 0.006140
2021-12-13 01:56:23,575 iteration 6627 : loss : 0.016326, loss_ce: 0.005365
2021-12-13 01:56:25,064 iteration 6628 : loss : 0.020297, loss_ce: 0.008480
2021-12-13 01:56:26,625 iteration 6629 : loss : 0.013035, loss_ce: 0.003700
2021-12-13 01:56:26,626 Training Data Eval:
2021-12-13 01:56:34,045   Average segmentation loss on training set: 0.0061
2021-12-13 01:56:34,045 Validation Data Eval:
2021-12-13 01:56:36,642   Average segmentation loss on validation set: 0.0748
2021-12-13 01:56:38,079 iteration 6630 : loss : 0.012930, loss_ce: 0.005180
 98%|████████████████████████████▎| 390/400 [2:54:47<04:43, 28.31s/it]2021-12-13 01:56:39,557 iteration 6631 : loss : 0.015667, loss_ce: 0.005027
2021-12-13 01:56:40,976 iteration 6632 : loss : 0.010419, loss_ce: 0.005004
2021-12-13 01:56:42,464 iteration 6633 : loss : 0.017958, loss_ce: 0.004632
2021-12-13 01:56:43,898 iteration 6634 : loss : 0.011370, loss_ce: 0.004396
2021-12-13 01:56:45,350 iteration 6635 : loss : 0.010781, loss_ce: 0.004209
2021-12-13 01:56:46,796 iteration 6636 : loss : 0.009484, loss_ce: 0.004588
2021-12-13 01:56:48,203 iteration 6637 : loss : 0.012940, loss_ce: 0.004294
2021-12-13 01:56:49,704 iteration 6638 : loss : 0.024232, loss_ce: 0.007213
2021-12-13 01:56:51,195 iteration 6639 : loss : 0.012346, loss_ce: 0.004736
2021-12-13 01:56:52,621 iteration 6640 : loss : 0.012517, loss_ce: 0.004139
2021-12-13 01:56:54,081 iteration 6641 : loss : 0.015216, loss_ce: 0.007252
2021-12-13 01:56:55,544 iteration 6642 : loss : 0.013067, loss_ce: 0.005488
2021-12-13 01:56:57,003 iteration 6643 : loss : 0.011211, loss_ce: 0.003865
2021-12-13 01:56:58,563 iteration 6644 : loss : 0.016167, loss_ce: 0.005715
2021-12-13 01:56:59,976 iteration 6645 : loss : 0.009701, loss_ce: 0.004123
2021-12-13 01:57:01,519 iteration 6646 : loss : 0.018056, loss_ce: 0.005534
2021-12-13 01:57:02,944 iteration 6647 : loss : 0.019286, loss_ce: 0.006722
 98%|████████████████████████████▎| 391/400 [2:55:12<04:05, 27.28s/it]2021-12-13 01:57:04,401 iteration 6648 : loss : 0.014417, loss_ce: 0.003464
2021-12-13 01:57:05,876 iteration 6649 : loss : 0.011602, loss_ce: 0.003660
2021-12-13 01:57:07,395 iteration 6650 : loss : 0.018605, loss_ce: 0.007093
2021-12-13 01:57:08,943 iteration 6651 : loss : 0.017501, loss_ce: 0.008077
2021-12-13 01:57:10,380 iteration 6652 : loss : 0.012753, loss_ce: 0.006087
2021-12-13 01:57:11,756 iteration 6653 : loss : 0.008211, loss_ce: 0.003325
2021-12-13 01:57:13,196 iteration 6654 : loss : 0.013640, loss_ce: 0.005607
2021-12-13 01:57:14,682 iteration 6655 : loss : 0.014584, loss_ce: 0.005906
2021-12-13 01:57:16,150 iteration 6656 : loss : 0.017698, loss_ce: 0.007237
2021-12-13 01:57:17,609 iteration 6657 : loss : 0.010107, loss_ce: 0.002946
2021-12-13 01:57:19,093 iteration 6658 : loss : 0.010248, loss_ce: 0.003724
2021-12-13 01:57:20,550 iteration 6659 : loss : 0.019347, loss_ce: 0.010037
2021-12-13 01:57:22,061 iteration 6660 : loss : 0.016119, loss_ce: 0.006476
2021-12-13 01:57:23,538 iteration 6661 : loss : 0.018338, loss_ce: 0.006846
2021-12-13 01:57:25,025 iteration 6662 : loss : 0.016414, loss_ce: 0.004376
2021-12-13 01:57:26,488 iteration 6663 : loss : 0.014335, loss_ce: 0.005209
2021-12-13 01:57:27,982 iteration 6664 : loss : 0.019301, loss_ce: 0.011245
 98%|████████████████████████████▍| 392/400 [2:55:37<03:32, 26.61s/it]2021-12-13 01:57:29,492 iteration 6665 : loss : 0.014457, loss_ce: 0.004435
2021-12-13 01:57:31,040 iteration 6666 : loss : 0.024182, loss_ce: 0.007939
2021-12-13 01:57:32,510 iteration 6667 : loss : 0.015852, loss_ce: 0.002783
2021-12-13 01:57:33,885 iteration 6668 : loss : 0.009896, loss_ce: 0.004670
2021-12-13 01:57:35,325 iteration 6669 : loss : 0.013959, loss_ce: 0.005278
2021-12-13 01:57:36,765 iteration 6670 : loss : 0.011958, loss_ce: 0.005850
2021-12-13 01:57:38,241 iteration 6671 : loss : 0.013293, loss_ce: 0.004907
2021-12-13 01:57:39,734 iteration 6672 : loss : 0.012613, loss_ce: 0.003795
2021-12-13 01:57:41,179 iteration 6673 : loss : 0.014560, loss_ce: 0.003339
2021-12-13 01:57:42,623 iteration 6674 : loss : 0.012438, loss_ce: 0.005706
2021-12-13 01:57:44,148 iteration 6675 : loss : 0.020130, loss_ce: 0.010976
2021-12-13 01:57:45,562 iteration 6676 : loss : 0.011124, loss_ce: 0.004218
2021-12-13 01:57:46,962 iteration 6677 : loss : 0.019081, loss_ce: 0.009814
2021-12-13 01:57:48,449 iteration 6678 : loss : 0.012006, loss_ce: 0.005645
2021-12-13 01:57:49,954 iteration 6679 : loss : 0.011723, loss_ce: 0.004615
2021-12-13 01:57:51,347 iteration 6680 : loss : 0.008460, loss_ce: 0.002966
2021-12-13 01:57:52,720 iteration 6681 : loss : 0.008260, loss_ce: 0.002751
 98%|████████████████████████████▍| 393/400 [2:56:01<03:02, 26.05s/it]2021-12-13 01:57:54,294 iteration 6682 : loss : 0.015371, loss_ce: 0.008048
2021-12-13 01:57:55,715 iteration 6683 : loss : 0.011390, loss_ce: 0.004441
2021-12-13 01:57:57,168 iteration 6684 : loss : 0.009786, loss_ce: 0.004356
2021-12-13 01:57:58,574 iteration 6685 : loss : 0.017449, loss_ce: 0.006008
2021-12-13 01:58:00,087 iteration 6686 : loss : 0.013606, loss_ce: 0.006213
2021-12-13 01:58:01,529 iteration 6687 : loss : 0.012446, loss_ce: 0.004514
2021-12-13 01:58:02,981 iteration 6688 : loss : 0.014094, loss_ce: 0.005173
2021-12-13 01:58:04,367 iteration 6689 : loss : 0.010435, loss_ce: 0.003314
2021-12-13 01:58:05,817 iteration 6690 : loss : 0.006965, loss_ce: 0.002024
2021-12-13 01:58:07,297 iteration 6691 : loss : 0.016780, loss_ce: 0.005528
2021-12-13 01:58:08,697 iteration 6692 : loss : 0.013045, loss_ce: 0.004704
2021-12-13 01:58:10,128 iteration 6693 : loss : 0.014761, loss_ce: 0.005349
2021-12-13 01:58:11,595 iteration 6694 : loss : 0.013732, loss_ce: 0.004290
2021-12-13 01:58:13,017 iteration 6695 : loss : 0.011568, loss_ce: 0.003942
2021-12-13 01:58:14,470 iteration 6696 : loss : 0.009654, loss_ce: 0.003571
2021-12-13 01:58:15,896 iteration 6697 : loss : 0.011766, loss_ce: 0.004272
2021-12-13 01:58:17,410 iteration 6698 : loss : 0.014573, loss_ce: 0.004816
 98%|████████████████████████████▌| 394/400 [2:56:26<02:33, 25.64s/it]2021-12-13 01:58:18,876 iteration 6699 : loss : 0.012164, loss_ce: 0.004156
2021-12-13 01:58:20,382 iteration 6700 : loss : 0.015548, loss_ce: 0.005228
2021-12-13 01:58:21,810 iteration 6701 : loss : 0.009051, loss_ce: 0.003265
2021-12-13 01:58:23,186 iteration 6702 : loss : 0.009248, loss_ce: 0.004349
2021-12-13 01:58:24,576 iteration 6703 : loss : 0.009369, loss_ce: 0.003118
2021-12-13 01:58:26,054 iteration 6704 : loss : 0.015699, loss_ce: 0.007892
2021-12-13 01:58:27,446 iteration 6705 : loss : 0.012222, loss_ce: 0.005752
2021-12-13 01:58:28,955 iteration 6706 : loss : 0.011354, loss_ce: 0.003507
2021-12-13 01:58:30,340 iteration 6707 : loss : 0.007698, loss_ce: 0.002921
2021-12-13 01:58:31,794 iteration 6708 : loss : 0.013166, loss_ce: 0.004720
2021-12-13 01:58:33,255 iteration 6709 : loss : 0.013422, loss_ce: 0.005652
2021-12-13 01:58:34,735 iteration 6710 : loss : 0.014895, loss_ce: 0.003489
2021-12-13 01:58:36,206 iteration 6711 : loss : 0.012672, loss_ce: 0.004025
2021-12-13 01:58:37,732 iteration 6712 : loss : 0.014224, loss_ce: 0.005196
2021-12-13 01:58:39,124 iteration 6713 : loss : 0.009503, loss_ce: 0.003681
2021-12-13 01:58:40,590 iteration 6714 : loss : 0.011306, loss_ce: 0.003824
2021-12-13 01:58:40,590 Training Data Eval:
2021-12-13 01:58:48,024   Average segmentation loss on training set: 0.0061
2021-12-13 01:58:48,024 Validation Data Eval:
2021-12-13 01:58:50,608   Average segmentation loss on validation set: 0.0680
2021-12-13 01:58:52,034 iteration 6715 : loss : 0.011546, loss_ce: 0.004287
 99%|████████████████████████████▋| 395/400 [2:57:01<02:21, 28.33s/it]2021-12-13 01:58:53,520 iteration 6716 : loss : 0.012117, loss_ce: 0.005382
2021-12-13 01:58:54,955 iteration 6717 : loss : 0.009406, loss_ce: 0.003813
2021-12-13 01:58:56,412 iteration 6718 : loss : 0.010887, loss_ce: 0.003986
2021-12-13 01:58:57,838 iteration 6719 : loss : 0.010518, loss_ce: 0.003844
2021-12-13 01:58:59,260 iteration 6720 : loss : 0.008807, loss_ce: 0.002409
2021-12-13 01:59:00,668 iteration 6721 : loss : 0.010730, loss_ce: 0.003445
2021-12-13 01:59:02,197 iteration 6722 : loss : 0.011727, loss_ce: 0.004486
2021-12-13 01:59:03,558 iteration 6723 : loss : 0.010128, loss_ce: 0.002962
2021-12-13 01:59:05,006 iteration 6724 : loss : 0.015276, loss_ce: 0.004474
2021-12-13 01:59:06,482 iteration 6725 : loss : 0.009395, loss_ce: 0.003247
2021-12-13 01:59:07,964 iteration 6726 : loss : 0.014842, loss_ce: 0.006424
2021-12-13 01:59:09,492 iteration 6727 : loss : 0.014072, loss_ce: 0.004573
2021-12-13 01:59:10,928 iteration 6728 : loss : 0.018197, loss_ce: 0.006271
2021-12-13 01:59:12,371 iteration 6729 : loss : 0.011264, loss_ce: 0.003362
2021-12-13 01:59:13,775 iteration 6730 : loss : 0.008283, loss_ce: 0.002984
2021-12-13 01:59:15,230 iteration 6731 : loss : 0.010762, loss_ce: 0.004312
2021-12-13 01:59:16,713 iteration 6732 : loss : 0.012581, loss_ce: 0.004905
 99%|████████████████████████████▋| 396/400 [2:57:25<01:48, 27.24s/it]2021-12-13 01:59:18,191 iteration 6733 : loss : 0.008786, loss_ce: 0.003073
2021-12-13 01:59:19,731 iteration 6734 : loss : 0.017793, loss_ce: 0.006427
2021-12-13 01:59:21,141 iteration 6735 : loss : 0.008587, loss_ce: 0.003336
2021-12-13 01:59:22,635 iteration 6736 : loss : 0.014627, loss_ce: 0.006432
2021-12-13 01:59:24,124 iteration 6737 : loss : 0.015290, loss_ce: 0.005405
2021-12-13 01:59:25,483 iteration 6738 : loss : 0.008893, loss_ce: 0.002531
2021-12-13 01:59:26,899 iteration 6739 : loss : 0.009869, loss_ce: 0.003564
2021-12-13 01:59:28,377 iteration 6740 : loss : 0.012264, loss_ce: 0.005393
2021-12-13 01:59:29,807 iteration 6741 : loss : 0.009684, loss_ce: 0.003278
2021-12-13 01:59:31,220 iteration 6742 : loss : 0.010479, loss_ce: 0.003136
2021-12-13 01:59:32,696 iteration 6743 : loss : 0.011659, loss_ce: 0.005130
2021-12-13 01:59:34,174 iteration 6744 : loss : 0.017018, loss_ce: 0.006521
2021-12-13 01:59:35,576 iteration 6745 : loss : 0.010882, loss_ce: 0.004260
2021-12-13 01:59:37,035 iteration 6746 : loss : 0.013218, loss_ce: 0.005267
2021-12-13 01:59:38,541 iteration 6747 : loss : 0.014415, loss_ce: 0.003521
2021-12-13 01:59:40,033 iteration 6748 : loss : 0.017025, loss_ce: 0.005779
2021-12-13 01:59:41,484 iteration 6749 : loss : 0.009896, loss_ce: 0.003976
 99%|████████████████████████████▊| 397/400 [2:57:50<01:19, 26.50s/it]2021-12-13 01:59:43,000 iteration 6750 : loss : 0.009442, loss_ce: 0.003365
2021-12-13 01:59:44,539 iteration 6751 : loss : 0.015156, loss_ce: 0.005881
2021-12-13 01:59:46,042 iteration 6752 : loss : 0.016824, loss_ce: 0.008221
2021-12-13 01:59:47,464 iteration 6753 : loss : 0.014589, loss_ce: 0.005021
2021-12-13 01:59:48,975 iteration 6754 : loss : 0.012727, loss_ce: 0.005160
2021-12-13 01:59:50,391 iteration 6755 : loss : 0.015468, loss_ce: 0.005204
2021-12-13 01:59:51,739 iteration 6756 : loss : 0.007789, loss_ce: 0.003400
2021-12-13 01:59:53,132 iteration 6757 : loss : 0.009863, loss_ce: 0.003942
2021-12-13 01:59:54,555 iteration 6758 : loss : 0.009764, loss_ce: 0.004629
2021-12-13 01:59:56,027 iteration 6759 : loss : 0.015950, loss_ce: 0.004518
2021-12-13 01:59:57,442 iteration 6760 : loss : 0.009673, loss_ce: 0.003910
2021-12-13 01:59:58,867 iteration 6761 : loss : 0.013021, loss_ce: 0.004716
2021-12-13 02:00:00,325 iteration 6762 : loss : 0.012416, loss_ce: 0.003901
2021-12-13 02:00:01,770 iteration 6763 : loss : 0.010788, loss_ce: 0.005098
2021-12-13 02:00:03,279 iteration 6764 : loss : 0.011994, loss_ce: 0.003907
2021-12-13 02:00:04,748 iteration 6765 : loss : 0.017964, loss_ce: 0.004921
2021-12-13 02:00:06,182 iteration 6766 : loss : 0.011705, loss_ce: 0.005881
100%|████████████████████████████▊| 398/400 [2:58:15<00:51, 25.96s/it]2021-12-13 02:00:07,720 iteration 6767 : loss : 0.020460, loss_ce: 0.008448
2021-12-13 02:00:09,129 iteration 6768 : loss : 0.013826, loss_ce: 0.004498
2021-12-13 02:00:10,553 iteration 6769 : loss : 0.008932, loss_ce: 0.002861
2021-12-13 02:00:12,017 iteration 6770 : loss : 0.018329, loss_ce: 0.005056
2021-12-13 02:00:13,440 iteration 6771 : loss : 0.012918, loss_ce: 0.005640
2021-12-13 02:00:14,883 iteration 6772 : loss : 0.010597, loss_ce: 0.004548
2021-12-13 02:00:16,265 iteration 6773 : loss : 0.008152, loss_ce: 0.003090
2021-12-13 02:00:17,707 iteration 6774 : loss : 0.015069, loss_ce: 0.005448
2021-12-13 02:00:19,126 iteration 6775 : loss : 0.014238, loss_ce: 0.002626
2021-12-13 02:00:20,563 iteration 6776 : loss : 0.013576, loss_ce: 0.004905
2021-12-13 02:00:22,003 iteration 6777 : loss : 0.015274, loss_ce: 0.006466
2021-12-13 02:00:23,392 iteration 6778 : loss : 0.011058, loss_ce: 0.004062
2021-12-13 02:00:24,815 iteration 6779 : loss : 0.008581, loss_ce: 0.004147
2021-12-13 02:00:26,294 iteration 6780 : loss : 0.011558, loss_ce: 0.004415
2021-12-13 02:00:27,750 iteration 6781 : loss : 0.010658, loss_ce: 0.004179
2021-12-13 02:00:29,163 iteration 6782 : loss : 0.010239, loss_ce: 0.003964
2021-12-13 02:00:30,646 iteration 6783 : loss : 0.015886, loss_ce: 0.005090
100%|████████████████████████████▉| 399/400 [2:58:39<00:25, 25.51s/it]2021-12-13 02:00:32,051 iteration 6784 : loss : 0.011586, loss_ce: 0.005934
2021-12-13 02:00:33,469 iteration 6785 : loss : 0.011201, loss_ce: 0.003187
2021-12-13 02:00:34,942 iteration 6786 : loss : 0.012226, loss_ce: 0.004597
2021-12-13 02:00:36,377 iteration 6787 : loss : 0.016853, loss_ce: 0.004535
2021-12-13 02:00:37,813 iteration 6788 : loss : 0.011353, loss_ce: 0.005487
2021-12-13 02:00:39,320 iteration 6789 : loss : 0.020703, loss_ce: 0.006029
2021-12-13 02:00:40,759 iteration 6790 : loss : 0.014974, loss_ce: 0.006501
2021-12-13 02:00:42,250 iteration 6791 : loss : 0.020162, loss_ce: 0.006752
2021-12-13 02:00:43,671 iteration 6792 : loss : 0.011164, loss_ce: 0.004724
2021-12-13 02:00:45,031 iteration 6793 : loss : 0.009089, loss_ce: 0.003356
2021-12-13 02:00:46,497 iteration 6794 : loss : 0.013697, loss_ce: 0.004716
2021-12-13 02:00:47,885 iteration 6795 : loss : 0.010087, loss_ce: 0.003987
2021-12-13 02:00:49,309 iteration 6796 : loss : 0.010709, loss_ce: 0.002941
2021-12-13 02:00:50,718 iteration 6797 : loss : 0.010342, loss_ce: 0.003427
2021-12-13 02:00:52,192 iteration 6798 : loss : 0.011293, loss_ce: 0.003485
2021-12-13 02:00:53,609 iteration 6799 : loss : 0.012902, loss_ce: 0.004370
2021-12-13 02:00:53,609 Training Data Eval:
2021-12-13 02:01:01,039   Average segmentation loss on training set: 0.0058
2021-12-13 02:01:01,040 Validation Data Eval:
2021-12-13 02:01:03,601   Average segmentation loss on validation set: 0.0756
2021-12-13 02:01:05,033 iteration 6800 : loss : 0.015463, loss_ce: 0.006859
100%|█████████████████████████████| 400/400 [2:59:14<00:00, 28.17s/it]100%|█████████████████████████████| 400/400 [2:59:14<00:00, 26.89s/it]
